diff --git a/include/LLVMSPIRVLib.h b/include/LLVMSPIRVLib.h
index 261b5d4..d122900 100644
--- a/include/LLVMSPIRVLib.h
+++ b/include/LLVMSPIRVLib.h
@@ -42,6 +42,7 @@
 #define SPIRV_H
 
 #include "LLVMSPIRVOpts.h"
+#include "llvm/../../projects/spirv/lib/SPIRV/libSPIRV/SPIRVUtil.h"
 
 #include <iostream>
 #include <string>
@@ -51,6 +52,7 @@ namespace llvm {
 // PassSupport.h.
 class PassRegistry;
 void initializeLLVMToSPIRVLegacyPass(PassRegistry &);
+void initializeLLVMToSPIRVTransformationsPass(PassRegistry&);
 void initializeOCLToSPIRVLegacyPass(PassRegistry &);
 void initializeOCLTypeToSPIRVLegacyPass(PassRegistry &);
 void initializeSPIRVLowerBoolLegacyPass(PassRegistry &);
@@ -83,7 +85,7 @@ bool isSpirvBinary(const std::string &Img);
 /// This function is not thread safe and should not be used in multi-thread
 /// applications unless guarded by a critical section.
 /// \returns true if succeeds.
-bool convertSpirv(std::istream &IS, std::ostream &OS, std::string &ErrMsg,
+bool convertSpirv(std::istream &IS, spv_ostream &OS, std::string &ErrMsg,
                   bool FromText, bool ToText);
 
 /// \brief Convert SPIR-V between binary and internal text formats.
@@ -113,7 +115,7 @@ namespace llvm {
 
 /// \brief Translate LLVM module to SPIR-V and write to ostream.
 /// \returns true if succeeds.
-bool writeSpirv(Module *M, std::ostream &OS, std::string &ErrMsg);
+bool writeSpirv(Module *M, spv_ostream &OS, std::string &ErrMsg);
 
 /// \brief Load SPIR-V from istream and translate to LLVM module.
 /// \returns true if succeeds.
@@ -122,7 +124,7 @@ bool readSpirv(LLVMContext &C, std::istream &IS, Module *&M,
 
 /// \brief Translate LLVM module to SPIR-V and write to ostream.
 /// \returns true if succeeds.
-bool writeSpirv(Module *M, const SPIRV::TranslatorOpts &Opts, std::ostream &OS,
+bool writeSpirv(Module *M, const SPIRV::TranslatorOpts &Opts, spv_ostream &OS,
                 std::string &ErrMsg);
 
 /// \brief Load SPIR-V from istream and translate to LLVM module.
@@ -163,6 +165,10 @@ void mangleOpenClBuiltin(const std::string &UnmangledName,
 /// Create a pass for translating LLVM to SPIR-V.
 ModulePass *createLLVMToSPIRVLegacy(SPIRV::SPIRVModule *);
 
+/// Create a pass that transforms certain IR to constructs that are better, or
+/// more easily, representable in SPIR-V.
+ModulePass *createLLVMToSPIRVTransformations();
+
 /// Create a pass for translating OCL C builtin functions to SPIR-V builtin
 /// functions.
 ModulePass *createOCLToSPIRVLegacy();
diff --git a/include/LLVMSPIRVOpts.h b/include/LLVMSPIRVOpts.h
index 8c73b64..ddea616 100644
--- a/include/LLVMSPIRVOpts.h
+++ b/include/LLVMSPIRVOpts.h
@@ -62,10 +62,10 @@ enum class VersionNumber : uint32_t {
   SPIRV_1_2 = 0x00010200,
   SPIRV_1_3 = 0x00010300,
   SPIRV_1_4 = 0x00010400,
-  // TODO: populate this enum with the latest versions (up to 1.5) once
+  SPIRV_1_5 = 0x00010500,
   // translator get support of corresponding features
   MinimumVersion = SPIRV_1_0,
-  MaximumVersion = SPIRV_1_4
+  MaximumVersion = SPIRV_1_5
 };
 
 enum class ExtensionID : uint32_t {
@@ -183,7 +183,7 @@ public:
 
 private:
   // Common translation options
-  VersionNumber MaxVersion = VersionNumber::MaximumVersion;
+  VersionNumber MaxVersion = VersionNumber::SPIRV_1_0;
   ExtensionsStatusMap ExtStatusMap;
   // SPIRVMemToReg option affects LLVM IR regularization phase
   bool SPIRVMemToReg = false;
diff --git a/include/spirv/unified1/spirv.hpp b/include/spirv/unified1/spirv.hpp
new file mode 100644
index 0000000..83356b6
--- /dev/null
+++ b/include/spirv/unified1/spirv.hpp
@@ -0,0 +1,2490 @@
+// Copyright (c) 2014-2020 The Khronos Group Inc.
+// 
+// Permission is hereby granted, free of charge, to any person obtaining a copy
+// of this software and/or associated documentation files (the "Materials"),
+// to deal in the Materials without restriction, including without limitation
+// the rights to use, copy, modify, merge, publish, distribute, sublicense,
+// and/or sell copies of the Materials, and to permit persons to whom the
+// Materials are furnished to do so, subject to the following conditions:
+// 
+// The above copyright notice and this permission notice shall be included in
+// all copies or substantial portions of the Materials.
+// 
+// MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
+// STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
+// HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/ 
+// 
+// THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+// FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
+// IN THE MATERIALS.
+
+// This header is automatically generated by the same tool that creates
+// the Binary Section of the SPIR-V specification.
+
+// Enumeration tokens for SPIR-V, in various styles:
+//   C, C++, C++11, JSON, Lua, Python, C#, D
+// 
+// - C will have tokens with a "Spv" prefix, e.g.: SpvSourceLanguageGLSL
+// - C++ will have tokens in the "spv" name space, e.g.: spv::SourceLanguageGLSL
+// - C++11 will use enum classes in the spv namespace, e.g.: spv::SourceLanguage::GLSL
+// - Lua will use tables, e.g.: spv.SourceLanguage.GLSL
+// - Python will use dictionaries, e.g.: spv['SourceLanguage']['GLSL']
+// - C# will use enum classes in the Specification class located in the "Spv" namespace,
+//     e.g.: Spv.Specification.SourceLanguage.GLSL
+// - D will have tokens under the "spv" module, e.g: spv.SourceLanguage.GLSL
+// 
+// Some tokens act like mask values, which can be OR'd together,
+// while others are mutually exclusive.  The mask-like ones have
+// "Mask" in their name, and a parallel enum that has the shift
+// amount (1 << x) for each corresponding enumerant.
+
+#ifndef spirv_HPP
+#define spirv_HPP
+
+namespace spv {
+
+typedef unsigned int Id;
+
+#define SPV_VERSION 0x10500
+#define SPV_REVISION 4
+
+static const unsigned int MagicNumber = 0x07230203;
+static const unsigned int Version = 0x00010500;
+static const unsigned int Revision = 4;
+static const unsigned int OpCodeMask = 0xffff;
+static const unsigned int WordCountShift = 16;
+
+enum SourceLanguage {
+    SourceLanguageUnknown = 0,
+    SourceLanguageESSL = 1,
+    SourceLanguageGLSL = 2,
+    SourceLanguageOpenCL_C = 3,
+    SourceLanguageOpenCL_CPP = 4,
+    SourceLanguageHLSL = 5,
+    SourceLanguageCPP_for_OpenCL = 6,
+    SourceLanguageMax = 0x7fffffff,
+};
+
+enum ExecutionModel {
+    ExecutionModelVertex = 0,
+    ExecutionModelTessellationControl = 1,
+    ExecutionModelTessellationEvaluation = 2,
+    ExecutionModelGeometry = 3,
+    ExecutionModelFragment = 4,
+    ExecutionModelGLCompute = 5,
+    ExecutionModelKernel = 6,
+    ExecutionModelTaskNV = 5267,
+    ExecutionModelMeshNV = 5268,
+    ExecutionModelRayGenerationKHR = 5313,
+    ExecutionModelRayGenerationNV = 5313,
+    ExecutionModelIntersectionKHR = 5314,
+    ExecutionModelIntersectionNV = 5314,
+    ExecutionModelAnyHitKHR = 5315,
+    ExecutionModelAnyHitNV = 5315,
+    ExecutionModelClosestHitKHR = 5316,
+    ExecutionModelClosestHitNV = 5316,
+    ExecutionModelMissKHR = 5317,
+    ExecutionModelMissNV = 5317,
+    ExecutionModelCallableKHR = 5318,
+    ExecutionModelCallableNV = 5318,
+    ExecutionModelMax = 0x7fffffff,
+    ExecutionModelInvalid = ExecutionModelMax,
+};
+
+enum AddressingModel {
+    AddressingModelLogical = 0,
+    AddressingModelPhysical32 = 1,
+    AddressingModelPhysical64 = 2,
+    AddressingModelPhysicalStorageBuffer64 = 5348,
+    AddressingModelPhysicalStorageBuffer64EXT = 5348,
+    AddressingModelMax = 0x7fffffff,
+};
+
+enum MemoryModel {
+    MemoryModelSimple = 0,
+    MemoryModelGLSL450 = 1,
+    MemoryModelOpenCL = 2,
+    MemoryModelVulkan = 3,
+    MemoryModelVulkanKHR = 3,
+    MemoryModelMax = 0x7fffffff,
+};
+
+enum ExecutionMode {
+    ExecutionModeInvocations = 0,
+    ExecutionModeSpacingEqual = 1,
+    ExecutionModeSpacingFractionalEven = 2,
+    ExecutionModeSpacingFractionalOdd = 3,
+    ExecutionModeVertexOrderCw = 4,
+    ExecutionModeVertexOrderCcw = 5,
+    ExecutionModePixelCenterInteger = 6,
+    ExecutionModeOriginUpperLeft = 7,
+    ExecutionModeOriginLowerLeft = 8,
+    ExecutionModeEarlyFragmentTests = 9,
+    ExecutionModePointMode = 10,
+    ExecutionModeXfb = 11,
+    ExecutionModeDepthReplacing = 12,
+    ExecutionModeDepthGreater = 14,
+    ExecutionModeDepthLess = 15,
+    ExecutionModeDepthUnchanged = 16,
+    ExecutionModeLocalSize = 17,
+    ExecutionModeLocalSizeHint = 18,
+    ExecutionModeInputPoints = 19,
+    ExecutionModeInputLines = 20,
+    ExecutionModeInputLinesAdjacency = 21,
+    ExecutionModeTriangles = 22,
+    ExecutionModeInputTrianglesAdjacency = 23,
+    ExecutionModeQuads = 24,
+    ExecutionModeIsolines = 25,
+    ExecutionModeOutputVertices = 26,
+    ExecutionModeOutputPoints = 27,
+    ExecutionModeOutputLineStrip = 28,
+    ExecutionModeOutputTriangleStrip = 29,
+    ExecutionModeVecTypeHint = 30,
+    ExecutionModeContractionOff = 31,
+    ExecutionModeInitializer = 33,
+    ExecutionModeFinalizer = 34,
+    ExecutionModeSubgroupSize = 35,
+    ExecutionModeSubgroupsPerWorkgroup = 36,
+    ExecutionModeSubgroupsPerWorkgroupId = 37,
+    ExecutionModeLocalSizeId = 38,
+    ExecutionModeLocalSizeHintId = 39,
+    ExecutionModeSubgroupUniformControlFlowKHR = 4421,
+    ExecutionModePostDepthCoverage = 4446,
+    ExecutionModeDenormPreserve = 4459,
+    ExecutionModeDenormFlushToZero = 4460,
+    ExecutionModeSignedZeroInfNanPreserve = 4461,
+    ExecutionModeRoundingModeRTE = 4462,
+    ExecutionModeRoundingModeRTZ = 4463,
+    ExecutionModeStencilRefReplacingEXT = 5027,
+    ExecutionModeOutputLinesNV = 5269,
+    ExecutionModeOutputPrimitivesNV = 5270,
+    ExecutionModeDerivativeGroupQuadsNV = 5289,
+    ExecutionModeDerivativeGroupLinearNV = 5290,
+    ExecutionModeOutputTrianglesNV = 5298,
+    ExecutionModePixelInterlockOrderedEXT = 5366,
+    ExecutionModePixelInterlockUnorderedEXT = 5367,
+    ExecutionModeSampleInterlockOrderedEXT = 5368,
+    ExecutionModeSampleInterlockUnorderedEXT = 5369,
+    ExecutionModeShadingRateInterlockOrderedEXT = 5370,
+    ExecutionModeShadingRateInterlockUnorderedEXT = 5371,
+    ExecutionModeSharedLocalMemorySizeINTEL = 5618,
+    ExecutionModeRoundingModeRTPINTEL = 5620,
+    ExecutionModeRoundingModeRTNINTEL = 5621,
+    ExecutionModeFloatingPointModeALTINTEL = 5622,
+    ExecutionModeFloatingPointModeIEEEINTEL = 5623,
+    ExecutionModeMaxWorkgroupSizeINTEL = 5893,
+    ExecutionModeMaxWorkDimINTEL = 5894,
+    ExecutionModeNoGlobalOffsetINTEL = 5895,
+    ExecutionModeNumSIMDWorkitemsINTEL = 5896,
+    ExecutionModeSchedulerTargetFmaxMhzINTEL = 5903,
+    ExecutionModeMax = 0x7fffffff,
+};
+
+enum StorageClass {
+    StorageClassUniformConstant = 0,
+    StorageClassInput = 1,
+    StorageClassUniform = 2,
+    StorageClassOutput = 3,
+    StorageClassWorkgroup = 4,
+    StorageClassCrossWorkgroup = 5,
+    StorageClassPrivate = 6,
+    StorageClassFunction = 7,
+    StorageClassGeneric = 8,
+    StorageClassPushConstant = 9,
+    StorageClassAtomicCounter = 10,
+    StorageClassImage = 11,
+    StorageClassStorageBuffer = 12,
+    StorageClassCallableDataKHR = 5328,
+    StorageClassCallableDataNV = 5328,
+    StorageClassIncomingCallableDataKHR = 5329,
+    StorageClassIncomingCallableDataNV = 5329,
+    StorageClassRayPayloadKHR = 5338,
+    StorageClassRayPayloadNV = 5338,
+    StorageClassHitAttributeKHR = 5339,
+    StorageClassHitAttributeNV = 5339,
+    StorageClassIncomingRayPayloadKHR = 5342,
+    StorageClassIncomingRayPayloadNV = 5342,
+    StorageClassShaderRecordBufferKHR = 5343,
+    StorageClassShaderRecordBufferNV = 5343,
+    StorageClassPhysicalStorageBuffer = 5349,
+    StorageClassPhysicalStorageBufferEXT = 5349,
+    StorageClassCodeSectionINTEL = 5605,
+    StorageClassDeviceOnlyINTEL = 5936,
+    StorageClassHostOnlyINTEL = 5937,
+    StorageClassMax = 0x7fffffff,
+};
+
+enum Dim {
+    Dim1D = 0,
+    Dim2D = 1,
+    Dim3D = 2,
+    DimCube = 3,
+    DimRect = 4,
+    DimBuffer = 5,
+    DimSubpassData = 6,
+    DimMax,
+};
+
+enum SamplerAddressingMode {
+    SamplerAddressingModeNone = 0,
+    SamplerAddressingModeClampToEdge = 1,
+    SamplerAddressingModeClamp = 2,
+    SamplerAddressingModeRepeat = 3,
+    SamplerAddressingModeRepeatMirrored = 4,
+    SamplerAddressingModeMax = 0x7fffffff,
+};
+
+enum SamplerFilterMode {
+    SamplerFilterModeNearest = 0,
+    SamplerFilterModeLinear = 1,
+    SamplerFilterModeMax = 0x7fffffff,
+};
+
+enum ImageFormat {
+    ImageFormatUnknown = 0,
+    ImageFormatRgba32f = 1,
+    ImageFormatRgba16f = 2,
+    ImageFormatR32f = 3,
+    ImageFormatRgba8 = 4,
+    ImageFormatRgba8Snorm = 5,
+    ImageFormatRg32f = 6,
+    ImageFormatRg16f = 7,
+    ImageFormatR11fG11fB10f = 8,
+    ImageFormatR16f = 9,
+    ImageFormatRgba16 = 10,
+    ImageFormatRgb10A2 = 11,
+    ImageFormatRg16 = 12,
+    ImageFormatRg8 = 13,
+    ImageFormatR16 = 14,
+    ImageFormatR8 = 15,
+    ImageFormatRgba16Snorm = 16,
+    ImageFormatRg16Snorm = 17,
+    ImageFormatRg8Snorm = 18,
+    ImageFormatR16Snorm = 19,
+    ImageFormatR8Snorm = 20,
+    ImageFormatRgba32i = 21,
+    ImageFormatRgba16i = 22,
+    ImageFormatRgba8i = 23,
+    ImageFormatR32i = 24,
+    ImageFormatRg32i = 25,
+    ImageFormatRg16i = 26,
+    ImageFormatRg8i = 27,
+    ImageFormatR16i = 28,
+    ImageFormatR8i = 29,
+    ImageFormatRgba32ui = 30,
+    ImageFormatRgba16ui = 31,
+    ImageFormatRgba8ui = 32,
+    ImageFormatR32ui = 33,
+    ImageFormatRgb10a2ui = 34,
+    ImageFormatRg32ui = 35,
+    ImageFormatRg16ui = 36,
+    ImageFormatRg8ui = 37,
+    ImageFormatR16ui = 38,
+    ImageFormatR8ui = 39,
+    ImageFormatR64ui = 40,
+    ImageFormatR64i = 41,
+    ImageFormatMax,
+};
+
+enum ImageChannelOrder {
+    ImageChannelOrderR = 0,
+    ImageChannelOrderA = 1,
+    ImageChannelOrderRG = 2,
+    ImageChannelOrderRA = 3,
+    ImageChannelOrderRGB = 4,
+    ImageChannelOrderRGBA = 5,
+    ImageChannelOrderBGRA = 6,
+    ImageChannelOrderARGB = 7,
+    ImageChannelOrderIntensity = 8,
+    ImageChannelOrderLuminance = 9,
+    ImageChannelOrderRx = 10,
+    ImageChannelOrderRGx = 11,
+    ImageChannelOrderRGBx = 12,
+    ImageChannelOrderDepth = 13,
+    ImageChannelOrderDepthStencil = 14,
+    ImageChannelOrdersRGB = 15,
+    ImageChannelOrdersRGBx = 16,
+    ImageChannelOrdersRGBA = 17,
+    ImageChannelOrdersBGRA = 18,
+    ImageChannelOrderABGR = 19,
+    ImageChannelOrderMax = 0x7fffffff,
+};
+
+enum ImageChannelDataType {
+    ImageChannelDataTypeSnormInt8 = 0,
+    ImageChannelDataTypeSnormInt16 = 1,
+    ImageChannelDataTypeUnormInt8 = 2,
+    ImageChannelDataTypeUnormInt16 = 3,
+    ImageChannelDataTypeUnormShort565 = 4,
+    ImageChannelDataTypeUnormShort555 = 5,
+    ImageChannelDataTypeUnormInt101010 = 6,
+    ImageChannelDataTypeSignedInt8 = 7,
+    ImageChannelDataTypeSignedInt16 = 8,
+    ImageChannelDataTypeSignedInt32 = 9,
+    ImageChannelDataTypeUnsignedInt8 = 10,
+    ImageChannelDataTypeUnsignedInt16 = 11,
+    ImageChannelDataTypeUnsignedInt32 = 12,
+    ImageChannelDataTypeHalfFloat = 13,
+    ImageChannelDataTypeFloat = 14,
+    ImageChannelDataTypeUnormInt24 = 15,
+    ImageChannelDataTypeUnormInt101010_2 = 16,
+    ImageChannelDataTypeMax = 0x7fffffff,
+};
+
+enum ImageOperandsShift {
+    ImageOperandsBiasShift = 0,
+    ImageOperandsLodShift = 1,
+    ImageOperandsGradShift = 2,
+    ImageOperandsConstOffsetShift = 3,
+    ImageOperandsOffsetShift = 4,
+    ImageOperandsConstOffsetsShift = 5,
+    ImageOperandsSampleShift = 6,
+    ImageOperandsMinLodShift = 7,
+    ImageOperandsMakeTexelAvailableShift = 8,
+    ImageOperandsMakeTexelAvailableKHRShift = 8,
+    ImageOperandsMakeTexelVisibleShift = 9,
+    ImageOperandsMakeTexelVisibleKHRShift = 9,
+    ImageOperandsNonPrivateTexelShift = 10,
+    ImageOperandsNonPrivateTexelKHRShift = 10,
+    ImageOperandsVolatileTexelShift = 11,
+    ImageOperandsVolatileTexelKHRShift = 11,
+    ImageOperandsSignExtendShift = 12,
+    ImageOperandsZeroExtendShift = 13,
+    ImageOperandsOffsetsShift = 16,
+    ImageOperandsMax = 0x7fffffff,
+};
+
+enum ImageOperandsMask {
+    ImageOperandsMaskNone = 0,
+    ImageOperandsBiasMask = 0x00000001,
+    ImageOperandsLodMask = 0x00000002,
+    ImageOperandsGradMask = 0x00000004,
+    ImageOperandsConstOffsetMask = 0x00000008,
+    ImageOperandsOffsetMask = 0x00000010,
+    ImageOperandsConstOffsetsMask = 0x00000020,
+    ImageOperandsSampleMask = 0x00000040,
+    ImageOperandsMinLodMask = 0x00000080,
+    ImageOperandsMakeTexelAvailableMask = 0x00000100,
+    ImageOperandsMakeTexelAvailableKHRMask = 0x00000100,
+    ImageOperandsMakeTexelVisibleMask = 0x00000200,
+    ImageOperandsMakeTexelVisibleKHRMask = 0x00000200,
+    ImageOperandsNonPrivateTexelMask = 0x00000400,
+    ImageOperandsNonPrivateTexelKHRMask = 0x00000400,
+    ImageOperandsVolatileTexelMask = 0x00000800,
+    ImageOperandsVolatileTexelKHRMask = 0x00000800,
+    ImageOperandsSignExtendMask = 0x00001000,
+    ImageOperandsZeroExtendMask = 0x00002000,
+    ImageOperandsOffsetsMask = 0x00010000,
+};
+
+enum FPFastMathModeShift {
+    FPFastMathModeNotNaNShift = 0,
+    FPFastMathModeNotInfShift = 1,
+    FPFastMathModeNSZShift = 2,
+    FPFastMathModeAllowRecipShift = 3,
+    FPFastMathModeFastShift = 4,
+    FPFastMathModeAllowContractFastINTELShift = 16,
+    FPFastMathModeAllowReassocINTELShift = 17,
+    FPFastMathModeMax = 0x7fffffff,
+};
+
+enum FPFastMathModeMask {
+    FPFastMathModeMaskNone = 0,
+    FPFastMathModeNotNaNMask = 0x00000001,
+    FPFastMathModeNotInfMask = 0x00000002,
+    FPFastMathModeNSZMask = 0x00000004,
+    FPFastMathModeAllowRecipMask = 0x00000008,
+    FPFastMathModeFastMask = 0x00000010,
+    FPFastMathModeAllowContractFastINTELMask = 0x00010000,
+    FPFastMathModeAllowReassocINTELMask = 0x00020000,
+};
+
+enum FPRoundingMode {
+    FPRoundingModeRTE = 0,
+    FPRoundingModeRTZ = 1,
+    FPRoundingModeRTP = 2,
+    FPRoundingModeRTN = 3,
+    FPRoundingModeMax = 0x7fffffff,
+};
+
+enum LinkageType {
+    LinkageTypeExport = 0,
+    LinkageTypeImport = 1,
+    LinkageTypeLinkOnceODR = 2,
+    LinkageTypeMax = 0x7fffffff,
+};
+
+enum AccessQualifier {
+    AccessQualifierReadOnly = 0,
+    AccessQualifierWriteOnly = 1,
+    AccessQualifierReadWrite = 2,
+    // used by Vulkan/SPIR-V, which can't have access qualifiers
+    AccessQualifierNone = 0x7fffffff,
+};
+
+enum FunctionParameterAttribute {
+    FunctionParameterAttributeZext = 0,
+    FunctionParameterAttributeSext = 1,
+    FunctionParameterAttributeByVal = 2,
+    FunctionParameterAttributeSret = 3,
+    FunctionParameterAttributeNoAlias = 4,
+    FunctionParameterAttributeNoCapture = 5,
+    FunctionParameterAttributeNoWrite = 6,
+    FunctionParameterAttributeNoReadWrite = 7,
+    FunctionParameterAttributeMax = 0x7fffffff,
+};
+
+enum Decoration {
+    DecorationRelaxedPrecision = 0,
+    DecorationSpecId = 1,
+    DecorationBlock = 2,
+    DecorationBufferBlock = 3,
+    DecorationRowMajor = 4,
+    DecorationColMajor = 5,
+    DecorationArrayStride = 6,
+    DecorationMatrixStride = 7,
+    DecorationGLSLShared = 8,
+    DecorationGLSLPacked = 9,
+    DecorationCPacked = 10,
+    DecorationBuiltIn = 11,
+    DecorationNoPerspective = 13,
+    DecorationFlat = 14,
+    DecorationPatch = 15,
+    DecorationCentroid = 16,
+    DecorationSample = 17,
+    DecorationInvariant = 18,
+    DecorationRestrict = 19,
+    DecorationAliased = 20,
+    DecorationVolatile = 21,
+    DecorationConstant = 22,
+    DecorationCoherent = 23,
+    DecorationNonWritable = 24,
+    DecorationNonReadable = 25,
+    DecorationUniform = 26,
+    DecorationUniformId = 27,
+    DecorationSaturatedConversion = 28,
+    DecorationStream = 29,
+    DecorationLocation = 30,
+    DecorationComponent = 31,
+    DecorationIndex = 32,
+    DecorationBinding = 33,
+    DecorationDescriptorSet = 34,
+    DecorationOffset = 35,
+    DecorationXfbBuffer = 36,
+    DecorationXfbStride = 37,
+    DecorationFuncParamAttr = 38,
+    DecorationFPRoundingMode = 39,
+    DecorationFPFastMathMode = 40,
+    DecorationLinkageAttributes = 41,
+    DecorationNoContraction = 42,
+    DecorationInputAttachmentIndex = 43,
+    DecorationAlignment = 44,
+    DecorationMaxByteOffset = 45,
+    DecorationAlignmentId = 46,
+    DecorationMaxByteOffsetId = 47,
+    DecorationNoSignedWrap = 4469,
+    DecorationNoUnsignedWrap = 4470,
+    DecorationExplicitInterpAMD = 4999,
+    DecorationOverrideCoverageNV = 5248,
+    DecorationPassthroughNV = 5250,
+    DecorationViewportRelativeNV = 5252,
+    DecorationSecondaryViewportRelativeNV = 5256,
+    DecorationPerPrimitiveNV = 5271,
+    DecorationPerViewNV = 5272,
+    DecorationPerTaskNV = 5273,
+    DecorationPerVertexNV = 5285,
+    DecorationNonUniform = 5300,
+    DecorationNonUniformEXT = 5300,
+    DecorationRestrictPointer = 5355,
+    DecorationRestrictPointerEXT = 5355,
+    DecorationAliasedPointer = 5356,
+    DecorationAliasedPointerEXT = 5356,
+    DecorationBindlessSamplerNV = 5398,
+    DecorationBindlessImageNV = 5399,
+    DecorationBoundSamplerNV = 5400,
+    DecorationBoundImageNV = 5401,
+    DecorationSIMTCallINTEL = 5599,
+    DecorationReferencedIndirectlyINTEL = 5602,
+    DecorationClobberINTEL = 5607,
+    DecorationSideEffectsINTEL = 5608,
+    DecorationVectorComputeVariableINTEL = 5624,
+    DecorationFuncParamIOKindINTEL = 5625,
+    DecorationVectorComputeFunctionINTEL = 5626,
+    DecorationStackCallINTEL = 5627,
+    DecorationGlobalVariableOffsetINTEL = 5628,
+    DecorationCounterBuffer = 5634,
+    DecorationHlslCounterBufferGOOGLE = 5634,
+    DecorationHlslSemanticGOOGLE = 5635,
+    DecorationUserSemantic = 5635,
+    DecorationUserTypeGOOGLE = 5636,
+    DecorationFunctionRoundingModeINTEL = 5822,
+    DecorationFunctionDenormModeINTEL = 5823,
+    DecorationRegisterINTEL = 5825,
+    DecorationMemoryINTEL = 5826,
+    DecorationNumbanksINTEL = 5827,
+    DecorationBankwidthINTEL = 5828,
+    DecorationMaxPrivateCopiesINTEL = 5829,
+    DecorationSinglepumpINTEL = 5830,
+    DecorationDoublepumpINTEL = 5831,
+    DecorationMaxReplicatesINTEL = 5832,
+    DecorationSimpleDualPortINTEL = 5833,
+    DecorationMergeINTEL = 5834,
+    DecorationBankBitsINTEL = 5835,
+    DecorationForcePow2DepthINTEL = 5836,
+    DecorationBurstCoalesceINTEL = 5899,
+    DecorationCacheSizeINTEL = 5900,
+    DecorationDontStaticallyCoalesceINTEL = 5901,
+    DecorationPrefetchINTEL = 5902,
+    DecorationStallEnableINTEL = 5905,
+    DecorationFuseLoopsInFunctionINTEL = 5907,
+    DecorationBufferLocationINTEL = 5921,
+    DecorationIOPipeStorageINTEL = 5944,
+    DecorationFunctionFloatingPointModeINTEL = 6080,
+    DecorationSingleElementVectorINTEL = 6085,
+    DecorationVectorComputeCallableFunctionINTEL = 6087,
+    DecorationMax = 0x7fffffff,
+};
+
+enum BuiltIn {
+    BuiltInPosition = 0,
+    BuiltInPointSize = 1,
+    BuiltInClipDistance = 3,
+    BuiltInCullDistance = 4,
+    BuiltInVertexId = 5,
+    BuiltInInstanceId = 6,
+    BuiltInPrimitiveId = 7,
+    BuiltInInvocationId = 8,
+    BuiltInLayer = 9,
+    BuiltInViewportIndex = 10,
+    BuiltInTessLevelOuter = 11,
+    BuiltInTessLevelInner = 12,
+    BuiltInTessCoord = 13,
+    BuiltInPatchVertices = 14,
+    BuiltInFragCoord = 15,
+    BuiltInPointCoord = 16,
+    BuiltInFrontFacing = 17,
+    BuiltInSampleId = 18,
+    BuiltInSamplePosition = 19,
+    BuiltInSampleMask = 20,
+    BuiltInFragDepth = 22,
+    BuiltInHelperInvocation = 23,
+    BuiltInNumWorkgroups = 24,
+    BuiltInWorkgroupSize = 25,
+    BuiltInWorkgroupId = 26,
+    BuiltInLocalInvocationId = 27,
+    BuiltInGlobalInvocationId = 28,
+    BuiltInLocalInvocationIndex = 29,
+    BuiltInWorkDim = 30,
+    BuiltInGlobalSize = 31,
+    BuiltInEnqueuedWorkgroupSize = 32,
+    BuiltInGlobalOffset = 33,
+    BuiltInGlobalLinearId = 34,
+    BuiltInSubgroupSize = 36,
+    BuiltInSubgroupMaxSize = 37,
+    BuiltInNumSubgroups = 38,
+    BuiltInNumEnqueuedSubgroups = 39,
+    BuiltInSubgroupId = 40,
+    BuiltInSubgroupLocalInvocationId = 41,
+    BuiltInVertexIndex = 42,
+    BuiltInInstanceIndex = 43,
+    BuiltInSubgroupEqMask = 4416,
+    BuiltInSubgroupEqMaskKHR = 4416,
+    BuiltInSubgroupGeMask = 4417,
+    BuiltInSubgroupGeMaskKHR = 4417,
+    BuiltInSubgroupGtMask = 4418,
+    BuiltInSubgroupGtMaskKHR = 4418,
+    BuiltInSubgroupLeMask = 4419,
+    BuiltInSubgroupLeMaskKHR = 4419,
+    BuiltInSubgroupLtMask = 4420,
+    BuiltInSubgroupLtMaskKHR = 4420,
+    BuiltInBaseVertex = 4424,
+    BuiltInBaseInstance = 4425,
+    BuiltInDrawIndex = 4426,
+    BuiltInPrimitiveShadingRateKHR = 4432,
+    BuiltInDeviceIndex = 4438,
+    BuiltInViewIndex = 4440,
+    BuiltInShadingRateKHR = 4444,
+    BuiltInBaryCoordNoPerspAMD = 4992,
+    BuiltInBaryCoordNoPerspCentroidAMD = 4993,
+    BuiltInBaryCoordNoPerspSampleAMD = 4994,
+    BuiltInBaryCoordSmoothAMD = 4995,
+    BuiltInBaryCoordSmoothCentroidAMD = 4996,
+    BuiltInBaryCoordSmoothSampleAMD = 4997,
+    BuiltInBaryCoordPullModelAMD = 4998,
+    BuiltInFragStencilRefEXT = 5014,
+    BuiltInViewportMaskNV = 5253,
+    BuiltInSecondaryPositionNV = 5257,
+    BuiltInSecondaryViewportMaskNV = 5258,
+    BuiltInPositionPerViewNV = 5261,
+    BuiltInViewportMaskPerViewNV = 5262,
+    BuiltInFullyCoveredEXT = 5264,
+    BuiltInTaskCountNV = 5274,
+    BuiltInPrimitiveCountNV = 5275,
+    BuiltInPrimitiveIndicesNV = 5276,
+    BuiltInClipDistancePerViewNV = 5277,
+    BuiltInCullDistancePerViewNV = 5278,
+    BuiltInLayerPerViewNV = 5279,
+    BuiltInMeshViewCountNV = 5280,
+    BuiltInMeshViewIndicesNV = 5281,
+    BuiltInBaryCoordNV = 5286,
+    BuiltInBaryCoordNoPerspNV = 5287,
+    BuiltInFragSizeEXT = 5292,
+    BuiltInFragmentSizeNV = 5292,
+    BuiltInFragInvocationCountEXT = 5293,
+    BuiltInInvocationsPerPixelNV = 5293,
+    BuiltInLaunchIdKHR = 5319,
+    BuiltInLaunchIdNV = 5319,
+    BuiltInLaunchSizeKHR = 5320,
+    BuiltInLaunchSizeNV = 5320,
+    BuiltInWorldRayOriginKHR = 5321,
+    BuiltInWorldRayOriginNV = 5321,
+    BuiltInWorldRayDirectionKHR = 5322,
+    BuiltInWorldRayDirectionNV = 5322,
+    BuiltInObjectRayOriginKHR = 5323,
+    BuiltInObjectRayOriginNV = 5323,
+    BuiltInObjectRayDirectionKHR = 5324,
+    BuiltInObjectRayDirectionNV = 5324,
+    BuiltInRayTminKHR = 5325,
+    BuiltInRayTminNV = 5325,
+    BuiltInRayTmaxKHR = 5326,
+    BuiltInRayTmaxNV = 5326,
+    BuiltInInstanceCustomIndexKHR = 5327,
+    BuiltInInstanceCustomIndexNV = 5327,
+    BuiltInObjectToWorldKHR = 5330,
+    BuiltInObjectToWorldNV = 5330,
+    BuiltInWorldToObjectKHR = 5331,
+    BuiltInWorldToObjectNV = 5331,
+    BuiltInHitTNV = 5332,
+    BuiltInHitKindKHR = 5333,
+    BuiltInHitKindNV = 5333,
+    BuiltInCurrentRayTimeNV = 5334,
+    BuiltInIncomingRayFlagsKHR = 5351,
+    BuiltInIncomingRayFlagsNV = 5351,
+    BuiltInRayGeometryIndexKHR = 5352,
+    BuiltInWarpsPerSMNV = 5374,
+    BuiltInSMCountNV = 5375,
+    BuiltInWarpIDNV = 5376,
+    BuiltInSMIDNV = 5377,
+    BuiltInMax = 0x7fffffff,
+};
+
+enum SelectionControlShift {
+    SelectionControlFlattenShift = 0,
+    SelectionControlDontFlattenShift = 1,
+    SelectionControlMax = 0x7fffffff,
+};
+
+enum SelectionControlMask {
+    SelectionControlMaskNone = 0,
+    SelectionControlFlattenMask = 0x00000001,
+    SelectionControlDontFlattenMask = 0x00000002,
+};
+
+enum LoopControlShift {
+    LoopControlUnrollShift = 0,
+    LoopControlDontUnrollShift = 1,
+    LoopControlDependencyInfiniteShift = 2,
+    LoopControlDependencyLengthShift = 3,
+    LoopControlMinIterationsShift = 4,
+    LoopControlMaxIterationsShift = 5,
+    LoopControlIterationMultipleShift = 6,
+    LoopControlPeelCountShift = 7,
+    LoopControlPartialCountShift = 8,
+    LoopControlInitiationIntervalINTELShift = 16,
+    LoopControlMaxConcurrencyINTELShift = 17,
+    LoopControlDependencyArrayINTELShift = 18,
+    LoopControlPipelineEnableINTELShift = 19,
+    LoopControlLoopCoalesceINTELShift = 20,
+    LoopControlMaxInterleavingINTELShift = 21,
+    LoopControlSpeculatedIterationsINTELShift = 22,
+    LoopControlNoFusionINTELShift = 23,
+    LoopControlMax = 0x7fffffff,
+};
+
+enum LoopControlMask {
+    LoopControlMaskNone = 0,
+    LoopControlUnrollMask = 0x00000001,
+    LoopControlDontUnrollMask = 0x00000002,
+    LoopControlDependencyInfiniteMask = 0x00000004,
+    LoopControlDependencyLengthMask = 0x00000008,
+    LoopControlMinIterationsMask = 0x00000010,
+    LoopControlMaxIterationsMask = 0x00000020,
+    LoopControlIterationMultipleMask = 0x00000040,
+    LoopControlPeelCountMask = 0x00000080,
+    LoopControlPartialCountMask = 0x00000100,
+    LoopControlInitiationIntervalINTELMask = 0x00010000,
+    LoopControlMaxConcurrencyINTELMask = 0x00020000,
+    LoopControlDependencyArrayINTELMask = 0x00040000,
+    LoopControlPipelineEnableINTELMask = 0x00080000,
+    LoopControlLoopCoalesceINTELMask = 0x00100000,
+    LoopControlMaxInterleavingINTELMask = 0x00200000,
+    LoopControlSpeculatedIterationsINTELMask = 0x00400000,
+    LoopControlNoFusionINTELMask = 0x00800000,
+};
+
+enum FunctionControlShift {
+    FunctionControlInlineShift = 0,
+    FunctionControlDontInlineShift = 1,
+    FunctionControlPureShift = 2,
+    FunctionControlConstShift = 3,
+    FunctionControlOptNoneINTELShift = 16,
+    FunctionControlMax = 0x7fffffff,
+};
+
+enum FunctionControlMask {
+    FunctionControlMaskNone = 0,
+    FunctionControlInlineMask = 0x00000001,
+    FunctionControlDontInlineMask = 0x00000002,
+    FunctionControlPureMask = 0x00000004,
+    FunctionControlConstMask = 0x00000008,
+    FunctionControlOptNoneINTELMask = 0x00010000,
+};
+
+enum MemorySemanticsShift {
+    MemorySemanticsAcquireShift = 1,
+    MemorySemanticsReleaseShift = 2,
+    MemorySemanticsAcquireReleaseShift = 3,
+    MemorySemanticsSequentiallyConsistentShift = 4,
+    MemorySemanticsUniformMemoryShift = 6,
+    MemorySemanticsSubgroupMemoryShift = 7,
+    MemorySemanticsWorkgroupMemoryShift = 8,
+    MemorySemanticsCrossWorkgroupMemoryShift = 9,
+    MemorySemanticsAtomicCounterMemoryShift = 10,
+    MemorySemanticsImageMemoryShift = 11,
+    MemorySemanticsOutputMemoryShift = 12,
+    MemorySemanticsOutputMemoryKHRShift = 12,
+    MemorySemanticsMakeAvailableShift = 13,
+    MemorySemanticsMakeAvailableKHRShift = 13,
+    MemorySemanticsMakeVisibleShift = 14,
+    MemorySemanticsMakeVisibleKHRShift = 14,
+    MemorySemanticsVolatileShift = 15,
+    MemorySemanticsMax = 0x7fffffff,
+};
+
+enum MemorySemanticsMask {
+    MemorySemanticsMaskNone = 0,
+    MemorySemanticsAcquireMask = 0x00000002,
+    MemorySemanticsReleaseMask = 0x00000004,
+    MemorySemanticsAcquireReleaseMask = 0x00000008,
+    MemorySemanticsSequentiallyConsistentMask = 0x00000010,
+    MemorySemanticsUniformMemoryMask = 0x00000040,
+    MemorySemanticsSubgroupMemoryMask = 0x00000080,
+    MemorySemanticsWorkgroupMemoryMask = 0x00000100,
+    MemorySemanticsCrossWorkgroupMemoryMask = 0x00000200,
+    MemorySemanticsAtomicCounterMemoryMask = 0x00000400,
+    MemorySemanticsImageMemoryMask = 0x00000800,
+    MemorySemanticsOutputMemoryMask = 0x00001000,
+    MemorySemanticsOutputMemoryKHRMask = 0x00001000,
+    MemorySemanticsMakeAvailableMask = 0x00002000,
+    MemorySemanticsMakeAvailableKHRMask = 0x00002000,
+    MemorySemanticsMakeVisibleMask = 0x00004000,
+    MemorySemanticsMakeVisibleKHRMask = 0x00004000,
+    MemorySemanticsVolatileMask = 0x00008000,
+};
+
+enum MemoryAccessShift {
+    MemoryAccessVolatileShift = 0,
+    MemoryAccessAlignedShift = 1,
+    MemoryAccessNontemporalShift = 2,
+    MemoryAccessMakePointerAvailableShift = 3,
+    MemoryAccessMakePointerAvailableKHRShift = 3,
+    MemoryAccessMakePointerVisibleShift = 4,
+    MemoryAccessMakePointerVisibleKHRShift = 4,
+    MemoryAccessNonPrivatePointerShift = 5,
+    MemoryAccessNonPrivatePointerKHRShift = 5,
+    MemoryAccessMax = 0x7fffffff,
+};
+
+enum MemoryAccessMask {
+    MemoryAccessMaskNone = 0,
+    MemoryAccessVolatileMask = 0x00000001,
+    MemoryAccessAlignedMask = 0x00000002,
+    MemoryAccessNontemporalMask = 0x00000004,
+    MemoryAccessMakePointerAvailableMask = 0x00000008,
+    MemoryAccessMakePointerAvailableKHRMask = 0x00000008,
+    MemoryAccessMakePointerVisibleMask = 0x00000010,
+    MemoryAccessMakePointerVisibleKHRMask = 0x00000010,
+    MemoryAccessNonPrivatePointerMask = 0x00000020,
+    MemoryAccessNonPrivatePointerKHRMask = 0x00000020,
+};
+
+enum Scope {
+    ScopeCrossDevice = 0,
+    ScopeDevice = 1,
+    ScopeWorkgroup = 2,
+    ScopeSubgroup = 3,
+    ScopeInvocation = 4,
+    ScopeQueueFamily = 5,
+    ScopeQueueFamilyKHR = 5,
+    ScopeShaderCallKHR = 6,
+    ScopeMax = 0x7fffffff,
+};
+
+enum GroupOperation {
+    GroupOperationReduce = 0,
+    GroupOperationInclusiveScan = 1,
+    GroupOperationExclusiveScan = 2,
+    GroupOperationClusteredReduce = 3,
+    GroupOperationPartitionedReduceNV = 6,
+    GroupOperationPartitionedInclusiveScanNV = 7,
+    GroupOperationPartitionedExclusiveScanNV = 8,
+    GroupOperationMax = 0x7fffffff,
+};
+
+enum KernelEnqueueFlags {
+    KernelEnqueueFlagsNoWait = 0,
+    KernelEnqueueFlagsWaitKernel = 1,
+    KernelEnqueueFlagsWaitWorkGroup = 2,
+    KernelEnqueueFlagsMax = 0x7fffffff,
+};
+
+enum KernelProfilingInfoShift {
+    KernelProfilingInfoCmdExecTimeShift = 0,
+    KernelProfilingInfoMax = 0x7fffffff,
+};
+
+enum KernelProfilingInfoMask {
+    KernelProfilingInfoMaskNone = 0,
+    KernelProfilingInfoCmdExecTimeMask = 0x00000001,
+};
+
+enum Capability {
+    CapabilityMatrix = 0,
+    CapabilityShader = 1,
+    CapabilityGeometry = 2,
+    CapabilityTessellation = 3,
+    CapabilityAddresses = 4,
+    CapabilityLinkage = 5,
+    CapabilityKernel = 6,
+    CapabilityVector16 = 7,
+    CapabilityFloat16Buffer = 8,
+    CapabilityFloat16 = 9,
+    CapabilityFloat64 = 10,
+    CapabilityInt64 = 11,
+    CapabilityInt64Atomics = 12,
+    CapabilityImageBasic = 13,
+    CapabilityImageReadWrite = 14,
+    CapabilityImageMipmap = 15,
+    CapabilityPipes = 17,
+    CapabilityGroups = 18,
+    CapabilityDeviceEnqueue = 19,
+    CapabilityLiteralSampler = 20,
+    CapabilityAtomicStorage = 21,
+    CapabilityInt16 = 22,
+    CapabilityTessellationPointSize = 23,
+    CapabilityGeometryPointSize = 24,
+    CapabilityImageGatherExtended = 25,
+    CapabilityStorageImageMultisample = 27,
+    CapabilityUniformBufferArrayDynamicIndexing = 28,
+    CapabilitySampledImageArrayDynamicIndexing = 29,
+    CapabilityStorageBufferArrayDynamicIndexing = 30,
+    CapabilityStorageImageArrayDynamicIndexing = 31,
+    CapabilityClipDistance = 32,
+    CapabilityCullDistance = 33,
+    CapabilityImageCubeArray = 34,
+    CapabilitySampleRateShading = 35,
+    CapabilityImageRect = 36,
+    CapabilitySampledRect = 37,
+    CapabilityGenericPointer = 38,
+    CapabilityInt8 = 39,
+    CapabilityInputAttachment = 40,
+    CapabilitySparseResidency = 41,
+    CapabilityMinLod = 42,
+    CapabilitySampled1D = 43,
+    CapabilityImage1D = 44,
+    CapabilitySampledCubeArray = 45,
+    CapabilitySampledBuffer = 46,
+    CapabilityImageBuffer = 47,
+    CapabilityImageMSArray = 48,
+    CapabilityStorageImageExtendedFormats = 49,
+    CapabilityImageQuery = 50,
+    CapabilityDerivativeControl = 51,
+    CapabilityInterpolationFunction = 52,
+    CapabilityTransformFeedback = 53,
+    CapabilityGeometryStreams = 54,
+    CapabilityStorageImageReadWithoutFormat = 55,
+    CapabilityStorageImageWriteWithoutFormat = 56,
+    CapabilityMultiViewport = 57,
+    CapabilitySubgroupDispatch = 58,
+    CapabilityNamedBarrier = 59,
+    CapabilityPipeStorage = 60,
+    CapabilityGroupNonUniform = 61,
+    CapabilityGroupNonUniformVote = 62,
+    CapabilityGroupNonUniformArithmetic = 63,
+    CapabilityGroupNonUniformBallot = 64,
+    CapabilityGroupNonUniformShuffle = 65,
+    CapabilityGroupNonUniformShuffleRelative = 66,
+    CapabilityGroupNonUniformClustered = 67,
+    CapabilityGroupNonUniformQuad = 68,
+    CapabilityShaderLayer = 69,
+    CapabilityShaderViewportIndex = 70,
+    CapabilityFragmentShadingRateKHR = 4422,
+    CapabilitySubgroupBallotKHR = 4423,
+    CapabilityDrawParameters = 4427,
+    CapabilityWorkgroupMemoryExplicitLayoutKHR = 4428,
+    CapabilityWorkgroupMemoryExplicitLayout8BitAccessKHR = 4429,
+    CapabilityWorkgroupMemoryExplicitLayout16BitAccessKHR = 4430,
+    CapabilitySubgroupVoteKHR = 4431,
+    CapabilityStorageBuffer16BitAccess = 4433,
+    CapabilityStorageUniformBufferBlock16 = 4433,
+    CapabilityStorageUniform16 = 4434,
+    CapabilityUniformAndStorageBuffer16BitAccess = 4434,
+    CapabilityStoragePushConstant16 = 4435,
+    CapabilityStorageInputOutput16 = 4436,
+    CapabilityDeviceGroup = 4437,
+    CapabilityMultiView = 4439,
+    CapabilityVariablePointersStorageBuffer = 4441,
+    CapabilityVariablePointers = 4442,
+    CapabilityAtomicStorageOps = 4445,
+    CapabilitySampleMaskPostDepthCoverage = 4447,
+    CapabilityStorageBuffer8BitAccess = 4448,
+    CapabilityUniformAndStorageBuffer8BitAccess = 4449,
+    CapabilityStoragePushConstant8 = 4450,
+    CapabilityDenormPreserve = 4464,
+    CapabilityDenormFlushToZero = 4465,
+    CapabilitySignedZeroInfNanPreserve = 4466,
+    CapabilityRoundingModeRTE = 4467,
+    CapabilityRoundingModeRTZ = 4468,
+    CapabilityRayQueryProvisionalKHR = 4471,
+    CapabilityRayQueryKHR = 4472,
+    CapabilityRayTraversalPrimitiveCullingKHR = 4478,
+    CapabilityRayTracingKHR = 4479,
+    CapabilityFloat16ImageAMD = 5008,
+    CapabilityImageGatherBiasLodAMD = 5009,
+    CapabilityFragmentMaskAMD = 5010,
+    CapabilityStencilExportEXT = 5013,
+    CapabilityImageReadWriteLodAMD = 5015,
+    CapabilityInt64ImageEXT = 5016,
+    CapabilityShaderClockKHR = 5055,
+    CapabilitySampleMaskOverrideCoverageNV = 5249,
+    CapabilityGeometryShaderPassthroughNV = 5251,
+    CapabilityShaderViewportIndexLayerEXT = 5254,
+    CapabilityShaderViewportIndexLayerNV = 5254,
+    CapabilityShaderViewportMaskNV = 5255,
+    CapabilityShaderStereoViewNV = 5259,
+    CapabilityPerViewAttributesNV = 5260,
+    CapabilityFragmentFullyCoveredEXT = 5265,
+    CapabilityMeshShadingNV = 5266,
+    CapabilityImageFootprintNV = 5282,
+    CapabilityFragmentBarycentricNV = 5284,
+    CapabilityComputeDerivativeGroupQuadsNV = 5288,
+    CapabilityFragmentDensityEXT = 5291,
+    CapabilityShadingRateNV = 5291,
+    CapabilityGroupNonUniformPartitionedNV = 5297,
+    CapabilityShaderNonUniform = 5301,
+    CapabilityShaderNonUniformEXT = 5301,
+    CapabilityRuntimeDescriptorArray = 5302,
+    CapabilityRuntimeDescriptorArrayEXT = 5302,
+    CapabilityInputAttachmentArrayDynamicIndexing = 5303,
+    CapabilityInputAttachmentArrayDynamicIndexingEXT = 5303,
+    CapabilityUniformTexelBufferArrayDynamicIndexing = 5304,
+    CapabilityUniformTexelBufferArrayDynamicIndexingEXT = 5304,
+    CapabilityStorageTexelBufferArrayDynamicIndexing = 5305,
+    CapabilityStorageTexelBufferArrayDynamicIndexingEXT = 5305,
+    CapabilityUniformBufferArrayNonUniformIndexing = 5306,
+    CapabilityUniformBufferArrayNonUniformIndexingEXT = 5306,
+    CapabilitySampledImageArrayNonUniformIndexing = 5307,
+    CapabilitySampledImageArrayNonUniformIndexingEXT = 5307,
+    CapabilityStorageBufferArrayNonUniformIndexing = 5308,
+    CapabilityStorageBufferArrayNonUniformIndexingEXT = 5308,
+    CapabilityStorageImageArrayNonUniformIndexing = 5309,
+    CapabilityStorageImageArrayNonUniformIndexingEXT = 5309,
+    CapabilityInputAttachmentArrayNonUniformIndexing = 5310,
+    CapabilityInputAttachmentArrayNonUniformIndexingEXT = 5310,
+    CapabilityUniformTexelBufferArrayNonUniformIndexing = 5311,
+    CapabilityUniformTexelBufferArrayNonUniformIndexingEXT = 5311,
+    CapabilityStorageTexelBufferArrayNonUniformIndexing = 5312,
+    CapabilityStorageTexelBufferArrayNonUniformIndexingEXT = 5312,
+    CapabilityRayTracingNV = 5340,
+    CapabilityRayTracingMotionBlurNV = 5341,
+    CapabilityVulkanMemoryModel = 5345,
+    CapabilityVulkanMemoryModelKHR = 5345,
+    CapabilityVulkanMemoryModelDeviceScope = 5346,
+    CapabilityVulkanMemoryModelDeviceScopeKHR = 5346,
+    CapabilityPhysicalStorageBufferAddresses = 5347,
+    CapabilityPhysicalStorageBufferAddressesEXT = 5347,
+    CapabilityComputeDerivativeGroupLinearNV = 5350,
+    CapabilityRayTracingProvisionalKHR = 5353,
+    CapabilityCooperativeMatrixNV = 5357,
+    CapabilityFragmentShaderSampleInterlockEXT = 5363,
+    CapabilityFragmentShaderShadingRateInterlockEXT = 5372,
+    CapabilityShaderSMBuiltinsNV = 5373,
+    CapabilityFragmentShaderPixelInterlockEXT = 5378,
+    CapabilityDemoteToHelperInvocationEXT = 5379,
+    CapabilityBindlessTextureNV = 5390,
+    CapabilitySubgroupShuffleINTEL = 5568,
+    CapabilitySubgroupBufferBlockIOINTEL = 5569,
+    CapabilitySubgroupImageBlockIOINTEL = 5570,
+    CapabilitySubgroupImageMediaBlockIOINTEL = 5579,
+    CapabilityRoundToInfinityINTEL = 5582,
+    CapabilityFloatingPointModeINTEL = 5583,
+    CapabilityIntegerFunctions2INTEL = 5584,
+    CapabilityFunctionPointersINTEL = 5603,
+    CapabilityIndirectReferencesINTEL = 5604,
+    CapabilityAsmINTEL = 5606,
+    CapabilityAtomicFloat32MinMaxEXT = 5612,
+    CapabilityAtomicFloat64MinMaxEXT = 5613,
+    CapabilityAtomicFloat16MinMaxEXT = 5616,
+    CapabilityVectorComputeINTEL = 5617,
+    CapabilityVectorAnyINTEL = 5619,
+    CapabilityExpectAssumeKHR = 5629,
+    CapabilitySubgroupAvcMotionEstimationINTEL = 5696,
+    CapabilitySubgroupAvcMotionEstimationIntraINTEL = 5697,
+    CapabilitySubgroupAvcMotionEstimationChromaINTEL = 5698,
+    CapabilityVariableLengthArrayINTEL = 5817,
+    CapabilityFunctionFloatControlINTEL = 5821,
+    CapabilityFPGAMemoryAttributesINTEL = 5824,
+    CapabilityFPFastMathModeINTEL = 5837,
+    CapabilityArbitraryPrecisionIntegersINTEL = 5844,
+    CapabilityArbitraryPrecisionFloatingPointINTEL = 5845,
+    CapabilityUnstructuredLoopControlsINTEL = 5886,
+    CapabilityFPGALoopControlsINTEL = 5888,
+    CapabilityKernelAttributesINTEL = 5892,
+    CapabilityFPGAKernelAttributesINTEL = 5897,
+    CapabilityFPGAMemoryAccessesINTEL = 5898,
+    CapabilityFPGAClusterAttributesINTEL = 5904,
+    CapabilityLoopFuseINTEL = 5906,
+    CapabilityFPGABufferLocationINTEL = 5920,
+    CapabilityArbitraryPrecisionFixedPointINTEL = 5922,
+    CapabilityUSMStorageClassesINTEL = 5935,
+    CapabilityIOPipesINTEL = 5943,
+    CapabilityBlockingPipesINTEL = 5945,
+    CapabilityFPGARegINTEL = 5948,
+    CapabilityDotProductInputAllKHR = 6016,
+    CapabilityDotProductInput4x8BitKHR = 6017,
+    CapabilityDotProductInput4x8BitPackedKHR = 6018,
+    CapabilityDotProductKHR = 6019,
+    CapabilityBitInstructions = 6025,
+    CapabilityAtomicFloat32AddEXT = 6033,
+    CapabilityAtomicFloat64AddEXT = 6034,
+    CapabilityLongConstantCompositeINTEL = 6089,
+    CapabilityOptNoneINTEL = 6094,
+    CapabilityAtomicFloat16AddEXT = 6095,
+    CapabilityDebugInfoModuleINTEL = 6114,
+    CapabilityMax = 0x7fffffff,
+};
+
+enum RayFlagsShift {
+    RayFlagsOpaqueKHRShift = 0,
+    RayFlagsNoOpaqueKHRShift = 1,
+    RayFlagsTerminateOnFirstHitKHRShift = 2,
+    RayFlagsSkipClosestHitShaderKHRShift = 3,
+    RayFlagsCullBackFacingTrianglesKHRShift = 4,
+    RayFlagsCullFrontFacingTrianglesKHRShift = 5,
+    RayFlagsCullOpaqueKHRShift = 6,
+    RayFlagsCullNoOpaqueKHRShift = 7,
+    RayFlagsSkipTrianglesKHRShift = 8,
+    RayFlagsSkipAABBsKHRShift = 9,
+    RayFlagsMax = 0x7fffffff,
+};
+
+enum RayFlagsMask {
+    RayFlagsMaskNone = 0,
+    RayFlagsOpaqueKHRMask = 0x00000001,
+    RayFlagsNoOpaqueKHRMask = 0x00000002,
+    RayFlagsTerminateOnFirstHitKHRMask = 0x00000004,
+    RayFlagsSkipClosestHitShaderKHRMask = 0x00000008,
+    RayFlagsCullBackFacingTrianglesKHRMask = 0x00000010,
+    RayFlagsCullFrontFacingTrianglesKHRMask = 0x00000020,
+    RayFlagsCullOpaqueKHRMask = 0x00000040,
+    RayFlagsCullNoOpaqueKHRMask = 0x00000080,
+    RayFlagsSkipTrianglesKHRMask = 0x00000100,
+    RayFlagsSkipAABBsKHRMask = 0x00000200,
+};
+
+enum RayQueryIntersection {
+    RayQueryIntersectionRayQueryCandidateIntersectionKHR = 0,
+    RayQueryIntersectionRayQueryCommittedIntersectionKHR = 1,
+    RayQueryIntersectionMax = 0x7fffffff,
+};
+
+enum RayQueryCommittedIntersectionType {
+    RayQueryCommittedIntersectionTypeRayQueryCommittedIntersectionNoneKHR = 0,
+    RayQueryCommittedIntersectionTypeRayQueryCommittedIntersectionTriangleKHR = 1,
+    RayQueryCommittedIntersectionTypeRayQueryCommittedIntersectionGeneratedKHR = 2,
+    RayQueryCommittedIntersectionTypeMax = 0x7fffffff,
+};
+
+enum RayQueryCandidateIntersectionType {
+    RayQueryCandidateIntersectionTypeRayQueryCandidateIntersectionTriangleKHR = 0,
+    RayQueryCandidateIntersectionTypeRayQueryCandidateIntersectionAABBKHR = 1,
+    RayQueryCandidateIntersectionTypeMax = 0x7fffffff,
+};
+
+enum FragmentShadingRateShift {
+    FragmentShadingRateVertical2PixelsShift = 0,
+    FragmentShadingRateVertical4PixelsShift = 1,
+    FragmentShadingRateHorizontal2PixelsShift = 2,
+    FragmentShadingRateHorizontal4PixelsShift = 3,
+    FragmentShadingRateMax = 0x7fffffff,
+};
+
+enum FragmentShadingRateMask {
+    FragmentShadingRateMaskNone = 0,
+    FragmentShadingRateVertical2PixelsMask = 0x00000001,
+    FragmentShadingRateVertical4PixelsMask = 0x00000002,
+    FragmentShadingRateHorizontal2PixelsMask = 0x00000004,
+    FragmentShadingRateHorizontal4PixelsMask = 0x00000008,
+};
+
+enum FPDenormMode {
+    FPDenormModePreserve = 0,
+    FPDenormModeFlushToZero = 1,
+    FPDenormModeMax = 0x7fffffff,
+};
+
+enum FPOperationMode {
+    FPOperationModeIEEE = 0,
+    FPOperationModeALT = 1,
+    FPOperationModeMax = 0x7fffffff,
+};
+
+enum QuantizationModes {
+    QuantizationModesTRN = 0,
+    QuantizationModesTRN_ZERO = 1,
+    QuantizationModesRND = 2,
+    QuantizationModesRND_ZERO = 3,
+    QuantizationModesRND_INF = 4,
+    QuantizationModesRND_MIN_INF = 5,
+    QuantizationModesRND_CONV = 6,
+    QuantizationModesRND_CONV_ODD = 7,
+    QuantizationModesMax = 0x7fffffff,
+};
+
+enum OverflowModes {
+    OverflowModesWRAP = 0,
+    OverflowModesSAT = 1,
+    OverflowModesSAT_ZERO = 2,
+    OverflowModesSAT_SYM = 3,
+    OverflowModesMax = 0x7fffffff,
+};
+
+enum PackedVectorFormat {
+    PackedVectorFormatPackedVectorFormat4x8BitKHR = 0,
+    PackedVectorFormatMax = 0x7fffffff,
+};
+
+enum Op {
+    OpNop = 0,
+    OpUndef = 1,
+    OpSourceContinued = 2,
+    OpSource = 3,
+    OpSourceExtension = 4,
+    OpName = 5,
+    OpMemberName = 6,
+    OpString = 7,
+    OpLine = 8,
+    OpExtension = 10,
+    OpExtInstImport = 11,
+    OpExtInst = 12,
+    OpMemoryModel = 14,
+    OpEntryPoint = 15,
+    OpExecutionMode = 16,
+    OpCapability = 17,
+    OpTypeVoid = 19,
+    OpTypeBool = 20,
+    OpTypeInt = 21,
+    OpTypeFloat = 22,
+    OpTypeVector = 23,
+    OpTypeMatrix = 24,
+    OpTypeImage = 25,
+    OpTypeSampler = 26,
+    OpTypeSampledImage = 27,
+    OpTypeArray = 28,
+    OpTypeRuntimeArray = 29,
+    OpTypeStruct = 30,
+    OpTypeOpaque = 31,
+    OpTypePointer = 32,
+    OpTypeFunction = 33,
+    OpTypeEvent = 34,
+    OpTypeDeviceEvent = 35,
+    OpTypeReserveId = 36,
+    OpTypeQueue = 37,
+    OpTypePipe = 38,
+    OpTypeForwardPointer = 39,
+    OpConstantTrue = 41,
+    OpConstantFalse = 42,
+    OpConstant = 43,
+    OpConstantComposite = 44,
+    OpConstantSampler = 45,
+    OpConstantNull = 46,
+    OpSpecConstantTrue = 48,
+    OpSpecConstantFalse = 49,
+    OpSpecConstant = 50,
+    OpSpecConstantComposite = 51,
+    OpSpecConstantOp = 52,
+    OpFunction = 54,
+    OpFunctionParameter = 55,
+    OpFunctionEnd = 56,
+    OpFunctionCall = 57,
+    OpVariable = 59,
+    OpImageTexelPointer = 60,
+    OpLoad = 61,
+    OpStore = 62,
+    OpCopyMemory = 63,
+    OpCopyMemorySized = 64,
+    OpAccessChain = 65,
+    OpInBoundsAccessChain = 66,
+    OpPtrAccessChain = 67,
+    OpArrayLength = 68,
+    OpGenericPtrMemSemantics = 69,
+    OpInBoundsPtrAccessChain = 70,
+    OpDecorate = 71,
+    OpMemberDecorate = 72,
+    OpDecorationGroup = 73,
+    OpGroupDecorate = 74,
+    OpGroupMemberDecorate = 75,
+    OpVectorExtractDynamic = 77,
+    OpVectorInsertDynamic = 78,
+    OpVectorShuffle = 79,
+    OpCompositeConstruct = 80,
+    OpCompositeExtract = 81,
+    OpCompositeInsert = 82,
+    OpCopyObject = 83,
+    OpTranspose = 84,
+    OpSampledImage = 86,
+    OpImageSampleImplicitLod = 87,
+    OpImageSampleExplicitLod = 88,
+    OpImageSampleDrefImplicitLod = 89,
+    OpImageSampleDrefExplicitLod = 90,
+    OpImageSampleProjImplicitLod = 91,
+    OpImageSampleProjExplicitLod = 92,
+    OpImageSampleProjDrefImplicitLod = 93,
+    OpImageSampleProjDrefExplicitLod = 94,
+    OpImageFetch = 95,
+    OpImageGather = 96,
+    OpImageDrefGather = 97,
+    OpImageRead = 98,
+    OpImageWrite = 99,
+    OpImage = 100,
+    OpImageQueryFormat = 101,
+    OpImageQueryOrder = 102,
+    OpImageQuerySizeLod = 103,
+    OpImageQuerySize = 104,
+    OpImageQueryLod = 105,
+    OpImageQueryLevels = 106,
+    OpImageQuerySamples = 107,
+    OpConvertFToU = 109,
+    OpConvertFToS = 110,
+    OpConvertSToF = 111,
+    OpConvertUToF = 112,
+    OpUConvert = 113,
+    OpSConvert = 114,
+    OpFConvert = 115,
+    OpQuantizeToF16 = 116,
+    OpConvertPtrToU = 117,
+    OpSatConvertSToU = 118,
+    OpSatConvertUToS = 119,
+    OpConvertUToPtr = 120,
+    OpPtrCastToGeneric = 121,
+    OpGenericCastToPtr = 122,
+    OpGenericCastToPtrExplicit = 123,
+    OpBitcast = 124,
+    OpSNegate = 126,
+    OpFNegate = 127,
+    OpIAdd = 128,
+    OpFAdd = 129,
+    OpISub = 130,
+    OpFSub = 131,
+    OpIMul = 132,
+    OpFMul = 133,
+    OpUDiv = 134,
+    OpSDiv = 135,
+    OpFDiv = 136,
+    OpUMod = 137,
+    OpSRem = 138,
+    OpSMod = 139,
+    OpFRem = 140,
+    OpFMod = 141,
+    OpVectorTimesScalar = 142,
+    OpMatrixTimesScalar = 143,
+    OpVectorTimesMatrix = 144,
+    OpMatrixTimesVector = 145,
+    OpMatrixTimesMatrix = 146,
+    OpOuterProduct = 147,
+    OpDot = 148,
+    OpIAddCarry = 149,
+    OpISubBorrow = 150,
+    OpUMulExtended = 151,
+    OpSMulExtended = 152,
+    OpAny = 154,
+    OpAll = 155,
+    OpIsNan = 156,
+    OpIsInf = 157,
+    OpIsFinite = 158,
+    OpIsNormal = 159,
+    OpSignBitSet = 160,
+    OpLessOrGreater = 161,
+    OpOrdered = 162,
+    OpUnordered = 163,
+    OpLogicalEqual = 164,
+    OpLogicalNotEqual = 165,
+    OpLogicalOr = 166,
+    OpLogicalAnd = 167,
+    OpLogicalNot = 168,
+    OpSelect = 169,
+    OpIEqual = 170,
+    OpINotEqual = 171,
+    OpUGreaterThan = 172,
+    OpSGreaterThan = 173,
+    OpUGreaterThanEqual = 174,
+    OpSGreaterThanEqual = 175,
+    OpULessThan = 176,
+    OpSLessThan = 177,
+    OpULessThanEqual = 178,
+    OpSLessThanEqual = 179,
+    OpFOrdEqual = 180,
+    OpFUnordEqual = 181,
+    OpFOrdNotEqual = 182,
+    OpFUnordNotEqual = 183,
+    OpFOrdLessThan = 184,
+    OpFUnordLessThan = 185,
+    OpFOrdGreaterThan = 186,
+    OpFUnordGreaterThan = 187,
+    OpFOrdLessThanEqual = 188,
+    OpFUnordLessThanEqual = 189,
+    OpFOrdGreaterThanEqual = 190,
+    OpFUnordGreaterThanEqual = 191,
+    OpShiftRightLogical = 194,
+    OpShiftRightArithmetic = 195,
+    OpShiftLeftLogical = 196,
+    OpBitwiseOr = 197,
+    OpBitwiseXor = 198,
+    OpBitwiseAnd = 199,
+    OpNot = 200,
+    OpBitFieldInsert = 201,
+    OpBitFieldSExtract = 202,
+    OpBitFieldUExtract = 203,
+    OpBitReverse = 204,
+    OpBitCount = 205,
+    OpDPdx = 207,
+    OpDPdy = 208,
+    OpFwidth = 209,
+    OpDPdxFine = 210,
+    OpDPdyFine = 211,
+    OpFwidthFine = 212,
+    OpDPdxCoarse = 213,
+    OpDPdyCoarse = 214,
+    OpFwidthCoarse = 215,
+    OpEmitVertex = 218,
+    OpEndPrimitive = 219,
+    OpEmitStreamVertex = 220,
+    OpEndStreamPrimitive = 221,
+    OpControlBarrier = 224,
+    OpMemoryBarrier = 225,
+    OpAtomicLoad = 227,
+    OpAtomicStore = 228,
+    OpAtomicExchange = 229,
+    OpAtomicCompareExchange = 230,
+    OpAtomicCompareExchangeWeak = 231,
+    OpAtomicIIncrement = 232,
+    OpAtomicIDecrement = 233,
+    OpAtomicIAdd = 234,
+    OpAtomicISub = 235,
+    OpAtomicSMin = 236,
+    OpAtomicUMin = 237,
+    OpAtomicSMax = 238,
+    OpAtomicUMax = 239,
+    OpAtomicAnd = 240,
+    OpAtomicOr = 241,
+    OpAtomicXor = 242,
+    OpPhi = 245,
+    OpLoopMerge = 246,
+    OpSelectionMerge = 247,
+    OpLabel = 248,
+    OpBranch = 249,
+    OpBranchConditional = 250,
+    OpSwitch = 251,
+    OpKill = 252,
+    OpReturn = 253,
+    OpReturnValue = 254,
+    OpUnreachable = 255,
+    OpLifetimeStart = 256,
+    OpLifetimeStop = 257,
+    OpGroupAsyncCopy = 259,
+    OpGroupWaitEvents = 260,
+    OpGroupAll = 261,
+    OpGroupAny = 262,
+    OpGroupBroadcast = 263,
+    OpGroupIAdd = 264,
+    OpGroupFAdd = 265,
+    OpGroupFMin = 266,
+    OpGroupUMin = 267,
+    OpGroupSMin = 268,
+    OpGroupFMax = 269,
+    OpGroupUMax = 270,
+    OpGroupSMax = 271,
+    OpReadPipe = 274,
+    OpWritePipe = 275,
+    OpReservedReadPipe = 276,
+    OpReservedWritePipe = 277,
+    OpReserveReadPipePackets = 278,
+    OpReserveWritePipePackets = 279,
+    OpCommitReadPipe = 280,
+    OpCommitWritePipe = 281,
+    OpIsValidReserveId = 282,
+    OpGetNumPipePackets = 283,
+    OpGetMaxPipePackets = 284,
+    OpGroupReserveReadPipePackets = 285,
+    OpGroupReserveWritePipePackets = 286,
+    OpGroupCommitReadPipe = 287,
+    OpGroupCommitWritePipe = 288,
+    OpEnqueueMarker = 291,
+    OpEnqueueKernel = 292,
+    OpGetKernelNDrangeSubGroupCount = 293,
+    OpGetKernelNDrangeMaxSubGroupSize = 294,
+    OpGetKernelWorkGroupSize = 295,
+    OpGetKernelPreferredWorkGroupSizeMultiple = 296,
+    OpRetainEvent = 297,
+    OpReleaseEvent = 298,
+    OpCreateUserEvent = 299,
+    OpIsValidEvent = 300,
+    OpSetUserEventStatus = 301,
+    OpCaptureEventProfilingInfo = 302,
+    OpGetDefaultQueue = 303,
+    OpBuildNDRange = 304,
+    OpImageSparseSampleImplicitLod = 305,
+    OpImageSparseSampleExplicitLod = 306,
+    OpImageSparseSampleDrefImplicitLod = 307,
+    OpImageSparseSampleDrefExplicitLod = 308,
+    OpImageSparseSampleProjImplicitLod = 309,
+    OpImageSparseSampleProjExplicitLod = 310,
+    OpImageSparseSampleProjDrefImplicitLod = 311,
+    OpImageSparseSampleProjDrefExplicitLod = 312,
+    OpImageSparseFetch = 313,
+    OpImageSparseGather = 314,
+    OpImageSparseDrefGather = 315,
+    OpImageSparseTexelsResident = 316,
+    OpNoLine = 317,
+    OpAtomicFlagTestAndSet = 318,
+    OpAtomicFlagClear = 319,
+    OpImageSparseRead = 320,
+    OpSizeOf = 321,
+    OpTypePipeStorage = 322,
+    OpConstantPipeStorage = 323,
+    OpCreatePipeFromPipeStorage = 324,
+    OpGetKernelLocalSizeForSubgroupCount = 325,
+    OpGetKernelMaxNumSubgroups = 326,
+    OpTypeNamedBarrier = 327,
+    OpNamedBarrierInitialize = 328,
+    OpMemoryNamedBarrier = 329,
+    OpModuleProcessed = 330,
+    OpExecutionModeId = 331,
+    OpDecorateId = 332,
+    OpGroupNonUniformElect = 333,
+    OpGroupNonUniformAll = 334,
+    OpGroupNonUniformAny = 335,
+    OpGroupNonUniformAllEqual = 336,
+    OpGroupNonUniformBroadcast = 337,
+    OpGroupNonUniformBroadcastFirst = 338,
+    OpGroupNonUniformBallot = 339,
+    OpGroupNonUniformInverseBallot = 340,
+    OpGroupNonUniformBallotBitExtract = 341,
+    OpGroupNonUniformBallotBitCount = 342,
+    OpGroupNonUniformBallotFindLSB = 343,
+    OpGroupNonUniformBallotFindMSB = 344,
+    OpGroupNonUniformShuffle = 345,
+    OpGroupNonUniformShuffleXor = 346,
+    OpGroupNonUniformShuffleUp = 347,
+    OpGroupNonUniformShuffleDown = 348,
+    OpGroupNonUniformIAdd = 349,
+    OpGroupNonUniformFAdd = 350,
+    OpGroupNonUniformIMul = 351,
+    OpGroupNonUniformFMul = 352,
+    OpGroupNonUniformSMin = 353,
+    OpGroupNonUniformUMin = 354,
+    OpGroupNonUniformFMin = 355,
+    OpGroupNonUniformSMax = 356,
+    OpGroupNonUniformUMax = 357,
+    OpGroupNonUniformFMax = 358,
+    OpGroupNonUniformBitwiseAnd = 359,
+    OpGroupNonUniformBitwiseOr = 360,
+    OpGroupNonUniformBitwiseXor = 361,
+    OpGroupNonUniformLogicalAnd = 362,
+    OpGroupNonUniformLogicalOr = 363,
+    OpGroupNonUniformLogicalXor = 364,
+    OpGroupNonUniformQuadBroadcast = 365,
+    OpGroupNonUniformQuadSwap = 366,
+    OpCopyLogical = 400,
+    OpPtrEqual = 401,
+    OpPtrNotEqual = 402,
+    OpPtrDiff = 403,
+    OpTerminateInvocation = 4416,
+    OpSubgroupBallotKHR = 4421,
+    OpSubgroupFirstInvocationKHR = 4422,
+    OpSubgroupAllKHR = 4428,
+    OpSubgroupAnyKHR = 4429,
+    OpSubgroupAllEqualKHR = 4430,
+    OpSubgroupReadInvocationKHR = 4432,
+    OpTraceRayKHR = 4445,
+    OpExecuteCallableKHR = 4446,
+    OpConvertUToAccelerationStructureKHR = 4447,
+    OpIgnoreIntersectionKHR = 4448,
+    OpTerminateRayKHR = 4449,
+    OpSDotKHR = 4450,
+    OpUDotKHR = 4451,
+    OpSUDotKHR = 4452,
+    OpSDotAccSatKHR = 4453,
+    OpUDotAccSatKHR = 4454,
+    OpSUDotAccSatKHR = 4455,
+    OpTypeRayQueryKHR = 4472,
+    OpRayQueryInitializeKHR = 4473,
+    OpRayQueryTerminateKHR = 4474,
+    OpRayQueryGenerateIntersectionKHR = 4475,
+    OpRayQueryConfirmIntersectionKHR = 4476,
+    OpRayQueryProceedKHR = 4477,
+    OpRayQueryGetIntersectionTypeKHR = 4479,
+    OpGroupIAddNonUniformAMD = 5000,
+    OpGroupFAddNonUniformAMD = 5001,
+    OpGroupFMinNonUniformAMD = 5002,
+    OpGroupUMinNonUniformAMD = 5003,
+    OpGroupSMinNonUniformAMD = 5004,
+    OpGroupFMaxNonUniformAMD = 5005,
+    OpGroupUMaxNonUniformAMD = 5006,
+    OpGroupSMaxNonUniformAMD = 5007,
+    OpFragmentMaskFetchAMD = 5011,
+    OpFragmentFetchAMD = 5012,
+    OpReadClockKHR = 5056,
+    OpImageSampleFootprintNV = 5283,
+    OpGroupNonUniformPartitionNV = 5296,
+    OpWritePackedPrimitiveIndices4x8NV = 5299,
+    OpReportIntersectionKHR = 5334,
+    OpReportIntersectionNV = 5334,
+    OpIgnoreIntersectionNV = 5335,
+    OpTerminateRayNV = 5336,
+    OpTraceNV = 5337,
+    OpTraceMotionNV = 5338,
+    OpTraceRayMotionNV = 5339,
+    OpTypeAccelerationStructureKHR = 5341,
+    OpTypeAccelerationStructureNV = 5341,
+    OpExecuteCallableNV = 5344,
+    OpTypeCooperativeMatrixNV = 5358,
+    OpCooperativeMatrixLoadNV = 5359,
+    OpCooperativeMatrixStoreNV = 5360,
+    OpCooperativeMatrixMulAddNV = 5361,
+    OpCooperativeMatrixLengthNV = 5362,
+    OpBeginInvocationInterlockEXT = 5364,
+    OpEndInvocationInterlockEXT = 5365,
+    OpDemoteToHelperInvocationEXT = 5380,
+    OpIsHelperInvocationEXT = 5381,
+    OpConvertUToImageNV = 5391,
+    OpConvertUToSamplerNV = 5392,
+    OpConvertImageToUNV = 5393,
+    OpConvertSamplerToUNV = 5394,
+    OpConvertUToSampledImageNV = 5395,
+    OpConvertSampledImageToUNV = 5396,
+    OpSamplerImageAddressingModeNV = 5397,
+    OpSubgroupShuffleINTEL = 5571,
+    OpSubgroupShuffleDownINTEL = 5572,
+    OpSubgroupShuffleUpINTEL = 5573,
+    OpSubgroupShuffleXorINTEL = 5574,
+    OpSubgroupBlockReadINTEL = 5575,
+    OpSubgroupBlockWriteINTEL = 5576,
+    OpSubgroupImageBlockReadINTEL = 5577,
+    OpSubgroupImageBlockWriteINTEL = 5578,
+    OpSubgroupImageMediaBlockReadINTEL = 5580,
+    OpSubgroupImageMediaBlockWriteINTEL = 5581,
+    OpUCountLeadingZerosINTEL = 5585,
+    OpUCountTrailingZerosINTEL = 5586,
+    OpAbsISubINTEL = 5587,
+    OpAbsUSubINTEL = 5588,
+    OpIAddSatINTEL = 5589,
+    OpUAddSatINTEL = 5590,
+    OpIAverageINTEL = 5591,
+    OpUAverageINTEL = 5592,
+    OpIAverageRoundedINTEL = 5593,
+    OpUAverageRoundedINTEL = 5594,
+    OpISubSatINTEL = 5595,
+    OpUSubSatINTEL = 5596,
+    OpIMul32x16INTEL = 5597,
+    OpUMul32x16INTEL = 5598,
+    OpConstFunctionPointerINTEL = 5600,
+    OpFunctionPointerCallINTEL = 5601,
+    OpAsmTargetINTEL = 5609,
+    OpAsmINTEL = 5610,
+    OpAsmCallINTEL = 5611,
+    OpAtomicFMinEXT = 5614,
+    OpAtomicFMaxEXT = 5615,
+    OpAssumeTrueKHR = 5630,
+    OpExpectKHR = 5631,
+    OpDecorateString = 5632,
+    OpDecorateStringGOOGLE = 5632,
+    OpMemberDecorateString = 5633,
+    OpMemberDecorateStringGOOGLE = 5633,
+    OpVmeImageINTEL = 5699,
+    OpTypeVmeImageINTEL = 5700,
+    OpTypeAvcImePayloadINTEL = 5701,
+    OpTypeAvcRefPayloadINTEL = 5702,
+    OpTypeAvcSicPayloadINTEL = 5703,
+    OpTypeAvcMcePayloadINTEL = 5704,
+    OpTypeAvcMceResultINTEL = 5705,
+    OpTypeAvcImeResultINTEL = 5706,
+    OpTypeAvcImeResultSingleReferenceStreamoutINTEL = 5707,
+    OpTypeAvcImeResultDualReferenceStreamoutINTEL = 5708,
+    OpTypeAvcImeSingleReferenceStreaminINTEL = 5709,
+    OpTypeAvcImeDualReferenceStreaminINTEL = 5710,
+    OpTypeAvcRefResultINTEL = 5711,
+    OpTypeAvcSicResultINTEL = 5712,
+    OpSubgroupAvcMceGetDefaultInterBaseMultiReferencePenaltyINTEL = 5713,
+    OpSubgroupAvcMceSetInterBaseMultiReferencePenaltyINTEL = 5714,
+    OpSubgroupAvcMceGetDefaultInterShapePenaltyINTEL = 5715,
+    OpSubgroupAvcMceSetInterShapePenaltyINTEL = 5716,
+    OpSubgroupAvcMceGetDefaultInterDirectionPenaltyINTEL = 5717,
+    OpSubgroupAvcMceSetInterDirectionPenaltyINTEL = 5718,
+    OpSubgroupAvcMceGetDefaultIntraLumaShapePenaltyINTEL = 5719,
+    OpSubgroupAvcMceGetDefaultInterMotionVectorCostTableINTEL = 5720,
+    OpSubgroupAvcMceGetDefaultHighPenaltyCostTableINTEL = 5721,
+    OpSubgroupAvcMceGetDefaultMediumPenaltyCostTableINTEL = 5722,
+    OpSubgroupAvcMceGetDefaultLowPenaltyCostTableINTEL = 5723,
+    OpSubgroupAvcMceSetMotionVectorCostFunctionINTEL = 5724,
+    OpSubgroupAvcMceGetDefaultIntraLumaModePenaltyINTEL = 5725,
+    OpSubgroupAvcMceGetDefaultNonDcLumaIntraPenaltyINTEL = 5726,
+    OpSubgroupAvcMceGetDefaultIntraChromaModeBasePenaltyINTEL = 5727,
+    OpSubgroupAvcMceSetAcOnlyHaarINTEL = 5728,
+    OpSubgroupAvcMceSetSourceInterlacedFieldPolarityINTEL = 5729,
+    OpSubgroupAvcMceSetSingleReferenceInterlacedFieldPolarityINTEL = 5730,
+    OpSubgroupAvcMceSetDualReferenceInterlacedFieldPolaritiesINTEL = 5731,
+    OpSubgroupAvcMceConvertToImePayloadINTEL = 5732,
+    OpSubgroupAvcMceConvertToImeResultINTEL = 5733,
+    OpSubgroupAvcMceConvertToRefPayloadINTEL = 5734,
+    OpSubgroupAvcMceConvertToRefResultINTEL = 5735,
+    OpSubgroupAvcMceConvertToSicPayloadINTEL = 5736,
+    OpSubgroupAvcMceConvertToSicResultINTEL = 5737,
+    OpSubgroupAvcMceGetMotionVectorsINTEL = 5738,
+    OpSubgroupAvcMceGetInterDistortionsINTEL = 5739,
+    OpSubgroupAvcMceGetBestInterDistortionsINTEL = 5740,
+    OpSubgroupAvcMceGetInterMajorShapeINTEL = 5741,
+    OpSubgroupAvcMceGetInterMinorShapeINTEL = 5742,
+    OpSubgroupAvcMceGetInterDirectionsINTEL = 5743,
+    OpSubgroupAvcMceGetInterMotionVectorCountINTEL = 5744,
+    OpSubgroupAvcMceGetInterReferenceIdsINTEL = 5745,
+    OpSubgroupAvcMceGetInterReferenceInterlacedFieldPolaritiesINTEL = 5746,
+    OpSubgroupAvcImeInitializeINTEL = 5747,
+    OpSubgroupAvcImeSetSingleReferenceINTEL = 5748,
+    OpSubgroupAvcImeSetDualReferenceINTEL = 5749,
+    OpSubgroupAvcImeRefWindowSizeINTEL = 5750,
+    OpSubgroupAvcImeAdjustRefOffsetINTEL = 5751,
+    OpSubgroupAvcImeConvertToMcePayloadINTEL = 5752,
+    OpSubgroupAvcImeSetMaxMotionVectorCountINTEL = 5753,
+    OpSubgroupAvcImeSetUnidirectionalMixDisableINTEL = 5754,
+    OpSubgroupAvcImeSetEarlySearchTerminationThresholdINTEL = 5755,
+    OpSubgroupAvcImeSetWeightedSadINTEL = 5756,
+    OpSubgroupAvcImeEvaluateWithSingleReferenceINTEL = 5757,
+    OpSubgroupAvcImeEvaluateWithDualReferenceINTEL = 5758,
+    OpSubgroupAvcImeEvaluateWithSingleReferenceStreaminINTEL = 5759,
+    OpSubgroupAvcImeEvaluateWithDualReferenceStreaminINTEL = 5760,
+    OpSubgroupAvcImeEvaluateWithSingleReferenceStreamoutINTEL = 5761,
+    OpSubgroupAvcImeEvaluateWithDualReferenceStreamoutINTEL = 5762,
+    OpSubgroupAvcImeEvaluateWithSingleReferenceStreaminoutINTEL = 5763,
+    OpSubgroupAvcImeEvaluateWithDualReferenceStreaminoutINTEL = 5764,
+    OpSubgroupAvcImeConvertToMceResultINTEL = 5765,
+    OpSubgroupAvcImeGetSingleReferenceStreaminINTEL = 5766,
+    OpSubgroupAvcImeGetDualReferenceStreaminINTEL = 5767,
+    OpSubgroupAvcImeStripSingleReferenceStreamoutINTEL = 5768,
+    OpSubgroupAvcImeStripDualReferenceStreamoutINTEL = 5769,
+    OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeMotionVectorsINTEL = 5770,
+    OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeDistortionsINTEL = 5771,
+    OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeReferenceIdsINTEL = 5772,
+    OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeMotionVectorsINTEL = 5773,
+    OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeDistortionsINTEL = 5774,
+    OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeReferenceIdsINTEL = 5775,
+    OpSubgroupAvcImeGetBorderReachedINTEL = 5776,
+    OpSubgroupAvcImeGetTruncatedSearchIndicationINTEL = 5777,
+    OpSubgroupAvcImeGetUnidirectionalEarlySearchTerminationINTEL = 5778,
+    OpSubgroupAvcImeGetWeightingPatternMinimumMotionVectorINTEL = 5779,
+    OpSubgroupAvcImeGetWeightingPatternMinimumDistortionINTEL = 5780,
+    OpSubgroupAvcFmeInitializeINTEL = 5781,
+    OpSubgroupAvcBmeInitializeINTEL = 5782,
+    OpSubgroupAvcRefConvertToMcePayloadINTEL = 5783,
+    OpSubgroupAvcRefSetBidirectionalMixDisableINTEL = 5784,
+    OpSubgroupAvcRefSetBilinearFilterEnableINTEL = 5785,
+    OpSubgroupAvcRefEvaluateWithSingleReferenceINTEL = 5786,
+    OpSubgroupAvcRefEvaluateWithDualReferenceINTEL = 5787,
+    OpSubgroupAvcRefEvaluateWithMultiReferenceINTEL = 5788,
+    OpSubgroupAvcRefEvaluateWithMultiReferenceInterlacedINTEL = 5789,
+    OpSubgroupAvcRefConvertToMceResultINTEL = 5790,
+    OpSubgroupAvcSicInitializeINTEL = 5791,
+    OpSubgroupAvcSicConfigureSkcINTEL = 5792,
+    OpSubgroupAvcSicConfigureIpeLumaINTEL = 5793,
+    OpSubgroupAvcSicConfigureIpeLumaChromaINTEL = 5794,
+    OpSubgroupAvcSicGetMotionVectorMaskINTEL = 5795,
+    OpSubgroupAvcSicConvertToMcePayloadINTEL = 5796,
+    OpSubgroupAvcSicSetIntraLumaShapePenaltyINTEL = 5797,
+    OpSubgroupAvcSicSetIntraLumaModeCostFunctionINTEL = 5798,
+    OpSubgroupAvcSicSetIntraChromaModeCostFunctionINTEL = 5799,
+    OpSubgroupAvcSicSetBilinearFilterEnableINTEL = 5800,
+    OpSubgroupAvcSicSetSkcForwardTransformEnableINTEL = 5801,
+    OpSubgroupAvcSicSetBlockBasedRawSkipSadINTEL = 5802,
+    OpSubgroupAvcSicEvaluateIpeINTEL = 5803,
+    OpSubgroupAvcSicEvaluateWithSingleReferenceINTEL = 5804,
+    OpSubgroupAvcSicEvaluateWithDualReferenceINTEL = 5805,
+    OpSubgroupAvcSicEvaluateWithMultiReferenceINTEL = 5806,
+    OpSubgroupAvcSicEvaluateWithMultiReferenceInterlacedINTEL = 5807,
+    OpSubgroupAvcSicConvertToMceResultINTEL = 5808,
+    OpSubgroupAvcSicGetIpeLumaShapeINTEL = 5809,
+    OpSubgroupAvcSicGetBestIpeLumaDistortionINTEL = 5810,
+    OpSubgroupAvcSicGetBestIpeChromaDistortionINTEL = 5811,
+    OpSubgroupAvcSicGetPackedIpeLumaModesINTEL = 5812,
+    OpSubgroupAvcSicGetIpeChromaModeINTEL = 5813,
+    OpSubgroupAvcSicGetPackedSkcLumaCountThresholdINTEL = 5814,
+    OpSubgroupAvcSicGetPackedSkcLumaSumThresholdINTEL = 5815,
+    OpSubgroupAvcSicGetInterRawSadsINTEL = 5816,
+    OpVariableLengthArrayINTEL = 5818,
+    OpSaveMemoryINTEL = 5819,
+    OpRestoreMemoryINTEL = 5820,
+    OpArbitraryFloatSinCosPiINTEL = 5840,
+    OpArbitraryFloatCastINTEL = 5841,
+    OpArbitraryFloatCastFromIntINTEL = 5842,
+    OpArbitraryFloatCastToIntINTEL = 5843,
+    OpArbitraryFloatAddINTEL = 5846,
+    OpArbitraryFloatSubINTEL = 5847,
+    OpArbitraryFloatMulINTEL = 5848,
+    OpArbitraryFloatDivINTEL = 5849,
+    OpArbitraryFloatGTINTEL = 5850,
+    OpArbitraryFloatGEINTEL = 5851,
+    OpArbitraryFloatLTINTEL = 5852,
+    OpArbitraryFloatLEINTEL = 5853,
+    OpArbitraryFloatEQINTEL = 5854,
+    OpArbitraryFloatRecipINTEL = 5855,
+    OpArbitraryFloatRSqrtINTEL = 5856,
+    OpArbitraryFloatCbrtINTEL = 5857,
+    OpArbitraryFloatHypotINTEL = 5858,
+    OpArbitraryFloatSqrtINTEL = 5859,
+    OpArbitraryFloatLogINTEL = 5860,
+    OpArbitraryFloatLog2INTEL = 5861,
+    OpArbitraryFloatLog10INTEL = 5862,
+    OpArbitraryFloatLog1pINTEL = 5863,
+    OpArbitraryFloatExpINTEL = 5864,
+    OpArbitraryFloatExp2INTEL = 5865,
+    OpArbitraryFloatExp10INTEL = 5866,
+    OpArbitraryFloatExpm1INTEL = 5867,
+    OpArbitraryFloatSinINTEL = 5868,
+    OpArbitraryFloatCosINTEL = 5869,
+    OpArbitraryFloatSinCosINTEL = 5870,
+    OpArbitraryFloatSinPiINTEL = 5871,
+    OpArbitraryFloatCosPiINTEL = 5872,
+    OpArbitraryFloatASinINTEL = 5873,
+    OpArbitraryFloatASinPiINTEL = 5874,
+    OpArbitraryFloatACosINTEL = 5875,
+    OpArbitraryFloatACosPiINTEL = 5876,
+    OpArbitraryFloatATanINTEL = 5877,
+    OpArbitraryFloatATanPiINTEL = 5878,
+    OpArbitraryFloatATan2INTEL = 5879,
+    OpArbitraryFloatPowINTEL = 5880,
+    OpArbitraryFloatPowRINTEL = 5881,
+    OpArbitraryFloatPowNINTEL = 5882,
+    OpLoopControlINTEL = 5887,
+    OpFixedSqrtINTEL = 5923,
+    OpFixedRecipINTEL = 5924,
+    OpFixedRsqrtINTEL = 5925,
+    OpFixedSinINTEL = 5926,
+    OpFixedCosINTEL = 5927,
+    OpFixedSinCosINTEL = 5928,
+    OpFixedSinPiINTEL = 5929,
+    OpFixedCosPiINTEL = 5930,
+    OpFixedSinCosPiINTEL = 5931,
+    OpFixedLogINTEL = 5932,
+    OpFixedExpINTEL = 5933,
+    OpPtrCastToCrossWorkgroupINTEL = 5934,
+    OpCrossWorkgroupCastToPtrINTEL = 5938,
+    OpReadPipeBlockingINTEL = 5946,
+    OpWritePipeBlockingINTEL = 5947,
+    OpFPGARegINTEL = 5949,
+    OpRayQueryGetRayTMinKHR = 6016,
+    OpRayQueryGetRayFlagsKHR = 6017,
+    OpRayQueryGetIntersectionTKHR = 6018,
+    OpRayQueryGetIntersectionInstanceCustomIndexKHR = 6019,
+    OpRayQueryGetIntersectionInstanceIdKHR = 6020,
+    OpRayQueryGetIntersectionInstanceShaderBindingTableRecordOffsetKHR = 6021,
+    OpRayQueryGetIntersectionGeometryIndexKHR = 6022,
+    OpRayQueryGetIntersectionPrimitiveIndexKHR = 6023,
+    OpRayQueryGetIntersectionBarycentricsKHR = 6024,
+    OpRayQueryGetIntersectionFrontFaceKHR = 6025,
+    OpRayQueryGetIntersectionCandidateAABBOpaqueKHR = 6026,
+    OpRayQueryGetIntersectionObjectRayDirectionKHR = 6027,
+    OpRayQueryGetIntersectionObjectRayOriginKHR = 6028,
+    OpRayQueryGetWorldRayDirectionKHR = 6029,
+    OpRayQueryGetWorldRayOriginKHR = 6030,
+    OpRayQueryGetIntersectionObjectToWorldKHR = 6031,
+    OpRayQueryGetIntersectionWorldToObjectKHR = 6032,
+    OpAtomicFAddEXT = 6035,
+    OpTypeBufferSurfaceINTEL = 6086,
+    OpTypeStructContinuedINTEL = 6090,
+    OpConstantCompositeContinuedINTEL = 6091,
+    OpSpecConstantCompositeContinuedINTEL = 6092,
+    OpMax = 0x7fffffff,
+};
+
+#ifdef SPV_ENABLE_UTILITY_CODE
+inline void HasResultAndType(Op opcode, bool *hasResult, bool *hasResultType) {
+    *hasResult = *hasResultType = false;
+    switch (opcode) {
+    default: /* unknown opcode */ break;
+    case OpNop: *hasResult = false; *hasResultType = false; break;
+    case OpUndef: *hasResult = true; *hasResultType = true; break;
+    case OpSourceContinued: *hasResult = false; *hasResultType = false; break;
+    case OpSource: *hasResult = false; *hasResultType = false; break;
+    case OpSourceExtension: *hasResult = false; *hasResultType = false; break;
+    case OpName: *hasResult = false; *hasResultType = false; break;
+    case OpMemberName: *hasResult = false; *hasResultType = false; break;
+    case OpString: *hasResult = true; *hasResultType = false; break;
+    case OpLine: *hasResult = false; *hasResultType = false; break;
+    case OpExtension: *hasResult = false; *hasResultType = false; break;
+    case OpExtInstImport: *hasResult = true; *hasResultType = false; break;
+    case OpExtInst: *hasResult = true; *hasResultType = true; break;
+    case OpMemoryModel: *hasResult = false; *hasResultType = false; break;
+    case OpEntryPoint: *hasResult = false; *hasResultType = false; break;
+    case OpExecutionMode: *hasResult = false; *hasResultType = false; break;
+    case OpCapability: *hasResult = false; *hasResultType = false; break;
+    case OpTypeVoid: *hasResult = true; *hasResultType = false; break;
+    case OpTypeBool: *hasResult = true; *hasResultType = false; break;
+    case OpTypeInt: *hasResult = true; *hasResultType = false; break;
+    case OpTypeFloat: *hasResult = true; *hasResultType = false; break;
+    case OpTypeVector: *hasResult = true; *hasResultType = false; break;
+    case OpTypeMatrix: *hasResult = true; *hasResultType = false; break;
+    case OpTypeImage: *hasResult = true; *hasResultType = false; break;
+    case OpTypeSampler: *hasResult = true; *hasResultType = false; break;
+    case OpTypeSampledImage: *hasResult = true; *hasResultType = false; break;
+    case OpTypeArray: *hasResult = true; *hasResultType = false; break;
+    case OpTypeRuntimeArray: *hasResult = true; *hasResultType = false; break;
+    case OpTypeStruct: *hasResult = true; *hasResultType = false; break;
+    case OpTypeOpaque: *hasResult = true; *hasResultType = false; break;
+    case OpTypePointer: *hasResult = true; *hasResultType = false; break;
+    case OpTypeFunction: *hasResult = true; *hasResultType = false; break;
+    case OpTypeEvent: *hasResult = true; *hasResultType = false; break;
+    case OpTypeDeviceEvent: *hasResult = true; *hasResultType = false; break;
+    case OpTypeReserveId: *hasResult = true; *hasResultType = false; break;
+    case OpTypeQueue: *hasResult = true; *hasResultType = false; break;
+    case OpTypePipe: *hasResult = true; *hasResultType = false; break;
+    case OpTypeForwardPointer: *hasResult = false; *hasResultType = false; break;
+    case OpConstantTrue: *hasResult = true; *hasResultType = true; break;
+    case OpConstantFalse: *hasResult = true; *hasResultType = true; break;
+    case OpConstant: *hasResult = true; *hasResultType = true; break;
+    case OpConstantComposite: *hasResult = true; *hasResultType = true; break;
+    case OpConstantSampler: *hasResult = true; *hasResultType = true; break;
+    case OpConstantNull: *hasResult = true; *hasResultType = true; break;
+    case OpSpecConstantTrue: *hasResult = true; *hasResultType = true; break;
+    case OpSpecConstantFalse: *hasResult = true; *hasResultType = true; break;
+    case OpSpecConstant: *hasResult = true; *hasResultType = true; break;
+    case OpSpecConstantComposite: *hasResult = true; *hasResultType = true; break;
+    case OpSpecConstantOp: *hasResult = true; *hasResultType = true; break;
+    case OpFunction: *hasResult = true; *hasResultType = true; break;
+    case OpFunctionParameter: *hasResult = true; *hasResultType = true; break;
+    case OpFunctionEnd: *hasResult = false; *hasResultType = false; break;
+    case OpFunctionCall: *hasResult = true; *hasResultType = true; break;
+    case OpVariable: *hasResult = true; *hasResultType = true; break;
+    case OpImageTexelPointer: *hasResult = true; *hasResultType = true; break;
+    case OpLoad: *hasResult = true; *hasResultType = true; break;
+    case OpStore: *hasResult = false; *hasResultType = false; break;
+    case OpCopyMemory: *hasResult = false; *hasResultType = false; break;
+    case OpCopyMemorySized: *hasResult = false; *hasResultType = false; break;
+    case OpAccessChain: *hasResult = true; *hasResultType = true; break;
+    case OpInBoundsAccessChain: *hasResult = true; *hasResultType = true; break;
+    case OpPtrAccessChain: *hasResult = true; *hasResultType = true; break;
+    case OpArrayLength: *hasResult = true; *hasResultType = true; break;
+    case OpGenericPtrMemSemantics: *hasResult = true; *hasResultType = true; break;
+    case OpInBoundsPtrAccessChain: *hasResult = true; *hasResultType = true; break;
+    case OpDecorate: *hasResult = false; *hasResultType = false; break;
+    case OpMemberDecorate: *hasResult = false; *hasResultType = false; break;
+    case OpDecorationGroup: *hasResult = true; *hasResultType = false; break;
+    case OpGroupDecorate: *hasResult = false; *hasResultType = false; break;
+    case OpGroupMemberDecorate: *hasResult = false; *hasResultType = false; break;
+    case OpVectorExtractDynamic: *hasResult = true; *hasResultType = true; break;
+    case OpVectorInsertDynamic: *hasResult = true; *hasResultType = true; break;
+    case OpVectorShuffle: *hasResult = true; *hasResultType = true; break;
+    case OpCompositeConstruct: *hasResult = true; *hasResultType = true; break;
+    case OpCompositeExtract: *hasResult = true; *hasResultType = true; break;
+    case OpCompositeInsert: *hasResult = true; *hasResultType = true; break;
+    case OpCopyObject: *hasResult = true; *hasResultType = true; break;
+    case OpTranspose: *hasResult = true; *hasResultType = true; break;
+    case OpSampledImage: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleDrefImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleDrefExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleProjImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleProjExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleProjDrefImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleProjDrefExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageFetch: *hasResult = true; *hasResultType = true; break;
+    case OpImageGather: *hasResult = true; *hasResultType = true; break;
+    case OpImageDrefGather: *hasResult = true; *hasResultType = true; break;
+    case OpImageRead: *hasResult = true; *hasResultType = true; break;
+    case OpImageWrite: *hasResult = false; *hasResultType = false; break;
+    case OpImage: *hasResult = true; *hasResultType = true; break;
+    case OpImageQueryFormat: *hasResult = true; *hasResultType = true; break;
+    case OpImageQueryOrder: *hasResult = true; *hasResultType = true; break;
+    case OpImageQuerySizeLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageQuerySize: *hasResult = true; *hasResultType = true; break;
+    case OpImageQueryLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageQueryLevels: *hasResult = true; *hasResultType = true; break;
+    case OpImageQuerySamples: *hasResult = true; *hasResultType = true; break;
+    case OpConvertFToU: *hasResult = true; *hasResultType = true; break;
+    case OpConvertFToS: *hasResult = true; *hasResultType = true; break;
+    case OpConvertSToF: *hasResult = true; *hasResultType = true; break;
+    case OpConvertUToF: *hasResult = true; *hasResultType = true; break;
+    case OpUConvert: *hasResult = true; *hasResultType = true; break;
+    case OpSConvert: *hasResult = true; *hasResultType = true; break;
+    case OpFConvert: *hasResult = true; *hasResultType = true; break;
+    case OpQuantizeToF16: *hasResult = true; *hasResultType = true; break;
+    case OpConvertPtrToU: *hasResult = true; *hasResultType = true; break;
+    case OpSatConvertSToU: *hasResult = true; *hasResultType = true; break;
+    case OpSatConvertUToS: *hasResult = true; *hasResultType = true; break;
+    case OpConvertUToPtr: *hasResult = true; *hasResultType = true; break;
+    case OpPtrCastToGeneric: *hasResult = true; *hasResultType = true; break;
+    case OpGenericCastToPtr: *hasResult = true; *hasResultType = true; break;
+    case OpGenericCastToPtrExplicit: *hasResult = true; *hasResultType = true; break;
+    case OpBitcast: *hasResult = true; *hasResultType = true; break;
+    case OpSNegate: *hasResult = true; *hasResultType = true; break;
+    case OpFNegate: *hasResult = true; *hasResultType = true; break;
+    case OpIAdd: *hasResult = true; *hasResultType = true; break;
+    case OpFAdd: *hasResult = true; *hasResultType = true; break;
+    case OpISub: *hasResult = true; *hasResultType = true; break;
+    case OpFSub: *hasResult = true; *hasResultType = true; break;
+    case OpIMul: *hasResult = true; *hasResultType = true; break;
+    case OpFMul: *hasResult = true; *hasResultType = true; break;
+    case OpUDiv: *hasResult = true; *hasResultType = true; break;
+    case OpSDiv: *hasResult = true; *hasResultType = true; break;
+    case OpFDiv: *hasResult = true; *hasResultType = true; break;
+    case OpUMod: *hasResult = true; *hasResultType = true; break;
+    case OpSRem: *hasResult = true; *hasResultType = true; break;
+    case OpSMod: *hasResult = true; *hasResultType = true; break;
+    case OpFRem: *hasResult = true; *hasResultType = true; break;
+    case OpFMod: *hasResult = true; *hasResultType = true; break;
+    case OpVectorTimesScalar: *hasResult = true; *hasResultType = true; break;
+    case OpMatrixTimesScalar: *hasResult = true; *hasResultType = true; break;
+    case OpVectorTimesMatrix: *hasResult = true; *hasResultType = true; break;
+    case OpMatrixTimesVector: *hasResult = true; *hasResultType = true; break;
+    case OpMatrixTimesMatrix: *hasResult = true; *hasResultType = true; break;
+    case OpOuterProduct: *hasResult = true; *hasResultType = true; break;
+    case OpDot: *hasResult = true; *hasResultType = true; break;
+    case OpIAddCarry: *hasResult = true; *hasResultType = true; break;
+    case OpISubBorrow: *hasResult = true; *hasResultType = true; break;
+    case OpUMulExtended: *hasResult = true; *hasResultType = true; break;
+    case OpSMulExtended: *hasResult = true; *hasResultType = true; break;
+    case OpAny: *hasResult = true; *hasResultType = true; break;
+    case OpAll: *hasResult = true; *hasResultType = true; break;
+    case OpIsNan: *hasResult = true; *hasResultType = true; break;
+    case OpIsInf: *hasResult = true; *hasResultType = true; break;
+    case OpIsFinite: *hasResult = true; *hasResultType = true; break;
+    case OpIsNormal: *hasResult = true; *hasResultType = true; break;
+    case OpSignBitSet: *hasResult = true; *hasResultType = true; break;
+    case OpLessOrGreater: *hasResult = true; *hasResultType = true; break;
+    case OpOrdered: *hasResult = true; *hasResultType = true; break;
+    case OpUnordered: *hasResult = true; *hasResultType = true; break;
+    case OpLogicalEqual: *hasResult = true; *hasResultType = true; break;
+    case OpLogicalNotEqual: *hasResult = true; *hasResultType = true; break;
+    case OpLogicalOr: *hasResult = true; *hasResultType = true; break;
+    case OpLogicalAnd: *hasResult = true; *hasResultType = true; break;
+    case OpLogicalNot: *hasResult = true; *hasResultType = true; break;
+    case OpSelect: *hasResult = true; *hasResultType = true; break;
+    case OpIEqual: *hasResult = true; *hasResultType = true; break;
+    case OpINotEqual: *hasResult = true; *hasResultType = true; break;
+    case OpUGreaterThan: *hasResult = true; *hasResultType = true; break;
+    case OpSGreaterThan: *hasResult = true; *hasResultType = true; break;
+    case OpUGreaterThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpSGreaterThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpULessThan: *hasResult = true; *hasResultType = true; break;
+    case OpSLessThan: *hasResult = true; *hasResultType = true; break;
+    case OpULessThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpSLessThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdNotEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordNotEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdLessThan: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordLessThan: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdGreaterThan: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordGreaterThan: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdLessThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordLessThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFOrdGreaterThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpFUnordGreaterThanEqual: *hasResult = true; *hasResultType = true; break;
+    case OpShiftRightLogical: *hasResult = true; *hasResultType = true; break;
+    case OpShiftRightArithmetic: *hasResult = true; *hasResultType = true; break;
+    case OpShiftLeftLogical: *hasResult = true; *hasResultType = true; break;
+    case OpBitwiseOr: *hasResult = true; *hasResultType = true; break;
+    case OpBitwiseXor: *hasResult = true; *hasResultType = true; break;
+    case OpBitwiseAnd: *hasResult = true; *hasResultType = true; break;
+    case OpNot: *hasResult = true; *hasResultType = true; break;
+    case OpBitFieldInsert: *hasResult = true; *hasResultType = true; break;
+    case OpBitFieldSExtract: *hasResult = true; *hasResultType = true; break;
+    case OpBitFieldUExtract: *hasResult = true; *hasResultType = true; break;
+    case OpBitReverse: *hasResult = true; *hasResultType = true; break;
+    case OpBitCount: *hasResult = true; *hasResultType = true; break;
+    case OpDPdx: *hasResult = true; *hasResultType = true; break;
+    case OpDPdy: *hasResult = true; *hasResultType = true; break;
+    case OpFwidth: *hasResult = true; *hasResultType = true; break;
+    case OpDPdxFine: *hasResult = true; *hasResultType = true; break;
+    case OpDPdyFine: *hasResult = true; *hasResultType = true; break;
+    case OpFwidthFine: *hasResult = true; *hasResultType = true; break;
+    case OpDPdxCoarse: *hasResult = true; *hasResultType = true; break;
+    case OpDPdyCoarse: *hasResult = true; *hasResultType = true; break;
+    case OpFwidthCoarse: *hasResult = true; *hasResultType = true; break;
+    case OpEmitVertex: *hasResult = false; *hasResultType = false; break;
+    case OpEndPrimitive: *hasResult = false; *hasResultType = false; break;
+    case OpEmitStreamVertex: *hasResult = false; *hasResultType = false; break;
+    case OpEndStreamPrimitive: *hasResult = false; *hasResultType = false; break;
+    case OpControlBarrier: *hasResult = false; *hasResultType = false; break;
+    case OpMemoryBarrier: *hasResult = false; *hasResultType = false; break;
+    case OpAtomicLoad: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicStore: *hasResult = false; *hasResultType = false; break;
+    case OpAtomicExchange: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicCompareExchange: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicCompareExchangeWeak: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicIIncrement: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicIDecrement: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicIAdd: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicISub: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicSMin: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicUMin: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicSMax: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicUMax: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicAnd: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicOr: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicXor: *hasResult = true; *hasResultType = true; break;
+    case OpPhi: *hasResult = true; *hasResultType = true; break;
+    case OpLoopMerge: *hasResult = false; *hasResultType = false; break;
+    case OpSelectionMerge: *hasResult = false; *hasResultType = false; break;
+    case OpLabel: *hasResult = true; *hasResultType = false; break;
+    case OpBranch: *hasResult = false; *hasResultType = false; break;
+    case OpBranchConditional: *hasResult = false; *hasResultType = false; break;
+    case OpSwitch: *hasResult = false; *hasResultType = false; break;
+    case OpKill: *hasResult = false; *hasResultType = false; break;
+    case OpReturn: *hasResult = false; *hasResultType = false; break;
+    case OpReturnValue: *hasResult = false; *hasResultType = false; break;
+    case OpUnreachable: *hasResult = false; *hasResultType = false; break;
+    case OpLifetimeStart: *hasResult = false; *hasResultType = false; break;
+    case OpLifetimeStop: *hasResult = false; *hasResultType = false; break;
+    case OpGroupAsyncCopy: *hasResult = true; *hasResultType = true; break;
+    case OpGroupWaitEvents: *hasResult = false; *hasResultType = false; break;
+    case OpGroupAll: *hasResult = true; *hasResultType = true; break;
+    case OpGroupAny: *hasResult = true; *hasResultType = true; break;
+    case OpGroupBroadcast: *hasResult = true; *hasResultType = true; break;
+    case OpGroupIAdd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFAdd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupUMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupSMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFMax: *hasResult = true; *hasResultType = true; break;
+    case OpGroupUMax: *hasResult = true; *hasResultType = true; break;
+    case OpGroupSMax: *hasResult = true; *hasResultType = true; break;
+    case OpReadPipe: *hasResult = true; *hasResultType = true; break;
+    case OpWritePipe: *hasResult = true; *hasResultType = true; break;
+    case OpReservedReadPipe: *hasResult = true; *hasResultType = true; break;
+    case OpReservedWritePipe: *hasResult = true; *hasResultType = true; break;
+    case OpReserveReadPipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpReserveWritePipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpCommitReadPipe: *hasResult = false; *hasResultType = false; break;
+    case OpCommitWritePipe: *hasResult = false; *hasResultType = false; break;
+    case OpIsValidReserveId: *hasResult = true; *hasResultType = true; break;
+    case OpGetNumPipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpGetMaxPipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpGroupReserveReadPipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpGroupReserveWritePipePackets: *hasResult = true; *hasResultType = true; break;
+    case OpGroupCommitReadPipe: *hasResult = false; *hasResultType = false; break;
+    case OpGroupCommitWritePipe: *hasResult = false; *hasResultType = false; break;
+    case OpEnqueueMarker: *hasResult = true; *hasResultType = true; break;
+    case OpEnqueueKernel: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelNDrangeSubGroupCount: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelNDrangeMaxSubGroupSize: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelWorkGroupSize: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelPreferredWorkGroupSizeMultiple: *hasResult = true; *hasResultType = true; break;
+    case OpRetainEvent: *hasResult = false; *hasResultType = false; break;
+    case OpReleaseEvent: *hasResult = false; *hasResultType = false; break;
+    case OpCreateUserEvent: *hasResult = true; *hasResultType = true; break;
+    case OpIsValidEvent: *hasResult = true; *hasResultType = true; break;
+    case OpSetUserEventStatus: *hasResult = false; *hasResultType = false; break;
+    case OpCaptureEventProfilingInfo: *hasResult = false; *hasResultType = false; break;
+    case OpGetDefaultQueue: *hasResult = true; *hasResultType = true; break;
+    case OpBuildNDRange: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleDrefImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleDrefExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleProjImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleProjExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleProjDrefImplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseSampleProjDrefExplicitLod: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseFetch: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseGather: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseDrefGather: *hasResult = true; *hasResultType = true; break;
+    case OpImageSparseTexelsResident: *hasResult = true; *hasResultType = true; break;
+    case OpNoLine: *hasResult = false; *hasResultType = false; break;
+    case OpAtomicFlagTestAndSet: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicFlagClear: *hasResult = false; *hasResultType = false; break;
+    case OpImageSparseRead: *hasResult = true; *hasResultType = true; break;
+    case OpSizeOf: *hasResult = true; *hasResultType = true; break;
+    case OpTypePipeStorage: *hasResult = true; *hasResultType = false; break;
+    case OpConstantPipeStorage: *hasResult = true; *hasResultType = true; break;
+    case OpCreatePipeFromPipeStorage: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelLocalSizeForSubgroupCount: *hasResult = true; *hasResultType = true; break;
+    case OpGetKernelMaxNumSubgroups: *hasResult = true; *hasResultType = true; break;
+    case OpTypeNamedBarrier: *hasResult = true; *hasResultType = false; break;
+    case OpNamedBarrierInitialize: *hasResult = true; *hasResultType = true; break;
+    case OpMemoryNamedBarrier: *hasResult = false; *hasResultType = false; break;
+    case OpModuleProcessed: *hasResult = false; *hasResultType = false; break;
+    case OpExecutionModeId: *hasResult = false; *hasResultType = false; break;
+    case OpDecorateId: *hasResult = false; *hasResultType = false; break;
+    case OpGroupNonUniformElect: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformAll: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformAny: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformAllEqual: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBroadcast: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBroadcastFirst: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBallot: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformInverseBallot: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBallotBitExtract: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBallotBitCount: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBallotFindLSB: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBallotFindMSB: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformShuffle: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformShuffleXor: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformShuffleUp: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformShuffleDown: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformIAdd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformFAdd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformIMul: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformFMul: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformSMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformUMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformFMin: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformSMax: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformUMax: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformFMax: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBitwiseAnd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBitwiseOr: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformBitwiseXor: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformLogicalAnd: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformLogicalOr: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformLogicalXor: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformQuadBroadcast: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformQuadSwap: *hasResult = true; *hasResultType = true; break;
+    case OpCopyLogical: *hasResult = true; *hasResultType = true; break;
+    case OpPtrEqual: *hasResult = true; *hasResultType = true; break;
+    case OpPtrNotEqual: *hasResult = true; *hasResultType = true; break;
+    case OpPtrDiff: *hasResult = true; *hasResultType = true; break;
+    case OpTerminateInvocation: *hasResult = false; *hasResultType = false; break;
+    case OpSubgroupBallotKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupFirstInvocationKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAllKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAnyKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAllEqualKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupReadInvocationKHR: *hasResult = true; *hasResultType = true; break;
+    case OpTraceRayKHR: *hasResult = false; *hasResultType = false; break;
+    case OpExecuteCallableKHR: *hasResult = false; *hasResultType = false; break;
+    case OpConvertUToAccelerationStructureKHR: *hasResult = true; *hasResultType = true; break;
+    case OpIgnoreIntersectionKHR: *hasResult = false; *hasResultType = false; break;
+    case OpTerminateRayKHR: *hasResult = false; *hasResultType = false; break;
+    case OpSDotKHR: *hasResult = true; *hasResultType = true; break;
+    case OpUDotKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSUDotKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSDotAccSatKHR: *hasResult = true; *hasResultType = true; break;
+    case OpUDotAccSatKHR: *hasResult = true; *hasResultType = true; break;
+    case OpSUDotAccSatKHR: *hasResult = true; *hasResultType = true; break;
+    case OpTypeRayQueryKHR: *hasResult = true; *hasResultType = false; break;
+    case OpRayQueryInitializeKHR: *hasResult = false; *hasResultType = false; break;
+    case OpRayQueryTerminateKHR: *hasResult = false; *hasResultType = false; break;
+    case OpRayQueryGenerateIntersectionKHR: *hasResult = false; *hasResultType = false; break;
+    case OpRayQueryConfirmIntersectionKHR: *hasResult = false; *hasResultType = false; break;
+    case OpRayQueryProceedKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionTypeKHR: *hasResult = true; *hasResultType = true; break;
+    case OpGroupIAddNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFAddNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFMinNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupUMinNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupSMinNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupFMaxNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupUMaxNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpGroupSMaxNonUniformAMD: *hasResult = true; *hasResultType = true; break;
+    case OpFragmentMaskFetchAMD: *hasResult = true; *hasResultType = true; break;
+    case OpFragmentFetchAMD: *hasResult = true; *hasResultType = true; break;
+    case OpReadClockKHR: *hasResult = true; *hasResultType = true; break;
+    case OpImageSampleFootprintNV: *hasResult = true; *hasResultType = true; break;
+    case OpGroupNonUniformPartitionNV: *hasResult = true; *hasResultType = true; break;
+    case OpWritePackedPrimitiveIndices4x8NV: *hasResult = false; *hasResultType = false; break;
+    case OpReportIntersectionNV: *hasResult = true; *hasResultType = true; break;
+    case OpIgnoreIntersectionNV: *hasResult = false; *hasResultType = false; break;
+    case OpTerminateRayNV: *hasResult = false; *hasResultType = false; break;
+    case OpTraceNV: *hasResult = false; *hasResultType = false; break;
+    case OpTraceMotionNV: *hasResult = false; *hasResultType = false; break;
+    case OpTraceRayMotionNV: *hasResult = false; *hasResultType = false; break;
+    case OpTypeAccelerationStructureNV: *hasResult = true; *hasResultType = false; break;
+    case OpExecuteCallableNV: *hasResult = false; *hasResultType = false; break;
+    case OpTypeCooperativeMatrixNV: *hasResult = true; *hasResultType = false; break;
+    case OpCooperativeMatrixLoadNV: *hasResult = true; *hasResultType = true; break;
+    case OpCooperativeMatrixStoreNV: *hasResult = false; *hasResultType = false; break;
+    case OpCooperativeMatrixMulAddNV: *hasResult = true; *hasResultType = true; break;
+    case OpCooperativeMatrixLengthNV: *hasResult = true; *hasResultType = true; break;
+    case OpBeginInvocationInterlockEXT: *hasResult = false; *hasResultType = false; break;
+    case OpEndInvocationInterlockEXT: *hasResult = false; *hasResultType = false; break;
+    case OpDemoteToHelperInvocationEXT: *hasResult = false; *hasResultType = false; break;
+    case OpIsHelperInvocationEXT: *hasResult = true; *hasResultType = true; break;
+    case OpConvertUToImageNV: *hasResult = true; *hasResultType = true; break;
+    case OpConvertUToSamplerNV: *hasResult = true; *hasResultType = true; break;
+    case OpConvertImageToUNV: *hasResult = true; *hasResultType = true; break;
+    case OpConvertSamplerToUNV: *hasResult = true; *hasResultType = true; break;
+    case OpConvertUToSampledImageNV: *hasResult = true; *hasResultType = true; break;
+    case OpConvertSampledImageToUNV: *hasResult = true; *hasResultType = true; break;
+    case OpSamplerImageAddressingModeNV: *hasResult = false; *hasResultType = false; break;
+    case OpSubgroupShuffleINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupShuffleDownINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupShuffleUpINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupShuffleXorINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupBlockReadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupBlockWriteINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpSubgroupImageBlockReadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupImageBlockWriteINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpSubgroupImageMediaBlockReadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupImageMediaBlockWriteINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpUCountLeadingZerosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUCountTrailingZerosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAbsISubINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAbsUSubINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpIAddSatINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUAddSatINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpIAverageINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUAverageINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpIAverageRoundedINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUAverageRoundedINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpISubSatINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUSubSatINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpIMul32x16INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpUMul32x16INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpConstFunctionPointerINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFunctionPointerCallINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAsmTargetINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAsmINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAsmCallINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicFMinEXT: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicFMaxEXT: *hasResult = true; *hasResultType = true; break;
+    case OpAssumeTrueKHR: *hasResult = false; *hasResultType = false; break;
+    case OpExpectKHR: *hasResult = true; *hasResultType = true; break;
+    case OpDecorateString: *hasResult = false; *hasResultType = false; break;
+    case OpMemberDecorateString: *hasResult = false; *hasResultType = false; break;
+    case OpVmeImageINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpTypeVmeImageINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImePayloadINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcRefPayloadINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcSicPayloadINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcMcePayloadINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcMceResultINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImeResultINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImeResultSingleReferenceStreamoutINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImeResultDualReferenceStreamoutINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImeSingleReferenceStreaminINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcImeDualReferenceStreaminINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcRefResultINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeAvcSicResultINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpSubgroupAvcMceGetDefaultInterBaseMultiReferencePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetInterBaseMultiReferencePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultInterShapePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetInterShapePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultInterDirectionPenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetInterDirectionPenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultIntraLumaShapePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultInterMotionVectorCostTableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultHighPenaltyCostTableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultMediumPenaltyCostTableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultLowPenaltyCostTableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetMotionVectorCostFunctionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultIntraLumaModePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultNonDcLumaIntraPenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetDefaultIntraChromaModeBasePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetAcOnlyHaarINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetSourceInterlacedFieldPolarityINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetSingleReferenceInterlacedFieldPolarityINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceSetDualReferenceInterlacedFieldPolaritiesINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToImePayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToImeResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToRefPayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToRefResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToSicPayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceConvertToSicResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetMotionVectorsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterDistortionsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetBestInterDistortionsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterMajorShapeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterMinorShapeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterDirectionsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterMotionVectorCountINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterReferenceIdsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcMceGetInterReferenceInterlacedFieldPolaritiesINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeInitializeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetSingleReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetDualReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeRefWindowSizeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeAdjustRefOffsetINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeConvertToMcePayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetMaxMotionVectorCountINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetUnidirectionalMixDisableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetEarlySearchTerminationThresholdINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeSetWeightedSadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithSingleReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithDualReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithSingleReferenceStreaminINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithDualReferenceStreaminINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithSingleReferenceStreamoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithDualReferenceStreamoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithSingleReferenceStreaminoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeEvaluateWithDualReferenceStreaminoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeConvertToMceResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetSingleReferenceStreaminINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetDualReferenceStreaminINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeStripSingleReferenceStreamoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeStripDualReferenceStreamoutINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeMotionVectorsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeDistortionsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutSingleReferenceMajorShapeReferenceIdsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeMotionVectorsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeDistortionsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetStreamoutDualReferenceMajorShapeReferenceIdsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetBorderReachedINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetTruncatedSearchIndicationINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetUnidirectionalEarlySearchTerminationINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetWeightingPatternMinimumMotionVectorINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcImeGetWeightingPatternMinimumDistortionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcFmeInitializeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcBmeInitializeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefConvertToMcePayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefSetBidirectionalMixDisableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefSetBilinearFilterEnableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefEvaluateWithSingleReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefEvaluateWithDualReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefEvaluateWithMultiReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefEvaluateWithMultiReferenceInterlacedINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcRefConvertToMceResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicInitializeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicConfigureSkcINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicConfigureIpeLumaINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicConfigureIpeLumaChromaINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetMotionVectorMaskINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicConvertToMcePayloadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetIntraLumaShapePenaltyINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetIntraLumaModeCostFunctionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetIntraChromaModeCostFunctionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetBilinearFilterEnableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetSkcForwardTransformEnableINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicSetBlockBasedRawSkipSadINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicEvaluateIpeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicEvaluateWithSingleReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicEvaluateWithDualReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicEvaluateWithMultiReferenceINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicEvaluateWithMultiReferenceInterlacedINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicConvertToMceResultINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetIpeLumaShapeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetBestIpeLumaDistortionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetBestIpeChromaDistortionINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetPackedIpeLumaModesINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetIpeChromaModeINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetPackedSkcLumaCountThresholdINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetPackedSkcLumaSumThresholdINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSubgroupAvcSicGetInterRawSadsINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpVariableLengthArrayINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpSaveMemoryINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpRestoreMemoryINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpArbitraryFloatSinCosPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCastINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCastFromIntINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCastToIntINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatAddINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatSubINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatMulINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatDivINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatGTINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatGEINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLTINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLEINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatEQINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatRecipINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatRSqrtINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCbrtINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatHypotINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatSqrtINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLogINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLog2INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLog10INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatLog1pINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatExpINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatExp2INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatExp10INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatExpm1INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatSinINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatSinCosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatSinPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatCosPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatASinINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatASinPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatACosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatACosPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatATanINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatATanPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatATan2INTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatPowINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatPowRINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpArbitraryFloatPowNINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpLoopControlINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpFixedSqrtINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedRecipINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedRsqrtINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedSinINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedCosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedSinCosINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedSinPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedCosPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedSinCosPiINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedLogINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFixedExpINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpPtrCastToCrossWorkgroupINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpCrossWorkgroupCastToPtrINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpReadPipeBlockingINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpWritePipeBlockingINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpFPGARegINTEL: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetRayTMinKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetRayFlagsKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionTKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionInstanceCustomIndexKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionInstanceIdKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionInstanceShaderBindingTableRecordOffsetKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionGeometryIndexKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionPrimitiveIndexKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionBarycentricsKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionFrontFaceKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionCandidateAABBOpaqueKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionObjectRayDirectionKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionObjectRayOriginKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetWorldRayDirectionKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetWorldRayOriginKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionObjectToWorldKHR: *hasResult = true; *hasResultType = true; break;
+    case OpRayQueryGetIntersectionWorldToObjectKHR: *hasResult = true; *hasResultType = true; break;
+    case OpAtomicFAddEXT: *hasResult = true; *hasResultType = true; break;
+    case OpTypeBufferSurfaceINTEL: *hasResult = true; *hasResultType = false; break;
+    case OpTypeStructContinuedINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpConstantCompositeContinuedINTEL: *hasResult = false; *hasResultType = false; break;
+    case OpSpecConstantCompositeContinuedINTEL: *hasResult = false; *hasResultType = false; break;
+    }
+}
+#endif /* SPV_ENABLE_UTILITY_CODE */
+
+// Overload operator| for mask bit combining
+
+inline ImageOperandsMask operator|(ImageOperandsMask a, ImageOperandsMask b) { return ImageOperandsMask(unsigned(a) | unsigned(b)); }
+inline FPFastMathModeMask operator|(FPFastMathModeMask a, FPFastMathModeMask b) { return FPFastMathModeMask(unsigned(a) | unsigned(b)); }
+inline SelectionControlMask operator|(SelectionControlMask a, SelectionControlMask b) { return SelectionControlMask(unsigned(a) | unsigned(b)); }
+inline LoopControlMask operator|(LoopControlMask a, LoopControlMask b) { return LoopControlMask(unsigned(a) | unsigned(b)); }
+inline FunctionControlMask operator|(FunctionControlMask a, FunctionControlMask b) { return FunctionControlMask(unsigned(a) | unsigned(b)); }
+inline MemorySemanticsMask operator|(MemorySemanticsMask a, MemorySemanticsMask b) { return MemorySemanticsMask(unsigned(a) | unsigned(b)); }
+inline MemoryAccessMask operator|(MemoryAccessMask a, MemoryAccessMask b) { return MemoryAccessMask(unsigned(a) | unsigned(b)); }
+inline KernelProfilingInfoMask operator|(KernelProfilingInfoMask a, KernelProfilingInfoMask b) { return KernelProfilingInfoMask(unsigned(a) | unsigned(b)); }
+inline RayFlagsMask operator|(RayFlagsMask a, RayFlagsMask b) { return RayFlagsMask(unsigned(a) | unsigned(b)); }
+inline FragmentShadingRateMask operator|(FragmentShadingRateMask a, FragmentShadingRateMask b) { return FragmentShadingRateMask(unsigned(a) | unsigned(b)); }
+
+}  // end namespace spv
+
+#endif  // #ifndef spirv_HPP
+
diff --git a/lib/SPIRV/CMakeLists.txt b/lib/SPIRV/CMakeLists.txt
index 0d80372..bdddcc2 100644
--- a/lib/SPIRV/CMakeLists.txt
+++ b/lib/SPIRV/CMakeLists.txt
@@ -1,6 +1,7 @@
 add_llvm_library(LLVMSPIRVLib
   LLVMSPIRVOpts.cpp
   LLVMToSPIRVDbgTran.cpp
+  LLVMToSPIRVTransformations.cpp
   Mangler/FunctionDescriptor.cpp
   Mangler/Mangler.cpp
   Mangler/ManglingUtils.cpp
@@ -10,6 +11,7 @@ add_llvm_library(LLVMSPIRVLib
   OCLUtil.cpp
   VectorComputeUtil.cpp
   SPIRVLowerBitCastToNonStandardType.cpp
+  SPIRVContainerWriterPass.cpp
   SPIRVLowerBool.cpp
   SPIRVLowerConstExpr.cpp
   SPIRVLowerMemmove.cpp
diff --git a/lib/SPIRV/LLVMToSPIRVTransformations.cpp b/lib/SPIRV/LLVMToSPIRVTransformations.cpp
new file mode 100644
index 0000000..8627272
--- /dev/null
+++ b/lib/SPIRV/LLVMToSPIRVTransformations.cpp
@@ -0,0 +1,302 @@
+//===- LLVMToSPIRVTransformations.cpp -------------------------------------===//
+//
+//  Flo's Open libRary (floor)
+//  Copyright (C) 2004 - 2021 Florian Ziesche
+//
+//  This program is free software; you can redistribute it and/or modify
+//  it under the terms of the GNU General Public License as published by
+//  the Free Software Foundation; version 2 of the License only.
+//
+//  This program is distributed in the hope that it will be useful,
+//  but WITHOUT ANY WARRANTY; without even the implied warranty of
+//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+//  GNU General Public License for more details.
+//
+//  You should have received a copy of the GNU General Public License along
+//  with this program; if not, write to the Free Software Foundation, Inc.,
+//  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+//
+//===----------------------------------------------------------------------===//
+//
+// Pre-pass (prior to SPIRVWriter) that performs a few LLVM to SPIR-V
+// transformations.
+//
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVInternal.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include <vector>
+using namespace llvm;
+using namespace SPIRV;
+
+#define DEBUG_TYPE "LLVMToSPIRVTransformations"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace SPIRV {
+struct LLVMToSPIRVTransformations
+    : public InstVisitor<LLVMToSPIRVTransformations>,
+      ModulePass {
+  static char ID; // Pass identification, replacement for typeid
+
+  Module *M{nullptr};
+  LLVMContext *ctx{nullptr};
+  bool was_modified{false};
+
+  // used by composite construction replacement
+  // we keep this both as an unordered_set for fast lookup and in a vector,
+  // because erasing must happen in reverse use order
+  std::unordered_set<Instruction *> kill_set;
+  std::vector<Instruction *> kill_list;
+
+  LLVMToSPIRVTransformations() : ModulePass(ID) {
+    initializeLLVMToSPIRVTransformationsPass(*PassRegistry::getPassRegistry());
+  }
+
+  StringRef getPassName() const override {
+    return "LLVM to SPIR-V transformations";
+  }
+
+  bool runOnModule(Module &Mod) override {
+    M = &Mod;
+    ctx = &M->getContext();
+    was_modified = false;
+
+    // return if not compiling Vulkan/SPIR-V
+    auto Src = getSPIRVSource(M);
+    if (std::get<0>(Src) != spv::SourceLanguageGLSL) {
+      return false;
+    }
+
+    //
+    for (auto &F : *M) {
+      // only handle actual functions
+      if (F.isDeclaration())
+        continue;
+      runOnFunction(F);
+    }
+
+    return was_modified;
+  }
+
+  void runOnFunction(Function &F) {
+    kill_set.clear();
+    kill_list.clear();
+    visit(F);
+    for (auto iter = kill_list.rbegin(); iter != kill_list.rend(); ++iter) {
+      (*iter)->eraseFromParent();
+    }
+  }
+
+  // InstVisitor overrides
+  using InstVisitor<LLVMToSPIRVTransformations>::visit;
+  void visit(Instruction &I) {
+    InstVisitor<LLVMToSPIRVTransformations>::visit(I);
+  }
+
+  // vector insert chain replacement
+  void visitInsertElement(InsertElementInst &I) {
+    if (kill_set.count(&I) > 0) {
+      return;
+    }
+
+    // sanity check
+    const auto vec_type = dyn_cast_or_null<FixedVectorType>(I.getType());
+    if (!vec_type) {
+      return;
+    }
+
+    // only continue this if the first object to insert into is undef
+    if (!isa<UndefValue>(I.getOperand(0))) {
+      return;
+    }
+
+    const auto elem_type = vec_type->getElementType();
+    const auto elem_count = vec_type->getNumElements();
+
+    bool replace = true;
+    std::vector<InsertElementInst *> insert_elems{&I};
+    std::vector<Value *> elems{I.getOperand(1)};
+    InsertElementInst *cur_insert = &I;
+    for (uint32_t i = 1;; ++i) {
+      // abort if the index isn't constant or is not contiguous in 0..#elems-1
+      // NOTE: we do except that LLVM has ordered these
+      auto idx = dyn_cast<ConstantInt>(cur_insert->getOperand(2));
+      if (idx == nullptr || idx->getZExtValue() != (i - 1)) {
+        replace = false;
+        break;
+      }
+
+      // done here
+      if (i == elem_count) {
+        break;
+      }
+
+      // abort if not exactly 1 use (this isn't a straight chain of inserts)
+      if (cur_insert->getNumUses() != 1) {
+        replace = false;
+        break;
+      }
+
+      //
+      cur_insert = dyn_cast<InsertElementInst>(*cur_insert->users().begin());
+      if (cur_insert == nullptr) {
+        replace = false;
+        break;
+      }
+      insert_elems.emplace_back(cur_insert);
+      elems.emplace_back(cur_insert->getOperand(1));
+    }
+    if (!replace)
+      return;
+
+    // we need to create a unique function name for this type
+    std::string func_name =
+        "floor.composite_construct.llvm." + std::to_string(elem_count) + "x";
+    raw_string_ostream func_name_stream(func_name);
+    elem_type->print(func_name_stream);
+    func_name_stream.flush();
+
+    // create composite construct at the last InsertElementInst + replace all
+    // its uses
+    std::vector<Type *> param_types(elem_count, elem_type);
+    const auto func_type =
+        llvm::FunctionType::get(vec_type, param_types, false);
+    llvm::CallInst *CI =
+        CallInst::Create(M->getOrInsertFunction(func_name, func_type), elems,
+                         (I.hasName() ? I.getName() + ".composite_construct"
+                                      : "composite_construct"),
+                         cur_insert);
+    CI->setCallingConv(CallingConv::FLOOR_FUNC);
+    CI->setDebugLoc(I.getDebugLoc()); // keep debug loc of first insert
+    cur_insert->replaceAllUsesWith(CI);
+
+    // add all replaced InsertElementInsts to the kill list
+    for (auto &instr : insert_elems) {
+      kill_list.emplace_back(instr);
+      kill_set.emplace(instr);
+    }
+
+    was_modified = true;
+  }
+
+  // aggregate insert chain replacement
+  void visitInsertValue(InsertValueInst &) {
+    // TODO: implement this
+  }
+
+  // vector shuffle with undef replacement
+  void visitShuffleVector(ShuffleVectorInst &I) {
+    if (isa<UndefValue>(I.getOperand(1))) {
+      I.setOperand(1, I.getOperand(0));
+      was_modified = true;
+      return;
+    }
+    if (isa<UndefValue>(I.getOperand(0))) {
+      I.setOperand(0, I.getOperand(1));
+      was_modified = true;
+      return;
+    }
+  }
+
+  //! returns a constant zero val for the specified type
+  //! NOTE: validation must have already happened
+  static Constant *make_zero_val(llvm::Type *val_type) {
+    if (val_type->isVectorTy()) {
+      auto vec_type = dyn_cast_or_null<FixedVectorType>(val_type);
+      auto vec_elem_type = vec_type->getElementType();
+      return ConstantVector::getSplat(
+          vec_type->getElementCount(),
+          vec_elem_type->isIntegerTy() ? ConstantInt::get(vec_elem_type, 0)
+                                       : ConstantFP::get(vec_elem_type, 0.0));
+    } else if (val_type->isIntegerTy()) {
+      return ConstantInt::get(val_type, 0);
+    } else if (val_type->isFloatingPointTy()) {
+      return ConstantFP::get(val_type, 0.0);
+    } else if (val_type->isPointerTy()) {
+      auto phi_ptr_type = dyn_cast_or_null<PointerType>(val_type);
+      assert(phi_ptr_type && "invalid ptr type");
+      return ConstantPointerNull::get(phi_ptr_type);
+    }
+    llvm_unreachable("invalid phi type");
+  }
+  // don't allow undef values in PHIs
+  void visitPHINode(PHINode &phi) {
+    auto val_type = phi.getType();
+    if (val_type->isVectorTy()) {
+      auto vec_type = dyn_cast_or_null<FixedVectorType>(val_type);
+      if (!vec_type || (!vec_type->getElementType()->isIntegerTy() &&
+                        !vec_type->getElementType()->isFloatingPointTy())) {
+        return; // can't handle this
+      }
+    } else if (!val_type->isIntegerTy() &&
+               !val_type->isFloatingPointTy() &&
+               !val_type->isPointerTy()) {
+      return; // can't handle this
+    }
+    for (uint32_t in_idx = 0, in_count = phi.getNumIncomingValues();
+         in_idx < in_count; ++in_idx) {
+      auto in_val = phi.getIncomingValue(in_idx);
+      if (auto undef = dyn_cast_or_null<UndefValue>(in_val)) {
+        phi.setIncomingValue(in_idx, make_zero_val(val_type));
+        was_modified = true;
+      }
+    }
+  }
+
+  void visitCallInst(CallInst &CI) {
+    // remove placeholder function calls
+    if (CI.getCalledFunction()->getName().startswith("floor.merge_block") ||
+        CI.getCalledFunction()->getName().startswith("floor.continue_block") ||
+        CI.getCalledFunction()->getName().startswith("floor.keep_block")) {
+      CI.eraseFromParent();
+      was_modified = true;
+    }
+#if 0
+    // remove unnecessary selection merge calls (branch that is no longer conditional)
+    if (CI.getCalledFunction()->getName() == "floor.selection_merge") {
+      auto term = CI.getParent()->getTerminator();
+      if (auto br = dyn_cast_or_null<BranchInst>(term); br && !br->isConditional()) {
+        CI.eraseFromParent();
+        was_modified = true;
+      }
+    }
+#endif
+  }
+};
+
+char LLVMToSPIRVTransformations::ID = 0;
+} // namespace SPIRV
+
+ModulePass *llvm::createLLVMToSPIRVTransformations() {
+  return new LLVMToSPIRVTransformations();
+}
+INITIALIZE_PASS(LLVMToSPIRVTransformations, "LLVM to SPIR-V transformations",
+                "LLVM to SPIR-V transformations", false, false)
diff --git a/lib/SPIRV/Mangler/ManglingUtils.cpp b/lib/SPIRV/Mangler/ManglingUtils.cpp
index d760a63..bdea1c8 100644
--- a/lib/SPIRV/Mangler/ManglingUtils.cpp
+++ b/lib/SPIRV/Mangler/ManglingUtils.cpp
@@ -66,6 +66,24 @@ static const char *PrimitiveNames[PRIMITIVE_NUM] = {
     "image2d_msaa_depth_rw_t",
     "image2d_array_msaa_depth_rw_t",
     "image3d_rw_t",
+	// --> for libfloor Vulkan/OpenCL
+    "image1d_t",
+    "image1d_array_t",
+    "image1d_buffer_t",
+    "image2d_t",
+    "image2d_array_t",
+    "image3d_t",
+    "image2d_msaa_t",
+    "image2d_array_msaa_t",
+    "image2d_msaa_depth_t",
+    "image2d_array_msaa_depth_t",
+    "image2d_depth_t",
+    "image2d_array_depth_t",
+    "imagecube_t",
+    "imagecube_array_t",
+    "imagecube_depth_t",
+    "imagecube_array_depth_t",
+	// <-- for libfloor Vulkan/OpenCL
     "event_t",
     "pipe_ro_t",
     "pipe_wo_t",
@@ -143,6 +161,24 @@ const char *MangledTypes[PRIMITIVE_NUM] = {
     "25ocl_image2d_msaa_depth_rw",       // PRIMITIVE_IMAGE2D_MSAA_DEPTH_RW_T
     "31ocl_image2d_array_msaa_depth_rw", // PRIMITIVE_IMAGE2D_ARRAY_MSAA_DEPTH_RW_T
     "14ocl_image3d_rw",                  // PRIMITIVE_IMAGE3D_RW_T
+	// --> for libfloor Vulkan/OpenCL
+	"11ocl_image1d",               // PRIMITIVE_IMAGE_1D_T
+    "16ocl_image1darray",          // PRIMITIVE_IMAGE_1D_ARRAY_T
+    "17ocl_image1dbuffer",         // PRIMITIVE_IMAGE_1D_BUFFER_T
+    "11ocl_image2d",               // PRIMITIVE_IMAGE_2D_T
+    "16ocl_image2darray",          // PRIMITIVE_IMAGE_2D_ARRAY_T
+    "11ocl_image3d",               // PRIMITIVE_IMAGE_3D_T
+    "15ocl_image2dmsaa",           // PRIMITIVE_IMAGE_2D_MSAA_T
+    "20ocl_image2darraymsaa",      // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T
+    "20ocl_image2dmsaadepth",      // PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T
+    "25ocl_image2darraymsaadepth", // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T
+    "16ocl_image2ddepth",          // PRIMITIVE_IMAGE_2D_DEPTH_T
+    "21ocl_image2darraydepth",     // PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T
+    "13ocl_imagecube",             // PRIMITIVE_IMAGE_CUBE_T
+    "18ocl_imagecubearray",        // PRIMITIVE_IMAGE_CUBE_ARRAY_T
+    "18ocl_imagecubedepth",        // PRIMITIVE_IMAGE_CUBE_DEPTH_T
+    "23ocl_imagecubearraydepth",   // PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T
+	// <-- for libfloor Vulkan/OpenCL
     "9ocl_event",                        // PRIMITIVE_EVENT_T
     "11ocl_pipe_ro",                     // PRIMITIVE_PIPE_RO_T
     "11ocl_pipe_wo",                     // PRIMITIVE_PIPE_WO_T
@@ -235,6 +271,24 @@ static const SPIRversion PrimitiveSupportedVersions[PRIMITIVE_NUM] = {
     SPIR12, // PRIMITIVE_IMAGE2D_MSAA_DEPTH_RW_T
     SPIR12, // PRIMITIVE_IMAGE2D_ARRAY_MSAA_DEPTH_RW_T
     SPIR12, // PRIMITIVE_IMAGE3D_RW_T
+	// --> for libfloor Vulkan/OpenCL
+    SPIR12, // PRIMITIVE_IMAGE_1D_T
+    SPIR12, // PRIMITIVE_IMAGE_1D_ARRAY_T
+    SPIR12, // PRIMITIVE_IMAGE_1D_BUFFER_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_T
+    SPIR12, // PRIMITIVE_IMAGE_3D_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_MSAA_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_DEPTH_T
+    SPIR12, // PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_ARRAY_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_DEPTH_T
+    SPIR20, // PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T
+	// <-- for libfloor Vulkan/OpenCL
     SPIR12, // PRIMITIVE_EVENT_T
     SPIR20, // PRIMITIVE_PIPE_RO_T
     SPIR20, // PRIMITIVE_PIPE_WO_T
diff --git a/lib/SPIRV/Mangler/ParameterType.h b/lib/SPIRV/Mangler/ParameterType.h
index cd05954..b39e799 100644
--- a/lib/SPIRV/Mangler/ParameterType.h
+++ b/lib/SPIRV/Mangler/ParameterType.h
@@ -84,6 +84,24 @@ enum TypePrimitiveEnum {
   PRIMITIVE_IMAGE2D_MSAA_DEPTH_RW_T,
   PRIMITIVE_IMAGE2D_ARRAY_MSAA_DEPTH_RW_T,
   PRIMITIVE_IMAGE3D_RW_T,
+  // --> for libfloor Vulkan/OpenCL
+  PRIMITIVE_IMAGE_1D_T,
+  PRIMITIVE_IMAGE_1D_ARRAY_T,
+  PRIMITIVE_IMAGE_1D_BUFFER_T,
+  PRIMITIVE_IMAGE_2D_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_T,
+  PRIMITIVE_IMAGE_3D_T,
+  PRIMITIVE_IMAGE_2D_MSAA_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T,
+  PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_DEPTH_T,
+  PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T,
+  PRIMITIVE_IMAGE_CUBE_T,
+  PRIMITIVE_IMAGE_CUBE_ARRAY_T,
+  PRIMITIVE_IMAGE_CUBE_DEPTH_T,
+  PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T,
+  // <-- for libfloor Vulkan/OpenCL
   PRIMITIVE_EVENT_T,
   PRIMITIVE_PIPE_RO_T,
   PRIMITIVE_PIPE_WO_T,
diff --git a/lib/SPIRV/OCLToSPIRV.cpp b/lib/SPIRV/OCLToSPIRV.cpp
index 1c2f547..47bf6dd 100644
--- a/lib/SPIRV/OCLToSPIRV.cpp
+++ b/lib/SPIRV/OCLToSPIRV.cpp
@@ -41,6 +41,8 @@
 #include "OCLTypeToSPIRV.h"
 #include "OCLUtil.h"
 #include "SPIRVInternal.h"
+#include "SPIRVFunction.h"
+#include "SPIRVInstruction.h"
 #include "libSPIRV/SPIRVDebug.h"
 
 #include "llvm/ADT/StringSwitch.h"
@@ -190,6 +192,9 @@ public:
   ///   return __spirv_ImageSampleExplicitLod_R{ReturnType}(sampled_image, ...);
   void visitCallReadImageWithSampler(CallInst *CI, StringRef MangledName);
 
+  void visitCallReadImageWithSamplerShader(CallInst *CI, StringRef MangledName,
+                                           const std::string &DemangledName);
+
   /// Transform read_image with msaa image arguments.
   /// Sample argument must be acoded as Image Operand.
   void visitCallReadImageMSAA(CallInst *CI, StringRef MangledName);
@@ -197,6 +202,9 @@ public:
   /// Transform {read|write}_image without sampler arguments.
   void visitCallReadWriteImage(CallInst *CI, StringRef DemangledName);
 
+  void visitCallWriteImageShader(CallInst *CI, StringRef MangledName,
+                                 const std::string &DemangledName);
+
   /// Transform to_{global|local|private}.
   ///
   /// T* a = ...;
@@ -269,6 +277,7 @@ private:
   Module *M;
   LLVMContext *Ctx;
   unsigned CLVer; /// OpenCL version as major*10+minor
+  spv::SourceLanguage SrcLang;
   std::set<Value *> ValuesToDelete;
   OCLTypeToSPIRVBase *OCLTypeToSPIRVPtr;
 
@@ -353,17 +362,34 @@ bool OCLToSPIRVBase::runOCLToSPIRV(Module &Module) {
   M = &Module;
   Ctx = &M->getContext();
   auto Src = getSPIRVSource(&Module);
+  SrcLang = (spv::SourceLanguage)std::get<0>(Src);
   // This is a pre-processing pass, which transform LLVM IR module to a more
-  // suitable form for the SPIR-V translation: it is specifically designed to
-  // handle OpenCL C built-in functions and shouldn't be launched for other
-  // source languages
-  if (std::get<0>(Src) != spv::SourceLanguageOpenCL_C)
+  // suitable form for the SPIR-V translation
+  if (SrcLang != spv::SourceLanguageOpenCL_C &&
+      SrcLang != spv::SourceLanguageGLSL)
     return false;
 
   CLVer = std::get<1>(Src);
 
   LLVM_DEBUG(dbgs() << "Enter OCLToSPIRV:\n");
 
+  // language specific handling
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    // as of now, Vulkan/SPIR-V/GLSL doesn't know constant/UniformConstant
+    // values/object, so replace all uses of the constant address space with the
+    // Function storage class
+    // NOTE: SPIRVWriter will also move all global constant vars to the inside
+    // of their respective functions (users)
+    SPIRSPIRVAddrSpaceMap::replace(SPIRAS_Constant, StorageClassFunction);
+
+    // add shader image caps
+    SPIRVImageInstBase::addCap(spv::CapabilityShader);
+    SPIRVImageQueryInstBase::addCap(spv::CapabilityImageQuery);
+  } else {
+    // set kernel image caps
+    SPIRVImageInstBase::addCap(spv::CapabilityImageBasic);
+  }
+
   visit(*M);
 
   for (auto &I : ValuesToDelete)
@@ -417,8 +443,10 @@ void OCLToSPIRVBase::visitCallInst(CallInst &CI) {
       DemangledName.find(kOCLBuiltinName::AtomPrefix) == 0) {
 
     // Compute atomic builtins do not support floating types.
+    // NOTE: allowing this for Vulkan
     if (CI.getType()->isFloatingPointTy() &&
-        isComputeAtomicOCLBuiltin(DemangledName))
+        isComputeAtomicOCLBuiltin(DemangledName) &&
+        SrcLang != spv::SourceLanguageGLSL)
       return;
 
     auto PCI = &CI;
@@ -470,7 +498,11 @@ void OCLToSPIRVBase::visitCallInst(CallInst &CI) {
   }
   if (DemangledName.find(kOCLBuiltinName::ReadImage) == 0) {
     if (MangledName.find(kMangledName::Sampler) != StringRef::npos) {
-      visitCallReadImageWithSampler(&CI, MangledName);
+      if (SrcLang != spv::SourceLanguageGLSL) {
+        visitCallReadImageWithSampler(&CI, MangledName);
+      } else {
+        visitCallReadImageWithSamplerShader(&CI, MangledName, DemangledName.str());
+      }
       return;
     }
     if (MangledName.find("msaa") != StringRef::npos) {
@@ -480,7 +512,12 @@ void OCLToSPIRVBase::visitCallInst(CallInst &CI) {
   }
   if (DemangledName.find(kOCLBuiltinName::ReadImage) == 0 ||
       DemangledName.find(kOCLBuiltinName::WriteImage) == 0) {
-    visitCallReadWriteImage(&CI, DemangledName);
+    if (SrcLang != spv::SourceLanguageGLSL) {
+      visitCallReadWriteImage(&CI, DemangledName);
+    } else {
+      assert(DemangledName.find(kOCLBuiltinName::ReadImage) == std::string::npos && "should not be here");
+      visitCallWriteImageShader(&CI, MangledName, DemangledName.str());
+    }
     return;
   }
   if (DemangledName == kOCLBuiltinName::ToGlobal ||
@@ -519,6 +556,7 @@ void OCLToSPIRVBase::visitCallInst(CallInst &CI) {
   }
   if (DemangledName == kOCLBuiltinName::FMin ||
       DemangledName == kOCLBuiltinName::FMax ||
+      DemangledName == kOCLBuiltinName::FMod ||
       DemangledName == kOCLBuiltinName::Min ||
       DemangledName == kOCLBuiltinName::Max ||
       DemangledName == kOCLBuiltinName::Step ||
@@ -836,10 +874,23 @@ void OCLToSPIRVBase::transAtomicBuiltin(CallInst *CI,
       M, CI,
       [=](CallInst *CI, std::vector<Value *> &Args) -> std::string {
         Info.PostProc(Args);
+
+        // rename atomic functions if necessary
+        std::string atom_func_name = Info.UniqName;
+        if (CI->getCalledFunction()->getReturnType()->isFloatTy()) {
+          if (atom_func_name == "atom_add") {
+            atom_func_name = "atom_fadd";
+          } else if (atom_func_name == "atomic_add") {
+            atom_func_name = "atomic_fadd";
+          } else if (atom_func_name == "atomic_fetch_add_explicit") {
+            atom_func_name = "atomic_fetch_fadd_explicit";
+          }
+        }
+
         // Order of args in OCL20:
         // object, 0-2 other args, 1-2 order, scope
         const size_t NumOrder =
-            getAtomicBuiltinNumMemoryOrderArgs(Info.UniqName);
+            getAtomicBuiltinNumMemoryOrderArgs(atom_func_name);
         const size_t ArgsCount = Args.size();
         const size_t ScopeIdx = ArgsCount - 1;
         const size_t OrderIdx = ScopeIdx - NumOrder;
@@ -848,8 +899,46 @@ void OCLToSPIRVBase::transAtomicBuiltin(CallInst *CI,
             transOCLMemScopeIntoSPIRVScope(Args[ScopeIdx], OCLMS_device, CI);
 
         for (size_t I = 0; I < NumOrder; ++I) {
-          Args[OrderIdx + I] = transOCLMemOrderIntoSPIRVMemorySemantics(
-              Args[OrderIdx + I], OCLMO_seq_cst, CI);
+          if (SrcLang == spv::SourceLanguageGLSL) {
+            Args[OrderIdx + I] = mapUInt(M, cast<ConstantInt>(Args[OrderIdx + I]),
+              [&Args, this](unsigned Ord) {
+                // add Vulkan/GLSL specific memory semantics
+                spv::MemorySemanticsMask memsem = spv::MemorySemanticsMaskNone;
+                if (SrcLang == spv::SourceLanguageGLSL) {
+                  switch (
+                      SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+                          Args[0]->getType()->getPointerAddressSpace()))) {
+                  case spv::StorageClassUniform:
+                    memsem = spv::MemorySemanticsUniformMemoryMask;
+                    break;
+                  // TODO: no sub-group storage class? handled differently?
+                  case spv::StorageClassWorkgroup:
+                    memsem = spv::MemorySemanticsWorkgroupMemoryMask;
+                    break;
+                  case spv::StorageClassStorageBuffer:
+                  case spv::StorageClassCrossWorkgroup:
+                    memsem = spv::MemorySemanticsCrossWorkgroupMemoryMask;
+                    break;
+                  case spv::StorageClassAtomicCounter:
+                    memsem = spv::MemorySemanticsAtomicCounterMemoryMask;
+                    break;
+                  case spv::StorageClassImage:
+                    memsem = spv::MemorySemanticsImageMemoryMask;
+                    break;
+                  default:
+                    break;
+                  }
+                  // SequentiallyConsistent memory order is not supported -> use AcquireRelease
+                  if (Ord == OCLMO_seq_cst) {
+                    Ord = OCLMO_acq_rel;
+                  }
+                }
+                return mapOCLMemSemanticToSPIRV(0, static_cast<OCLMemOrderKind>(Ord)) | memsem;
+              });
+          } else {
+            Args[OrderIdx + I] = transOCLMemOrderIntoSPIRVMemorySemantics(
+                Args[OrderIdx + I], OCLMO_seq_cst, CI);
+          }
         }
         // Order of args in SPIR-V:
         // object, scope, 1-2 order, 0-2 other args
@@ -859,7 +948,7 @@ void OCLToSPIRVBase::transAtomicBuiltin(CallInst *CI,
           // argument just where it should be, so don't move the last argument
           // then.
           int Offset =
-              Info.UniqName.find("atomic_compare_exchange") == 0 ? 1 : 0;
+              atom_func_name.find("atomic_compare_exchange") == 0 ? 1 : 0;
           std::rotate(Args.begin() + 2, Args.begin() + OrderIdx,
                       Args.end() - Offset);
         }
@@ -870,7 +959,7 @@ void OCLToSPIRVBase::transAtomicBuiltin(CallInst *CI,
                  ReturnType->isDoubleTy();
         };
         auto SPIRVFunctionName =
-            getSPIRVFuncName(OCLSPIRVBuiltinMap::map(Info.UniqName));
+            getSPIRVFuncName(OCLSPIRVBuiltinMap::map(atom_func_name));
         if (!IsFPType(AtomicBuiltinsReturnType))
           return SPIRVFunctionName;
         // Translate FP-typed atomic builtins. Currently we only need to
@@ -904,7 +993,9 @@ void OCLToSPIRVBase::visitCallBarrier(CallInst *CI) {
         // But if the flags argument is set to 0, we use
         // None(Relaxed) memory order.
         unsigned MemFenceFlag = std::get<0>(Lit);
-        OCLMemOrderKind MemOrder = MemFenceFlag ? OCLMO_seq_cst : OCLMO_relaxed;
+        // NOTE: we can not use OCLMO_seq_cst with Vulkan memory model
+        OCLMemOrderKind MemOrder = MemFenceFlag && SrcLang != spv::SourceLanguageGLSL ?
+            OCLMO_seq_cst : OCLMO_relaxed;
         Args[2] = addInt32(mapOCLMemSemanticToSPIRV(
             MemFenceFlag, MemOrder)); // Memory semantics
         return getSPIRVFuncName(OpControlBarrier);
@@ -1078,6 +1169,9 @@ void OCLToSPIRVBase::transBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info) {
   Op OC = OpNop;
   unsigned ExtOp = ~0U;
   SPIRVBuiltinVariableKind BVKind = BuiltInMax;
+  const auto ext_kind =
+      (SrcLang == spv::SourceLanguageOpenCL_C ? SPIRVEIS_OpenCL
+                                              : SPIRVEIS_GLSL);
   if (StringRef(Info.UniqName).startswith(kSPIRVName::Prefix))
     return;
   if (OCLSPIRVBuiltinMap::find(Info.UniqName, &OC)) {
@@ -1096,8 +1190,8 @@ void OCLToSPIRVBase::transBuiltin(CallInst *CI, OCLBuiltinTransInfo &Info) {
     } else {
       Info.UniqName = getSPIRVFuncName(OC);
     }
-  } else if ((ExtOp = getExtOp(Info.MangledName, Info.UniqName)) != ~0U)
-    Info.UniqName = getSPIRVExtFuncName(SPIRVEIS_OpenCL, ExtOp);
+  } else if ((ExtOp = getExtOp(Info.MangledName, Info.UniqName, ext_kind)) != ~0U)
+    Info.UniqName = getSPIRVExtFuncName(ext_kind, ExtOp);
   else if (SPIRSPIRVBuiltinVariableMap::find(Info.UniqName, &BVKind)) {
     // Map OCL work item builtins to SPV-IR work item builtins.
     // e.g. get_global_id() --> __spirv_BuiltinGlobalInvocationId()
@@ -1201,6 +1295,12 @@ void OCLToSPIRVBase::visitCallReadImageWithSampler(CallInst *CI,
       &Attrs);
 }
 
+void OCLToSPIRVBase::visitCallReadImageWithSamplerShader(
+    CallInst *CI, StringRef MangledName, const std::string &DemangledName) {
+  // NOTE: we'll be handling this in SPIRVWriter, not here, because we need
+  // information that is only available there
+}
+
 void OCLToSPIRVBase::visitCallGetImageSize(CallInst *CI,
                                            StringRef DemangledName) {
   AttributeList Attrs = CI->getCalledFunction()->getAttributes();
@@ -1216,7 +1316,7 @@ void OCLToSPIRVBase::visitCallGetImageSize(CallInst *CI,
   mutateCallInstSPIRV(
       M, CI,
       [&](CallInst *, std::vector<Value *> &Args, Type *&Ret) {
-        assert(Args.size() == 1);
+        assert(Args.size() == 1 || (Args.size() == 2 && SrcLang == spv::SourceLanguageGLSL));
         Ret = CI->getType()->isIntegerTy(64) ? Type::getInt64Ty(*Ctx)
                                              : Type::getInt32Ty(*Ctx);
         if (Dim > 1)
@@ -1224,7 +1324,9 @@ void OCLToSPIRVBase::visitCallGetImageSize(CallInst *CI,
         if (Desc.Dim == DimBuffer)
           return getSPIRVFuncName(OpImageQuerySize, CI->getType());
         else {
-          Args.push_back(getInt32(M, 0));
+          if (Args.size() == 1) {
+            Args.push_back(getInt32(M, 0));
+          }
           return getSPIRVFuncName(OpImageQuerySizeLod, CI->getType());
         }
       },
@@ -1316,6 +1418,13 @@ void OCLToSPIRVBase::visitCallReadWriteImage(CallInst *CI,
   transBuiltin(CI, Info);
 }
 
+void OCLToSPIRVBase::visitCallWriteImageShader(CallInst *CI,
+                                               StringRef MangledName,
+                                               const std::string &DemangledName) {
+  // NOTE: we'll be handling this in SPIRVWriter, not here, because we need
+  // information that is only available there
+}
+
 void OCLToSPIRVBase::visitCallToAddr(CallInst *CI, StringRef DemangledName) {
   auto AddrSpace =
       static_cast<SPIRAddressSpace>(CI->getType()->getPointerAddressSpace());
@@ -1457,6 +1566,7 @@ void OCLToSPIRVBase::visitCallScalToVec(CallInst *CI, StringRef MangledName,
   std::vector<unsigned int> ScalarPos;
   if (DemangledName == kOCLBuiltinName::FMin ||
       DemangledName == kOCLBuiltinName::FMax ||
+      DemangledName == kOCLBuiltinName::FMod ||
       DemangledName == kOCLBuiltinName::Min ||
       DemangledName == kOCLBuiltinName::Max) {
     VecPos.push_back(0);
@@ -1479,6 +1589,9 @@ void OCLToSPIRVBase::visitCallScalToVec(CallInst *CI, StringRef MangledName,
   }
 
   AttributeList Attrs = CI->getCalledFunction()->getAttributes();
+  const auto ext_kind =
+      (SrcLang == spv::SourceLanguageOpenCL_C ? SPIRVEIS_OpenCL
+                                              : SPIRVEIS_GLSL);
   mutateCallInstSPIRV(
       M, CI,
       [=](CallInst *, std::vector<Value *> &Args) {
@@ -1499,8 +1612,8 @@ void OCLToSPIRVBase::visitCallScalToVec(CallInst *CI, StringRef MangledName,
 
           Args[I] = NewVec;
         }
-        return getSPIRVExtFuncName(SPIRVEIS_OpenCL,
-                                   getExtOp(MangledName, DemangledName));
+        return getSPIRVExtFuncName(ext_kind,
+                                   getExtOp(MangledName, DemangledName, ext_kind));
       },
       &Attrs);
 }
@@ -1583,7 +1696,7 @@ void OCLToSPIRVBase::visitCallEnqueueKernel(CallInst *CI,
       FunctionType::get(CI->getType(), getTypes(Args), false /*isVarArg*/);
   Function *NewF =
       Function::Create(FT, GlobalValue::ExternalLinkage, NewName, M);
-  NewF->setCallingConv(CallingConv::SPIR_FUNC);
+  NewF->setCallingConv(CallingConv::FLOOR_FUNC);
   CallInst *NewCall = CallInst::Create(NewF, Args, "", CI);
   NewCall->setCallingConv(NewF->getCallingConv());
   CI->replaceAllUsesWith(NewCall);
@@ -1886,9 +1999,9 @@ void OCLToSPIRVBase::visitSubgroupAVCBuiltinCallWithSampler(
 } // namespace SPIRV
 
 INITIALIZE_PASS_BEGIN(OCLToSPIRVLegacy, "ocl-to-spv",
-                      "Transform OCL 2.0 to SPIR-V", false, false)
+                      "Transform OCL 2.0 / GLSL to SPIR-V", false, false)
 INITIALIZE_PASS_DEPENDENCY(OCLTypeToSPIRVLegacy)
 INITIALIZE_PASS_END(OCLToSPIRVLegacy, "ocl-to-spv",
-                    "Transform OCL 2.0 to SPIR-V", false, false)
+                    "Transform OCL 2.0 / GLSL to SPIR-V", false, false)
 
 ModulePass *llvm::createOCLToSPIRVLegacy() { return new OCLToSPIRVLegacy(); }
diff --git a/lib/SPIRV/OCLTypeToSPIRV.cpp b/lib/SPIRV/OCLTypeToSPIRV.cpp
index c0101a4..5acc352 100644
--- a/lib/SPIRV/OCLTypeToSPIRV.cpp
+++ b/lib/SPIRV/OCLTypeToSPIRV.cpp
@@ -111,6 +111,10 @@ void OCLTypeToSPIRVBase::addAdaptedType(Value *V, Type *T) {
   AdaptedTy[V] = T;
 }
 
+void OCLTypeToSPIRVBase::addAdaptedType(Argument &A, Type *T) {
+  addAdaptedType(&A, T);
+}
+
 void OCLTypeToSPIRVBase::addWork(Function *F) {
   LLVM_DEBUG(dbgs() << "[add work] "; F->printAsOperand(dbgs(), true, M);
              dbgs() << '\n');
diff --git a/lib/SPIRV/OCLTypeToSPIRV.h b/lib/SPIRV/OCLTypeToSPIRV.h
index 68df6f0..d3f1b16 100644
--- a/lib/SPIRV/OCLTypeToSPIRV.h
+++ b/lib/SPIRV/OCLTypeToSPIRV.h
@@ -77,6 +77,7 @@ private:
   void adaptArgumentsBySamplerUse(Module &M);
   void adaptFunction(Function *F);
   void addAdaptedType(Value *V, Type *T);
+  void addAdaptedType(Argument &A, Type *T);
   void addWork(Function *F);
 };
 
diff --git a/lib/SPIRV/OCLUtil.cpp b/lib/SPIRV/OCLUtil.cpp
index c71660e..ab6420b 100644
--- a/lib/SPIRV/OCLUtil.cpp
+++ b/lib/SPIRV/OCLUtil.cpp
@@ -195,6 +195,11 @@ template <> void SPIRVMap<OclExt::Kind, std::string>::init() {
   _SPIRV_OP(cl_khr_egl_event)
   _SPIRV_OP(cl_khr_srgb_image_writes)
   _SPIRV_OP(cl_khr_extended_bit_ops)
+  _SPIRV_OP(vk_capability_int16)
+  _SPIRV_OP(vk_capability_int64)
+  _SPIRV_OP(vk_capability_float16)
+  _SPIRV_OP(vk_capability_float64)
+  _SPIRV_OP(vk_capability_multiview)
 #undef _SPIRV_OP
 }
 
@@ -208,6 +213,11 @@ template <> void SPIRVMap<OclExt::Kind, SPIRVCapabilityKind>::init() {
   add(OclExt::cl_khr_mipmap_image, CapabilityImageMipmap);
   add(OclExt::cl_khr_mipmap_image_writes, CapabilityImageMipmap);
   add(OclExt::cl_khr_extended_bit_ops, CapabilityBitInstructions);
+  add(OclExt::vk_capability_int16, CapabilityInt16);
+  add(OclExt::vk_capability_int64, CapabilityInt64);
+  add(OclExt::vk_capability_float16, CapabilityFloat16);
+  add(OclExt::vk_capability_float64, CapabilityFloat64);
+  add(OclExt::vk_capability_multiview, CapabilityMultiView);
 }
 
 /// Map OpenCL work functions to SPIR-V builtin variables.
@@ -247,6 +257,8 @@ template <> void SPIRVMap<std::string, SPIRVBuiltinVariableKind>::init() {
 class SPIRVInstruction;
 template <> void SPIRVMap<std::string, Op, SPIRVInstruction>::init() {
 #define _SPIRV_OP(x, y) add("atom_" #x, OpAtomic##y);
+  // Vulkan float32/float64 atomic add
+  _SPIRV_OP(fadd, FAddEXT)
   // cl_khr_int64_base_atomics builtins
   _SPIRV_OP(add, IAdd)
   _SPIRV_OP(sub, ISub)
@@ -272,6 +284,8 @@ template <> void SPIRVMap<std::string, Op, SPIRVInstruction>::init() {
   _SPIRV_OP(compare_exchange_weak_explicit, AtomicCompareExchangeWeak)
   _SPIRV_OP(inc, AtomicIIncrement)
   _SPIRV_OP(dec, AtomicIDecrement)
+  // Vulkan float32/float64 atomic add
+  _SPIRV_OP(fetch_fadd_explicit, AtomicFAddEXT)
   _SPIRV_OP(fetch_add_explicit, AtomicIAdd)
   _SPIRV_OP(fetch_sub_explicit, AtomicISub)
   _SPIRV_OP(fetch_umin_explicit, AtomicUMin)
@@ -370,6 +384,8 @@ template <> void SPIRVMap<std::string, Op, SPIRVInstruction>::init() {
   _SPIRV_OP(get_image_channel_order, ImageQueryOrder)
   _SPIRV_OP(get_image_num_mip_levels, ImageQueryLevels)
   _SPIRV_OP(get_image_num_samples, ImageQuerySamples)
+  // GLSL or standard SPIR-V (TODO: how to ignore these for OpenCL?)
+  _SPIRV_OP(fmod, FMod)
   // Intel Subgroups builtins
   _SPIRV_OP(intel_sub_group_shuffle, SubgroupShuffleINTEL)
   _SPIRV_OP(intel_sub_group_shuffle_down, SubgroupShuffleDownINTEL)
@@ -671,6 +687,8 @@ bool isComputeAtomicOCLBuiltin(StringRef DemangledName) {
     return false;
 
   return llvm::StringSwitch<bool>(DemangledName)
+      .EndsWith("fadd", true)
+      .EndsWith("add", true)
       .EndsWith("sub", true)
       .EndsWith("atomic_add", true)
       .EndsWith("atomic_min", true)
@@ -684,6 +702,8 @@ bool isComputeAtomicOCLBuiltin(StringRef DemangledName) {
       .EndsWith("and", true)
       .EndsWith("or", true)
       .EndsWith("xor", true)
+      .EndsWith("fadd_explicit", true)
+      .EndsWith("add_explicit", true)
       .EndsWith("sub_explicit", true)
       .EndsWith("or_explicit", true)
       .EndsWith("xor_explicit", true)
@@ -713,34 +733,62 @@ BarrierLiterals getBarrierLiterals(CallInst *CI) {
                          Scope);
 }
 
-unsigned getExtOp(StringRef OrigName, StringRef GivenDemangledName) {
+unsigned getExtOp(StringRef OrigName, StringRef GivenDemangledName,
+                  SPIRVExtInstSetKind ext_kind) {
   std::string DemangledName{GivenDemangledName};
   if (DemangledName.empty() || !oclIsBuiltin(OrigName, GivenDemangledName))
     return ~0U;
   LLVM_DEBUG(dbgs() << "getExtOp: demangled name: " << DemangledName << '\n');
-  OCLExtOpKind EOC;
-  bool Found = OCLExtOpMap::rfind(DemangledName, &EOC);
-  if (!Found) {
-    std::string Prefix;
-    switch (lastFuncParamType(OrigName)) {
-    case ParamType::UNSIGNED:
-      Prefix = "u_";
-      break;
-    case ParamType::SIGNED:
-      Prefix = "s_";
-      break;
-    case ParamType::FLOAT:
-      Prefix = "f";
-      break;
-    case ParamType::UNKNOWN:
-      break;
+  if (ext_kind == SPIRVExtInstSetKind::SPIRVEIS_OpenCL) {
+    OCLExtOpKind EOC;
+    bool Found = OCLExtOpMap::rfind(DemangledName, &EOC);
+    if (!Found) {
+      std::string Prefix;
+      switch (lastFuncParamType(OrigName)) {
+      case ParamType::UNSIGNED:
+        Prefix = "u_";
+        break;
+      case ParamType::SIGNED:
+        Prefix = "s_";
+        break;
+      case ParamType::FLOAT:
+        Prefix = "f";
+        break;
+      case ParamType::UNKNOWN:
+        break;
+      }
+      Found = OCLExtOpMap::rfind(Prefix + DemangledName, &EOC);
+    }
+    if (Found)
+      return EOC;
+    else
+      return ~0U;
+  } else if (ext_kind == SPIRVExtInstSetKind::SPIRVEIS_GLSL) {
+    GLSLExtOpKind EGLSL;
+    bool Found = GLSLExtOpMap::rfind(DemangledName, &EGLSL);
+    if (!Found) {
+      std::string Prefix;
+      switch (lastFuncParamType(OrigName)) {
+      case ParamType::UNSIGNED:
+        Prefix = "u_";
+        break;
+      case ParamType::SIGNED:
+        Prefix = "s_";
+        break;
+      case ParamType::FLOAT:
+        Prefix = "f";
+        break;
+      default:
+        llvm_unreachable("unknown mangling!");
+      }
+      Found = GLSLExtOpMap::rfind(Prefix + DemangledName, &EGLSL);
     }
-    Found = OCLExtOpMap::rfind(Prefix + DemangledName, &EOC);
+    if (Found)
+      return EGLSL;
+    else
+      return ~0U;
   }
-  if (Found)
-    return EOC;
-  else
-    return ~0U;
+  llvm_unreachable("invalid ext set");
 }
 
 ///////////////////////////////////////////////////////////////////////////////
@@ -956,6 +1004,24 @@ getOCLOpaqueTypeAddrSpace(SPIR::TypePrimitiveEnum Prim) {
   case SPIR::PRIMITIVE_IMAGE2D_MSAA_DEPTH_RW_T:
   case SPIR::PRIMITIVE_IMAGE2D_ARRAY_MSAA_DEPTH_RW_T:
   case SPIR::PRIMITIVE_IMAGE3D_RW_T:
+  // --> for libfloor Vulkan/OpenCL
+  case SPIR::PRIMITIVE_IMAGE_1D_T:
+  case SPIR::PRIMITIVE_IMAGE_1D_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_1D_BUFFER_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_3D_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_MSAA_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_DEPTH_T:
+  case SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T:
+  // <-- for libfloor Vulkan/OpenCL
     return mapAddrSpaceEnums(SPIRV_IMAGE_ADDR_SPACE);
   default:
     llvm_unreachable("No address space is determined for a SPIR primitive");
diff --git a/lib/SPIRV/OCLUtil.h b/lib/SPIRV/OCLUtil.h
index 6ea6b4f..07ad3ff 100644
--- a/lib/SPIRV/OCLUtil.h
+++ b/lib/SPIRV/OCLUtil.h
@@ -94,11 +94,11 @@ enum OCLScopeKind {
 // To avoid any inconsistence here, constants are explicitly initialized with
 // the corresponding constants from 'std::memory_order' enum.
 enum OCLMemOrderKind {
-  OCLMO_relaxed = std::memory_order::memory_order_relaxed,
-  OCLMO_acquire = std::memory_order::memory_order_acquire,
-  OCLMO_release = std::memory_order::memory_order_release,
-  OCLMO_acq_rel = std::memory_order::memory_order_acq_rel,
-  OCLMO_seq_cst = std::memory_order::memory_order_seq_cst
+  OCLMO_relaxed = (uint32_t)std::memory_order_relaxed,
+  OCLMO_acquire = (uint32_t)std::memory_order_acquire,
+  OCLMO_release = (uint32_t)std::memory_order_release,
+  OCLMO_acq_rel = (uint32_t)std::memory_order_acq_rel,
+  OCLMO_seq_cst = (uint32_t)std::memory_order_seq_cst
 };
 
 enum IntelFPGAMemoryAccessesVal {
@@ -247,6 +247,7 @@ const static char FixedLogINTEL[] = "intel_arbitrary_fixed_log";
 const static char FixedExpINTEL[] = "intel_arbitrary_fixed_exp";
 const static char FMax[] = "fmax";
 const static char FMin[] = "fmin";
+const static char FMod[] = "fmod";
 const static char FPGARegIntel[] = "__builtin_intel_fpga_reg";
 const static char GetFence[] = "get_fence";
 const static char GetImageArraySize[] = "get_image_array_size";
@@ -354,6 +355,11 @@ enum Kind {
   _SPIRV_OP(cl_khr_egl_event)
   _SPIRV_OP(cl_khr_srgb_image_writes)
   _SPIRV_OP(cl_khr_extended_bit_ops)
+  _SPIRV_OP(vk_capability_int16)
+  _SPIRV_OP(vk_capability_int64)
+  _SPIRV_OP(vk_capability_float16)
+  _SPIRV_OP(vk_capability_float64)
+  _SPIRV_OP(vk_capability_multiview)
 #undef _SPIRV_OP
 };
 // clang-format on
@@ -375,12 +381,14 @@ const static char TypePrefix[] = "opencl.intel_sub_group_avc_";
 
 /// Get instruction index for SPIR-V extended instruction for OpenCL.std
 ///   extended instruction set.
-/// \param MangledName The mangled name of OpenCL builtin function.
-/// \param DemangledName The demangled name of OpenCL builtin function if
+/// \param MangledName The mangled name of OpenCL/GLSL builtin function.
+/// \param DemangledName The demangled name of OpenCL/GLSL builtin function if
 ///   not empty.
-/// \return instruction index of extended instruction if the OpenCL builtin
-///   function is translated to an extended instruction, otherwise ~0U.
-unsigned getExtOp(StringRef MangledName, StringRef DemangledName = "");
+/// \param ext_kind the extended instruction set kind that should be used
+/// \return instruction index of extended instruction if the OpenCL/GLSL
+///   builtin function is translated to an extended instruction, otherwise ~0U.
+unsigned getExtOp(StringRef MangledName, StringRef DemangledName,
+                  SPIRVExtInstSetKind ext_kind);
 
 /// Get literal arguments of call of atomic_work_item_fence.
 AtomicWorkItemFenceLiterals getAtomicWorkItemFenceLiterals(CallInst *CI);
diff --git a/lib/SPIRV/PreprocessMetadata.cpp b/lib/SPIRV/PreprocessMetadata.cpp
index ac1c00b..93c62be 100644
--- a/lib/SPIRV/PreprocessMetadata.cpp
+++ b/lib/SPIRV/PreprocessMetadata.cpp
@@ -144,6 +144,11 @@ void PreprocessMetadataBase::visit(Module *M) {
   SPIRVMDBuilder B(*M);
   SPIRVMDWalker W(*M);
 
+  Triple TT(M->getTargetTriple());
+  assert(isSupportedTriple(TT) && "Invalid triple");
+  const bool is_vulkan =
+      (TT.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan);
+
   preprocessOCLMetadata(M, &B, &W);
   preprocessVectorComputeMetadata(M, &B, &W);
 
@@ -155,21 +160,29 @@ void PreprocessMetadataBase::visit(Module *M) {
   if (auto *GV = M->getGlobalVariable("llvm.global_ctors"))
     preprocessCXXStructorList(EM, GV, spv::ExecutionModeInitializer);
 
+  if (is_vulkan) {
+    // NOTE: don't want work-group size metadata here, this is already
+    // handled elsewhere
+    return;
+  }
+
   // Add execution modes for kernels. We take it from metadata attached to
   // the kernel functions.
-  for (Function &Kernel : *M) {
-    if (Kernel.getCallingConv() != CallingConv::SPIR_KERNEL)
+  for (Function &Func : *M) {
+    if (Func.getCallingConv() != CallingConv::FLOOR_KERNEL &&
+		Func.getCallingConv() != CallingConv::FLOOR_VERTEX &&
+		Func.getCallingConv() != CallingConv::FLOOR_FRAGMENT)
       continue;
 
     // Specifing execution modes for the Kernel and adding it to the list
     // of ExecutionMode instructions.
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 17, i32 X, i32 Y, i32 Z}
-    if (MDNode *WGSize = Kernel.getMetadata(kSPIR2MD::WGSize)) {
+    if (MDNode *WGSize = Func.getMetadata(kSPIR2MD::WGSize)) {
       unsigned X, Y, Z;
       decodeMDNode(WGSize, X, Y, Z);
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeLocalSize)
           .add(X)
           .add(Y)
@@ -178,11 +191,11 @@ void PreprocessMetadataBase::visit(Module *M) {
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 18, i32 X, i32 Y, i32 Z}
-    if (MDNode *WGSizeHint = Kernel.getMetadata(kSPIR2MD::WGSizeHint)) {
+    if (MDNode *WGSizeHint = Func.getMetadata(kSPIR2MD::WGSizeHint)) {
       unsigned X, Y, Z;
       decodeMDNode(WGSizeHint, X, Y, Z);
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeLocalSizeHint)
           .add(X)
           .add(Y)
@@ -191,18 +204,18 @@ void PreprocessMetadataBase::visit(Module *M) {
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 30, i32 hint}
-    if (MDNode *VecTypeHint = Kernel.getMetadata(kSPIR2MD::VecTyHint)) {
+    if (MDNode *VecTypeHint = Func.getMetadata(kSPIR2MD::VecTyHint)) {
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeVecTypeHint)
           .add(transVecTypeHint(VecTypeHint))
           .done();
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 35, i32 size}
-    if (MDNode *ReqdSubgroupSize = Kernel.getMetadata(kSPIR2MD::SubgroupSize)) {
+    if (MDNode *ReqdSubgroupSize = Func.getMetadata(kSPIR2MD::SubgroupSize)) {
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeSubgroupSize)
           .add(getMDOperandAsInt(ReqdSubgroupSize, 0))
           .done();
@@ -211,11 +224,11 @@ void PreprocessMetadataBase::visit(Module *M) {
     // !{void (i32 addrspace(1)*)* @kernel, i32 max_work_group_size, i32 X,
     //         i32 Y, i32 Z}
     if (MDNode *MaxWorkgroupSizeINTEL =
-            Kernel.getMetadata(kSPIR2MD::MaxWGSize)) {
+            Func.getMetadata(kSPIR2MD::MaxWGSize)) {
       unsigned X, Y, Z;
       decodeMDNode(MaxWorkgroupSizeINTEL, X, Y, Z);
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeMaxWorkgroupSizeINTEL)
           .add(X)
           .add(Y)
@@ -224,23 +237,23 @@ void PreprocessMetadataBase::visit(Module *M) {
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 no_global_work_offset}
-    if (Kernel.getMetadata(kSPIR2MD::NoGlobalOffset)) {
-      EM.addOp().add(&Kernel).add(spv::ExecutionModeNoGlobalOffsetINTEL).done();
+    if (Func.getMetadata(kSPIR2MD::NoGlobalOffset)) {
+      EM.addOp().add(&Func).add(spv::ExecutionModeNoGlobalOffsetINTEL).done();
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 max_global_work_dim, i32 dim}
-    if (MDNode *MaxWorkDimINTEL = Kernel.getMetadata(kSPIR2MD::MaxWGDim)) {
+    if (MDNode *MaxWorkDimINTEL = Func.getMetadata(kSPIR2MD::MaxWGDim)) {
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeMaxWorkDimINTEL)
           .add(getMDOperandAsInt(MaxWorkDimINTEL, 0))
           .done();
     }
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 num_simd_work_items, i32 num}
-    if (MDNode *NumSIMDWorkitemsINTEL = Kernel.getMetadata(kSPIR2MD::NumSIMD)) {
+    if (MDNode *NumSIMDWorkitemsINTEL = Func.getMetadata(kSPIR2MD::NumSIMD)) {
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeNumSIMDWorkitemsINTEL)
           .add(getMDOperandAsInt(NumSIMDWorkitemsINTEL, 0))
           .done();
@@ -249,9 +262,9 @@ void PreprocessMetadataBase::visit(Module *M) {
     // !{void (i32 addrspace(1)*)* @kernel, i32 scheduler_target_fmax_mhz,
     //   i32 num}
     if (MDNode *SchedulerTargetFmaxMhzINTEL =
-            Kernel.getMetadata(kSPIR2MD::FmaxMhz)) {
+            Func.getMetadata(kSPIR2MD::FmaxMhz)) {
       EM.addOp()
-          .add(&Kernel)
+          .add(&Func)
           .add(spv::ExecutionModeSchedulerTargetFmaxMhzINTEL)
           .add(getMDOperandAsInt(SchedulerTargetFmaxMhzINTEL, 0))
           .done();
@@ -259,7 +272,7 @@ void PreprocessMetadataBase::visit(Module *M) {
 
     // !{void (i32 addrspace(1)*)* @kernel, i32 ip_interface, i32 interface}
     if (MDNode *Interface =
-            Kernel.getMetadata(kSPIR2MD::IntelFPGAIPInterface)) {
+            Func.getMetadata(kSPIR2MD::IntelFPGAIPInterface)) {
       std::set<std::string> InterfaceStrSet;
       // Default mode is 'csr' aka !ip_interface !N
       //                           !N = !{!”csr”}
@@ -278,7 +291,7 @@ void PreprocessMetadataBase::visit(Module *M) {
         if (InterfaceStrSet.find("stall_free_return") != InterfaceStrSet.end())
           InterfaceMode = 1;
         EM.addOp()
-            .add(&Kernel)
+            .add(&Func)
             .add(spv::internal::ExecutionModeStreamingInterfaceINTEL)
             .add(InterfaceMode)
             .done();
@@ -292,13 +305,23 @@ void PreprocessMetadataBase::preprocessOCLMetadata(Module *M, SPIRVMDBuilder *B,
   unsigned CLVer = getOCLVersion(M, true);
   if (CLVer == 0)
     return;
+
+  Triple TT(M->getTargetTriple());
+  assert(isSupportedTriple(TT) && "Invalid triple");
+  const bool is_vulkan =
+      (TT.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan);
+  if (is_vulkan)
+    EraseOCLMD = true;
+
   // Preprocess OpenCL-specific metadata
   // !spirv.Source = !{!x}
   // !{x} = !{i32 3, i32 102000}
   B->addNamedMD(kSPIRVMD::Source)
       .addOp()
-      .add(CLVer == kOCLVer::CL21 ? spv::SourceLanguageOpenCL_CPP
-                                  : spv::SourceLanguageOpenCL_C)
+      .add(!is_vulkan ? (CLVer == kOCLVer::CL21 ?
+						 spv::SourceLanguageOpenCL_CPP :
+						 spv::SourceLanguageOpenCL_C) :
+		   spv::SourceLanguageGLSL)
       .add(CLVer)
       .done();
   if (EraseOCLMD)
@@ -306,14 +329,20 @@ void PreprocessMetadataBase::preprocessOCLMetadata(Module *M, SPIRVMDBuilder *B,
 
   // !spirv.MemoryModel = !{!x}
   // !{x} = !{i32 1, i32 2}
-  Triple TT(M->getTargetTriple());
-  assert(isSupportedTriple(TT) && "Invalid triple");
-  B->addNamedMD(kSPIRVMD::MemoryModel)
-      .addOp()
-      .add(TT.isArch32Bit() ? spv::AddressingModelPhysical32
-                            : spv::AddressingModelPhysical64)
-      .add(spv::MemoryModelOpenCL)
-      .done();
+  if (!is_vulkan) {
+    B->addNamedMD(kSPIRVMD::MemoryModel)
+        .addOp()
+        .add(TT.isArch32Bit() ? spv::AddressingModelPhysical32
+                              : spv::AddressingModelPhysical64)
+        .add(spv::MemoryModelOpenCL)
+        .done();
+  } else {
+    B->addNamedMD(kSPIRVMD::MemoryModel)
+        .addOp()
+        .add(spv::AddressingModelPhysicalStorageBuffer64)
+        .add(spv::MemoryModelVulkan)
+        .done();
+  }
 
   // Add source extensions
   // !spirv.SourceExtension = !{!x, !y, ...}
@@ -322,8 +351,12 @@ void PreprocessMetadataBase::preprocessOCLMetadata(Module *M, SPIRVMDBuilder *B,
   auto Exts = getNamedMDAsStringSet(M, kSPIR2MD::Extensions);
   if (!Exts.empty()) {
     auto N = B->addNamedMD(kSPIRVMD::SourceExtension);
-    for (auto &I : Exts)
+    for (auto &I : Exts) {
+      // skip cl_* extensions for vulkan
+      if (is_vulkan && I.find("cl_") == 0)
+        continue;
       N.addOp().add(I).done();
+    }
   }
   if (EraseOCLMD)
     B->eraseNamedMD(kSPIR2MD::Extensions).eraseNamedMD(kSPIR2MD::OptFeatures);
@@ -340,7 +373,7 @@ void PreprocessMetadataBase::preprocessVectorComputeMetadata(Module *M,
   auto EM = B->addNamedMD(kSPIRVMD::ExecutionMode);
 
   for (auto &F : *M) {
-    if (F.getCallingConv() != CallingConv::SPIR_KERNEL)
+    if (F.getCallingConv() != CallingConv::FLOOR_KERNEL)
       continue;
 
     // Add VC float control execution modes
diff --git a/lib/SPIRV/SPIRVContainerWriterPass.cpp b/lib/SPIRV/SPIRVContainerWriterPass.cpp
new file mode 100644
index 0000000..5fbdc39
--- /dev/null
+++ b/lib/SPIRV/SPIRVContainerWriterPass.cpp
@@ -0,0 +1,248 @@
+//===- SPIRVContainerWriterPass.cpp - SPIRV writing pass ------------------===//
+//
+//  Flo's Open libRary (floor)
+//  Copyright (C) 2004 - 2021 Florian Ziesche
+//
+//  This program is free software; you can redistribute it and/or modify
+//  it under the terms of the GNU General Public License as published by
+//  the Free Software Foundation; version 2 of the License only.
+//
+//  This program is distributed in the hope that it will be useful,
+//  but WITHOUT ANY WARRANTY; without even the implied warranty of
+//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+//  GNU General Public License for more details.
+//
+//  You should have received a copy of the GNU General Public License along
+//  with this program; if not, write to the Free Software Foundation, Inc.,
+//  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+//
+//===----------------------------------------------------------------------===//
+//
+// SPIRVContainerWriterPass implementation: this is used to split up (clone) a
+// LLVM module into individual per-entry-point modules, which is necessary for
+// SPIR-V shaders, because we can't generally have globals that use the same
+// descriptor set index and binding index with different layouts, even if an
+// entry point only makes specific use of a valid set of descriptors.
+// This will then combine all SPIR-V binaries/modules into a single container
+// file, with some additional helpful metadata (function names and types per
+// SPIR-V module).
+//
+// TODO: in the future, it might make sense to specify a specific pipeline in
+// the source (set of shader functions), for which we can then guarantee (or
+// enforce) that only a valid set of descriptors is being used. This would then
+// allow these shaders to be emitted in one single SPIR-V module.
+//
+//
+// #### SPIR-V container file format ####
+// ## header
+// char[4]: identifier "SPVC"
+// uint32_t: version (currently 2)
+// uint32_t: entry_count
+//
+// ## header entries [entry_count]
+// uint32_t: function_entry_count
+// uint32_t: SPIR-V module word count (word == uint32_t)
+//
+// ## module entries [entry_count]
+// uint32_t[header_entry[i].word_count]: SPIR-V module
+//
+// ## additional metadata [entry_count]
+// uint32_t[function_entry_count]: function types
+// char[function_entry_count][]: function names (always \0 terminated, with \0
+//                                               padding to achieve
+//                                               4-byte/uint32_t alignment)
+//
+// ####
+//
+// function type (enum):
+//  * compute/kernel: 1
+//  * vertex: 2
+//  * fragment: 3
+//  * geometry: 4
+//  * tessellation control: 5
+//  * tessellation evaluation: 6
+//
+//===----------------------------------------------------------------------===//
+
+#include "SPIRVContainerWriterPass.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/PassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/Casting.h"
+#include "LLVMSPIRVLib.h"
+#include "llvm/Transforms/Utils/Cloning.h"
+#include <string>
+#include <unordered_set>
+using namespace llvm;
+
+static bool is_used_in_function(const Function *F, const GlobalVariable *GV) {
+  // always flag certain builtin constants as used
+  switch (F->getCallingConv()) {
+  case CallingConv::FLOOR_KERNEL:
+    if (GV->getName().find(".vulkan_constant.workgroup_size") !=
+        StringRef::npos)
+      return true;
+    break;
+  case CallingConv::FLOOR_VERTEX:
+    break;
+  case CallingConv::FLOOR_FRAGMENT:
+    break;
+  }
+
+  for (const auto &user : GV->users()) {
+    if (const auto instr = dyn_cast<Instruction>(user)) {
+      if (instr->getParent()->getParent() == F) {
+        return true;
+      }
+    }
+  }
+  return false;
+}
+
+static bool write_container(Module &M, raw_ostream &OS) {
+  bool success = true;
+
+  // header
+  static constexpr const uint32_t container_version{2u};
+  OS.write("SPVC", 4);
+  OS.write((const char *)&container_version, sizeof(container_version));
+
+  // gather entry point functions that we want to clone/emit
+  std::unordered_set<const Function *> clone_functions;
+  for (const auto &F : M) {
+    if (F.getCallingConv() != CallingConv::FLOOR_KERNEL &&
+        F.getCallingConv() != CallingConv::FLOOR_VERTEX &&
+        F.getCallingConv() != CallingConv::FLOOR_FRAGMENT) {
+      continue;
+    }
+    clone_functions.emplace(&F);
+  }
+  // entry count
+  const auto entry_count = uint32_t(clone_functions.size());
+  OS.write((const char *)&entry_count, sizeof(entry_count));
+
+  // we need a separate stream for the actual spir-v data, since we need to know
+  // the size of each spir-v module/file (no way to know this beforehand)
+  std::string spirv_data{""};
+  raw_string_ostream spirv_stream(spirv_data);
+
+  for (const auto &func : clone_functions) {
+    // clone the module with the current entry point function and any global
+    // vars that we need
+    ValueToValueMapTy VMap;
+    auto cloned_mod = CloneModule(M, VMap, [&func](const GlobalValue *GV) {
+      if (GV == func) {
+        return true;
+      }
+      // only clone global vars if they are needed in a specific function
+      if (const GlobalVariable *GVar = dyn_cast<GlobalVariable>(GV)) {
+        return is_used_in_function(func, GVar);
+      }
+      return false;
+    });
+
+    // function entry count
+    const uint32_t function_entry_count = 1u;
+    OS.write((const char *)&function_entry_count, sizeof(function_entry_count));
+
+    // spir-v binary
+    const auto cur_pos = spirv_stream.tell();
+    std::string err;
+    // TODO: only enable extensions that are generally supported (needs host enablement as well)
+    SPIRV::TranslatorOpts::ExtensionsStatusMap exts;
+    exts[SPIRV::ExtensionID::SPV_EXT_shader_atomic_float_add] = true;
+    //exts[SPIRV::ExtensionID::SPV_KHR_no_integer_wrap_decoration] = true;
+    //exts[SPIRV::ExtensionID::SPV_KHR_float_controls] = true;
+    SPIRV::TranslatorOpts opts(SPIRV::VersionNumber::MaximumVersion, exts);
+    const auto module_success = writeSpirv(cloned_mod.get(), opts, spirv_stream, err);
+    auto module_size = uint32_t(spirv_stream.tell() - cur_pos);
+    if (module_size % 4 != 0) {
+      success = false;
+      errs() << "SPIR-V data size is not a multiple of 4\n";
+    }
+
+    // write the SPIR-V data word count
+    module_size /= 4;
+    OS.write((const char *)&module_size, sizeof(module_size));
+
+    // emit error if unsuccessful (still continue though)
+    success &= module_success;
+    if (!module_success) {
+      errs() << "failed to write/translate module for \"" << func->getName()
+             << "\": " << err << "\n";
+    }
+  }
+
+  // all header entries written -> write actual spir-v data
+  spirv_stream.flush();
+  OS.write(spirv_data.c_str(), spirv_data.size());
+
+  // write per-module metadata
+  for (const auto &func : clone_functions) {
+    // function types
+    uint32_t function_type = 0;
+    switch (func->getCallingConv()) {
+    case CallingConv::FLOOR_KERNEL:
+      function_type = 1;
+      break;
+    case CallingConv::FLOOR_VERTEX:
+      function_type = 2;
+      break;
+    case CallingConv::FLOOR_FRAGMENT:
+      function_type = 3;
+      break;
+    default:
+      llvm_unreachable("invalid function type");
+    }
+    OS.write((const char *)&function_type, sizeof(function_type));
+
+    // function names
+    const auto name = func->getName().str();
+    const auto name_len = (uint32_t)name.size();
+    const auto name_padding = 4u - (name_len % 4u);
+    OS << name.c_str();
+    switch (name_padding) {
+    case 4:
+      OS << '\0';
+    LLVM_FALLTHROUGH; case 3:
+      OS << '\0';
+    LLVM_FALLTHROUGH; case 2:
+      OS << '\0';
+    LLVM_FALLTHROUGH; case 1:
+      OS << '\0';
+      break;
+    default:
+      llvm_unreachable("bad math");
+    }
+  }
+
+  return success;
+}
+
+PreservedAnalyses SPIRVContainerWriterPass::run(Module &M, ModuleAnalysisManager &) {
+  write_container(M, OS);
+  return PreservedAnalyses::all();
+}
+
+namespace {
+class WriteSPIRVContainerPass : public ModulePass {
+  raw_ostream &OS; // raw_ostream to print on
+public:
+  static char ID; // Pass identification, replacement for typeid
+  explicit WriteSPIRVContainerPass(raw_ostream &o) : ModulePass(ID), OS(o) {}
+
+  StringRef getPassName() const override { return "SPIR-V Container Writer"; }
+
+  bool runOnModule(Module &M) override {
+    write_container(M, OS);
+    return false;
+  }
+};
+}
+
+char WriteSPIRVContainerPass::ID = 0;
+
+ModulePass *llvm::createSPIRVContainerWriterPass(raw_ostream &Str) {
+  return new WriteSPIRVContainerPass(Str);
+}
diff --git a/lib/SPIRV/SPIRVContainerWriterPass.h b/lib/SPIRV/SPIRVContainerWriterPass.h
new file mode 100644
index 0000000..82678dc
--- /dev/null
+++ b/lib/SPIRV/SPIRVContainerWriterPass.h
@@ -0,0 +1,62 @@
+//===-SPIRVContainerWriterPass.h - SPIR-V container writing pass -- C++ -*-===//
+//
+//  Flo's Open libRary (floor)
+//  Copyright (C) 2004 - 2021 Florian Ziesche
+//
+//  This program is free software; you can redistribute it and/or modify
+//  it under the terms of the GNU General Public License as published by
+//  the Free Software Foundation; version 2 of the License only.
+//
+//  This program is distributed in the hope that it will be useful,
+//  but WITHOUT ANY WARRANTY; without even the implied warranty of
+//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+//  GNU General Public License for more details.
+//
+//  You should have received a copy of the GNU General Public License along
+//  with this program; if not, write to the Free Software Foundation, Inc.,
+//  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+//
+//===----------------------------------------------------------------------===//
+/// \file
+///
+/// This file provides a SPIR-V container writing pass.
+///
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_SPIRVCONTAINERWRITERPASS_H
+#define LLVM_SPIRVCONTAINERWRITERPASS_H
+
+#include "llvm/ADT/StringRef.h"
+#include "llvm/IR/PassManager.h"
+
+namespace llvm {
+class Module;
+class ModulePass;
+class raw_ostream;
+class PreservedAnalyses;
+
+/// \brief Create and return a pass that writes the module to the specified
+/// ostream. Note that this pass is designed for use with the legacy pass
+/// manager.
+ModulePass *createSPIRVContainerWriterPass(raw_ostream &Str);
+
+/// \brief Pass for writing a module of IR out to a SPIR-V container file.
+///
+/// Note that this is intended for use with the new pass manager. To construct
+/// a pass for the legacy pass manager, use the function above.
+class SPIRVContainerWriterPass : public PassInfoMixin<SPIRVContainerWriterPass> {
+  raw_ostream &OS;
+
+public:
+  /// \brief Construct a SPIRV writer pass around a particular output stream.
+  explicit SPIRVContainerWriterPass(raw_ostream &OS) : OS(OS) {}
+
+  /// \brief Run the SPIRV writer pass, and output the module to the selected
+  /// output stream.
+  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);
+
+  static StringRef name() { return "SPIRVContainerWriterPass"; }
+};
+}
+
+#endif
diff --git a/lib/SPIRV/SPIRVInternal.h b/lib/SPIRV/SPIRVInternal.h
index 608187d..ecea837 100644
--- a/lib/SPIRV/SPIRVInternal.h
+++ b/lib/SPIRV/SPIRVInternal.h
@@ -182,17 +182,30 @@ typedef SPIRVMap<Op, Op, IntBoolOpMapId> IntBoolOpMap;
   "-v128:128:128-v192:256:256-v256:256:256"                                    \
   "-v512:512:512-v1024:1024:1024"
 
+// NOTE: modify VulkanFinal pass and clang Targets when this changes
 enum SPIRAddressSpace {
-  SPIRAS_Private,
-  SPIRAS_Global,
-  SPIRAS_Constant,
-  SPIRAS_Local,
-  SPIRAS_Generic,
-  SPIRAS_GlobalDevice,
-  SPIRAS_GlobalHost,
-  SPIRAS_Input,
-  SPIRAS_Output,
-  SPIRAS_Count,
+  SPIRAS_Private = 0,
+  SPIRAS_Global = 1,
+  SPIRAS_Constant = 2,
+  SPIRAS_Local = 3,
+  SPIRAS_Generic = 4,
+  // OpenCL
+  SPIRAS_GlobalDevice = 100,
+  SPIRAS_GlobalHost = 101,
+  // Vulkan/GLSL specific ones
+  SPIRAS_Uniform = 5,
+  SPIRAS_Input = 6,
+  SPIRAS_Output = 7,
+  SPIRAS_VulkanPrivate = 8, // != SPIRAS_Private
+  SPIRAS_PushConstant = 9,
+  SPIRAS_AtomicCounter = 10,
+  SPIRAS_Image = 11,
+  SPIRAS_StorageBuffer = 12,
+  // Workgroup == SPIRAS_Local
+  // CrossWorkgroup == SPIRAS_Global
+  // Function = SPIRAS_Private
+  // UniformConstant = SPIRAS_Constant
+  SPIRAS_PhysicalStorageBuffer = 5349,
 };
 
 template <> inline void SPIRVMap<SPIRAddressSpace, std::string>::init() {
@@ -201,9 +214,17 @@ template <> inline void SPIRVMap<SPIRAddressSpace, std::string>::init() {
   add(SPIRAS_Constant, "Constant");
   add(SPIRAS_Local, "Local");
   add(SPIRAS_Generic, "Generic");
-  add(SPIRAS_Input, "Input");
   add(SPIRAS_GlobalDevice, "GlobalDevice");
   add(SPIRAS_GlobalHost, "GlobalHost");
+  add(SPIRAS_Uniform, "Uniform");
+  add(SPIRAS_Input, "Input");
+  add(SPIRAS_Output, "Output");
+  add(SPIRAS_VulkanPrivate, "Private");
+  add(SPIRAS_PushConstant, "PushConstant");
+  add(SPIRAS_AtomicCounter, "AtomicCounter");
+  add(SPIRAS_Image, "Image");
+  add(SPIRAS_StorageBuffer, "StorageBuffer");
+  add(SPIRAS_PhysicalStorageBuffer, "PhysicalStorageBuffer");
 }
 typedef SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind>
     SPIRAddrSpaceCapitalizedNameMap;
@@ -215,9 +236,17 @@ inline void SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind>::init() {
   add(SPIRAS_Constant, StorageClassUniformConstant);
   add(SPIRAS_Local, StorageClassWorkgroup);
   add(SPIRAS_Generic, StorageClassGeneric);
-  add(SPIRAS_Input, StorageClassInput);
   add(SPIRAS_GlobalDevice, StorageClassDeviceOnlyINTEL);
   add(SPIRAS_GlobalHost, StorageClassHostOnlyINTEL);
+  add(SPIRAS_Uniform, StorageClassUniform);
+  add(SPIRAS_Input, StorageClassInput);
+  add(SPIRAS_Output, StorageClassOutput);
+  add(SPIRAS_VulkanPrivate, StorageClassPrivate);
+  add(SPIRAS_PushConstant, StorageClassPushConstant);
+  add(SPIRAS_AtomicCounter, StorageClassAtomicCounter);
+  add(SPIRAS_Image, StorageClassImage);
+  add(SPIRAS_StorageBuffer, StorageClassStorageBuffer);
+  add(SPIRAS_PhysicalStorageBuffer, StorageClassPhysicalStorageBuffer);
 }
 typedef SPIRVMap<SPIRAddressSpace, SPIRVStorageClassKind> SPIRSPIRVAddrSpaceMap;
 
@@ -227,6 +256,7 @@ inline void SPIRVMap<std::string, SPIRVAccessQualifierKind>::init() {
   add("read_only", AccessQualifierReadOnly);
   add("write_only", AccessQualifierWriteOnly);
   add("read_write", AccessQualifierReadWrite);
+  add("", AccessQualifierNone);
 }
 typedef SPIRVMap<std::string, SPIRVAccessQualifierKind>
     SPIRSPIRVAccessQualifierMap;
@@ -261,6 +291,7 @@ template <>
 inline void
 SPIRVMap<SPIRVExtInstSetKind, std::string, SPIRVExtSetShortName>::init() {
   add(SPIRVEIS_OpenCL, "ocl");
+  add(SPIRVEIS_GLSL, "glsl");
 }
 typedef SPIRVMap<SPIRVExtInstSetKind, std::string, SPIRVExtSetShortName>
     SPIRVExtSetShortNameMap;
@@ -912,9 +943,10 @@ std::string getSPIRVImageSampledTypeName(SPIRVType *Ty);
 /// E.g. %opencl.image1d_rw_t -> %spirv.Image._void_0_0_0_0_0_0_2
 Type *getSPIRVImageTypeFromOCL(Module *M, Type *T);
 
-/// Get LLVM type for sampled type of SPIR-V image type by postfix.
-Type *getLLVMTypeForSPIRVImageSampledTypePostfix(StringRef Postfix,
-                                                 LLVMContext &Ctx);
+/// Translates GLSL image type names to SPIR-V.
+Type *getSPIRVImageTypeFromGLSL(Module *M, Type *T, const char *sample_type,
+                                const bool is_storage,
+                                const spv::ImageFormat format);
 
 /// Return the unqualified and unsuffixed base name of an image type.
 /// E.g. opencl.image2d_ro_t.3 -> image2d_t
@@ -979,6 +1011,10 @@ std::string getSPIRVFriendlyIRFunctionName(OCLExtOpKind ExtOpId,
                                            ArrayRef<Type *> ArgTys,
                                            Type *RetTy = nullptr);
 
+std::string getSPIRVFriendlyIRFunctionName(GLSLExtOpKind ExtOpId,
+                                           ArrayRef<Type *> ArgTys,
+                                           Type *RetTy = nullptr);
+
 /// Mangle a function in SPIR-V friendly IR manner
 /// \param UniqName full unmangled name of the SPIR-V built-in function that
 /// contains possible postfixes that depend not on opcode but on decorations or
diff --git a/lib/SPIRV/SPIRVLowerConstExpr.cpp b/lib/SPIRV/SPIRVLowerConstExpr.cpp
index 12e4d1c..3f63440 100644
--- a/lib/SPIRV/SPIRVLowerConstExpr.cpp
+++ b/lib/SPIRV/SPIRVLowerConstExpr.cpp
@@ -144,7 +144,21 @@ void SPIRVLowerConstExprBase::visit(Module *M) {
         auto *CE = cast<ConstantExpr>(V);
         SPIRVDBG(dbgs() << "[lowerConstantExpressions] " << *CE;)
         auto ReplInst = CE->getAsInstruction();
-        auto InsPoint = II->getParent() == &*FBegin ? II : &FBegin->back();
+        Instruction *InsPoint = nullptr;
+        if (II->getParent() == &*FBegin) {
+          InsPoint = II;
+        } else {
+          InsPoint = &FBegin->back();
+          // ensure that the insertion point does not come before a selection/loop merge in the block
+          if (InsPoint && InsPoint->isTerminator()) {
+            if (auto pre_term_call_instr = dyn_cast_or_null<CallInst>(InsPoint->getPrevNode()); pre_term_call_instr) {
+              const auto& call_func_name = pre_term_call_instr->getCalledFunction()->getName();
+              if (call_func_name == "floor.selection_merge" || call_func_name == "floor.loop_merge") {
+                InsPoint = pre_term_call_instr;
+              }
+            }
+          }
+        }
         ReplInst->insertBefore(InsPoint);
         SPIRVDBG(dbgs() << " -> " << *ReplInst << '\n';)
         std::vector<Instruction *> Users;
diff --git a/lib/SPIRV/SPIRVReader.cpp b/lib/SPIRV/SPIRVReader.cpp
index ef07497..90b22f1 100644
--- a/lib/SPIRV/SPIRVReader.cpp
+++ b/lib/SPIRV/SPIRVReader.cpp
@@ -2232,7 +2232,7 @@ Value *SPIRVToLLVM::transValueWithoutDecoration(SPIRVValue *BV, Function *F,
         cast<FunctionType>(V->getType()->getPointerElementType()), V,
         transValue(BC->getArgumentValues(), F, BB), BC->getName(), BB);
     // Assuming we are calling a regular device function
-    Call->setCallingConv(CallingConv::SPIR_FUNC);
+    Call->setCallingConv(CallingConv::FLOOR_FUNC);
     // Don't set attributes, because at translation time we don't know which
     // function exactly we are calling.
     return mapValue(BV, Call);
@@ -2556,7 +2556,7 @@ CallInst *SPIRVToLLVM::transFixedPointInst(SPIRVInstruction *BI,
   FunctionCallee FCallee = M->getOrInsertFunction(FuncName, FT);
 
   auto *Fn = cast<Function>(FCallee.getCallee());
-  Fn->setCallingConv(CallingConv::SPIR_FUNC);
+  Fn->setCallingConv(CallingConv::FLOOR_FUNC);
   if (isFuncNoUnwind())
     Fn->addFnAttr(Attribute::NoUnwind);
 
@@ -2683,7 +2683,7 @@ CallInst *SPIRVToLLVM::transArbFloatInst(SPIRVInstruction *BI, BasicBlock *BB,
   FunctionCallee FCallee = M->getOrInsertFunction(FuncName, FT);
 
   auto *Func = cast<Function>(FCallee.getCallee());
-  Func->setCallingConv(CallingConv::SPIR_FUNC);
+  Func->setCallingConv(CallingConv::FLOOR_FUNC);
   if (isFuncNoUnwind())
     Func->addFnAttr(Attribute::NoUnwind);
 
@@ -2729,8 +2729,8 @@ Function *SPIRVToLLVM::transFunction(SPIRVFunction *BF) {
   if (F->isIntrinsic())
     return F;
 
-  F->setCallingConv(IsKernel ? CallingConv::SPIR_KERNEL
-                             : CallingConv::SPIR_FUNC);
+  F->setCallingConv(IsKernel ? CallingConv::FLOOR_KERNEL
+                             : CallingConv::FLOOR_FUNC);
   if (BF->hasDecorate(DecorationReferencedIndirectlyINTEL))
     F->addFnAttr("referenced-indirectly");
   if (isFuncNoUnwind())
@@ -3056,7 +3056,7 @@ Instruction *SPIRVToLLVM::transBuiltinFromInst(const std::string &FuncName,
   if (!Func || Func->getFunctionType() != FT) {
     LLVM_DEBUG(for (auto &I : ArgTys) { dbgs() << *I << '\n'; });
     Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
-    Func->setCallingConv(CallingConv::SPIR_FUNC);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
     if (isFuncNoUnwind())
       Func->addFnAttr(Attribute::NoUnwind);
     auto OC = BI->getOpCode();
@@ -3089,7 +3089,6 @@ std::string getSPIRVFuncSuffix(SPIRVInstruction *BI) {
            "Invalid type of CreatePipeFromStorage");
     auto PipeType = static_cast<SPIRVTypePipe *>(CPFPS->getType());
     switch (PipeType->getAccessQualifier()) {
-    default:
     case AccessQualifierReadOnly:
       Suffix = "_read";
       break;
@@ -3099,6 +3098,8 @@ std::string getSPIRVFuncSuffix(SPIRVInstruction *BI) {
     case AccessQualifierReadWrite:
       Suffix = "_read_write";
       break;
+    case AccessQualifierNone:
+      break;
     }
   }
   if (BI->hasDecorate(DecorationSaturatedConversion)) {
@@ -3245,20 +3246,19 @@ bool SPIRVToLLVM::transAddressingModel() {
   case AddressingModelPhysical64:
     M->setTargetTriple(SPIR_TARGETTRIPLE64);
     M->setDataLayout(SPIR_DATALAYOUT64);
-    break;
+    return true;
   case AddressingModelPhysical32:
     M->setTargetTriple(SPIR_TARGETTRIPLE32);
     M->setDataLayout(SPIR_DATALAYOUT32);
-    break;
+    return true;
   case AddressingModelLogical:
+  case AddressingModelPhysicalStorageBuffer64:
     // Do not set target triple and data layout
-    break;
+    return true;
   default:
-    SPIRVCKRT(0, InvalidAddressingModel,
-              "Actual addressing mode is " +
-                  std::to_string(BM->getAddressingModel()));
+    break;
   }
-  return true;
+  llvm_unreachable("invalid addressing model");
 }
 
 void generateIntelFPGAAnnotation(const SPIRVEntry *E,
@@ -3728,7 +3728,7 @@ bool SPIRVToLLVM::transMetadata() {
         BF->getExecutionMode(internal::ExecutionModeFastCompositeKernelINTEL))
       F->addFnAttr(kVCMetadata::VCFCEntry);
 
-    if (F->getCallingConv() != CallingConv::SPIR_KERNEL)
+    if (F->getCallingConv() != CallingConv::FLOOR_KERNEL)
       continue;
 
     // Generate metadata for reqd_work_group_size
@@ -3819,7 +3819,7 @@ bool SPIRVToLLVM::transMetadata() {
 bool SPIRVToLLVM::transOCLMetadata(SPIRVFunction *BF) {
   Function *F = static_cast<Function *>(getTranslatedValue(BF));
   assert(F && "Invalid translated function");
-  if (F->getCallingConv() != CallingConv::SPIR_KERNEL)
+  if (F->getCallingConv() != CallingConv::FLOOR_KERNEL)
     return true;
 
   if (BF->hasDecorate(DecorationVectorComputeFunctionINTEL))
@@ -4138,16 +4138,26 @@ bool SPIRVToLLVM::transAlign(SPIRVValue *BV, Value *V) {
 Instruction *SPIRVToLLVM::transOCLBuiltinFromExtInst(SPIRVExtInst *BC,
                                                      BasicBlock *BB) {
   assert(BB && "Invalid BB");
-  auto ExtOp = static_cast<OCLExtOpKind>(BC->getExtOp());
-  std::string UnmangledName = OCLExtOpMap::map(ExtOp);
 
-  assert(BM->getBuiltinSet(BC->getExtSetId()) == SPIRVEIS_OpenCL &&
-         "Not OpenCL extended instruction");
+  const auto ext_kind = BM->getBuiltinSet(BC->getExtSetId());
+  assert((ext_kind == SPIRVEIS_OpenCL || ext_kind == SPIRVEIS_GLSL) &&
+         "Not OpenCL or GLSL extended instruction");
 
   std::vector<Type *> ArgTypes = transTypeVector(BC->getArgTypes());
   Type *RetTy = transType(BC->getType());
-  std::string MangledName =
-      getSPIRVFriendlyIRFunctionName(ExtOp, ArgTypes, RetTy);
+
+  std::string UnmangledName, MangledName;
+  if (ext_kind == SPIRVEIS_OpenCL) {
+    auto CLExtOp = static_cast<OCLExtOpKind>(BC->getExtOp());
+    UnmangledName = OCLExtOpMap::map(CLExtOp);
+    MangledName = getSPIRVFriendlyIRFunctionName(CLExtOp, ArgTypes, RetTy);
+  } else if (ext_kind == SPIRVEIS_GLSL) {
+    auto GLSLExtOp = static_cast<GLSLExtOpKind>(BC->getExtOp());
+    UnmangledName = GLSLExtOpMap::map(GLSLExtOp);
+    MangledName = getSPIRVFriendlyIRFunctionName(GLSLExtOp, ArgTypes, RetTy);
+  } else {
+    llvm_unreachable("invalid extension kind");
+  }
 
   SPIRVDBG(spvdbgs() << "[transOCLBuiltinFromExtInst] UnmangledName: "
                      << UnmangledName << " MangledName: " << MangledName
@@ -4157,7 +4167,7 @@ Instruction *SPIRVToLLVM::transOCLBuiltinFromExtInst(SPIRVExtInst *BC,
   Function *F = M->getFunction(MangledName);
   if (!F) {
     F = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
-    F->setCallingConv(CallingConv::SPIR_FUNC);
+    F->setCallingConv(CallingConv::FLOOR_FUNC);
     if (isFuncNoUnwind())
       F->addFnAttr(Attribute::NoUnwind);
     if (isFuncReadNone(UnmangledName))
diff --git a/lib/SPIRV/SPIRVRegularizeLLVM.cpp b/lib/SPIRV/SPIRVRegularizeLLVM.cpp
index 648c8f6..40a1587 100644
--- a/lib/SPIRV/SPIRVRegularizeLLVM.cpp
+++ b/lib/SPIRV/SPIRVRegularizeLLVM.cpp
@@ -43,10 +43,12 @@
 
 #include "llvm/ADT/StringExtras.h" // llvm::isDigit
 #include "llvm/Demangle/Demangle.h"
+#include "llvm/IR/Dominators.h"
 #include "llvm/IR/InstVisitor.h"
 #include "llvm/IR/Instructions.h"
 #include "llvm/IR/Operator.h"
 #include "llvm/IR/PassManager.h"
+#include "llvm/IR/Verifier.h"
 #include "llvm/Pass.h"
 #include "llvm/Support/Debug.h"
 #include "llvm/Transforms/Utils/LowerMemIntrinsics.h" // expandMemSetAsLoop()
@@ -368,6 +370,35 @@ bool SPIRVRegularizeLLVMBase::runRegularizeLLVM(Module &Module) {
   return true;
 }
 
+// final cleanup: sort BBs according to the DT
+void sort_bbs(Function *F) {
+  // dominator fixes: reorder blocks
+  // NOTE: obviously only necessary when there are more than 2 blocks
+  if (F->getBasicBlockList().size() <= 2)
+    return;
+
+  DominatorTree DT;
+  DT.recalculate(*F);
+
+  // use the dominator tree order to sort the bbs, i.e. with the DT we already
+  // know the sorted order,
+  // we just need to physically move the blocks according to it
+  std::vector<BasicBlock *> sorted_blocks;
+  const std::function<void(const DomTreeNodeBase<BasicBlock> &)> sort_recurse =
+      [&sort_recurse, &sorted_blocks](const DomTreeNodeBase<BasicBlock> &node) {
+        sorted_blocks.emplace_back(node.getBlock());
+        for (const auto &child : node) {
+          sort_recurse(*child);
+        }
+      };
+  sort_recurse(*DT.getRootNode());
+
+  // move blocks in reverse order (not moving entry of course)
+  for (size_t i = 0, count = sorted_blocks.size(); i < count - 2; ++i) {
+    sorted_blocks[count - i - 2]->moveBefore(sorted_blocks[count - i - 1]);
+  }
+}
+
 /// Remove entities not representable by SPIR-V
 bool SPIRVRegularizeLLVMBase::regularize() {
   eraseUselessFunctions(M);
@@ -404,6 +435,15 @@ bool SPIRVRegularizeLLVMBase::regularize() {
           if (isa<PossiblyExactOperator>(BO) && BO->isExact())
             BO->setIsExact(false);
         }
+
+        // ref: https://github.com/KhronosGroup/SPIRV-LLVM-Translator/issues/1140
+        // FIXME: This is not valid handling for freeze instruction
+        if (auto FI = dyn_cast<FreezeInst>(&II)) {
+          FI->replaceAllUsesWith(FI->getOperand(0));
+          FI->dropAllReferences();
+          ToErase.push_back(FI);
+        }
+
         // Remove metadata not supported by SPIRV
         static const char *MDs[] = {
             "fpmath",
@@ -497,6 +537,18 @@ bool SPIRVRegularizeLLVMBase::regularize() {
   for (StructType *ST : M->getIdentifiedStructTypes())
     adaptStructTypes(ST);
 
+  // sort BBs according to DT
+  for (auto &F : *M) {
+    sort_bbs(&F);
+  }
+
+  std::string Err;
+  raw_string_ostream ErrorOS(Err);
+  if (llvm::verifyModule(*M, &ErrorOS)) {
+    SPIRVDBG(errs() << "Fails to verify module: " << ErrorOS.str();)
+    return false;
+  }
+
   if (SPIRVDbgSaveRegularizedModule)
     saveLLVMModule(M, RegularizedModuleTmpFile);
   return true;
diff --git a/lib/SPIRV/SPIRVToLLVMDbgTran.cpp b/lib/SPIRV/SPIRVToLLVMDbgTran.cpp
index 205dda4..7b1d41e 100644
--- a/lib/SPIRV/SPIRVToLLVMDbgTran.cpp
+++ b/lib/SPIRV/SPIRVToLLVMDbgTran.cpp
@@ -64,7 +64,9 @@ static uint64_t getDerivedSizeInBits(const DIType *Ty) {
 SPIRVToLLVMDbgTran::SPIRVToLLVMDbgTran(SPIRVModule *TBM, Module *TM,
                                        SPIRVToLLVM *Reader)
     : BM(TBM), M(TM), Builder(*M), SPIRVReader(Reader) {
-  Enable = BM->hasDebugInfo();
+  // TODO: OpLines are all over the place now -> better hasDebugInfo()
+  Enable = true; // always enable for now
+  //Enable = BM->hasDebugInfo();
 }
 
 void SPIRVToLLVMDbgTran::addDbgInfoVersion() {
diff --git a/lib/SPIRV/SPIRVUtil.cpp b/lib/SPIRV/SPIRVUtil.cpp
index a756290..9dbc9b2 100644
--- a/lib/SPIRV/SPIRVUtil.cpp
+++ b/lib/SPIRV/SPIRVUtil.cpp
@@ -124,6 +124,9 @@ std::string mapLLVMTypeToOCLType(const Type *Ty, bool Signed) {
     if (!Signed)
       SignPrefix = "u";
     switch (IntTy->getIntegerBitWidth()) {
+    case 1:
+      Stem = "bool";
+      break;
     case 8:
       Stem = "char";
       break;
@@ -334,7 +337,7 @@ Function *getOrCreateFunction(Module *M, Type *RetTy, ArrayRef<Type *> ArgTypes,
     LLVM_DEBUG(dbgs() << "[getOrCreateFunction] ";
                if (F) dbgs() << *F << " => "; dbgs() << *NewF << '\n';);
     F = NewF;
-    F->setCallingConv(CallingConv::SPIR_FUNC);
+    F->setCallingConv(CallingConv::FLOOR_FUNC);
     if (Attrs)
       F->setAttributes(*Attrs);
   }
@@ -413,6 +416,9 @@ std::string getSPIRVExtFuncName(SPIRVExtInstSetKind Set, unsigned ExtOp,
   case SPIRVEIS_OpenCL:
     ExtOpName = getName(static_cast<OCLExtOpKind>(ExtOp));
     break;
+  case SPIRVEIS_GLSL:
+    ExtOpName = getName(static_cast<GLSLExtOpKind>(ExtOp));
+    break;
   }
   return prefixSPIRVName(SPIRVExtSetShortNameMap::map(Set) + '_' + ExtOpName +
                          PostFix.str());
@@ -985,6 +991,29 @@ SPIR::TypePrimitiveEnum getOCLTypePrimitiveEnum(StringRef TyName) {
       .Case("opencl.image2d_array_msaa_depth_rw_t",
             SPIR::PRIMITIVE_IMAGE2D_ARRAY_MSAA_DEPTH_RW_T)
       .Case("opencl.image3d_rw_t", SPIR::PRIMITIVE_IMAGE3D_RW_T)
+	  // --> for libfloor Vulkan/OpenCL
+      .Case("opencl.image1d_t", SPIR::PRIMITIVE_IMAGE_1D_T)
+      .Case("opencl.image1d_array_t", SPIR::PRIMITIVE_IMAGE_1D_ARRAY_T)
+      .Case("opencl.image1d_buffer_t", SPIR::PRIMITIVE_IMAGE_1D_BUFFER_T)
+      .Case("opencl.image2d_t", SPIR::PRIMITIVE_IMAGE_2D_T)
+      .Case("opencl.image2d_array_t", SPIR::PRIMITIVE_IMAGE_2D_ARRAY_T)
+      .Case("opencl.image3d_t", SPIR::PRIMITIVE_IMAGE_3D_T)
+      .Case("opencl.image2d_msaa_t", SPIR::PRIMITIVE_IMAGE_2D_MSAA_T)
+      .Case("opencl.image2d_array_msaa_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_T)
+      .Case("opencl.image2d_msaa_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_MSAA_DEPTH_T)
+      .Case("opencl.image2d_array_msaa_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_MSAA_DEPTH_T)
+      .Case("opencl.image2d_depth_t", SPIR::PRIMITIVE_IMAGE_2D_DEPTH_T)
+      .Case("opencl.image2d_array_depth_t",
+            SPIR::PRIMITIVE_IMAGE_2D_ARRAY_DEPTH_T)
+      .Case("opencl.imagecube_t", SPIR::PRIMITIVE_IMAGE_CUBE_T)
+      .Case("opencl.imagecube_array_t", SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_T)
+      .Case("opencl.imagecube_depth_t", SPIR::PRIMITIVE_IMAGE_CUBE_DEPTH_T)
+      .Case("opencl.imagecube_array_depth_t",
+            SPIR::PRIMITIVE_IMAGE_CUBE_ARRAY_DEPTH_T)
+	  // <-- for libfloor Vulkan/OpenCL
       .Case("opencl.event_t", SPIR::PRIMITIVE_EVENT_T)
       .Case("opencl.pipe_ro_t", SPIR::PRIMITIVE_PIPE_RO_T)
       .Case("opencl.pipe_wo_t", SPIR::PRIMITIVE_PIPE_WO_T)
@@ -1300,23 +1329,6 @@ std::string getSPIRVImageSampledTypeName(SPIRVType *Ty) {
   return std::string();
 }
 
-// ToDo: Find a way to represent uint sampled type in LLVM, maybe an
-//      opaque type.
-Type *getLLVMTypeForSPIRVImageSampledTypePostfix(StringRef Postfix,
-                                                 LLVMContext &Ctx) {
-  if (Postfix == kSPIRVImageSampledTypeName::Void)
-    return Type::getVoidTy(Ctx);
-  if (Postfix == kSPIRVImageSampledTypeName::Float)
-    return Type::getFloatTy(Ctx);
-  if (Postfix == kSPIRVImageSampledTypeName::Half)
-    return Type::getHalfTy(Ctx);
-  if (Postfix == kSPIRVImageSampledTypeName::Int ||
-      Postfix == kSPIRVImageSampledTypeName::UInt)
-    return Type::getInt32Ty(Ctx);
-  llvm_unreachable("Invalid sampled type postfix");
-  return nullptr;
-}
-
 std::string getImageBaseTypeName(StringRef Name) {
 
   SmallVector<StringRef, 4> SubStrs;
@@ -1399,8 +1411,13 @@ void eraseIfNoUse(Value *V) {
 
 bool eraseUselessFunctions(Module *M) {
   bool Changed = false;
-  for (auto I = M->begin(), E = M->end(); I != E;)
-    Changed |= eraseIfNoUse(&(*I++));
+  for (auto I = M->begin(), E = M->end(); I != E;) {
+    // iterator will be invalidated if the function is erased
+    // -> need to increment before calling eraseIfNoUse
+    Function *func_ptr = &*I;
+    ++I;
+    Changed |= eraseIfNoUse(func_ptr);
+  }
   return Changed;
 }
 
@@ -1747,7 +1764,7 @@ bool lowerBuiltinVariableToCall(GlobalVariable *GV,
   if (!Func) {
     FunctionType *FT = FunctionType::get(ReturnTy, ArgTy, false);
     Func = Function::Create(FT, GlobalValue::ExternalLinkage, MangledName, M);
-    Func->setCallingConv(CallingConv::SPIR_FUNC);
+    Func->setCallingConv(CallingConv::FLOOR_FUNC);
     Func->addFnAttr(Attribute::NoUnwind);
     Func->addFnAttr(Attribute::ReadNone);
     Func->addFnAttr(Attribute::WillReturn);
@@ -1969,6 +1986,40 @@ bool postProcessBuiltinsWithArrayArguments(Module *M, bool IsCpp) {
   return true;
 }
 
+/// Translates GLSL image type names to SPIR-V.
+Type *getSPIRVImageTypeFromGLSL(Module *M, Type *ImageTy,
+                                const char *sample_type, const bool is_storage,
+                                const spv::ImageFormat format) {
+  assert(isOCLImageType(ImageTy) && "invalid image type");
+  auto Name = ImageTy->getPointerElementType()->getStructName();
+  assert(Name.startswith(kSPR2TypeName::ImagePrefix) && "invalid image type");
+
+  std::string BaseTy;
+  std::string Postfixes;
+  raw_string_ostream OS(Postfixes);
+  OS << kSPIRVTypeName::PostfixDelim;
+
+  SmallVector<StringRef, 4> SubStrs;
+  const char Delims[] = {kSPR2TypeName::Delimiter, 0};
+  Name.split(SubStrs, Delims);
+  std::string ImageTyName = SubStrs[1].str();
+  if (hasAccessQualifiedName(Name))
+    ImageTyName.erase(ImageTyName.size() - 5, 3);
+  auto Desc = map<SPIRVTypeImageDescriptor>(ImageTyName);
+  Desc.Sampled = (is_storage ? 2 : 1);
+  Desc.Format = format;
+  LLVM_DEBUG(dbgs() << "[trans image type] " << SubStrs[1] << " => "
+               << "(" << (unsigned)Desc.Dim << ", " << Desc.Depth << ", "
+               << Desc.Arrayed << ", " << Desc.MS << ", " << Desc.Sampled
+               << ", " << Desc.Format << ")\n");
+
+  BaseTy = kSPIRVTypeName::Image;
+  OS << getSPIRVImageTypePostfixes(sample_type, Desc, spv::AccessQualifierNone);
+  auto spirv_type_name = getSPIRVTypeName(BaseTy, OS.str());
+
+  return getOrCreateOpaquePtrType(M, spirv_type_name);
+}
+
 } // namespace SPIRV
 
 namespace {
@@ -2119,6 +2170,31 @@ private:
   OCLExtOpKind ExtOpId;
   ArrayRef<Type *> ArgTys;
 };
+class GLSLToSPIRVFriendlyIRMangleInfo : public BuiltinFuncMangleInfo {
+public:
+  GLSLToSPIRVFriendlyIRMangleInfo(GLSLExtOpKind ExtOpId_,
+                                  ArrayRef<Type *> ArgTys, Type *RetTy)
+      : ExtOpId(ExtOpId_), ArgTys(ArgTys) {
+
+    std::string Postfix = "";
+    if (needRetTypePostfix())
+      Postfix = kSPIRVPostfix::Divider + getPostfixForReturnType(RetTy, true);
+
+    UnmangledName = getSPIRVExtFuncName(SPIRVEIS_GLSL, ExtOpId, Postfix);
+  }
+
+  bool needRetTypePostfix() {
+    return false;
+  }
+
+  void init(StringRef) override {
+    // nop
+  }
+
+private:
+  GLSLExtOpKind ExtOpId;
+  ArrayRef<Type *> ArgTys;
+};
 } // namespace
 
 namespace SPIRV {
@@ -2129,6 +2205,13 @@ std::string getSPIRVFriendlyIRFunctionName(OCLExtOpKind ExtOpId,
   return mangleBuiltin(MangleInfo.getUnmangledName(), ArgTys, &MangleInfo);
 }
 
+std::string getSPIRVFriendlyIRFunctionName(GLSLExtOpKind ExtOpId,
+                                           ArrayRef<Type *> ArgTys,
+                                           Type *RetTy) {
+  GLSLToSPIRVFriendlyIRMangleInfo MangleInfo(ExtOpId, ArgTys, RetTy);
+  return mangleBuiltin(MangleInfo.getUnmangledName(), ArgTys, &MangleInfo);
+}
+
 std::string getSPIRVFriendlyIRFunctionName(const std::string &UniqName,
                                            spv::Op OC,
                                            ArrayRef<Type *> ArgTys) {
diff --git a/lib/SPIRV/SPIRVWriter.cpp b/lib/SPIRV/SPIRVWriter.cpp
index 6263a87..9cfd946 100644
--- a/lib/SPIRV/SPIRVWriter.cpp
+++ b/lib/SPIRV/SPIRVWriter.cpp
@@ -6,6 +6,7 @@
 // License. See LICENSE.TXT for details.
 //
 // Copyright (c) 2014 Advanced Micro Devices, Inc. All rights reserved.
+// Copyright (c) 2016 - 2021 Florian Ziesche Vulkan/SPIR-V support
 //
 // Permission is hereby granted, free of charge, to any person obtaining a
 // copy of this software and associated documentation files (the "Software"),
@@ -62,6 +63,8 @@
 #include "llvm/ADT/Triple.h"
 #include "llvm/Analysis/LoopInfo.h"
 #include "llvm/Analysis/ValueTracking.h"
+#include "llvm/Bitcode/BitcodeReader.h"
+#include "llvm/Bitcode/BitcodeWriter.h"
 #include "llvm/IR/Constants.h"
 #include "llvm/IR/DerivedTypes.h"
 #include "llvm/IR/Dominators.h"
@@ -73,10 +76,12 @@
 #include "llvm/IR/LegacyPassManager.h"
 #include "llvm/IR/Module.h"
 #include "llvm/IR/Operator.h"
+#include "llvm/IR/PatternMatch.h"
 #include "llvm/Pass.h"
 #include "llvm/Support/Casting.h"
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Support/Debug.h"
+#include "llvm/Transforms/LibFloor/VulkanSampling.h"
 #include "llvm/Transforms/Utils.h" // loop-simplify pass
 
 #include <cstdlib>
@@ -167,12 +172,30 @@ SPIRVValue *LLVMToSPIRVBase::getTranslatedValue(const Value *V) const {
   return nullptr;
 }
 
-bool LLVMToSPIRVBase::isKernel(Function *F) {
-  if (F->getCallingConv() == CallingConv::SPIR_KERNEL)
+bool LLVMToSPIRVBase::isEntryPoint(Function *F) {
+  if (F->getCallingConv() == CallingConv::FLOOR_KERNEL||
+      F->getCallingConv() == CallingConv::FLOOR_VERTEX ||
+      F->getCallingConv() == CallingConv::FLOOR_FRAGMENT)
     return true;
   return false;
 }
 
+spv::ExecutionModel LLVMToSPIRVBase::getEntryPointType(Function *F,
+                                                       unsigned int SrcLang) {
+  switch (F->getCallingConv()) {
+  case CallingConv::FLOOR_KERNEL:
+    return (SrcLang == spv::SourceLanguageGLSL
+                ? spv::ExecutionModel::ExecutionModelGLCompute
+                : spv::ExecutionModel::ExecutionModelKernel);
+  case CallingConv::FLOOR_VERTEX:
+    return spv::ExecutionModel::ExecutionModelVertex;
+  case CallingConv::FLOOR_FRAGMENT:
+    return spv::ExecutionModel::ExecutionModelFragment;
+  default:
+    return spv::ExecutionModel::ExecutionModelInvalid;
+  }
+}
+
 bool LLVMToSPIRVBase::isBuiltinTransToInst(Function *F) {
   StringRef DemangledName;
   if (!oclIsBuiltin(F->getName(), DemangledName) &&
@@ -200,19 +223,34 @@ bool LLVMToSPIRVBase::isBuiltinTransToExtInst(
   SPIRVExtInstSetKind Set = SPIRVEIS_Count;
   if (!SPIRVExtSetShortNameMap::rfind(ExtSetName.str(), &Set))
     return false;
-  assert((Set == SPIRVEIS_OpenCL || Set == BM->getDebugInfoEIS()) &&
+  assert((Set == SPIRVEIS_OpenCL || Set == BM->getDebugInfoEIS() ||
+          Set == SPIRVEIS_GLSL) &&
          "Unsupported extended instruction set");
 
   auto ExtOpName = S.substr(Loc + 1);
   auto Splited = ExtOpName.split(kSPIRVPostfix::ExtDivider);
-  OCLExtOpKind EOC;
-  if (!OCLExtOpMap::rfind(Splited.first.str(), &EOC))
-    return false;
+  if (Set == SPIRVEIS_OpenCL) {
+    OCLExtOpKind EOC;
+    if (!OCLExtOpMap::rfind(Splited.first.str(), &EOC))
+      return false;
+
+    if (ExtSet)
+      *ExtSet = Set;
+    if (ExtOp)
+      *ExtOp = EOC;
+  } else if (Set == SPIRVEIS_GLSL) {
+    GLSLExtOpKind EGLSL;
+    if (!GLSLExtOpMap::rfind(Splited.first.str(), &EGLSL))
+      return false;
+
+    if (ExtSet)
+      *ExtSet = Set;
+    if (ExtOp)
+      *ExtOp = EGLSL;
+  } else {
+    llvm_unreachable("unhandled instruction set");
+  }
 
-  if (ExtSet)
-    *ExtSet = Set;
-  if (ExtOp)
-    *ExtOp = EOC;
   if (Dec) {
     SmallVector<StringRef, 2> P;
     Splited.second.split(P, kSPIRVPostfix::Divider);
@@ -274,15 +312,33 @@ SPIRVType *LLVMToSPIRVBase::transType(Type *T) {
 
   if (T->isIntegerTy()) {
     unsigned BitWidth = T->getIntegerBitWidth();
-    // SPIR-V 2.16.1. Universal Validation Rules: Scalar integer types can be
-    // parameterized only as 32 bit, plus any additional sizes enabled by
-    // capabilities.
-    if (BM->isAllowedToUseExtension(
-            ExtensionID::SPV_INTEL_arbitrary_precision_integers) ||
-        BM->getErrorLog().checkError(
-            BitWidth == 8 || BitWidth == 16 || BitWidth == 32 || BitWidth == 64,
-            SPIRVEC_InvalidBitWidth, std::to_string(BitWidth))) {
-      return mapType(T, BM->addIntegerType(T->getIntegerBitWidth()));
+    if (SrcLang == spv::SourceLanguageGLSL) {
+      // legalize int width
+      if (BitWidth <= 8) {
+        BitWidth = 8;
+      } else if (BitWidth <= 16) {
+        BitWidth = 16;
+      } else if (BitWidth <= 32) {
+        BitWidth = 32;
+      } else if (BitWidth <= 64) {
+        BitWidth = 64;
+      } else {
+        assert(false && "bit-width is not supported (too large)");
+      }
+      // always signed (by default)
+      return mapType(T, BM->addIntegerType(BitWidth, true));
+    } else { // OpenCL, or others
+      // SPIR-V 2.16.1. Universal Validation Rules: Scalar integer types can be
+      // parameterized only as 32 bit, plus any additional sizes enabled by
+      // capabilities.
+      if (BM->isAllowedToUseExtension(
+              ExtensionID::SPV_INTEL_arbitrary_precision_integers) ||
+          BM->getErrorLog().checkError(
+              BitWidth == 8 || BitWidth == 16 || BitWidth == 32 || BitWidth == 64,
+              SPIRVEC_InvalidBitWidth, std::to_string(BitWidth))) {
+        // always unsigned
+        return mapType(T, BM->addIntegerType(BitWidth, false));
+      }
     }
   }
 
@@ -337,9 +393,14 @@ SPIRVType *LLVMToSPIRVBase::transType(Type *T) {
         return mapType(T, PipeT);
       }
       if (STName.startswith(kSPR2TypeName::ImagePrefix)) {
-        assert(AddrSpc == SPIRAS_Global);
-        auto SPIRVImageTy = getSPIRVImageTypeFromOCL(M, T);
-        return mapType(T, transType(SPIRVImageTy));
+        if (SrcLang != SourceLanguageGLSL) {
+          assert(AddrSpc == SPIRAS_Global);
+          auto SPIRVImageTy = getSPIRVImageTypeFromOCL(M, T);
+          return mapType(T, transType(SPIRVImageTy));
+        } else {
+          errs() << "invalid trans type: " << *T << "\n";
+          assert(false && "should not be here");
+        }
       }
       if (STName == kSPR2TypeName::Sampler)
         return mapType(T, transType(getSamplerType(M)));
@@ -496,8 +557,13 @@ SPIRVType *LLVMToSPIRVBase::transType(Type *T) {
     return mapType(T, BM->addFunctionType(RT, PT));
   }
 
+  if (T->isLabelTy()) {
+    assert(false && "labels can't be mapped as types - handle this earlier!");
+    return nullptr;
+  }
+
   llvm_unreachable("Not implemented!");
-  return 0;
+  return nullptr;
 }
 
 SPIRVType *LLVMToSPIRVBase::transSPIRVOpaqueType(Type *T) {
@@ -506,7 +572,7 @@ SPIRVType *LLVMToSPIRVBase::transSPIRVOpaqueType(Type *T) {
   auto STName = ST->getStructName();
   assert(STName.startswith(kSPIRVTypeName::PrefixAndDelim) &&
          "Invalid SPIR-V opaque type name");
-  SmallVector<std::string, 8> Postfixes;
+  SmallVector<std::string, 9> Postfixes;
   auto TN = decodeSPIRVTypeName(STName, Postfixes);
   if (TN == kSPIRVTypeName::Pipe) {
     assert(T->getPointerAddressSpace() == SPIRAS_Global);
@@ -517,18 +583,33 @@ SPIRVType *LLVMToSPIRVBase::transSPIRVOpaqueType(Type *T) {
     return mapType(T, PipeT);
   } else if (TN == kSPIRVTypeName::Image) {
     assert(T->getPointerAddressSpace() == SPIRAS_Global);
-    // The sampled type needs to be translated through LLVM type to guarantee
-    // uniqueness.
-    auto SampledT = transType(
-        getLLVMTypeForSPIRVImageSampledTypePostfix(Postfixes[0], *Ctx));
+
+    SPIRVType *SampledT = nullptr;
+    if (Postfixes[1] == kSPIRVImageSampledTypeName::Void) {
+      SampledT = BM->addVoidType();
+    } else if (Postfixes[1] == kSPIRVImageSampledTypeName::Float) {
+      SampledT = BM->addFloatType(32);
+    } else if (Postfixes[1] == kSPIRVImageSampledTypeName::Half) {
+      SampledT = BM->addFloatType(16);
+    } else if (Postfixes[1] == kSPIRVImageSampledTypeName::UInt) {
+      SampledT = BM->addIntegerType(32, false);
+    } else if (Postfixes[1] == kSPIRVImageSampledTypeName::Int) {
+      SampledT = BM->addIntegerType(32, true);
+    } else {
+      assert(false && "Invalid sampled type postfix");
+    }
+      
     SmallVector<int, 7> Ops;
-    for (unsigned I = 1; I < 8; ++I)
+    for (unsigned I = 2; I < 9; ++I)
       Ops.push_back(atoi(Postfixes[I].c_str()));
     SPIRVTypeImageDescriptor Desc(static_cast<SPIRVImageDimKind>(Ops[0]),
                                   Ops[1], Ops[2], Ops[3], Ops[4], Ops[5]);
-    return mapType(T,
-                   BM->addImageType(SampledT, Desc,
-                                    static_cast<spv::AccessQualifier>(Ops[6])));
+    auto spirv_image_type =
+        (static_cast<spv::AccessQualifier>(Ops[6]) != spv::AccessQualifierNone
+             ? BM->addImageType(SampledT, Desc,
+                                static_cast<spv::AccessQualifier>(Ops[6]))
+             : BM->addImageType(SampledT, Desc));
+    return mapType(T, spirv_image_type);
   } else if (TN == kSPIRVTypeName::SampledImg) {
     return mapType(
         T, BM->addSampledImageType(static_cast<SPIRVTypeImage *>(
@@ -586,123 +667,187 @@ SPIRVType *LLVMToSPIRVBase::transSPIRVOpaqueType(Type *T) {
                    BM->addOpaqueGenericType(SPIRVOpaqueTypeOpCodeMap::map(TN)));
 }
 
+SPIRVType *LLVMToSPIRVBase::addSignPreservingLLVMType(llvm::Type *type,
+                                                      const bool is_signed) {
+  const auto add_scalar_uint_type = [this](llvm::Type *scalar_type) {
+    assert(scalar_type->isIntegerTy());
+    return BM->addIntegerType(cast<IntegerType>(scalar_type)->getBitWidth(),
+                              false);
+  };
+
+  if (type->isVectorTy()) {
+    const auto vec_type = dyn_cast<llvm::FixedVectorType>(type);
+    auto elem_type = vec_type->getElementType();
+    auto elem_count = vec_type->getNumElements();
+    if (is_signed) {
+      return BM->addVectorType(transType(type), elem_count);
+    } else {
+      auto scalar_uint_type = add_scalar_uint_type(elem_type);
+      return BM->addVectorType(scalar_uint_type, elem_count);
+    }
+  } else {
+    assert(type->isFloatTy() || type->isIntegerTy());
+    if (is_signed) {
+      return transType(type);
+    } else {
+      return add_scalar_uint_type(type);
+    }
+  }
+}
+
 SPIRVFunction *LLVMToSPIRVBase::transFunctionDecl(Function *F) {
+  // don't translate/emit entry point declarations when the function only is a
+  // declaration, not a definition
+  if (F->isDeclaration() && F->getCallingConv() != CallingConv::FLOOR_FUNC)
+    return nullptr;
+
+  // skip any floor.* functions, these shouldn't be here
+  if (F->getName().startswith("floor."))
+    return nullptr;
+
+  // ignore any non-entry-point functions in shader mode
+  if (SrcLang == spv::SourceLanguageGLSL &&
+      F->getCallingConv() == CallingConv::FLOOR_FUNC)
+    return nullptr;
+
+  // return already translated value
   if (auto BF = getTranslatedValue(F))
     return static_cast<SPIRVFunction *>(BF);
 
-  if (F->isIntrinsic() && (!BM->isSPIRVAllowUnknownIntrinsicsEnabled() ||
-                           isKnownIntrinsic(F->getIntrinsicID()))) {
-    // We should not translate LLVM intrinsics as a function
-    assert(none_of(F->users(),
-                   [this](User *U) { return getTranslatedValue(U); }) &&
-           "LLVM intrinsics shouldn't be called in SPIRV");
-    return nullptr;
-  }
+  // all shader/glsl entry points need special handling compared to normal and
+  // kernel functions
+  const auto entry_point_type = getEntryPointType(F, SrcLang);
+  SPIRVFunction *BF = nullptr;
+  if (entry_point_type == spv::ExecutionModel::ExecutionModelKernel ||
+      entry_point_type == spv::ExecutionModel::ExecutionModelInvalid) {
+    if (F->isIntrinsic() && (!BM->isSPIRVAllowUnknownIntrinsicsEnabled() ||
+                             isKnownIntrinsic(F->getIntrinsicID()))) {
+      // We should not translate LLVM intrinsics as a function
+      assert(none_of(F->users(),
+                     [this](User *U) { return getTranslatedValue(U); }) &&
+             "LLVM intrinsics shouldn't be called in SPIRV");
+      return nullptr;
+    }
 
-  SPIRVTypeFunction *BFT = static_cast<SPIRVTypeFunction *>(
-      transType(OCLTypeToSPIRVPtr->getAdaptedType(F)));
-  SPIRVFunction *BF =
-      static_cast<SPIRVFunction *>(mapValue(F, BM->addFunction(BFT)));
-  BF->setFunctionControlMask(transFunctionControlMask(F));
-  if (F->hasName())
-    BM->setName(BF, F->getName().str());
-  if (isKernel(F))
-    BM->addEntryPoint(ExecutionModelKernel, BF->getId());
-  else if (F->getLinkage() != GlobalValue::InternalLinkage)
-    BF->setLinkageType(transLinkageType(F));
-
-  // Translate OpenCL/SYCL buffer_location metadata if it's attached to the
-  // translated function declaration
-  MDNode *BufferLocation = nullptr;
-  if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_fpga_buffer_location))
-    BufferLocation = F->getMetadata("kernel_arg_buffer_location");
-
-  // Translate runtime_aligned metadata if it's attached to the translated
-  // function declaration
-  MDNode *RuntimeAligned = nullptr;
-  if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_runtime_aligned))
-    RuntimeAligned = F->getMetadata("kernel_arg_runtime_aligned");
+    SPIRVTypeFunction *BFT = static_cast<SPIRVTypeFunction *>(
+        transType(OCLTypeToSPIRVPtr->getAdaptedType(F)));
+    BF =
+        static_cast<SPIRVFunction *>(mapValue(F, BM->addFunction(BFT)));
+    BF->setFunctionControlMask(transFunctionControlMask(F));
+    if (F->hasName())
+      BM->setName(BF, F->getName().str());
+    if (entry_point_type != spv::ExecutionModel::ExecutionModelInvalid)
+      BM->addEntryPoint(ExecutionModelKernel, BF->getId());
+    else if (F->getLinkage() != GlobalValue::InternalLinkage)
+      BF->setLinkageType(transLinkageType(F));
+
+    // Translate OpenCL/SYCL buffer_location metadata if it's attached to the
+    // translated function declaration
+    MDNode *BufferLocation = nullptr;
+    if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_fpga_buffer_location))
+      BufferLocation = F->getMetadata("kernel_arg_buffer_location");
+
+    // Translate runtime_aligned metadata if it's attached to the translated
+    // function declaration
+    MDNode *RuntimeAligned = nullptr;
+    if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_runtime_aligned))
+      RuntimeAligned = F->getMetadata("kernel_arg_runtime_aligned");
+
+    auto Attrs = F->getAttributes();
+
+    for (Function::arg_iterator I = F->arg_begin(), E = F->arg_end(); I != E;
+         ++I) {
+      auto ArgNo = I->getArgNo();
+      SPIRVFunctionParameter *BA = BF->getArgument(ArgNo);
+      if (I->hasName())
+        BM->setName(BA, I->getName().str());
+      if (I->hasByValAttr())
+        BA->addAttr(FunctionParameterAttributeByVal);
+      if (I->hasNoAliasAttr())
+        BA->addAttr(FunctionParameterAttributeNoAlias);
+      if (I->hasNoCaptureAttr())
+        BA->addAttr(FunctionParameterAttributeNoCapture);
+      if (I->hasStructRetAttr())
+        BA->addAttr(FunctionParameterAttributeSret);
+      if (I->onlyReadsMemory())
+        BA->addAttr(FunctionParameterAttributeNoWrite);
+      if (Attrs.hasParamAttr(ArgNo, Attribute::ZExt))
+        BA->addAttr(FunctionParameterAttributeZext);
+      if (Attrs.hasParamAttr(ArgNo, Attribute::SExt))
+        BA->addAttr(FunctionParameterAttributeSext);
+      if (Attrs.hasParamAttr(ArgNo, Attribute::Alignment)) {
+        SPIRVWord AlignmentBytes = Attrs.getParamAttr(ArgNo, Attribute::Alignment)
+                                        .getAlignment()
+                                        .valueOrOne()
+                                        .value();
+        BA->setAlignment(AlignmentBytes);
+      }
+      if (BM->isAllowedToUseVersion(VersionNumber::SPIRV_1_1) &&
+          Attrs.hasParamAttr(ArgNo, Attribute::Dereferenceable))
+        BA->addDecorate(DecorationMaxByteOffset,
+                        Attrs.getParamAttr(ArgNo, Attribute::Dereferenceable)
+                            .getDereferenceableBytes());
+      if (BufferLocation && I->getType()->isPointerTy()) {
+        // Order of integer numbers in MD node follows the order of function
+        // parameters on which we shall attach the appropriate decoration. Add
+        // decoration only if MD value is not negative.
+        int LocID = -1;
+        if (!isa<MDString>(BufferLocation->getOperand(ArgNo)) &&
+            !isa<MDNode>(BufferLocation->getOperand(ArgNo)))
+          LocID = getMDOperandAsInt(BufferLocation, ArgNo);
+        if (LocID >= 0)
+          BA->addDecorate(DecorationBufferLocationINTEL, LocID);
+      }
+      if (RuntimeAligned && I->getType()->isPointerTy()) {
+        // Order of integer numbers in MD node follows the order of function
+        // parameters on which we shall attach the appropriate decoration. Add
+        // decoration only if MD value is 1.
+        int LocID = 0;
+        if (!isa<MDString>(RuntimeAligned->getOperand(ArgNo)) &&
+            !isa<MDNode>(RuntimeAligned->getOperand(ArgNo)))
+          LocID = getMDOperandAsInt(RuntimeAligned, ArgNo);
+        if (LocID == 1)
+          BA->addDecorate(internal::DecorationRuntimeAlignedINTEL, LocID);
+      }
+    }
+    if (Attrs.hasRetAttr(Attribute::ZExt))
+      BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeZext);
+    if (Attrs.hasRetAttr(Attribute::SExt))
+      BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeSext);
+    if (Attrs.hasFnAttr("referenced-indirectly")) {
+      assert(!isEntryPoint(F) &&
+             "kernel function was marked as referenced-indirectly");
+      BF->addDecorate(DecorationReferencedIndirectlyINTEL);
+    }
 
-  auto Attrs = F->getAttributes();
+    if (Attrs.hasFnAttr(kVCMetadata::VCCallable) &&
+        BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_fast_composite)) {
+      BF->addDecorate(internal::DecorationCallableFunctionINTEL);
+    }
 
-  for (Function::arg_iterator I = F->arg_begin(), E = F->arg_end(); I != E;
-       ++I) {
-    auto ArgNo = I->getArgNo();
-    SPIRVFunctionParameter *BA = BF->getArgument(ArgNo);
-    if (I->hasName())
-      BM->setName(BA, I->getName().str());
-    if (I->hasByValAttr())
-      BA->addAttr(FunctionParameterAttributeByVal);
-    if (I->hasNoAliasAttr())
-      BA->addAttr(FunctionParameterAttributeNoAlias);
-    if (I->hasNoCaptureAttr())
-      BA->addAttr(FunctionParameterAttributeNoCapture);
-    if (I->hasStructRetAttr())
-      BA->addAttr(FunctionParameterAttributeSret);
-    if (I->onlyReadsMemory())
-      BA->addAttr(FunctionParameterAttributeNoWrite);
-    if (Attrs.hasParamAttr(ArgNo, Attribute::ZExt))
-      BA->addAttr(FunctionParameterAttributeZext);
-    if (Attrs.hasParamAttr(ArgNo, Attribute::SExt))
-      BA->addAttr(FunctionParameterAttributeSext);
-    if (Attrs.hasParamAttr(ArgNo, Attribute::Alignment)) {
-      SPIRVWord AlignmentBytes = Attrs.getParamAttr(ArgNo, Attribute::Alignment)
-                                     .getAlignment()
-                                     .valueOrOne()
-                                     .value();
-      BA->setAlignment(AlignmentBytes);
-    }
-    if (BM->isAllowedToUseVersion(VersionNumber::SPIRV_1_1) &&
-        Attrs.hasParamAttr(ArgNo, Attribute::Dereferenceable))
-      BA->addDecorate(DecorationMaxByteOffset,
-                      Attrs.getParamAttr(ArgNo, Attribute::Dereferenceable)
-                          .getDereferenceableBytes());
-    if (BufferLocation && I->getType()->isPointerTy()) {
-      // Order of integer numbers in MD node follows the order of function
-      // parameters on which we shall attach the appropriate decoration. Add
-      // decoration only if MD value is not negative.
-      int LocID = -1;
-      if (!isa<MDString>(BufferLocation->getOperand(ArgNo)) &&
-          !isa<MDNode>(BufferLocation->getOperand(ArgNo)))
-        LocID = getMDOperandAsInt(BufferLocation, ArgNo);
-      if (LocID >= 0)
-        BA->addDecorate(DecorationBufferLocationINTEL, LocID);
-    }
-    if (RuntimeAligned && I->getType()->isPointerTy()) {
-      // Order of integer numbers in MD node follows the order of function
-      // parameters on which we shall attach the appropriate decoration. Add
-      // decoration only if MD value is 1.
-      int LocID = 0;
-      if (!isa<MDString>(RuntimeAligned->getOperand(ArgNo)) &&
-          !isa<MDNode>(RuntimeAligned->getOperand(ArgNo)))
-        LocID = getMDOperandAsInt(RuntimeAligned, ArgNo);
-      if (LocID == 1)
-        BA->addDecorate(internal::DecorationRuntimeAlignedINTEL, LocID);
-    }
-  }
-  if (Attrs.hasRetAttr(Attribute::ZExt))
-    BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeZext);
-  if (Attrs.hasRetAttr(Attribute::SExt))
-    BF->addDecorate(DecorationFuncParamAttr, FunctionParameterAttributeSext);
-  if (Attrs.hasFnAttr("referenced-indirectly")) {
-    assert(!isKernel(F) &&
-           "kernel function was marked as referenced-indirectly");
-    BF->addDecorate(DecorationReferencedIndirectlyINTEL);
-  }
-
-  if (Attrs.hasFnAttr(kVCMetadata::VCCallable) &&
-      BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_fast_composite)) {
-    BF->addDecorate(internal::DecorationCallableFunctionINTEL);
-  }
-
-  if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_vector_compute))
-    transVectorComputeMetadata(F);
-
-  transFPGAFunctionMetadata(BF, F);
-
-  SPIRVDBG(dbgs() << "[transFunction] " << *F << " => ";
-           spvdbgs() << *BF << '\n';)
-  return BF;
+    if (BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_vector_compute))
+      transVectorComputeMetadata(F);
+
+    transFPGAFunctionMetadata(BF, F);
+
+    SPIRVDBG(dbgs() << "[transFunction (kernel)] " << *F << " => ";
+             spvdbgs() << *BF << '\n';)
+    return BF;
+  } else {
+    // shader function is always "void func_name()"
+    const auto shader_func_type =
+        llvm::FunctionType::get(llvm::Type::getVoidTy(*Ctx), false);
+    SPIRVTypeFunction *BFT =
+        static_cast<SPIRVTypeFunction *>(transType(shader_func_type));
+    BF = static_cast<SPIRVFunction *>(mapValue(F, BM->addFunction(BFT)));
+    assert(F->hasName() && "entry point function must have a name");
+    BM->setName(BF, F->getName().str());
+    BM->addEntryPoint(entry_point_type, BF->getId());
+    // NOTE: not handling/adding function parameters here
+    SPIRVDBG(dbgs() << "[transFunction (shader)] " << *F << " => ";
+             spvdbgs() << *BF << '\n';)
+    return BF;
+  }
 }
 
 void LLVMToSPIRVBase::transVectorComputeMetadata(Function *F) {
@@ -749,7 +894,7 @@ void LLVMToSPIRVBase::transVectorComputeMetadata(Function *F) {
       translateSEVDecoration(
           Attrs.getParamAttr(ArgNo, kVCMetadata::VCSingleElementVector), BA);
   }
-  if (!isKernel(F) &&
+  if (!isEntryPoint(F) &&
       BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_float_controls2) &&
       Attrs.hasFnAttr(kVCMetadata::VCFloatControl)) {
 
@@ -935,7 +1080,13 @@ SPIRVValue *LLVMToSPIRVBase::transConstant(Value *V) {
   }
 
   if (isa<UndefValue>(V)) {
-    return BM->addUndef(transType(V->getType()));
+    // TODO/NOTE: don't allow global undef constants in Vulkan/GLSL until
+    // drivers (AMD) catch up
+    if (SrcLang == spv::SourceLanguageGLSL) {
+      return nullptr;
+    } else {
+      return BM->addUndef(transType(V->getType()));
+    }
   }
 
   return nullptr;
@@ -967,18 +1118,62 @@ SPIRVValue *LLVMToSPIRVBase::transValue(Value *V, SPIRVBasicBlock *BB,
 
 SPIRVInstruction *LLVMToSPIRVBase::transBinaryInst(BinaryOperator *B,
                                                    SPIRVBasicBlock *BB) {
+  // in LLVM (fneg x) is represented as (fsub +/-0 x) -> special case this to
+  // produce OpFNegate instead
+  Value *fneg_val;
+  if (PatternMatch::match(B, PatternMatch::m_FNeg(PatternMatch::m_Value(
+                                 fneg_val)))) {
+    return BM->addUnaryInst(spv::OpFNegate, transType(B->getType()),
+                            transValue(B->getOperand(1), BB), BB);
+  }
+
   unsigned LLVMOC = B->getOpcode();
+  Op BOC = OpCodeMap::map(LLVMOC);
   auto Op0 = transValue(B->getOperand(0), BB);
+
+  // take care of signed/unsigned type conversion mismatches,
+  // TODO: as with unary instructions, we need to do this properly at some point
+  const auto type = transType(B->getType());
+  const auto is_int = type->isTypeInt();
+  const auto is_sint = (is_int ? ((SPIRVTypeInt *)type)->isSigned() : false);
+  const auto is_uint = (is_int ? !((SPIRVTypeInt *)type)->isSigned() : false);
+  switch (BOC) {
+  case spv::OpUMod:
+    if (is_sint) {
+      BOC = OpSMod;
+    }
+    break;
+  case spv::OpSMod:
+    if (is_uint) {
+      BOC = OpUMod;
+    }
+    break;
+  case spv::OpUDiv:
+    if (is_sint) {
+      BOC = OpSDiv;
+    }
+    break;
+  case spv::OpSDiv:
+    if (is_uint) {
+      BOC = OpUDiv;
+    }
+    break;
+  default:
+    break;
+  }
+
   SPIRVInstruction *BI = BM->addBinaryInst(
-      transBoolOpCode(Op0, OpCodeMap::map(LLVMOC)), transType(B->getType()),
+      transBoolOpCode(Op0, BOC), type,
       Op0, transValue(B->getOperand(1), BB), BB);
 
+#if 0 // this is stupid
   if (isUnfusedMulAdd(B)) {
     Function *F = B->getFunction();
     SPIRVDBG(dbgs() << "[fp-contract] disabled for " << F->getName()
                     << ": possible fma candidate " << *B << '\n');
     joinFPContract(F, FPContract::DISABLED);
   }
+#endif
 
   return BI;
 }
@@ -1004,6 +1199,7 @@ SPIRVInstruction *LLVMToSPIRVBase::transCmpInst(CmpInst *Cmp,
 
 SPIRV::SPIRVInstruction *LLVMToSPIRVBase::transUnaryInst(UnaryInstruction *U,
                                                          SPIRVBasicBlock *BB) {
+  // TODO: properly handle int/uint conversions and type handling
   Op BOC = OpNop;
   if (auto Cast = dyn_cast<AddrSpaceCastInst>(U)) {
     const auto SrcAddrSpace = Cast->getSrcTy()->getPointerAddressSpace();
@@ -1062,8 +1258,39 @@ SPIRV::SPIRVInstruction *LLVMToSPIRVBase::transUnaryInst(UnaryInstruction *U,
   }
 
   auto Op = transValue(U->getOperand(0), BB, true, FuncTransMode::Pointer);
-  return BM->addUnaryInst(transBoolOpCode(Op, BOC), transType(U->getType()), Op,
-                          BB);
+
+  // take care of signed/unsigned type conversion mismatches,
+  // as stated above this should be done properly at some point
+  // -> fixup superficial stuff caused by unary int conversion translation
+  const auto type = transType(U->getType());
+  const auto is_int = type->isTypeInt();
+  const auto is_sint = (is_int ? ((SPIRVTypeInt *)type)->isSigned() : false);
+  const auto is_uint = (is_int ? !((SPIRVTypeInt *)type)->isSigned() : false);
+  switch (BOC) {
+  case spv::OpUConvert:
+    if (is_sint) {
+      BOC = OpSConvert;
+    }
+    break;
+  case spv::OpSConvert:
+    if (is_uint) {
+      BOC = OpUConvert;
+    }
+    break;
+  case spv::OpConvertFToU:
+    if (is_sint) {
+      BOC = OpConvertFToS;
+    }
+    break;
+  case spv::OpConvertFToS:
+    if (is_uint) {
+      BOC = OpConvertFToU;
+    }
+    break;
+  default:
+    break;
+  }
+  return BM->addUnaryInst(transBoolOpCode(Op, BOC), type, Op, BB);
 }
 
 /// This helper class encapsulates information extraction from
@@ -1139,7 +1366,8 @@ private:
 spv::LoopControlMask
 LLVMToSPIRVBase::getLoopControl(const BranchInst *Branch,
                                 std::vector<SPIRVWord> &Parameters) {
-  if (!Branch)
+  // do not allow this for Vulkan at all
+  if (!Branch || SrcLang == spv::SourceLanguageGLSL)
     return spv::LoopControlMaskNone;
   MDNode *LoopMD = Branch->getMetadata("llvm.loop");
   if (!LoopMD)
@@ -1421,12 +1649,46 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
 
   if (auto GV = dyn_cast<GlobalVariable>(V)) {
     llvm::PointerType *Ty = GV->getType();
+
+    if (GV->hasName() && GV->getName().find(".vulkan") != std::string::npos) {
+      // special global variables are handled/added in transFunction
+      // (note: should only be output vars here)
+      return nullptr;
+    }
+
     // Though variables with common linkage type are initialized by 0,
     // they can be represented in SPIR-V as uninitialized variables with
     // 'Export' linkage type, just as tentative definitions look in C
     llvm::Value *Init = GV->hasInitializer() && !GV->hasCommonLinkage()
                             ? GV->getInitializer()
                             : nullptr;
+
+    SPIRVStorageClassKind StorageClass;
+    auto AddressSpace = static_cast<SPIRAddressSpace>(Ty->getAddressSpace());
+    bool IsVectorCompute =
+        BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_vector_compute) &&
+        GV->hasAttribute(kVCMetadata::VCGlobalVariable);
+    if (IsVectorCompute)
+      StorageClass =
+          VectorComputeUtil::getVCGlobalVarStorageClass(AddressSpace);
+    else {
+      // Lower global_device and global_host address spaces that were added in
+      // SYCL as part of SYCL_INTEL_usm_address_spaces extension to just global
+      // address space if device doesn't support SPV_INTEL_usm_storage_classes
+      // extension
+      if ((AddressSpace == SPIRAS_GlobalDevice ||
+           AddressSpace == SPIRAS_GlobalHost) &&
+          !BM->isAllowedToUseExtension(
+              ExtensionID::SPV_INTEL_usm_storage_classes))
+        AddressSpace = SPIRAS_Global;
+      StorageClass = SPIRSPIRVAddrSpaceMap::map(AddressSpace);
+      assert(((StorageClass == spv::StorageClassFunction && BB != nullptr) ||
+              StorageClass != spv::StorageClassFunction) &&
+             "invalid GV/BB");
+    }
+
+    // for Vulkan, we will remove invalid initializers (zero or undef needs to
+    // be present in LLVM,  but not in SPIR-V)
     SPIRVValue *BVarInit = nullptr;
     StructType *ST = Init ? dyn_cast<StructType>(Init->getType()) : nullptr;
     if (ST && ST->hasName() && isSPIRVConstantName(ST->getName())) {
@@ -1441,19 +1703,22 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
       }
       Inst->dropAllReferences();
       UnboundInst.push_back(Inst);
-      BVarInit = transValue(Init, nullptr);
+      BVarInit = (StorageClass == StorageClassWorkgroup || Init == nullptr ? nullptr : transValue(Init, nullptr));
     } else if (ST && isa<UndefValue>(Init)) {
       // Undef initializer for LLVM structure be can translated to
       // OpConstantComposite with OpUndef constituents.
-      auto I = ValueMap.find(Init);
-      if (I == ValueMap.end()) {
-        std::vector<SPIRVValue *> Elements;
-        for (Type *E : ST->elements())
-          Elements.push_back(transValue(UndefValue::get(E), nullptr));
-        BVarInit = BM->addCompositeConstant(transType(ST), Elements);
-        ValueMap[Init] = BVarInit;
-      } else
-        BVarInit = I->second;
+      if (SrcLang == spv::SourceLanguageGLSL) {
+        auto I = ValueMap.find(Init);
+        if (I == ValueMap.end()) {
+          std::vector<SPIRVValue *> Elements;
+          for (Type *E : ST->elements())
+            Elements.push_back(transValue(UndefValue::get(E), nullptr));
+          BVarInit = BM->addCompositeConstant(transType(ST), Elements);
+          ValueMap[Init] = BVarInit;
+        } else {
+          BVarInit = I->second;
+        }
+      }
     } else if (Init && !isa<UndefValue>(Init)) {
       if (!BM->isAllowedToUseExtension(
               ExtensionID::SPV_INTEL_long_constant_composite)) {
@@ -1475,33 +1740,23 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
           }
         }
       }
-      BVarInit = transValue(Init, nullptr);
+      BVarInit = (StorageClass == StorageClassWorkgroup || Init == nullptr ? nullptr : transValue(Init, nullptr));
     }
 
-    SPIRVStorageClassKind StorageClass;
-    auto AddressSpace = static_cast<SPIRAddressSpace>(Ty->getAddressSpace());
-    bool IsVectorCompute =
-        BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_vector_compute) &&
-        GV->hasAttribute(kVCMetadata::VCGlobalVariable);
-    if (IsVectorCompute)
-      StorageClass =
-          VectorComputeUtil::getVCGlobalVarStorageClass(AddressSpace);
-    else {
-      // Lower global_device and global_host address spaces that were added in
-      // SYCL as part of SYCL_INTEL_usm_address_spaces extension to just global
-      // address space if device doesn't support SPV_INTEL_usm_storage_classes
-      // extension
-      if ((AddressSpace == SPIRAS_GlobalDevice ||
-           AddressSpace == SPIRAS_GlobalHost) &&
-          !BM->isAllowedToUseExtension(
-              ExtensionID::SPV_INTEL_usm_storage_classes))
-        AddressSpace = SPIRAS_Global;
-      StorageClass = SPIRSPIRVAddrSpaceMap::map(AddressSpace);
-    }
+    // Vulkan/GLSL doesn't do linkage
+    auto linkage =
+        (SrcLang != spv::SourceLanguageGLSL ? transLinkageType(GV)
+                                            : spv::internal::LinkageTypeInternal);
 
+    // vars with Function storage must be added to the entry block
+    SPIRVBasicBlock* var_bb = nullptr;
+    if (StorageClass == spv::StorageClassFunction) {
+      var_bb = BB->getParent()->getBasicBlock(0);
+    }
     auto BVar = static_cast<SPIRVVariable *>(
-        BM->addVariable(transType(Ty), GV->isConstant(), transLinkageType(GV),
-                        BVarInit, GV->getName().str(), StorageClass, nullptr));
+        BM->addVariable(transType(Ty), GV->isConstant(), linkage,
+                        BVarInit, GV->getName().str(), StorageClass,
+                        var_bb));
 
     if (IsVectorCompute) {
       BVar->addDecorate(DecorationVectorComputeVariableINTEL);
@@ -1521,6 +1776,11 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     }
 
     mapValue(V, BVar);
+    if (Ty->isPointerTy()) {
+      auto elem_type = Ty->getPointerElementType();
+      auto spirv_elem_type = transType(elem_type);
+      decorateComposite(elem_type, spirv_elem_type);
+    }
     spv::BuiltIn Builtin = spv::BuiltInPosition;
     if (!GV->hasName() || !getSPIRVBuiltin(GV->getName().str(), Builtin))
       return BVar;
@@ -1541,6 +1801,16 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     return BVar;
   }
 
+  // always create a new undef variable for vulkan/glsl to workaround driver
+  // issues
+  if (isa<UndefValue>(V) && SrcLang == spv::SourceLanguageGLSL) {
+    if (BB != nullptr) {
+      return BM->addUndefInst(transType(V->getType()), BB);
+    }
+    // if this isn't inside a BB (e.g. inside a constant), just use 0
+    return BM->addConstant(transType(V->getType()), 0);
+  }
+
   if (isa<Constant>(V)) {
     auto BV = transConstant(V);
     assert(BV);
@@ -1581,11 +1851,38 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     if (MemoryAccess.front() == 0)
       MemoryAccess.clear();
 
-    return mapValue(V,
-                    BM->addStoreInst(transValue(ST->getPointerOperand(), BB),
-                                     transValue(ST->getValueOperand(), BB, true,
-                                                FuncTransMode::Pointer),
-                                     MemoryAccess, BB));
+    // check if we need to do int <-> uint casting
+    auto dst = transValue(ST->getPointerOperand(), BB);
+    auto src = transValue(ST->getValueOperand(), BB, true, FuncTransMode::Pointer);
+    assert(dst->getType()->isTypePointer());
+    auto dst_elem_type =
+        ((SPIRVTypePointer *)dst->getType())->getPointerElementType();
+    auto src_elem_type = src->getType();
+    if (dst_elem_type != src_elem_type) {
+      bool emit_bitcast = false;
+      if (dst_elem_type->isTypeInt()) {
+        assert(src_elem_type->isTypeInt());
+        if (((SPIRVTypeInt *)dst_elem_type)->isSigned() !=
+            ((SPIRVTypeInt *)src_elem_type)->isSigned()) {
+          emit_bitcast = true;
+        }
+      } else if (dst_elem_type->isTypeVectorInt()) {
+        assert(src_elem_type->isTypeVectorInt());
+        if (((SPIRVTypeInt *)((SPIRVTypeVector *)dst_elem_type)
+                 ->getComponentType())
+                ->isSigned() !=
+            ((SPIRVTypeInt *)((SPIRVTypeVector *)src_elem_type)
+                 ->getComponentType())
+                ->isSigned()) {
+          emit_bitcast = true;
+        }
+      }
+      if (emit_bitcast) {
+        src = BM->addUnaryInst(spv::OpBitcast, dst_elem_type, src, BB);
+      }
+    }
+
+    return mapValue(V, BM->addStoreInst(dst, src, MemoryAccess, BB));
   }
 
   if (LoadInst *LD = dyn_cast<LoadInst>(V)) {
@@ -1620,8 +1917,14 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     return mapValue(V, BI);
   }
 
-  if (dyn_cast<UnreachableInst>(V))
+  if (dyn_cast<UnreachableInst>(V)) {
+    // TODO: fix this be either creating a llvm OpKill instruction or metadata
+    if (ignore_next_unreachable) {
+      ignore_next_unreachable = false;
+      return nullptr;
+    }
     return mapValue(V, BM->addUnreachableInst(BB));
+  }
 
   if (auto RI = dyn_cast<ReturnInst>(V)) {
     if (auto RV = RI->getReturnValue())
@@ -1765,9 +2068,18 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
   }
 
   if (auto Phi = dyn_cast<PHINode>(V)) {
+    // NOTE: LLVM has the tendency to allow duplicate predecessors and PHI incoming blocks
+    // -> ensure we only add incoming values for unique predecessors
     std::vector<SPIRVValue *> IncomingPairs;
+    std::unordered_set<BasicBlock*> unique_bbs;
 
     for (size_t I = 0, E = Phi->getNumIncomingValues(); I != E; ++I) {
+      auto in_bb = Phi->getIncomingBlock(I);
+      if (unique_bbs.count(in_bb) > 0) {
+        continue;
+      }
+      unique_bbs.emplace(in_bb);
+
       IncomingPairs.push_back(transValue(Phi->getIncomingValue(I), BB, true,
                                          FuncTransMode::Pointer));
       IncomingPairs.push_back(transValue(Phi->getIncomingBlock(I), nullptr));
@@ -1801,57 +2113,97 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     std::vector<SPIRVValue *> Indices;
     for (unsigned I = 0, E = GEP->getNumIndices(); I != E; ++I)
       Indices.push_back(transValue(GEP->getOperand(I + 1), BB));
-    auto *PointerOperand = GEP->getPointerOperand();
-    auto *TransPointerOperand = transValue(PointerOperand, BB);
-
-    // Certain array-related optimization hints can be expressed via
-    // LLVM metadata. For the purpose of linking this metadata with
-    // the accessed array variables, our GEP may have been marked into
-    // a so-called index group, an MDNode by itself.
-    if (MDNode *IndexGroup = GEP->getMetadata("llvm.index.group")) {
-      SPIRVValue *ActualMemoryPtr = TransPointerOperand;
-      if (auto *Load = dyn_cast<LoadInst>(PointerOperand)) {
-        ActualMemoryPtr = transValue(Load->getPointerOperand(), BB);
+    if (SrcLang != spv::SourceLanguageGLSL) {
+      auto *PointerOperand = GEP->getPointerOperand();
+      auto *TransPointerOperand = transValue(PointerOperand, BB);
+
+      // Certain array-related optimization hints can be expressed via
+      // LLVM metadata. For the purpose of linking this metadata with
+      // the accessed array variables, our GEP may have been marked into
+      // a so-called index group, an MDNode by itself.
+      if (MDNode *IndexGroup = GEP->getMetadata("llvm.index.group")) {
+        SPIRVValue *ActualMemoryPtr = TransPointerOperand;
+        if (auto *Load = dyn_cast<LoadInst>(PointerOperand)) {
+          ActualMemoryPtr = transValue(Load->getPointerOperand(), BB);
+        }
+        SPIRVId AccessedArrayId = ActualMemoryPtr->getId();
+        unsigned NumOperands = IndexGroup->getNumOperands();
+        // When we're working with embedded loops, it's natural that
+        // the outer loop's hints apply to all code contained within.
+        // The inner loop's specific hints, however, should stay private
+        // to the inner loop's scope.
+        // Consequently, the following division of the index group metadata
+        // nodes emerges:
+
+        // 1) The metadata node has no operands. It will be directly referenced
+        //    from within the optimization hint metadata.
+        if (NumOperands == 0)
+          IndexGroupArrayMap[IndexGroup].insert(AccessedArrayId);
+        // 2) The metadata node has several operands. It serves to link an index
+        //    group specific to some embedded loop with other index groups that
+        //    mark the same array variable for the outer loop(s).
+        for (unsigned I = 0; I < NumOperands; ++I) {
+          auto *ContainedIndexGroup = getMDOperandAsMDNode(IndexGroup, I);
+          IndexGroupArrayMap[ContainedIndexGroup].insert(AccessedArrayId);
+        }
       }
-      SPIRVId AccessedArrayId = ActualMemoryPtr->getId();
-      unsigned NumOperands = IndexGroup->getNumOperands();
-      // When we're working with embedded loops, it's natural that
-      // the outer loop's hints apply to all code contained within.
-      // The inner loop's specific hints, however, should stay private
-      // to the inner loop's scope.
-      // Consequently, the following division of the index group metadata
-      // nodes emerges:
-
-      // 1) The metadata node has no operands. It will be directly referenced
-      //    from within the optimization hint metadata.
-      if (NumOperands == 0)
-        IndexGroupArrayMap[IndexGroup].insert(AccessedArrayId);
-      // 2) The metadata node has several operands. It serves to link an index
-      //    group specific to some embedded loop with other index groups that
-      //    mark the same array variable for the outer loop(s).
-      for (unsigned I = 0; I < NumOperands; ++I) {
-        auto *ContainedIndexGroup = getMDOperandAsMDNode(IndexGroup, I);
-        IndexGroupArrayMap[ContainedIndexGroup].insert(AccessedArrayId);
+
+      return mapValue(V, BM->addPtrAccessChainInst(transType(GEP->getType()),
+                                                   TransPointerOperand, Indices,
+                                                   BB, GEP->isInBounds()));
+    } else {
+      // with variable pointers we can now use PtrAccessChain instead of the simple AccessChain (for SSBOs, local memory and physical SSBOs)
+      auto gep_type = transType(GEP->getType());
+      auto gep_value = transValue(GEP->getPointerOperand(), BB);
+      auto gep_value_type = gep_value->getType();
+      const auto storage_class = gep_value_type->getPointerStorageClass();
+      if (storage_class == spv::StorageClassWorkgroup ||
+          storage_class == spv::StorageClassPhysicalStorageBuffer ||
+          storage_class == spv::StorageClassStorageBuffer) {
+        // must still treat access to SSBO runtime arrays specially by adding two additional 0 indices
+        if (storage_class == spv::StorageClassStorageBuffer) {
+          auto gep_value_elem_type = gep_value_type->getPointerElementType();
+          if (gep_value_elem_type->isTypeStruct()) {
+            auto gep_struct_type = (SPIRV::SPIRVTypeStruct*)gep_value_elem_type;
+            if (gep_struct_type->getMemberCount() > 0 && gep_struct_type->getMemberType(0)->isTypeRuntimeArray()) {
+              auto zero_const = transValue(llvm::ConstantInt::get(llvm::Type::getInt32Ty(*Ctx), 0), BB);
+              Indices.insert(Indices.begin(), zero_const);
+              Indices.insert(Indices.begin(), zero_const);
+            }
+          }
+        }
+        return mapValue(
+            V, BM->addPtrAccessChainInst(gep_type, gep_value,
+                                         Indices, BB, false /* never emit inbounds */));
+      } else {
+        // for all other storage classes: fall back to (Inbounds)AccessChain
+        return mapValue(
+            V, BM->addAccessChainInst(transType(GEP->getType()),
+                                      transValue(GEP->getPointerOperand(), BB),
+                                      Indices, BB, GEP->isInBounds()));
       }
     }
-
-    return mapValue(V, BM->addPtrAccessChainInst(transType(GEP->getType()),
-                                                 TransPointerOperand, Indices,
-                                                 BB, GEP->isInBounds()));
   }
 
   if (auto Ext = dyn_cast<ExtractElementInst>(V)) {
     auto Index = Ext->getIndexOperand();
-    if (auto Const = dyn_cast<ConstantInt>(Index))
-      return mapValue(V, BM->addCompositeExtractInst(
-                             transType(Ext->getType()),
-                             transValue(Ext->getVectorOperand(), BB),
+    if (auto Const = dyn_cast<ConstantInt>(Index)) {
+      auto val = transValue(Ext->getVectorOperand(), BB);
+      SPIRVType *type = nullptr;
+      if (val->getType()->isTypeVector()) {
+        // assume component type that we've already mapped
+        type = val->getType()->getVectorComponentType();
+      } else {
+        type = transType(Ext->getType());
+      }
+      return mapValue(V, BM->addCompositeExtractInst(type, val,
                              std::vector<SPIRVWord>(1, Const->getZExtValue()),
                              BB));
-    else
+    } else {
       return mapValue(V, BM->addVectorExtractDynamicInst(
                              transValue(Ext->getVectorOperand(), BB),
                              transValue(Index, BB), BB));
+    }
   }
 
   if (auto Ins = dyn_cast<InsertElementInst>(V)) {
@@ -1930,6 +2282,7 @@ LLVMToSPIRVBase::transValueWithoutDecoration(Value *V, SPIRVBasicBlock *BB,
     BM->SPIRVCK(false, InvalidInstruction, toString(Inst));
   }
 
+  errs() << "not implemented: " << *V << "\n";
   llvm_unreachable("Not implemented");
   return nullptr;
 }
@@ -1944,7 +2297,7 @@ SPIRVType *LLVMToSPIRVBase::mapType(Type *T, SPIRVType *BT) {
   return BT;
 }
 
-SPIRVValue *LLVMToSPIRVBase::mapValue(Value *V, SPIRVValue *BV) {
+SPIRVValue *LLVMToSPIRVBase::mapValue(const Value *V, SPIRVValue *BV) {
   auto Loc = ValueMap.find(V);
   if (Loc != ValueMap.end()) {
     if (Loc->second == BV)
@@ -2000,7 +2353,7 @@ bool LLVMToSPIRVBase::transDecoration(Value *V, SPIRVValue *BV) {
     }
   }
 
-  if (auto BVF = dyn_cast_or_null<FPMathOperator>(V)) {
+  if (auto BVF = dyn_cast_or_null<FPMathOperator>(V); BVF && SrcLang != spv::SourceLanguageGLSL) {
     auto Opcode = BVF->getOpcode();
     if (Opcode == Instruction::FAdd || Opcode == Instruction::FSub ||
         Opcode == Instruction::FMul || Opcode == Instruction::FDiv ||
@@ -2051,6 +2404,11 @@ bool LLVMToSPIRVBase::transDecoration(Value *V, SPIRVValue *BV) {
 }
 
 bool LLVMToSPIRVBase::transAlign(Value *V, SPIRVValue *BV) {
+  // shader doesn't have the alignment decoration -> just return
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    return true;
+  }
+
   if (auto AL = dyn_cast<AllocaInst>(V)) {
     BM->setAlignment(BV, AL->getAlignment());
     return true;
@@ -2090,9 +2448,19 @@ void LLVMToSPIRVBase::transMemAliasingINTELDecorations(Instruction *Inst,
 
 /// Do this after source language is set.
 bool LLVMToSPIRVBase::transBuiltinSet() {
+  SPIRVWord Ver = 0;
+  SourceLanguage Kind = BM->getSourceLanguage(&Ver);
+  assert((Kind == SourceLanguageOpenCL_C || Kind == SourceLanguageOpenCL_CPP ||
+          Kind == SourceLanguageGLSL) && "not supported");
+
   SPIRVId EISId;
-  if (!BM->importBuiltinSet("OpenCL.std", &EISId))
-    return false;
+  if (Kind != SourceLanguageGLSL) {
+    if (!BM->importBuiltinSet("OpenCL.std", &EISId))
+      return false;
+  } else {
+    if (!BM->importBuiltinSet("GLSL.std.450", &EISId))
+      return false;
+  }
   if (SPIRVMDWalker(*M).getNamedMD("llvm.dbg.cu")) {
     if (!BM->importBuiltinSet(
             SPIRVBuiltinSetNameMap::map(BM->getDebugInfoEIS()), &EISId))
@@ -2641,7 +3009,68 @@ LLVMToSPIRVBase::applyRoundingModeConstraint(Value *V, SPIRVInstruction *I) {
   return I;
 }
 
-static SPIRVWord getBuiltinIdForIntrinsic(Intrinsic::ID IID) {
+static SPIRVWord getBuiltinIdForIntrinsicGLSL(Intrinsic::ID IID) {
+  switch (IID) {
+  case Intrinsic::ceil:
+    return GLSLLIB::Ceil;
+  case Intrinsic::cos:
+    return GLSLLIB::Cos;
+  case Intrinsic::exp:
+    return GLSLLIB::Exp;
+  case Intrinsic::exp2:
+    return GLSLLIB::Exp2;
+  case Intrinsic::fabs:
+    return GLSLLIB::FAbs;
+  case Intrinsic::floor:
+    return GLSLLIB::Floor;
+  case Intrinsic::fma:
+    return GLSLLIB::Fma;
+  case Intrinsic::log:
+    return GLSLLIB::Log;
+  case Intrinsic::log2:
+    return GLSLLIB::Log2;
+  case Intrinsic::maximum:
+    return GLSLLIB::FMax;
+  case Intrinsic::maxnum:
+    return GLSLLIB::FMax;
+  case Intrinsic::minimum:
+    return GLSLLIB::FMin;
+  case Intrinsic::minnum:
+    return GLSLLIB::FMin;
+  case Intrinsic::nearbyint:
+    return GLSLLIB::RoundEven;
+  case Intrinsic::pow:
+    return GLSLLIB::Pow;
+  case Intrinsic::rint:
+    return GLSLLIB::RoundEven;
+  case Intrinsic::round:
+    return GLSLLIB::Round;
+  case Intrinsic::roundeven:
+    return GLSLLIB::RoundEven;
+  case Intrinsic::sin:
+    return GLSLLIB::Sin;
+  case Intrinsic::sqrt:
+    return GLSLLIB::Sqrt;
+  case Intrinsic::trunc:
+    return GLSLLIB::Trunc;
+  case Intrinsic::abs:
+    return GLSLLIB::SAbs;
+  case Intrinsic::ctlz:
+  case Intrinsic::cttz:
+    assert(false && "ctz/clz are not supported with GLSL/Vulkan - use libfloor wrappers instead");
+    return 0;
+  case Intrinsic::copysign:
+  case Intrinsic::log10:
+  case Intrinsic::powi:
+    assert(false && "intrinsic not supported with GLSL/Vulkan!");
+    return 0;
+  default:
+    assert(false && "Builtin ID requested for Unhandled intrinsic!");
+    return 0;
+  }
+}
+
+static SPIRVWord getBuiltinIdForIntrinsicOpenCL(Intrinsic::ID IID) {
   switch (IID) {
   // Note: In some cases the semantics of the OpenCL builtin are not identical
   //       to the semantics of the corresponding LLVM IR intrinsic. The LLVM
@@ -2698,12 +3127,25 @@ static SPIRVWord getBuiltinIdForIntrinsic(Intrinsic::ID IID) {
     return OpenCLLIB::Sqrt;
   case Intrinsic::trunc:
     return OpenCLLIB::Trunc;
+  case Intrinsic::abs:
+    return OpenCLLIB::SAbs;
+  case Intrinsic::ctlz:
+    return OpenCLLIB::Clz;
+  case Intrinsic::cttz:
+    return OpenCLLIB::Ctz;
   default:
     assert(false && "Builtin ID requested for Unhandled intrinsic!");
     return 0;
   }
 }
 
+static SPIRVWord getBuiltinIdForIntrinsic(Intrinsic::ID IID, SPIRVWord src_lang) {
+  if ((spv::SourceLanguage)src_lang == spv::SourceLanguage::SourceLanguageGLSL) {
+    return getBuiltinIdForIntrinsicGLSL(IID);
+  }
+  return getBuiltinIdForIntrinsicOpenCL(IID);
+}
+
 SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
                                                 SPIRVBasicBlock *BB) {
   auto GetMemoryAccess = [](MemIntrinsic *MI) -> std::vector<SPIRVWord> {
@@ -2728,6 +3170,7 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
   // LLVM intrinsics with known translation to SPIR-V are handled here. They
   // also must be registered at isKnownIntrinsic function in order to make
   // -spirv-allow-unknown-intrinsics work correctly.
+  const auto ext_set = (SrcLang == SourceLanguageGLSL ? SPIRVEIS_GLSL : SPIRVEIS_OpenCL);
   switch (II->getIntrinsicID()) {
   case Intrinsic::assume: {
     // llvm.assume translation is currently supported only within
@@ -2765,10 +3208,10 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
   case Intrinsic::trunc: {
     if (!checkTypeForSPIRVExtendedInstLowering(II, BM))
       break;
-    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID());
+    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID(), SrcLang);
     SPIRVType *STy = transType(II->getType());
     std::vector<SPIRVValue *> Ops(1, transValue(II->getArgOperand(0), BB));
-    return BM->addExtInst(STy, BM->getExtInstSetId(SPIRVEIS_OpenCL), ExtOp, Ops,
+    return BM->addExtInst(STy, BM->getExtInstSetId(ext_set), ExtOp, Ops,
                           BB);
   }
   // Binary FP intrinsics
@@ -2781,11 +3224,11 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
   case Intrinsic::minnum: {
     if (!checkTypeForSPIRVExtendedInstLowering(II, BM))
       break;
-    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID());
+    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID(), SrcLang);
     SPIRVType *STy = transType(II->getType());
     std::vector<SPIRVValue *> Ops{transValue(II->getArgOperand(0), BB),
                                   transValue(II->getArgOperand(1), BB)};
-    return BM->addExtInst(STy, BM->getExtInstSetId(SPIRVEIS_OpenCL), ExtOp, Ops,
+    return BM->addExtInst(STy, BM->getExtInstSetId(ext_set), ExtOp, Ops,
                           BB);
   }
   case Intrinsic::umin:
@@ -2812,12 +3255,12 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
   case Intrinsic::fma: {
     if (!checkTypeForSPIRVExtendedInstLowering(II, BM))
       break;
-    SPIRVWord ExtOp = OpenCLLIB::Fma;
+    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID(), SrcLang);
     SPIRVType *STy = transType(II->getType());
     std::vector<SPIRVValue *> Ops{transValue(II->getArgOperand(0), BB),
                                   transValue(II->getArgOperand(1), BB),
                                   transValue(II->getArgOperand(2), BB)};
-    return BM->addExtInst(STy, BM->getExtInstSetId(SPIRVEIS_OpenCL), ExtOp, Ops,
+    return BM->addExtInst(STy, BM->getExtInstSetId(ext_set), ExtOp, Ops,
                           BB);
   }
   case Intrinsic::abs: {
@@ -2825,10 +3268,10 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
       break;
     // LLVM has only one version of abs and it is only for signed integers. We
     // unconditionally choose SAbs here
-    SPIRVWord ExtOp = OpenCLLIB::SAbs;
+    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID(), SrcLang);
     SPIRVType *STy = transType(II->getType());
     std::vector<SPIRVValue *> Ops(1, transValue(II->getArgOperand(0), BB));
-    return BM->addExtInst(STy, BM->getExtInstSetId(SPIRVEIS_OpenCL), ExtOp, Ops,
+    return BM->addExtInst(STy, BM->getExtInstSetId(ext_set), ExtOp, Ops,
                           BB);
   }
   case Intrinsic::ctpop: {
@@ -2837,11 +3280,10 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
   }
   case Intrinsic::ctlz:
   case Intrinsic::cttz: {
-    SPIRVWord ExtOp = II->getIntrinsicID() == Intrinsic::ctlz ? OpenCLLIB::Clz
-                                                              : OpenCLLIB::Ctz;
+    SPIRVWord ExtOp = getBuiltinIdForIntrinsic(II->getIntrinsicID(), SrcLang);
     SPIRVType *Ty = transType(II->getType());
     std::vector<SPIRVValue *> Ops(1, transValue(II->getArgOperand(0), BB));
-    return BM->addExtInst(Ty, BM->getExtInstSetId(SPIRVEIS_OpenCL), ExtOp, Ops,
+    return BM->addExtInst(Ty, BM->getExtInstSetId(ext_set), ExtOp, Ops,
                           BB);
   }
   case Intrinsic::expect: {
@@ -2962,7 +3404,7 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
     // If allowed, let's replace llvm.fmuladd.* with mad from OpenCL extended
     // instruction set, as it has the same semantic for FULL_PROFILE OpenCL
     // devices (implementation-defined for EMBEDDED_PROFILE).
-    if (BM->shouldReplaceLLVMFmulAddWithOpenCLMad()) {
+    if (BM->shouldReplaceLLVMFmulAddWithOpenCLMad() && ext_set == SPIRVEIS_OpenCL) {
       std::vector<SPIRVValue *> Ops{transValue(II->getArgOperand(0), BB),
                                     transValue(II->getArgOperand(1), BB),
                                     transValue(II->getArgOperand(2), BB)};
@@ -3035,14 +3477,43 @@ SPIRVValue *LLVMToSPIRVBase::transIntrinsicInst(IntrinsicInst *II,
         transType(PointerType::get(Val->getType(), SPIRV::SPIRAS_Constant));
     SPIRVValue *Source = BM->addUnaryInst(OpBitcast, SourceTy, Var, BB);
     SPIRVValue *Target = transValue(MSI->getRawDest(), BB);
+    assert(SrcLang != spv::SourceLanguageGLSL && "unhandled memset during Vulkan/SPIR-V emission");
     return BM->addCopyMemorySizedInst(Target, Source, CompositeTy->getLength(),
                                       GetMemoryAccess(MSI), BB);
   } break;
-  case Intrinsic::memcpy:
-    return BM->addCopyMemorySizedInst(
-        transValue(II->getOperand(0), BB), transValue(II->getOperand(1), BB),
-        transValue(II->getOperand(2), BB),
-        GetMemoryAccess(cast<MemIntrinsic>(II)), BB);
+  case Intrinsic::memcpy: {
+    auto dst = II->getOperand(0);
+    auto src = II->getOperand(1);
+    if (SrcLang == spv::SourceLanguageGLSL) {
+      // OpCopyMemory has the requirement that we copy to/from the actual underlying type, not i8*
+      // -> remove bitcasts
+      do {
+        auto bitcast = dyn_cast_or_null<BitCastInst>(dst);
+        if (!bitcast) {
+          break;
+        }
+        dst = bitcast->getOperand(0);
+      } while(true);
+      do {
+        auto bitcast = dyn_cast_or_null<BitCastInst>(src);
+        if (!bitcast) {
+          break;
+        }
+        src = bitcast->getOperand(0);
+      } while(true);
+      assert(dst->getType()->isPointerTy());
+      assert(src->getType()->isPointerTy());
+      // -> assert we're actually copying data of the same type
+      assert(dst->getType()->getPointerElementType() ==
+             src->getType()->getPointerElementType());
+      return BM->addCopyMemoryInst(transValue(dst, BB), transValue(src, BB),
+          GetMemoryAccess(cast<MemIntrinsic>(II)), BB);
+    } else {
+      return BM->addCopyMemorySizedInst(transValue(dst, BB),
+          transValue(src, BB), transValue(II->getOperand(2), BB),
+          GetMemoryAccess(cast<MemIntrinsic>(II)), BB);
+    }
+  }
   case Intrinsic::lifetime_start:
   case Intrinsic::lifetime_end: {
     Op OC = (II->getIntrinsicID() == Intrinsic::lifetime_start)
@@ -3298,7 +3769,7 @@ SPIRVValue *LLVMToSPIRVBase::transDirectCallInst(CallInst *CI,
 
   SmallVector<std::string, 2> Dec;
   if (isBuiltinTransToExtInst(CI->getCalledFunction(), &ExtSetKind, &ExtOp,
-                              &Dec))
+                &Dec)) {
     return addDecorations(
         BM->addExtInst(
             transType(CI->getType()), BM->getExtInstSetId(ExtSetKind), ExtOp,
@@ -3306,26 +3777,223 @@ SPIRVValue *LLVMToSPIRVBase::transDirectCallInst(CallInst *CI,
                            SPIRVEntry::createUnique(ExtSetKind, ExtOp).get()),
             BB),
         Dec);
+  }
 
-  Function *Callee = CI->getCalledFunction();
-  if (Callee->isDeclaration()) {
-    SPIRVDBG(dbgs() << "[fp-contract] disabled for " << F->getName().str()
-                    << ": call to an undefined function " << *CI << '\n');
-    joinFPContract(CI->getFunction(), FPContract::DISABLED);
-  } else {
-    FPContract CalleeFPC = getFPContract(Callee);
-    joinFPContract(CI->getFunction(), CalleeFPC);
-    if (CalleeFPC == FPContract::DISABLED) {
-      SPIRVDBG(dbgs() << "[fp-contract] disabled for " << F->getName().str()
-                      << ": call to a function with disabled contraction: "
-                      << *CI << '\n');
+  // helper functions to force an integer value to be unsigned or signed
+  const auto force_uint_value = [&BB, this](SPIRVValue *val) -> SPIRVValue * {
+    auto type = val->getType();
+    if (!type->isTypeInt()) {
+      assert(false && "expected an integer type");
+      return val;
     }
-  }
+    if (((SPIRVTypeInt *)type)->isSigned()) {
+      // bitcast to unsigned
+      return BM->addUnaryInst(spv::OpBitcast,
+                              ((SPIRVTypeInt *)type)->getUnsigned(), val, BB);
+    }
+    // already unsigned
+    return val;
+  };
+  const auto force_int_value = [&BB, this](SPIRVValue *val) -> SPIRVValue * {
+    auto type = val->getType();
+    if (!type->isTypeInt()) {
+      assert(false && "expected an integer type");
+      return val;
+    }
+    if (!((SPIRVTypeInt *)type)->isSigned()) {
+      // bitcast to signed
+      return BM->addUnaryInst(spv::OpBitcast,
+                              ((SPIRVTypeInt *)type)->getSigned(), val, BB);
+    }
+    // already signed
+    return val;
+  };
 
-  return BM->addCallInst(
-      transFunctionDecl(Callee),
-      transArguments(CI, BB, SPIRVEntry::createUnique(OpFunctionCall).get()),
-      BB);
+  // TODO: put this into an extra function + use lut
+  if (MangledName.startswith("floor.")) {
+    if (MangledName.startswith("floor.composite_construct.")) {
+      std::vector<SPIRVWord> Constituents;
+      for (const auto &elem : CI->args()) {
+        Constituents.emplace_back(transValue(elem, BB)->getId());
+      }
+      return BM->addCompositeConstructInst(transType(CI->getType()),
+                                           Constituents, BB);
+    } else if (MangledName == "floor.dfdx.f32" ||
+               MangledName == "floor.dfdy.f32" ||
+               MangledName == "floor.fwidth.f32") {
+      auto OC = spv::OpDPdx;
+      if (MangledName == "floor.dfdy.f32")
+        OC = spv::OpDPdy;
+      if (MangledName == "floor.fwidth.f32")
+        OC = spv::OpFwidth;
+      assert(CI->getArgOperand(0)->getType() == CI->getType() &&
+             "invalid derivative type");
+      return BM->addDerivativeInst(OC, transValue(CI->getArgOperand(0), BB),
+                                   BB);
+    } else if (MangledName == "floor.discard_fragment") {
+      // since "discard" can't be modelled as a single noreturn +
+      // unreachable-after-call instruction right now, but must add an
+      // "additional" unreachable instead, we need to get rid of (ignore) the
+      // next unreachable (this isn't particularly nice, but we can't do this on
+      // the llvm side, b/c it would badly break things)
+      ignore_next_unreachable = true;
+      return BM->addKillInst(BB);
+    } else if (MangledName.startswith("floor.find_int_lsb.")) {
+      auto arg = transValue(CI->getArgOperand(0), BB);
+      if (MangledName.startswith("floor.find_int_lsb.u")) {
+        // force uint eval
+        arg = force_uint_value(arg);
+      }
+      return BM->addExtInst(
+          ((SPIRVTypeInt *)arg->getType())->getSigned() /* force signed */,
+          BM->getExtInstSetId(SPIRVEIS_GLSL), GLSLLIB::FindILsb, getVec(arg), BB);
+    } else if (MangledName.startswith("floor.find_int_msb.")) {
+      auto arg = transValue(CI->getArgOperand(0), BB);
+      bool is_uint = false;
+      if (MangledName.startswith("floor.find_int_msb.u")) {
+        // force uint eval
+        arg = force_uint_value(arg);
+        is_uint = true;
+      } else if (MangledName.startswith("floor.find_int_msb.s")) {
+        // force int eval
+        arg = force_int_value(arg);
+      }
+      return BM->addExtInst(
+          ((SPIRVTypeInt *)arg->getType())->getSigned() /* force signed */,
+          BM->getExtInstSetId(SPIRVEIS_GLSL), (is_uint ? GLSLLIB::FindUMsb : GLSLLIB::FindSMsb),
+          getVec(arg), BB);
+    } else if (MangledName.startswith("floor.bit_reverse.")) {
+      auto arg = transValue(CI->getArgOperand(0), BB);
+      if (MangledName.startswith("floor.bit_reverse.u")) {
+        // force uint eval
+        arg = force_uint_value(arg);
+      }
+      return BM->addBitReverseInst(arg->getType(), arg, BB);
+    } else if (MangledName.startswith("floor.bit_count.")) {
+      auto arg = transValue(CI->getArgOperand(0), BB);
+      if (MangledName.startswith("floor.bit_count.u")) {
+        // force uint eval
+        arg = force_uint_value(arg);
+      }
+      return BM->addBitCountInst(arg->getType(), arg, BB);
+    } else if (MangledName.startswith("floor.image_array_load.")) {
+      auto img = CI->getOperand(0);
+      const auto img_type_iter = image_type_map.find(img);
+      assert(img_type_iter != image_type_map.end() && "unknown image");
+
+      auto img_ptr_type = BM->addPointerType(spv::StorageClassUniformConstant,
+                                             img_type_iter->second);
+
+      auto img_array = transValue(CI->getOperand(0), BB);
+      const std::vector<SPIRVValue *> indices{
+          transValue(CI->getOperand(1), BB)};
+      auto gep =
+          BM->addAccessChainInst(img_ptr_type, img_array, indices, BB, true);
+      return BM->addLoadInst(gep, {}, BB);
+    } else if (MangledName == "floor.loop_merge") {
+      auto merge_bb = transValue(CI->getArgOperand(0), nullptr);
+      auto continue_bb = transValue(CI->getArgOperand(1), nullptr);
+      // NOTE: not allowing any control hints, b/c LLVM will have already optimized everything
+      return BM->addLoopMergeInst(merge_bb->getId(), continue_bb->getId(), spv::LoopControlMaskNone, {}, BB);
+    } else if (MangledName == "floor.selection_merge") {
+      auto merge_bb = (SPIRVBasicBlock *)transValue(CI->getArgOperand(0), nullptr);
+      // NOTE: not allowing any control hints, b/c LLVM will have already optimized
+      // everything - except for structured CFG insanity that we needed to create
+      // -> always mark as flatten and (hopefully) let vendor compilers deal with this
+      return BM->addSelectionMergeInst(merge_bb->getId(), spv::SelectionControlFlattenMask, BB);
+    } else if (MangledName.startswith("floor.pack_") ||
+               MangledName.startswith("floor.unpack_")) {
+      static const std::unordered_map<std::string, GLSLExtOpKind> pack_lut{
+          {"floor.pack_snorm_4x8", GLSLLIB::PackSnorm4x8},
+          {"floor.pack_unorm_4x8", GLSLLIB::PackUnorm4x8},
+          {"floor.pack_snorm_2x16", GLSLLIB::PackSnorm2x16},
+          {"floor.pack_unorm_2x16", GLSLLIB::PackUnorm2x16},
+          {"floor.pack_half_2x16", GLSLLIB::PackHalf2x16},
+          {"floor.pack_double_2x32", GLSLLIB::PackDouble2x32},
+          {"floor.unpack_snorm_4x8", GLSLLIB::UnpackSnorm4x8},
+          {"floor.unpack_unorm_4x8", GLSLLIB::UnpackUnorm4x8},
+          {"floor.unpack_snorm_2x16", GLSLLIB::UnpackSnorm2x16},
+          {"floor.unpack_unorm_2x16", GLSLLIB::UnpackUnorm2x16},
+          {"floor.unpack_half_2x16", GLSLLIB::UnpackHalf2x16},
+          {"floor.unpack_double_2x32", GLSLLIB::UnpackDouble2x32},
+      };
+      const auto ext_op = pack_lut.find(MangledName.str());
+      if (ext_op == pack_lut.end()) {
+        errs() << "unknown pack/unpack call: " << MangledName << "\n";
+        return nullptr;
+      }
+
+      SPIRVType *ret_type = nullptr;
+      if (MangledName.startswith("floor.pack_") &&
+          MangledName != "floor.pack_double_2x32") {
+        // enforce 32-bit unsigned integer return type
+        ret_type = BM->addIntegerType(32, false);
+      } else {
+        // otherwise, simply translate the return type
+        ret_type = transType(CI->getType());
+      }
+
+      auto args = transValue(getArguments(CI), BB);
+      if (args.size() != 1) {
+        errs() << "invalid arg count for pack/unpack call: " << MangledName
+               << "\n";
+        return nullptr;
+      }
+
+      // enforce 32-bit unsigned integer arg type
+      if (MangledName.startswith("floor.unpack_") &&
+          MangledName != "floor.unpack_double_2x32") {
+        if (((SPIRVTypeInt *)args[0]->getType())->isSigned()) {
+          args[0] = BM->addUnaryInst(
+              spv::OpBitcast, BM->addIntegerType(32, false), args[0], BB);
+        }
+      }
+
+      return BM->addExtInst(ret_type, BM->getExtInstSetId(SPIRVEIS_GLSL), ext_op->second, args, BB);
+    } else if (MangledName.startswith("floor.bitcast.")) {
+      auto args = transValue(getArguments(CI), BB);
+      if (args.size() != 1) {
+        errs() << "invalid arg count for bitcast call: " << MangledName << "\n";
+        return nullptr;
+      }
+      transType(CI->getType());
+      if (MangledName == "floor.bitcast.f32.i32") {
+        return BM->addUnaryInst(spv::OpBitcast, BM->addIntegerType(32, true),
+                                args[0], BB);
+      } else if (MangledName == "floor.bitcast.f32.u32") {
+        return BM->addUnaryInst(spv::OpBitcast, BM->addIntegerType(32, false),
+                                args[0], BB);
+      } else if (MangledName == "floor.bitcast.i32.f32") {
+        return BM->addUnaryInst(spv::OpBitcast, BM->addFloatType(32), args[0],
+                                BB);
+      } else if (MangledName == "floor.bitcast.u32.f32") {
+        return BM->addUnaryInst(spv::OpBitcast, BM->addFloatType(32), args[0],
+                                BB);
+      }
+      // else: fallthrough
+    }
+    errs() << "unhandled floor func: " << MangledName << "\n";
+  }
+
+  Function *Callee = CI->getCalledFunction();
+  if (Callee->isDeclaration()) {
+    SPIRVDBG(dbgs() << "[fp-contract] disabled for " << F->getName().str()
+                    << ": call to an undefined function " << *CI << '\n');
+    joinFPContract(CI->getFunction(), FPContract::DISABLED);
+  } else {
+    FPContract CalleeFPC = getFPContract(Callee);
+    joinFPContract(CI->getFunction(), CalleeFPC);
+    if (CalleeFPC == FPContract::DISABLED) {
+      SPIRVDBG(dbgs() << "[fp-contract] disabled for " << F->getName().str()
+                      << ": call to a function with disabled contraction: "
+                      << *CI << '\n');
+    }
+  }
+
+  return BM->addCallInst(
+      transFunctionDecl(Callee),
+      transArguments(CI, BB, SPIRVEntry::createUnique(OpFunctionCall).get()),
+      BB);
 }
 
 SPIRVValue *LLVMToSPIRVBase::transIndirectCallInst(CallInst *CI,
@@ -3371,12 +4039,31 @@ SPIRVValue *LLVMToSPIRVBase::transAsmCallINTEL(CallInst *CI,
 bool LLVMToSPIRVBase::transAddressingMode() {
   Triple TargetTriple(M->getTargetTriple());
 
-  if (TargetTriple.isArch32Bit())
-    BM->setAddressingModel(AddressingModelPhysical32);
-  else
-    BM->setAddressingModel(AddressingModelPhysical64);
-  // Physical addressing model requires Addresses capability
-  BM->addCapability(CapabilityAddresses);
+  if (TargetTriple.getEnvironment() != llvm::Triple::EnvironmentType::Vulkan) {
+    if (TargetTriple.isArch32Bit())
+      BM->setAddressingModel(AddressingModelPhysical32);
+    else
+      BM->setAddressingModel(AddressingModelPhysical64);
+    // Physical addressing model requires Addresses capability
+    BM->addCapability(CapabilityAddresses);
+    // OpenCL memory model requires Kernel capability
+    BM->setMemoryModel(MemoryModelOpenCL);
+  } else {
+    BM->setAddressingModel(AddressingModelPhysicalStorageBuffer64);
+    BM->setMemoryModel(MemoryModelVulkan);
+
+    // always add these
+    BM->addCapability(CapabilityShader);
+    BM->addCapability(CapabilityVulkanMemoryModel);
+    BM->addCapability(CapabilityVulkanMemoryModelDeviceScope);
+    BM->addCapability(CapabilityPhysicalStorageBufferAddresses);
+    BM->addCapability(CapabilityVariablePointersStorageBuffer);
+    BM->addCapability(CapabilityVariablePointers);
+    BM->addCapability(CapabilityUniformBufferArrayDynamicIndexing);
+    BM->addCapability(CapabilityStorageBufferArrayDynamicIndexing);
+    BM->addCapability(CapabilitySampledImageArrayDynamicIndexing);
+    BM->addCapability(CapabilityStorageImageArrayDynamicIndexing);
+  }
   return true;
 }
 std::vector<SPIRVValue *>
@@ -3470,7 +4157,42 @@ void LLVMToSPIRVBase::transGlobalIOPipeStorage(GlobalVariable *V, MDNode *IO) {
 }
 
 bool LLVMToSPIRVBase::transGlobalVariables() {
+  // add global fixed/immutable samplers array that is always present
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    auto samplers_type = BM->addPointerType(
+        spv::StorageClassUniformConstant,
+        BM->addArrayType(BM->addSamplerType(),
+                         BM->getLiteralAsConstant(32, false)));
+    immutable_samplers = static_cast<SPIRVVariable *>(
+        BM->addVariable(samplers_type, true, spv::internal::LinkageTypeInternal, nullptr,
+                        "vulkan.immutable_samplers",
+                        spv::StorageClassUniformConstant, nullptr));
+    BM->setName(immutable_samplers, "vulkan.immutable_samplers");
+    immutable_samplers->addDecorate(
+        new SPIRVDecorate(DecorationDescriptorSet, immutable_samplers, 0));
+    immutable_samplers->addDecorate(
+        new SPIRVDecorate(DecorationBinding, immutable_samplers, 0));
+  }
+
   for (auto I = M->global_begin(), E = M->global_end(); I != E; ++I) {
+    // ignore any special vulkan globals used by functions (these will be
+    // handled when translating the functions)
+    if ((*I).hasName() && (*I).getName().find(".vulkan") != std::string::npos)
+      continue;
+
+    // ignore any globals that need to be put into functions (map to function
+    // storage class), these are handled later
+    if (SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+            (*I).getType()->getAddressSpace())) == spv::StorageClassFunction)
+      continue;
+
+    // ignore external globals
+    if ((*I).getLinkage() == GlobalValue::ExternalLinkage ||
+        (*I).getLinkage() == GlobalValue::AvailableExternallyLinkage ||
+        (*I).getLinkage() == GlobalValue::PrivateLinkage ||
+        (*I).getLinkage() == GlobalValue::ExternalWeakLinkage)
+      continue;
+
     if ((*I).getName() == "llvm.global.annotations")
       transGlobalAnnotation(&(*I));
     else if ([I]() -> bool {
@@ -3653,13 +4375,1153 @@ void LLVMToSPIRVBase::fpContractUpdateRecursive(Function *F, FPContract FPC) {
   }
 }
 
-void LLVMToSPIRVBase::transFunction(Function *I) {
-  SPIRVFunction *BF = transFunctionDecl(I);
-  // Creating all basic blocks before creating any instruction.
-  for (auto &FI : *I) {
-    transValue(&FI, nullptr);
+// TODO: move this to a proper place
+enum class VULKAN_STAGE : uint32_t {
+  NONE = 0u,
+  VERTEX = (1u << 0u),
+  TESSELLATION_CONTROL = (1u << 1u),
+  TESSELLATION_EVALUATION = (1u << 2u),
+  GEOMETRY = (1u << 3u),
+  FRAGMENT = (1u << 4u),
+  KERNEL = (1u << 5u),
+};
+static const char *vulkan_stage_to_string(const VULKAN_STAGE &stage) {
+  switch (stage) {
+  case VULKAN_STAGE::VERTEX:
+    return "vertex";
+  case VULKAN_STAGE::TESSELLATION_CONTROL:
+    return "tessellation-control";
+  case VULKAN_STAGE::TESSELLATION_EVALUATION:
+    return "tesselation-evaluation";
+  case VULKAN_STAGE::GEOMETRY:
+    return "geometry";
+  case VULKAN_STAGE::FRAGMENT:
+    return "fragment";
+  case VULKAN_STAGE::KERNEL:
+    return "kernel";
+  default:
+    break;
+  }
+  return "";
+}
+constexpr VULKAN_STAGE operator|(const VULKAN_STAGE &e0,
+                                 const VULKAN_STAGE &e1) {
+  return (VULKAN_STAGE)((typename std::underlying_type<VULKAN_STAGE>::type)e0 |
+                        (typename std::underlying_type<VULKAN_STAGE>::type)e1);
+}
+constexpr VULKAN_STAGE &operator|=(VULKAN_STAGE &e0, const VULKAN_STAGE &e1) {
+  e0 = e0 | e1;
+  return e0;
+}
+constexpr VULKAN_STAGE operator&(const VULKAN_STAGE &e0,
+                                 const VULKAN_STAGE &e1) {
+  return (VULKAN_STAGE)((typename std::underlying_type<VULKAN_STAGE>::type)e0 &
+                        (typename std::underlying_type<VULKAN_STAGE>::type)e1);
+}
+constexpr VULKAN_STAGE &operator&=(VULKAN_STAGE &e0, const VULKAN_STAGE &e1) {
+  e0 = e0 & e1;
+  return e0;
+}
+
+void LLVMToSPIRVBase::decorateComposite(llvm::Type *llvm_type,
+                                    SPIRVType *spirv_type) {
+  if (SrcLang != SourceLanguageGLSL)
+    return;
+  // TODO: this doesn't respect padding/alignment yet, fix it (might already
+  // need to dump this info on the clang/llvm side)
+  const auto &DL = M->getDataLayout();
+  if (auto struct_type = dyn_cast<llvm::StructType>(llvm_type)) {
+    uint32_t member_idx = 0, offset = 0;
+    for (const auto &elem_type : struct_type->elements()) {
+      auto spirv_elem_type =
+          ((SPIRVTypeStruct *)spirv_type)->getMemberType(member_idx);
+
+      const auto this_member_idx = member_idx++;
+      const auto &member_decs = spirv_type->getMemberDecorates();
+      const auto iter =
+          member_decs.find({this_member_idx, spv::DecorationOffset});
+      if (iter == member_decs.end()) {
+        spirv_type->addMemberDecorate(this_member_idx, spv::DecorationOffset,
+                                      offset);
+      } else {
+        // shouldn't occur as far as I can tell, but better check it to be
+        // certain
+        assert(iter->second->getMemberNumber() == this_member_idx &&
+               iter->second->getLiteral(0) == offset &&
+               "existing member decoration differs from this one");
+      }
+      offset += DL.getTypeStoreSize(elem_type);
+
+      // recurse
+      decorateComposite(elem_type, spirv_elem_type);
+    }
+  } else if (auto array_type = dyn_cast<llvm::ArrayType>(llvm_type)) {
+    spirv_type->addDecorate(spv::DecorationArrayStride,
+                            DL.getTypeStoreSize(array_type->getElementType()));
+    auto spirv_elem_type =
+        (spirv_type->isTypeRuntimeArray()
+             ? ((SPIRVTypeRuntimeArray *)spirv_type)->getElementType()
+             : ((SPIRVTypeArray *)spirv_type)->getElementType());
+
+    // recurse
+    decorateComposite(array_type->getElementType(), spirv_elem_type);
   }
-  for (auto &FI : *I) {
+}
+
+SPIRVVariable *LLVMToSPIRVBase::emitShaderSPIRVGlobal(
+    SPIRVFunction *spirv_func, const GlobalVariable &GV,
+    const std::string &var_name, uint32_t address_space,
+    const spirv_global_io_type global_type, const std::string &md_info,
+    spv::BuiltIn builtin) {
+  spv::StorageClass storage_class = spv::StorageClassUniform;
+  if (global_type.is_builtin) {
+    storage_class = (global_type.is_input ? spv::StorageClassInput
+                                          : spv::StorageClassOutput);
+  } else if (global_type.is_input) {
+    storage_class = spv::StorageClassInput;
+  } else if (global_type.is_image) {
+    storage_class = spv::StorageClassUniformConstant;
+  } else if (global_type.is_uniform) {
+    storage_class = spv::StorageClassUniform;
+    if ((!global_type.is_constant ||
+         (global_type.is_constant && !global_type.is_iub))) {
+      storage_class = spv::StorageClassStorageBuffer;
+    }
+  } else {
+    storage_class = spv::StorageClassOutput;
+  }
+
+  SPIRVType *mapped_type = nullptr;
+  uint32_t fbo_location = 0;
+  if (global_type.is_uniform) {
+    assert(GV.getType()->isPointerTy() && "uniform must be a pointer type");
+    auto elem_type = GV.getType()->getPointerElementType();
+
+    // -> SSBOs or IUBs
+    if (!global_type.is_image) {
+      auto spirv_elem_type = transType(elem_type);
+      if (!global_type.is_iub) {
+        if (!global_type.is_constant) {
+          // this is a SSBO with an unknown size, switch out the top pointer
+          // type with a runtime array type
+          auto rtarr_type = BM->addRuntimeArrayType(spirv_elem_type);
+          std::string enclosing_type_name = "enclose.";
+          if (elem_type->isStructTy()) {
+            enclosing_type_name += elem_type->getStructName().str();
+          } else {
+            std::string type_str = "";
+            llvm::raw_string_ostream type_stream(type_str);
+            elem_type->print(type_stream, false, true);
+            enclosing_type_name += type_stream.str();
+          }
+          auto enclosing_type = BM->openStructType(1, enclosing_type_name);
+          enclosing_type->setMemberType(0, rtarr_type);
+          BM->closeStructType(enclosing_type, false);
+          mapped_type = BM->addPointerType(storage_class, enclosing_type);
+        
+          // add required deco
+          enclosing_type->addDecorate(new SPIRVDecorate(DecorationBlock, enclosing_type));
+          enclosing_type->addMemberDecorate(0, spv::DecorationOffset, 0);
+          rtarr_type->addDecorate(spv::DecorationArrayStride,
+                    M->getDataLayout().getTypeStoreSize(elem_type));
+        } else {
+          // we need to use the storage buffer storage class
+          assert(elem_type->isStructTy() && "SSBO must be a struct");
+          auto ssbo_ptr_type = llvm::PointerType::get(GV.getType()->getPointerElementType(), SPIRAS_StorageBuffer);
+          mapped_type = transType(ssbo_ptr_type);
+          spirv_elem_type->addDecorate(new SPIRVDecorate(DecorationBlock, spirv_elem_type));
+        }
+      } else {
+        assert(elem_type->isStructTy() && "uniform type must be a struct");
+        // we need to use the uniform buffer storage class
+        auto uniform_ptr_type = llvm::PointerType::get(GV.getType()->getPointerElementType(), SPIRAS_Uniform);
+        mapped_type = transType(uniform_ptr_type);
+        spirv_elem_type->addDecorate(new SPIRVDecorate(DecorationBlock, spirv_elem_type));
+      }
+      decorateComposite(elem_type, spirv_elem_type);
+    }
+    // -> images
+    else {
+      const auto access_split_pos = md_info.find(':');
+      const auto array_or_scalar_split_pos =
+          md_info.find(':', access_split_pos + 1);
+      const auto elem_count_split_pos =
+          md_info.find(':', array_or_scalar_split_pos + 1);
+
+      const auto access_type = md_info.substr(0, access_split_pos);
+      const auto array_or_scalar_str =
+          md_info.substr(access_split_pos + 1,
+                         array_or_scalar_split_pos - access_split_pos - 1);
+      const auto elem_count_str =
+          md_info.substr(array_or_scalar_split_pos + 1,
+                         elem_count_split_pos - array_or_scalar_split_pos - 1);
+      const auto sample_type = md_info.substr(elem_count_split_pos + 1);
+
+      const bool is_array = (array_or_scalar_str == "array");
+      const bool is_write = (access_type == "write");
+
+      if (is_write) {
+        // TODO: handle storage images with format
+        BM->addCapability(spv::CapabilityStorageImageWriteWithoutFormat);
+      }
+
+      //
+      const auto elem_count = (uint32_t)std::stoull(elem_count_str);
+      llvm::Type *img_type = GV.getType();
+      if (is_array) {
+        // image array
+        assert(isa<PointerType>(img_type) && "must be a pointer type");
+        const auto img_array_type =
+            dyn_cast<ArrayType>(img_type->getPointerElementType());
+        assert(img_array_type != nullptr && "image type must be an array type");
+        assert(img_array_type->getNumElements() == elem_count &&
+               "invalid image array element count");
+        img_type = img_array_type->getArrayElementType();
+      }
+      //
+      auto SPIRVImageTy = getSPIRVImageTypeFromGLSL(
+          M, img_type, sample_type.c_str(), is_write, spv::ImageFormatUnknown);
+      auto transSPIRVImageTy = transSPIRVOpaqueType(SPIRVImageTy);
+
+      // cache it
+      image_type_map.emplace(&GV, transSPIRVImageTy);
+
+      //
+      auto ptr_img_type = transSPIRVImageTy;
+      if (is_array) {
+        ptr_img_type = BM->addArrayType(
+            transSPIRVImageTy, BM->getLiteralAsConstant(elem_count, false));
+      }
+
+      mapped_type =
+          BM->addPointerType(spv::StorageClassUniformConstant, ptr_img_type);
+    }
+  } else if (global_type.is_fbo_color) {
+    // extract location idx
+    const auto location_pos = md_info.rfind(':');
+    assert(location_pos != std::string::npos);
+    const auto location_str = md_info.substr(location_pos + 1);
+    fbo_location = (uint32_t)strtoull(location_str.c_str(), nullptr, 10);
+
+    // extract data type
+    const auto data_type_pos = md_info.rfind(':', location_pos - 1);
+    assert(data_type_pos != std::string::npos);
+    const auto data_type_str =
+        md_info.substr(data_type_pos + 1, location_pos - data_type_pos - 1);
+
+    // float and (signed) int can always be translated directly, unsigned int
+    // needs special treatment, b/c llvm doesn't differentiate ints and uints
+    if (data_type_str == "uint") {
+      assert(GV.getType()->isPointerTy());
+      mapped_type = BM->addPointerType(
+          storage_class, addSignPreservingLLVMType(
+                             GV.getType()->getPointerElementType(), false));
+    } else {
+      mapped_type = transType(GV.getType());
+    }
+
+  } else if (global_type.is_fbo_depth) {
+    // extract depth qualifier
+    const auto depth_qual_pos = md_info.rfind(':');
+    assert(depth_qual_pos != std::string::npos);
+    const auto depth_qual = md_info.substr(depth_qual_pos + 1);
+
+    // add execution mode for "less" and "greater"
+    if (depth_qual == "less") {
+      spirv_func->addExecutionMode(
+          new SPIRVExecutionMode(spirv_func, ExecutionModeDepthLess));
+    } else if (depth_qual == "greater") {
+      spirv_func->addExecutionMode(
+          new SPIRVExecutionMode(spirv_func, ExecutionModeDepthGreater));
+    }
+    // else: "any"/default, keep as-is
+
+    mapped_type = transType(GV.getType());
+
+  } else {
+    mapped_type = transType(GV.getType());
+  }
+
+  auto BVar = static_cast<SPIRVVariable *>(
+      BM->addVariable(mapped_type, false, spv::internal::LinkageTypeInternal, nullptr,
+                      GV.getName().str(), storage_class, nullptr));
+  BM->setName(BVar, GV.getName().str());
+  mapValue((const Value *)&GV, BVar);
+
+  if (global_type.is_builtin) {
+    BVar->setBuiltin(builtin);
+  }
+
+  BM->addEntryPointIO(spirv_func->getId(), BVar);
+
+  // set non-readable/-writable deco on SSBOs
+  if (global_type.is_uniform && !global_type.is_image) {
+    if (global_type.is_read_only || global_type.is_constant) {
+      BVar->addDecorate(new SPIRVDecorate(DecorationNonWritable, BVar));
+#if 0 // NOTE: the NVIDIA driver/compiler can't deal with this if we're using a
+      // SSBO -> disable for now
+      if (global_type.is_constant) {
+        BVar->addDecorate(new SPIRVDecorate(DecorationUniform, BVar));
+      }
+#endif
+      // IUB is always uniform
+      if (global_type.is_constant && global_type.is_iub) {
+        BVar->addDecorate(new SPIRVDecorate(DecorationUniform, BVar));
+      }
+    } else if (global_type.is_write_only) {
+      BVar->addDecorate(new SPIRVDecorate(DecorationNonReadable, BVar));
+    }
+  }
+
+  // handle decoration
+  if (global_type.is_fbo_color) {
+    BVar->addDecorate(
+        new SPIRVDecorate(DecorationLocation, BVar, fbo_location));
+  } else if ((storage_class == spv::StorageClassOutput ||
+              storage_class == spv::StorageClassInput) &&
+             global_type.set_location) {
+    BVar->addDecorate(
+        new SPIRVDecorate(DecorationLocation, BVar, global_type.location));
+  }
+
+  // automatically add the "flat" decoration on types that need it
+  // NOTE: vulkan requires that this is only set on input variables
+  if (storage_class == spv::StorageClassInput && !global_type.is_fbo_color &&
+      !global_type.is_fbo_depth && !global_type.is_builtin) {
+    // I/O should always be a pointer type
+    if (GV.getType()->isPointerTy()) {
+      auto elem_type = GV.getType()->getPointerElementType();
+      auto elem_vec_type = dyn_cast_or_null<FixedVectorType>(elem_type);
+      if (elem_type->isIntegerTy() ||
+          (elem_vec_type && elem_vec_type->getElementType()->isIntegerTy())) {
+        BVar->addDecorate(new SPIRVDecorate(DecorationFlat, BVar));
+      }
+    }
+  }
+
+  return BVar;
+}
+
+GlobalVariable *LLVMToSPIRVBase::emitShaderGlobal(
+    const Function &F, SPIRVFunction *spirv_func, const std::string &var_name,
+    llvm::Type *llvm_type, uint32_t address_space,
+    const spirv_global_io_type global_type, const std::string &md_info,
+    SPIRVVariable **created_spirv_var, spv::BuiltIn builtin) {
+  std::string name_type = ".";
+  if (global_type.is_builtin) {
+    name_type = (global_type.is_input ? ".vulkan_builtin_input."
+                                      : ".vulkan_builtin_output.");
+  } else if (global_type.is_input) {
+    name_type = ".vulkan_input.";
+  } else if (global_type.is_uniform) {
+    name_type = ".vulkan_uniform.";
+  }
+
+  auto GV =
+      new GlobalVariable(*M, llvm_type, false, GlobalVariable::InternalLinkage,
+                         nullptr, F.getName().str() + name_type + var_name,
+                         nullptr, GlobalValue::NotThreadLocal, address_space);
+
+  // also add the SPIR-V global
+  auto spirv_var = emitShaderSPIRVGlobal(
+      spirv_func, *GV, var_name, address_space, global_type, md_info, builtin);
+  if (created_spirv_var != nullptr) {
+    *created_spirv_var = spirv_var;
+  }
+
+  return GV;
+}
+
+// helper function to figure out if a SSBO argument is only being written to
+// TODO/NOTE: since WriteOnly is a fairly new attribute, the FunctionAttrs pass
+// can't handle it yet (like it does for readonly/readnone) -> once it can infer
+// the WriteOnly attribute, use that instead
+static bool is_write_only_arg(Function &F, Argument &arg) {
+  // since Vulkan/SPIR-V is very restrictive on pointer usage, that makes this
+  // rather simple. however, we still bail out if we find something that we
+  // can't handle.
+  const std::function<bool(Value *)> user_recurse =
+      [&user_recurse](Value *val) {
+        for (User *user : val->users()) {
+          // is read from -> bail
+          if (isa<LoadInst>(user)) {
+            return false;
+          }
+          // is written to -> continue
+          else if (isa<StoreInst>(user)) {
+            continue;
+          }
+          // recurse for GEPs
+          else if (isa<GetElementPtrInst>(user)) {
+            // bail if GEP is used for loads
+            if (!user_recurse(user)) {
+              return false;
+            }
+          }
+          // calls are somewhat tricky
+          else if (CallInst *CI = dyn_cast<CallInst>(user)) {
+            // does read -> bail
+            if (!CI->doesNotReadMemory()) {
+              return false;
+            }
+            // we don't know what the call is doing exactly, but if it does
+            // return a pointer, assume it's us
+            if (CI->getType()->isPointerTy()) {
+              if (!user_recurse(user)) {
+                return false;
+              }
+            }
+          }
+          // NOTE: Vulkan/SPIR-V doesn't allow pointer usage in
+          // select/phi/bitcast, so we're good here
+          // unknown usage -> assume it's being read
+          else {
+            return false;
+          }
+        }
+        // didn't find any loads -> write-only
+        return true;
+      };
+  return user_recurse(&arg);
+}
+
+void LLVMToSPIRVBase::transFunction(Function *F) {
+  // again, ignore any floor.* functions
+  if (F->getName().startswith("floor."))
+    return;
+
+  // ignore any non-entry-point functions
+  if (F->getCallingConv() == CallingConv::FLOOR_FUNC)
+    return;
+
+  SPIRVFunction *BF = transFunctionDecl(F);
+
+  // we're only interested in shader entry points here
+  // TODO: cleanup + move to functions
+  if (SrcLang == SourceLanguageGLSL &&
+      (F->getCallingConv() == llvm::CallingConv::FLOOR_KERNEL ||
+       F->getCallingConv() == llvm::CallingConv::FLOOR_VERTEX ||
+       F->getCallingConv() == llvm::CallingConv::FLOOR_FRAGMENT)) {
+    VULKAN_STAGE stage;
+    switch (F->getCallingConv()) {
+    case llvm::CallingConv::FLOOR_VERTEX:
+      stage = VULKAN_STAGE::VERTEX;
+      break;
+    case llvm::CallingConv::FLOOR_FRAGMENT:
+      stage = VULKAN_STAGE::FRAGMENT;
+      break;
+    case llvm::CallingConv::FLOOR_KERNEL:
+      stage = VULKAN_STAGE::KERNEL;
+      break;
+    default:
+      return;
+    }
+
+    // always add this
+    if (stage == VULKAN_STAGE::FRAGMENT) {
+      BF->addExecutionMode(
+          new SPIRVExecutionMode(BF, ExecutionModeOriginUpperLeft));
+    }
+
+    const std::string func_name = F->getName().str();
+    std::vector<std::string> md_data_input, md_data_output;
+    auto vulkan_io_md = M->getNamedMetadata("vulkan.stage_io");
+    assert(vulkan_io_md != nullptr && "vulkan.io metadata doesn't exist");
+    for (const auto &op : vulkan_io_md->operands()) {
+      assert(op->getNumOperands() > 0 &&
+             "invalid op count in vulkan.io metadata");
+      if (auto md_func_name = dyn_cast<llvm::MDString>(op->getOperand(0))) {
+        if (md_func_name->getString() == func_name) {
+          // found our function, dump metadata strings to an easier to use
+          // vector<string>
+          bool at_input = false, at_output = false;
+          for (uint32_t i = 1; i < op->getNumOperands(); ++i) {
+            const auto md_op_str =
+                dyn_cast<llvm::MDString>(op->getOperand(i))->getString();
+
+            if (md_op_str == "stage_input") {
+              at_input = true;
+              at_output = false;
+              continue;
+            } else if (md_op_str == "stage_output") {
+              at_input = false;
+              at_output = true;
+              continue;
+            }
+
+            if (at_input)
+              md_data_input.emplace_back(md_op_str.str());
+            else if (at_output)
+              md_data_output.emplace_back(md_op_str.str());
+          }
+          break;
+        }
+      }
+    }
+
+    const auto get_builtin =
+        [](const std::string &str) -> std::pair<spv::BuiltIn, bool> {
+      static const std::unordered_map<std::string, spv::BuiltIn> builtin_lut{
+          {"position", spv::BuiltInPosition},
+          {"point_size", spv::BuiltInPointSize},
+          {"clip_distance", spv::BuiltInClipDistance},
+          {"cull_distance", spv::BuiltInCullDistance},
+          //{ "vertex_id", spv::BuiltInVertexId }, // unsupported in vulkan
+          //{ "instance_id", spv::BuiltInInstanceId }, // unsupported in vulkan
+          {"primitive_id", spv::BuiltInPrimitiveId},
+          {"invocation_id", spv::BuiltInInvocationId},
+          {"layer", spv::BuiltInLayer},
+          {"viewport_index", spv::BuiltInViewportIndex},
+          {"tess_level_outer", spv::BuiltInTessLevelOuter},
+          {"tess_level_inner", spv::BuiltInTessLevelInner},
+          {"tess_coord", spv::BuiltInTessCoord},
+          {"patch_vertices", spv::BuiltInPatchVertices},
+          {"frag_coord", spv::BuiltInFragCoord},
+          {"point_coord", spv::BuiltInPointCoord},
+          {"front_facing", spv::BuiltInFrontFacing},
+          {"sample_id", spv::BuiltInSampleId},
+          {"sample_position", spv::BuiltInSamplePosition},
+          {"sample_mask", spv::BuiltInSampleMask},
+          {"frag_depth", spv::BuiltInFragDepth},
+          {"helper_invocation", spv::BuiltInHelperInvocation},
+          {"num_workgroups", spv::BuiltInNumWorkgroups},
+          //{ "workgroup_size", spv::BuiltInWorkgroupSize }, // NOTE: must be a
+          // constant or spec constant
+          {"workgroup_id", spv::BuiltInWorkgroupId},
+          {"local_invocation_id", spv::BuiltInLocalInvocationId},
+          {"global_invocation_id", spv::BuiltInGlobalInvocationId},
+          // OpenCL-only:
+          //{ "local_invocation_index", spv::BuiltInLocalInvocationIndex },
+          //{ "work_dim", spv::BuiltInWorkDim },
+          //{ "global_size", spv::BuiltInGlobalSize },
+          //{ "enqueued_workgroup_size", spv::BuiltInEnqueuedWorkgroupSize },
+          //{ "global_offset", spv::BuiltInGlobalOffset },
+          //{ "global_linear_id", spv::BuiltInGlobalLinearId },
+          //{ "subgroup_size", spv::BuiltInSubgroupSize },
+          //{ "subgroup_max_size", spv::BuiltInSubgroupMaxSize },
+          //{ "num_subgroups", spv::BuiltInNumSubgroups },
+          //{ "num_enqueued_subgroups", spv::BuiltInNumEnqueuedSubgroups },
+          //{ "subgroup_id", spv::BuiltInSubgroupId },
+          //{ "subgroup_local_invocation_id",
+          // spv::BuiltInSubgroupLocalInvocationId },
+          {"vertex_index", spv::BuiltInVertexIndex},
+          {"instance_index", spv::BuiltInInstanceIndex},
+          {"view_index", spv::BuiltInViewIndex},
+      };
+      const auto iter = builtin_lut.find(str);
+      if (iter == builtin_lut.end()) {
+        return {spv::BuiltInPosition, false};
+      }
+      return {iter->second, true};
+    };
+    const auto is_builtin_valid_in_stage = [](const spv::BuiltIn &builtin,
+                                              const VULKAN_STAGE &stage,
+                                              const bool is_input) {
+      // NOTE: the non-listed/commented ones are unsupported in vulkan
+      static const std::unordered_map<spv::BuiltIn, VULKAN_STAGE>
+          builtin_validity_input_lut{
+              {spv::BuiltInPosition, (VULKAN_STAGE::TESSELLATION_CONTROL |
+                                      VULKAN_STAGE::TESSELLATION_EVALUATION |
+                                      VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInPointSize, (VULKAN_STAGE::TESSELLATION_CONTROL |
+                                       VULKAN_STAGE::TESSELLATION_EVALUATION |
+                                       VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInClipDistance,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInCullDistance,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              //{ spv::BuiltInVertexId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInInstanceId, VULKAN_STAGE::NONE },
+              {spv::BuiltInPrimitiveId, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInInvocationId,
+               (VULKAN_STAGE::TESSELLATION_CONTROL | VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInLayer, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInViewportIndex, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInTessLevelOuter,
+               VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInTessLevelInner,
+               VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInTessCoord, VULKAN_STAGE::TESSELLATION_EVALUATION},
+              {spv::BuiltInPatchVertices,
+               (VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION)},
+              {spv::BuiltInFragCoord, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInPointCoord, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFrontFacing, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSampleId, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSamplePosition, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInSampleMask, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFragDepth, VULKAN_STAGE::NONE},
+              {spv::BuiltInHelperInvocation, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInNumWorkgroups, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInWorkgroupSize,
+               VULKAN_STAGE::NONE}, // NOTE: must be a constant or spec constant
+              {spv::BuiltInWorkgroupId, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInLocalInvocationId, VULKAN_STAGE::KERNEL},
+              {spv::BuiltInGlobalInvocationId, VULKAN_STAGE::KERNEL},
+              //{ spv::BuiltInLocalInvocationIndex, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInWorkDim, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInEnqueuedWorkgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalOffset, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalLinearId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupMaxSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumEnqueuedSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupLocalInvocationId, VULKAN_STAGE::NONE },
+              {spv::BuiltInVertexIndex, VULKAN_STAGE::VERTEX},
+              {spv::BuiltInInstanceIndex, VULKAN_STAGE::VERTEX},
+              {spv::BuiltInViewIndex,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION | VULKAN_STAGE::GEOMETRY |
+                VULKAN_STAGE::FRAGMENT)},
+          };
+      static const std::unordered_map<spv::BuiltIn, VULKAN_STAGE>
+          builtin_validity_output_lut{
+              {spv::BuiltInPosition,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInPointSize,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInClipDistance,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInCullDistance,
+               (VULKAN_STAGE::VERTEX | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              //{ spv::BuiltInVertexId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInInstanceId, VULKAN_STAGE::NONE },
+              {spv::BuiltInPrimitiveId,
+               (VULKAN_STAGE::FRAGMENT | VULKAN_STAGE::TESSELLATION_CONTROL |
+                VULKAN_STAGE::TESSELLATION_EVALUATION |
+                VULKAN_STAGE::GEOMETRY)},
+              {spv::BuiltInInvocationId, VULKAN_STAGE::NONE},
+              {spv::BuiltInLayer, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInViewportIndex, VULKAN_STAGE::GEOMETRY},
+              {spv::BuiltInTessLevelOuter, VULKAN_STAGE::TESSELLATION_CONTROL},
+              {spv::BuiltInTessLevelInner, VULKAN_STAGE::TESSELLATION_CONTROL},
+              {spv::BuiltInTessCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInPatchVertices, VULKAN_STAGE::NONE},
+              {spv::BuiltInFragCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInPointCoord, VULKAN_STAGE::NONE},
+              {spv::BuiltInFrontFacing, VULKAN_STAGE::NONE},
+              {spv::BuiltInSampleId, VULKAN_STAGE::NONE},
+              {spv::BuiltInSamplePosition, VULKAN_STAGE::NONE},
+              {spv::BuiltInSampleMask, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInFragDepth, VULKAN_STAGE::FRAGMENT},
+              {spv::BuiltInHelperInvocation, VULKAN_STAGE::NONE},
+              {spv::BuiltInNumWorkgroups, VULKAN_STAGE::NONE},
+              {spv::BuiltInWorkgroupSize, VULKAN_STAGE::NONE},
+              {spv::BuiltInWorkgroupId, VULKAN_STAGE::NONE},
+              {spv::BuiltInLocalInvocationId, VULKAN_STAGE::NONE},
+              {spv::BuiltInGlobalInvocationId, VULKAN_STAGE::NONE},
+              //{ spv::BuiltInLocalInvocationIndex, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInWorkDim, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInEnqueuedWorkgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalOffset, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInGlobalLinearId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupMaxSize, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInNumEnqueuedSubgroups, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupId, VULKAN_STAGE::NONE },
+              //{ spv::BuiltInSubgroupLocalInvocationId, VULKAN_STAGE::NONE },
+              {spv::BuiltInVertexIndex, VULKAN_STAGE::NONE},
+              {spv::BuiltInInstanceIndex, VULKAN_STAGE::NONE},
+              {spv::BuiltInViewIndex, VULKAN_STAGE::NONE},
+          };
+
+      if (is_input) {
+        const auto iter = builtin_validity_input_lut.find(builtin);
+        if (iter == builtin_validity_input_lut.end()) {
+          return false;
+        }
+        return (iter->second & stage) != VULKAN_STAGE::NONE;
+      } else {
+        const auto iter = builtin_validity_output_lut.find(builtin);
+        if (iter == builtin_validity_output_lut.end()) {
+          return false;
+        }
+        return (iter->second & stage) != VULKAN_STAGE::NONE;
+      }
+    };
+
+    // handle parameters (input or globals)
+    // TODO: proper input/output location handling: 1x - 4x 32-bit values can be
+    // packed into a single location, anything larger needs to be distributed
+    // over multiple locations
+    uint32_t input_arg_idx = 0, uniform_arg_idx = 0;
+    uint32_t input_location = 0;
+    uint32_t desc_set = 0;
+    switch (stage) { // put each stage into a different set
+    case VULKAN_STAGE::KERNEL:
+    case VULKAN_STAGE::VERTEX:
+      desc_set = 1;
+      break;
+    case VULKAN_STAGE::FRAGMENT:
+      desc_set = 2;
+      break;
+    case VULKAN_STAGE::GEOMETRY:
+      desc_set = 3;
+      break;
+    case VULKAN_STAGE::TESSELLATION_CONTROL:
+      desc_set = 4;
+      break;
+    case VULKAN_STAGE::TESSELLATION_EVALUATION:
+      desc_set = 5;
+      break;
+    default:
+      llvm_unreachable("invalid stage");
+    }
+    for (Argument &arg : F->args()) {
+      llvm::Type *arg_type = arg.getType();
+      const auto arg_name = arg.getName();
+
+      const auto md_prefix_split_pos = md_data_input[input_arg_idx].find(':');
+      const std::string md_prefix =
+          (md_prefix_split_pos != std::string::npos
+               ? md_data_input[input_arg_idx].substr(0, md_prefix_split_pos)
+               : "");
+      const std::string md_info =
+          (md_prefix_split_pos != std::string::npos
+               ? md_data_input[input_arg_idx].substr(md_prefix_split_pos + 1)
+               : md_data_input[input_arg_idx]);
+
+      if (arg_type->isPointerTy() &&
+          arg_type->getPointerAddressSpace() != SPIRAS_Input) {
+        llvm::Type *elem_type = arg_type->getPointerElementType();
+
+        // -> globals
+        SPIRVVariable *uniform_var = nullptr;
+        const auto ptr_as = arg_type->getPointerAddressSpace();
+        if (arg.onlyReadsMemory() &&
+            (arg.hasAttribute(Attribute::Dereferenceable) ||
+             arg.hasAttribute(Attribute::DereferenceableOrNull))) {
+          // -> uniform, use static/fixed SSBO
+          // NOTE: this could be made a Block variable, but that would have
+          // insane alignment/offset requirements, so always make it a SSBO,
+          // which has less restrictions
+          // (TODO: could also make this a push constant later on)
+          spirv_global_io_type global_type;
+          global_type.is_constant = true;
+          global_type.is_uniform = true;
+          global_type.is_read_only = true;
+          auto storage_class = SPIRAS_StorageBuffer;
+          if (md_prefix == "iub") {
+            global_type.is_iub = true;
+            storage_class = SPIRAS_Uniform;
+          }
+          auto GV = emitShaderGlobal(*F, BF, arg_name.str(), elem_type,
+                                     storage_class, global_type, md_info,
+                                     &uniform_var);
+          arg.replaceAllUsesWith(GV, true);
+        } else if (ptr_as == SPIRAS_Uniform || ptr_as == SPIRAS_StorageBuffer) {
+          // all image types are opaque/unsized
+          if (!elem_type->isSized()) {
+            // -> image
+            assert(ptr_as == SPIRAS_Uniform);
+            spirv_global_io_type global_type;
+            global_type.is_image = true;
+            global_type.is_constant = true;
+            global_type.is_uniform = true;
+            auto GV = emitShaderGlobal(*F, BF, arg_name.str(),
+                                       elem_type, SPIRAS_Uniform, global_type,
+                                       md_info, &uniform_var);
+            arg.replaceAllUsesWith(GV);
+          } else {
+            // -> BufferBlock uniform (SSBO)
+            spirv_global_io_type global_type;
+            global_type.is_uniform = true;
+            global_type.is_read_only = arg.onlyReadsMemory();
+            global_type.is_write_only =
+                (!global_type.is_read_only ? is_write_only_arg(*F, arg)
+                                           : false);
+            const auto storage_class = SPIRAS_StorageBuffer;
+            auto GV = emitShaderGlobal(*F, BF, arg_name.str(),
+                                       elem_type, storage_class, global_type,
+                                       md_info, &uniform_var);
+            // any GEPs can be directly replaced with the new GV, all others can
+            // no longer access it directly, but must go through a new "GEP #0"
+            // access
+            while (!arg.user_empty()) {
+              auto user = *arg.user_begin();
+              // simple GEP ptr replacement
+              if (GetElementPtrInst *GEP = dyn_cast<GetElementPtrInst>(user)) {
+                GEP->setOperand(0, GV);
+                continue;
+              }
+              // direct access
+              if (Instruction *instr = dyn_cast<Instruction>(user)) {
+                // create GEP to the first element
+                llvm::Value *idx_list[]{
+                    llvm::ConstantInt::get(llvm::Type::getInt32Ty(*Ctx), 0),
+                };
+                auto zero_gep = GetElementPtrInst::CreateInBounds(GV->getType()->getScalarType()->getPointerElementType(), GV, idx_list, "", instr);
+                zero_gep->setDebugLoc(instr->getDebugLoc());
+
+                // replace all uses in the instruction
+                for (uint32_t op_idx = 0; op_idx < instr->getNumOperands();
+                     ++op_idx) {
+                  auto op = instr->getOperand(op_idx);
+                  if (op == &arg) {
+                    instr->setOperand(op_idx, zero_gep);
+                  }
+                }
+                continue;
+              }
+              assert(false && "should not be here - unknown arg user");
+            }
+          }
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Private &&
+                   arg_type->getPointerElementType()->isArrayTy()) {
+          auto array_type = cast<ArrayType>(arg_type->getPointerElementType());
+
+          auto img_ptr_type = array_type->getArrayElementType();
+          assert(img_ptr_type->isPointerTy() && "expected image pointer type");
+          auto img_type = img_ptr_type->getPointerElementType();
+          assert(img_type->isStructTy() && "expected image struct type");
+          auto st_img_type = cast<StructType>(img_type);
+          assert(st_img_type->getStructName().startswith("opencl.image") &&
+                 "expected image type");
+
+          // -> image array
+          spirv_global_io_type global_type;
+          global_type.is_image = true;
+          global_type.is_constant = true;
+          global_type.is_uniform = true;
+          auto GV = emitShaderGlobal(*F, BF, arg_name.str(), array_type,
+                                     SPIRAS_Uniform, global_type, md_info,
+                                     &uniform_var);
+          // replace with address space change (private to uniform)
+          arg.replaceAllUsesWith(GV, true);
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Local) {
+          // -> local memory (TODO: implement this)
+          llvm_unreachable("local memory parameters are not yet implemented");
+        } else if (arg_type->getPointerAddressSpace() == SPIRAS_Generic) {
+          // -> unknown generic
+          llvm_unreachable("generic parameters are not supported");
+        } else
+          llvm_unreachable("unknown parameter address space");
+
+        //
+        uniform_var->addDecorate(
+            new SPIRVDecorate(DecorationDescriptorSet, uniform_var, desc_set));
+        uniform_var->addDecorate(
+            new SPIRVDecorate(DecorationBinding, uniform_var, uniform_arg_idx));
+        ++uniform_arg_idx;
+      } else {
+        if (md_prefix == "builtin") {
+          // -> special input variable
+          // transform function parameter to in-function alloca + input
+          // annotation
+          const auto builtin = get_builtin(md_info);
+          if (!builtin.second) {
+            errs() << "unknown builtin: " << md_info << "\n";
+          }
+
+          const auto is_valid =
+              is_builtin_valid_in_stage(builtin.first, stage, true /* input */);
+          if (is_valid) {
+            llvm::Type *elem_type = arg_type->getPointerElementType();
+            spirv_global_io_type global_type;
+            global_type.is_input = true;
+            global_type.is_builtin = true;
+            auto repl_var = emitShaderGlobal(
+                *F, BF, arg_name.str(), elem_type, SPIRAS_Input, global_type,
+                md_info, nullptr, builtin.first);
+            arg.replaceAllUsesWith(repl_var);
+          } else {
+            // TODO: should catch this earlier
+            if (arg.getNumUses() > 0) {
+              errs() << "input builtin \"" << md_info
+                     << "\" can not be used in stage \""
+                     << vulkan_stage_to_string(stage) << "\"\n";
+            }
+          }
+        } else if (md_prefix == "stage" || md_prefix == "") {
+          // -> stage input
+          spirv_global_io_type global_type;
+          global_type.is_input = true;
+          global_type.is_read_only = true;
+          if (md_prefix != "stage") {
+            // only emit this input if it is an actual input (not a builtin)
+            global_type.set_location = true;
+            global_type.location = input_location++;
+
+            auto repl_var =
+                emitShaderGlobal(*F, BF, arg_name.str(), arg_type,
+                                 SPIRAS_Input, global_type, md_info);
+            // only emit load if there actually is a user
+            if (arg.getNumUses() > 0) {
+              LoadInst *load_repl_var = new LoadInst(arg_type, repl_var, arg_name, false,
+                                                     &*(F->front().begin()));
+              arg.replaceAllUsesWith(load_repl_var);
+            }
+          } else {
+            // builtin input -> must be ignored
+            if (arg.getNumUses() != 0) {
+              errs() << "stage input should not have any users (must use "
+                        "built-ins)\n";
+              assert(
+                  false &&
+                  "stage input should not have any users (must use built-ins)");
+            }
+          }
+        } else {
+          assert(false && "unknown or unhandled input");
+        }
+      }
+
+      // used by all arg types
+      ++input_arg_idx;
+    }
+
+    // handle return value / output
+    // TODO: more metadata + handling
+    // NOTE: inputs, builtins and uniforms are handled on the SPIRVLib side
+    // above, outputs are however already handled on the LLVM side (VulkanFinal
+    // pass) and thus have no SPIRVVariable mapping yet and have not been added
+    // to the entry point i/o set yet
+    // -> create SPIRVVariable for outputs + add them to the entry point i/o set
+    // in here
+    const std::string output_var_name_stub = func_name + ".vulkan_output.";
+    uint32_t output_arg_idx = 0, output_location = 0;
+    for (const auto &GV : M->globals()) {
+      if (GV.hasName() &&
+          GV.getName().find(output_var_name_stub) != std::string::npos) {
+        auto output_name = GV.getName().split(".vulkan_output.").second;
+
+        assert(output_arg_idx < md_data_output.size() &&
+               "invalid/incomplete output metadata");
+        const auto md_prefix_split_pos =
+            md_data_output[output_arg_idx].find(':');
+        const std::string md_prefix =
+            (md_prefix_split_pos != std::string::npos
+                 ? md_data_output[output_arg_idx].substr(0, md_prefix_split_pos)
+                 : "");
+        const std::string md_info =
+            (md_prefix_split_pos != std::string::npos
+                 ? md_data_output[output_arg_idx].substr(md_prefix_split_pos +
+                                                         1)
+                 : md_data_output[output_arg_idx]);
+
+        if (md_prefix != "") {
+          // -> fbo color
+          if (md_prefix == "stage" &&
+              md_info.find("fbo_output:") != std::string::npos) {
+            spirv_global_io_type global_type;
+            global_type.is_write_only = true;
+            global_type.is_fbo_color = true;
+            emitShaderSPIRVGlobal(BF, GV, output_name.str(), SPIRAS_Output,
+                                  global_type, md_info);
+          }
+          // -> fbo depth
+          else if (md_prefix == "stage" &&
+                   md_info.find("fbo_depth:") != std::string::npos) {
+            spirv_global_io_type global_type;
+            global_type.is_write_only = true;
+            global_type.is_fbo_depth = true;
+            global_type.is_builtin = true;
+            emitShaderSPIRVGlobal(BF, GV, output_name.str(), SPIRAS_Output,
+                                  global_type, md_info, spv::BuiltInFragDepth);
+            // since we explicitly write depth, flag the function as
+            // "DepthReplacing"
+            BF->addExecutionMode(new SPIRVExecutionMode(
+                BF, ExecutionModeDepthReplacing));
+          }
+          // -> builtin
+          else if (md_prefix == "builtin" || md_prefix == "stage") {
+            const auto builtin = get_builtin(md_info);
+            if (!builtin.second) {
+              errs() << "unknown builtin: " << md_info << "\n";
+            }
+
+            const auto is_valid = is_builtin_valid_in_stage(
+                builtin.first, stage, false /* output */);
+            if (is_valid) {
+              spirv_global_io_type global_type;
+              global_type.is_builtin = true;
+              global_type.is_write_only = true;
+              emitShaderSPIRVGlobal(BF, GV, output_name.str(), SPIRAS_Output,
+                                    global_type, md_info, builtin.first);
+            } else {
+              // TODO: should catch this earlier
+              errs() << "output builtin \"" << md_info
+                     << "\" can not be used in stage \""
+                     << vulkan_stage_to_string(stage) << "\"\n";
+            }
+          }
+          // -> unknown or unhandled yet
+          else {
+            assert(false && "unknown or unhandled output");
+          }
+        }
+        // -> normal output
+        else {
+          spirv_global_io_type global_type;
+          global_type.is_write_only = true;
+          global_type.set_location = true;
+          global_type.location = output_location++;
+          emitShaderSPIRVGlobal(BF, GV, output_name.str(), SPIRAS_Output,
+                                global_type, md_info);
+        }
+        ++output_arg_idx;
+      }
+    }
+
+    // add immutable samples to the interface
+    if (immutable_samplers) {
+      BM->addEntryPointIO(BF->getId(), immutable_samplers);
+    }
+
+    // Create all basic blocks before creating any instruction.
+    for (Function::iterator FI = F->begin(), FE = F->end(); FI != FE; ++FI) {
+      transValue(&*FI, nullptr);
+    }
+
+    // set compute shader constant work-group size
+    if (F->getCallingConv() == llvm::CallingConv::FLOOR_KERNEL) {
+      const auto global_name = func_name + ".vulkan_constant.workgroup_size";
+      auto gv_wg_size = M->getNamedGlobal(global_name);
+
+      // NOTE: 128 is the minimum value that has to be supported for x
+      const uint32_t default_wg_size_vals[3]{128, 1, 1};
+      auto uint_type = BM->addIntegerType(32, false);
+      auto uint3_type = BM->addVectorType(uint_type, 3);
+      std::vector<SPIRVValue *> wg_size_vals{
+          BM->addSpecIntegerConstant(uint_type, default_wg_size_vals[0]),
+          BM->addSpecIntegerConstant(uint_type, default_wg_size_vals[1]),
+          BM->addSpecIntegerConstant(uint_type, default_wg_size_vals[2]),
+      };
+      auto wg_size = BM->addSpecCompositeConstant(uint3_type, wg_size_vals);
+      wg_size->addDecorate(spv::DecorationBuiltIn, spv::BuiltInWorkgroupSize);
+      BM->setName(wg_size, global_name);
+      BF->addExecutionMode(new SPIRVExecutionMode(
+          BF, spv::ExecutionModeLocalSize, default_wg_size_vals[0],
+          default_wg_size_vals[1], default_wg_size_vals[2]));
+
+      // set work-group size (x, y, z) spec ids to 1, 2 and 3
+      // NOTE: we're starting this at 1 instead of 0, b/c of nvidia driver bugs
+      for (uint32_t i = 0; i < 3; ++i) {
+        wg_size_vals[i]->addDecorate(spv::DecorationSpecId, i + 1);
+      }
+
+      // preempt loads of the "<i32 x 3>*" work-group size constant
+      // -> this has to be a constant composite in SPIR-V, not a variable
+      // -> replace (map) all loads with the constant
+      std::vector<User *> users;
+      for (auto user : gv_wg_size->users()) {
+        users.emplace_back(user);
+      }
+
+      if (!users.empty()) {
+        // bitcast uint3 -> int3 for all users
+        // NOTE/TODO: ideally, this should stay a uint3, but this would incur
+        // type mismatch problems later on (would need to do int type inference
+        // over the whole function to fix this properly)
+        auto int_type = BM->addIntegerType(32, true);
+        auto int3_type = BM->addVectorType(int_type, 3);
+        auto entry_bb = (SPIRVBasicBlock *)transValue(&*F->begin(), nullptr);
+        auto wg_size_int3 =
+            BM->addUnaryInst(spv::OpBitcast, int3_type, wg_size, entry_bb);
+
+        for (auto user : users) {
+          if (const auto instr = dyn_cast<LoadInst>(user)) {
+            mapValue((const Value *)instr, wg_size_int3);
+          }
+        }
+      }
+    }
+  } else if (SrcLang != SourceLanguageGLSL) {
+    // Creating all basic blocks before creating any instruction.
+    for (auto &FI : *F) {
+      transValue(&FI, nullptr);
+    }
+  }
+
+  // handle global constant variables, these need to be lowered to
+  // function-scope (duplicate per function)
+  // SPIR-V 1.4+: also handle local buffers (add to interface)
+  // NOTE: needs to be done after basic blocks have been created (to add
+  // OpVariables), but before being used when adding the instructions
+  std::unordered_set<GlobalVariable *> added_globals;
+  for (auto &GV : M->globals()) {
+    // don't want to handle the globals that we added in here
+    if (added_globals.count(&GV) > 0)
+      continue;
+
+    // ignore external globals
+    if (GV.getLinkage() == GlobalValue::ExternalLinkage ||
+        GV.getLinkage() == GlobalValue::AvailableExternallyLinkage ||
+        GV.getLinkage() == GlobalValue::PrivateLinkage ||
+        GV.getLinkage() == GlobalValue::ExternalWeakLinkage)
+      continue;
+
+    const auto gv_as = GV.getType()->getAddressSpace();
+    if (SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(gv_as)) ==
+        spv::StorageClassFunction) {
+      bool is_used_in_function = false;
+      for (const auto &user : GV.users()) {
+        if (const auto instr = dyn_cast<Instruction>(user)) {
+          if (instr->getParent()->getParent() == F) {
+            is_used_in_function = true;
+            break;
+          }
+        }
+      }
+      if (!is_used_in_function)
+        continue;
+
+      // duplicate the global + replace all uses of it in this function with the
+      // duplicate
+      auto dup = new GlobalVariable(
+          *M, GV.getType()->getPointerElementType(), GV.isConstant(),
+          GlobalVariable::InternalLinkage,
+          (GV.hasInitializer() ? GV.getInitializer() : nullptr),
+          GV.getName() + "." + F->getName(), nullptr,
+          GlobalValue::NotThreadLocal, GV.getType()->getAddressSpace());
+      added_globals.emplace(dup);
+
+      // need to copy all uses beforehand due iter invalidation
+      std::vector<Use *> uses;
+      uses.reserve(GV.getNumUses());
+      for (auto &use : GV.uses()) {
+        uses.emplace_back(&use);
+      }
+
+      for (auto &use : uses) {
+        if (const auto instr = dyn_cast<Instruction>(use->getUser())) {
+          if (instr->getParent()->getParent() == F) {
+            use->set(dup);
+          }
+        }
+      }
+
+      // translate value/duplicate at the beginning of the entry BB of this
+      // function
+      auto BB = (SPIRVBasicBlock *)transValue(&F->getEntryBlock(), nullptr);
+      transValue(dup, BB);
+    } else if (SPIRSPIRVAddrSpaceMap::map(static_cast<SPIRAddressSpace>(
+                   gv_as)) == spv::StorageClassWorkgroup) {
+      BM->addEntryPointIO(BF->getId(),
+                          (SPIRVVariable *)transValue(&GV, nullptr));
+    }
+  }
+
+  // create all instructions
+  for (auto &FI : *F) {
     SPIRVBasicBlock *BB =
         static_cast<SPIRVBasicBlock *>(transValue(&FI, nullptr));
     for (auto &BI : FI) {
@@ -3667,14 +5529,74 @@ void LLVMToSPIRVBase::transFunction(Function *I) {
     }
   }
   // Enable FP contraction unless proven otherwise
-  joinFPContract(I, FPContract::ENABLED);
-  fpContractUpdateRecursive(I, getFPContract(I));
+  joinFPContract(F, FPContract::ENABLED);
+  fpContractUpdateRecursive(F, getFPContract(F));
+
+  if (isEntryPoint(F) && SrcLang != SourceLanguageGLSL /* already handled */) {
+    collectInputOutputVariables(BF, F);
+  }
+}
+
+bool LLVMToSPIRVBase::transVulkanVersion() {
+  SrcLang = std::get<0>(getSPIRVSource(M));
+  if (SrcLang != SourceLanguageGLSL) {
+    return true;
+  }
 
-  bool IsKernelEntryPoint = isKernel(I);
+  const llvm::NamedMDNode *VulkanVersion =
+      M->getNamedMetadata("vulkan.version");
+  if (VulkanVersion == nullptr || VulkanVersion->getNumOperands() != 1) {
+    return false;
+  }
 
-  if (IsKernelEntryPoint) {
-    collectInputOutputVariables(BF, I);
+  const MDNode *vulkan_version_md = VulkanVersion->getOperand(0);
+  if (vulkan_version_md->getNumOperands() < 2) {
+    return false;
+  }
+
+  uint64_t version_major = 0, version_minor = 0;
+
+  const MDOperand &version_major_op = vulkan_version_md->getOperand(0);
+  if (const ConstantAsMetadata *version_major_md =
+          dyn_cast_or_null<ConstantAsMetadata>(version_major_op.get())) {
+    if (const ConstantInt *version_major_int =
+            dyn_cast_or_null<ConstantInt>(version_major_md->getValue())) {
+      version_major = version_major_int->getZExtValue();
+    } else {
+      return false;
+    }
+  } else {
+    return false;
+  }
+
+  const MDOperand &version_minor_op = vulkan_version_md->getOperand(1);
+  if (const ConstantAsMetadata *version_minor_md =
+          dyn_cast_or_null<ConstantAsMetadata>(version_minor_op.get())) {
+    if (const ConstantInt *version_minor_int =
+            dyn_cast_or_null<ConstantInt>(version_minor_md->getValue())) {
+      version_minor = version_minor_int->getZExtValue();
+    } else {
+      return false;
+    }
+  } else {
+    return false;
+  }
+
+  switch (version_major) {
+  case 1:
+    switch (version_minor) {
+    case 2:
+      BM->setSPIRVVersion(static_cast<uint32_t>(VersionNumber::SPIRV_1_5));
+      break;
+    default:
+      return false;
+    }
+    break;
+  default:
+    return false;
   }
+
+  return true;
 }
 
 bool isEmptyLLVMModule(Module *M) {
@@ -3692,6 +5614,8 @@ bool LLVMToSPIRVBase::translate() {
   if (!transWorkItemBuiltinCallsToVariables())
     return false;
 
+  if (!transVulkanVersion())
+    return false;
   if (!transSourceLanguage())
     return false;
   if (!transExtension())
@@ -3790,37 +5714,55 @@ SPIRVInstruction *LLVMToSPIRVBase::transBuiltinToInst(StringRef DemangledName,
                                                       CallInst *CI,
                                                       SPIRVBasicBlock *BB) {
   SmallVector<std::string, 2> Dec;
-  auto OC = getSPIRVFuncOC(DemangledName, &Dec);
+  Op OC = OpNop;
+  SPIRVInstruction *Inst = nullptr;
+
+  // special handling for Vulkan/SPIR-V image read/write
+  if (SrcLang == spv::SourceLanguageGLSL &&
+      (DemangledName.find(kOCLBuiltinName::ReadImage) == 0 ||
+       DemangledName.find(kOCLBuiltinName::WriteImage) == 0 ||
+       DemangledName.find(std::string(kSPIRVName::Prefix) +
+                          kSPIRVName::ImageQuerySize) ==
+           0 /* matches both LOD and non-LOD */)) {
+    auto inst_op = transVulkanImageFunction(CI, BB, DemangledName.str());
+    assert(inst_op.first != nullptr && inst_op.second != OpNop &&
+           "failed to translate image read/write function");
+    Inst = inst_op.first;
+    OC = inst_op.second;
+  } else {
+    OC = getSPIRVFuncOC(DemangledName, &Dec);
 
-  if (OC == OpNop)
-    return nullptr;
+    if (OC == OpNop)
+      return nullptr;
 
-  if (OpReadPipeBlockingINTEL <= OC && OC <= OpWritePipeBlockingINTEL &&
-      !BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_blocking_pipes))
-    return nullptr;
+    if (OpReadPipeBlockingINTEL <= OC && OC <= OpWritePipeBlockingINTEL &&
+        !BM->isAllowedToUseExtension(ExtensionID::SPV_INTEL_blocking_pipes))
+      return nullptr;
+
+    if (OpFixedSqrtINTEL <= OC && OC <= OpFixedExpINTEL)
+      BM->getErrorLog().checkError(
+          BM->isAllowedToUseExtension(
+              ExtensionID::SPV_INTEL_arbitrary_precision_fixed_point),
+          SPIRVEC_InvalidInstruction,
+          CI->getCalledOperand()->getName().str() +
+              "\nFixed point instructions can't be translated correctly without "
+              "enabled SPV_INTEL_arbitrary_precision_fixed_point extension!\n");
+
+    if ((OpArbitraryFloatSinCosPiINTEL <= OC &&
+         OC <= OpArbitraryFloatCastToIntINTEL) ||
+        (OpArbitraryFloatAddINTEL <= OC && OC <= OpArbitraryFloatPowNINTEL))
+      BM->getErrorLog().checkError(
+          BM->isAllowedToUseExtension(
+              ExtensionID::SPV_INTEL_arbitrary_precision_floating_point),
+          SPIRVEC_InvalidInstruction,
+          CI->getCalledOperand()->getName().str() +
+              "\nFloating point instructions can't be translated correctly "
+              "without enabled SPV_INTEL_arbitrary_precision_floating_point "
+              "extension!\n");
+
+    Inst = transBuiltinToInstWithoutDecoration(OC, CI, BB);
+  }
 
-  if (OpFixedSqrtINTEL <= OC && OC <= OpFixedExpINTEL)
-    BM->getErrorLog().checkError(
-        BM->isAllowedToUseExtension(
-            ExtensionID::SPV_INTEL_arbitrary_precision_fixed_point),
-        SPIRVEC_InvalidInstruction,
-        CI->getCalledOperand()->getName().str() +
-            "\nFixed point instructions can't be translated correctly without "
-            "enabled SPV_INTEL_arbitrary_precision_fixed_point extension!\n");
-
-  if ((OpArbitraryFloatSinCosPiINTEL <= OC &&
-       OC <= OpArbitraryFloatCastToIntINTEL) ||
-      (OpArbitraryFloatAddINTEL <= OC && OC <= OpArbitraryFloatPowNINTEL))
-    BM->getErrorLog().checkError(
-        BM->isAllowedToUseExtension(
-            ExtensionID::SPV_INTEL_arbitrary_precision_floating_point),
-        SPIRVEC_InvalidInstruction,
-        CI->getCalledOperand()->getName().str() +
-            "\nFloating point instructions can't be translated correctly "
-            "without enabled SPV_INTEL_arbitrary_precision_floating_point "
-            "extension!\n");
-
-  auto Inst = transBuiltinToInstWithoutDecoration(OC, CI, BB);
   addDecorations(Inst, Dec);
   return Inst;
 }
@@ -3846,8 +5788,10 @@ bool LLVMToSPIRVBase::transExecutionMode() {
 
       switch (EMode) {
       case spv::ExecutionModeContractionOff:
-        BF->addExecutionMode(BM->add(
-            new SPIRVExecutionMode(BF, static_cast<ExecutionMode>(EMode))));
+        if (SrcLang != spv::SourceLanguageGLSL) {
+          BF->addExecutionMode(BM->add(
+              new SPIRVExecutionMode(BF, static_cast<ExecutionMode>(EMode))));
+        }
         break;
       case spv::ExecutionModeInitializer:
       case spv::ExecutionModeFinalizer:
@@ -3959,9 +5903,9 @@ void LLVMToSPIRVBase::transFPContract() {
     }
     SPIRVFunction *BF = static_cast<SPIRVFunction *>(TranslatedF);
 
-    bool IsKernelEntryPoint =
+    bool IsEntryPoint =
         BF->getModule()->isEntryPoint(spv::ExecutionModelKernel, BF->getId());
-    if (!IsKernelEntryPoint)
+    if (!IsEntryPoint)
       continue;
 
     FPContract FPC = getFPContract(&F);
@@ -3980,7 +5924,7 @@ void LLVMToSPIRVBase::transFPContract() {
       break;
     }
 
-    if (DisableContraction) {
+    if (DisableContraction && SrcLang != spv::SourceLanguageGLSL) {
       BF->addExecutionMode(BF->getModule()->add(
           new SPIRVExecutionMode(BF, spv::ExecutionModeContractionOff)));
     }
@@ -4009,8 +5953,13 @@ static void transKernelArgTypeMD(SPIRVModule *BM, Function *F, MDNode *MD,
 }
 
 bool LLVMToSPIRVBase::transOCLMetadata() {
+  // TODO: do shaders need to be handled in here?
+  if (SrcLang == spv::SourceLanguageGLSL) {
+    return true;
+  }
+
   for (auto &F : *M) {
-    if (F.getCallingConv() != CallingConv::SPIR_KERNEL)
+    if (F.getCallingConv() != CallingConv::FLOOR_KERNEL)
       continue;
 
     SPIRVFunction *BF = static_cast<SPIRVFunction *>(getTranslatedValue(&F));
@@ -4057,6 +6006,10 @@ bool LLVMToSPIRVBase::transSourceLanguage() {
   auto Src = getSPIRVSource(M);
   SrcLang = std::get<0>(Src);
   SrcLangVer = std::get<1>(Src);
+  if (SrcLang == SourceLanguageGLSL) {
+    // "GLSL" is compiled as OpenCL 2.0 -> switch out the version number
+    SrcLangVer = 450;
+  }
   BM->setSourceLanguage(static_cast<SourceLanguage>(SrcLang), SrcLangVer);
   return true;
 }
@@ -4098,9 +6051,299 @@ Op LLVMToSPIRVBase::transBoolOpCode(SPIRVValue *Opn, Op OC) {
   return OC;
 }
 
+std::pair<SPIRVInstruction *, Op>
+LLVMToSPIRVBase::transVulkanImageFunction(CallInst *CI, SPIRVBasicBlock *BB,
+                                          const std::string &DemangledName) {
+  // NOTE: argument validity checking has already been done in VulkanImage
+  //
+  // read(image, sampler_idx, coord_with_layer,
+  //      lod_type, [lod_arg_0], [lod_arg_1],
+  //      bool is_offset, [offset],
+  //      [sample_idx],
+  //      [compare_val])
+  //
+  // write(image, coord_with_layer, data,
+  //       // NOTE: only explicit lod or no lod
+  //       lod_type, [lod_arg_0])
+  //
+  // query(image, lod)
+  //
+
+  // TODO: try to "cache" these things (image loads and sampler stuff)
+
+  auto args = getArguments(CI);
+  auto img_arg = args[0];
+  auto spirv_img = getSPIRVValue(img_arg);
+  assert(spirv_img != nullptr && "invalid image");
+
+  SPIRVValue *loaded_img = nullptr;
+  if (!isa<CallInst>(img_arg)) {
+    // load the image (image function argument)
+    loaded_img = BM->addLoadInst(spirv_img, {}, BB);
+  } else {
+    // special call, image has already been loaded (e.g. image array load)
+    loaded_img = spirv_img;
+  }
+  auto spirv_img_type = (SPIRVTypeImage *)loaded_img->getType();
+
+  std::vector<SPIRVWord> image_operands;
+  uint32_t operands_mask = spv::ImageOperandsMaskNone;
+
+  if (DemangledName.find("read_image") == 0) {
+    // retrieve the sampler idx + load the sampler
+    auto sampler_idx_arg = dyn_cast<ConstantInt>(args[1]);
+    assert(sampler_idx_arg != nullptr && "sampler must be a constant int");
+    const vulkan_sampling::sampler sampler_val{
+        (uint32_t)sampler_idx_arg->getZExtValue()};
+    const bool is_fetch =
+        ((sampler_val.value &
+          vulkan_sampling::sampler::COORD_MODE::__COORD_MODE_MASK) ==
+         vulkan_sampling::sampler::COORD_MODE::PIXEL);
+
+    // only load the sampler + create the sampled image if necessary
+    SPIRVValue *loaded_sampler = nullptr;
+    SPIRVValue *img = loaded_img;
+    if (!is_fetch) {
+      std::vector<SPIRVValue *> indices{
+          BM->getLiteralAsConstant(sampler_val.value, false)};
+
+      auto sampler_ptr = BM->addAccessChainInst(
+          BM->addPointerType(spv::StorageClassUniformConstant,
+                             BM->addSamplerType()),
+          immutable_samplers, indices, BB, true);
+      loaded_sampler = BM->addLoadInst(sampler_ptr, {}, BB);
+
+      // create the sampled image
+      std::vector<SPIRVWord> sampled_img_ops{
+          loaded_img->getId(),
+          loaded_sampler->getId(),
+      };
+      img = BM->addInstTemplate(OpSampledImage, sampled_img_ops, BB,
+                                BM->addSampledImageType(spirv_img_type));
+    }
+
+    std::vector<SPIRVWord> read_operands{img->getId()};
+    spv::Op read_opcode = spv::OpNop;
+
+    // coords
+    auto coords_arg = transValue(args[2], BB);
+    read_operands.emplace_back(coords_arg->getId());
+
+    // lod type and args
+    auto lod_type_arg = dyn_cast<ConstantInt>(args[3]);
+    uint32_t arg_idx = 4; // from here on: arg count and indices are variable
+    assert(lod_type_arg != nullptr && "lod type must be a constant int");
+    auto lod_type = (vulkan_sampling::LOD_TYPE)lod_type_arg->getZExtValue();
+    assert(lod_type <= vulkan_sampling::LOD_TYPE::__MAX_LOD_TYPE &&
+           "invalid lod type");
+
+    const bool is_fragment_shader = (CI->getParent()->getParent()->getCallingConv() == CallingConv::FLOOR_FRAGMENT);
+    if (!is_fragment_shader && (lod_type == vulkan_sampling::LOD_TYPE::IMPLICIT_LOD ||
+                                lod_type == vulkan_sampling::LOD_TYPE::IMPLICIT_LOD_WITH_BIAS)) {
+      // implicit LOD is only allowed in fragment shaders -> fix it
+      auto explicit_lod_arg = ConstantInt::get(IntegerType::get(M->getContext(), 32), 0);
+      if (lod_type == vulkan_sampling::LOD_TYPE::IMPLICIT_LOD_WITH_BIAS) {
+        // replace bias arg with dummy 0
+        args[arg_idx] = explicit_lod_arg;
+      } else {
+        // insert dummy 0
+        args.insert(args.begin() + arg_idx, explicit_lod_arg);
+      }
+      lod_type = vulkan_sampling::LOD_TYPE::EXPLICIT_LOD;
+    }
+
+    switch (lod_type) {
+    case vulkan_sampling::LOD_TYPE::NO_LOD:
+      read_opcode = spv::OpImageFetch;
+      break;
+    case vulkan_sampling::LOD_TYPE::IMPLICIT_LOD:
+      read_opcode = spv::OpImageSampleImplicitLod;
+      break;
+    case vulkan_sampling::LOD_TYPE::IMPLICIT_LOD_WITH_BIAS:
+      read_opcode = spv::OpImageSampleImplicitLod;
+      operands_mask |= spv::ImageOperandsBiasMask;
+      image_operands.emplace_back(transValue(args[arg_idx++], BB)->getId());
+      break;
+    case vulkan_sampling::LOD_TYPE::EXPLICIT_LOD:
+      read_opcode =
+          (!is_fetch ? spv::OpImageSampleExplicitLod : spv::OpImageFetch);
+      operands_mask |= spv::ImageOperandsLodMask;
+      image_operands.emplace_back(transValue(args[arg_idx++], BB)->getId());
+      break;
+    case vulkan_sampling::LOD_TYPE::GRADIENT:
+      read_opcode =
+          (!is_fetch ? spv::OpImageSampleExplicitLod : spv::OpImageFetch);
+      operands_mask |= spv::ImageOperandsGradMask;
+      image_operands.emplace_back(transValue(args[arg_idx++], BB)->getId());
+      image_operands.emplace_back(transValue(args[arg_idx++], BB)->getId());
+      break;
+    default:
+      llvm_unreachable("invalid lod type");
+    }
+
+    // offset
+    auto is_offset_arg = dyn_cast<ConstantInt>(args[arg_idx++]);
+    assert(is_offset_arg != nullptr && "is_offset flag must be a constant int");
+    if (!is_offset_arg->isZero()) {
+      auto offset_arg = args[arg_idx++];
+      if (isa<Constant>(offset_arg)) {
+        operands_mask |= spv::ImageOperandsConstOffsetMask;
+      } else {
+        operands_mask |= spv::ImageOperandsOffsetMask;
+        BM->addCapability(spv::CapabilityImageGatherExtended);
+      }
+      image_operands.emplace_back(transValue(offset_arg, BB)->getId());
+    }
+
+    // sample idx
+    if (DemangledName.find("msaa") != std::string::npos) {
+      auto sample_idx_arg = args[arg_idx++];
+      operands_mask |= spv::ImageOperandsSampleMask;
+      image_operands.emplace_back(transValue(sample_idx_arg, BB)->getId());
+    }
+
+    // depth compare
+    bool is_depth_compare = false;
+    if (arg_idx < args.size()) {
+      is_depth_compare = true;
+      auto compare_arg = args[arg_idx++];
+
+      // must switch out the opcode
+      assert((read_opcode == spv::OpImageSampleImplicitLod ||
+              read_opcode == spv::OpImageSampleExplicitLod) &&
+             "invalid read opcode");
+      read_opcode = (read_opcode == spv::OpImageSampleImplicitLod ?
+                     spv::OpImageSampleDrefImplicitLod :
+                     spv::OpImageSampleDrefExplicitLod);
+      read_operands.emplace_back(transValue(compare_arg, BB)->getId());
+    }
+
+    // sanity check
+    assert(arg_idx == args.size() && "unhandled args");
+
+    // create the image read
+    if (operands_mask != spv::ImageOperandsMaskNone) {
+      // must only be emitted if mask != None + operands are ordered
+      read_operands.emplace_back(operands_mask);
+      for (const auto &id : image_operands) {
+        read_operands.emplace_back(id);
+      }
+    }
+
+    SPIRVType *scalar_ret_type = nullptr;
+    if (DemangledName.find("read_imageui") == 0) {
+      scalar_ret_type = BM->addIntegerType(32, false);
+    } else if (DemangledName.find("read_imagei") == 0) {
+      scalar_ret_type = BM->addIntegerType(32, true);
+    } else if (DemangledName.find("read_imagef") == 0) {
+      scalar_ret_type = BM->addFloatType(32);
+    } else {
+      assert(false && "invalid image read function");
+    }
+
+    SPIRVType *ret_type = scalar_ret_type; // only depth compare is scalar
+    if (!is_depth_compare) {
+      ret_type = BM->addVectorType(scalar_ret_type, 4);
+    }
+
+    auto read_sample =
+        BM->addInstTemplate(read_opcode, read_operands, BB, ret_type);
+    return {read_sample, read_sample->getOpCode()};
+  } else if (DemangledName.find("write_image") == 0) {
+    std::vector<SPIRVWord> write_operands{loaded_img->getId()};
+
+    // coords
+    auto coords_arg = transValue(args[1], BB);
+    write_operands.emplace_back(coords_arg->getId());
+
+    // data
+    // TODO: proper uint/int data type?
+    auto data_arg = transValue(args[2], BB);
+    write_operands.emplace_back(data_arg->getId());
+
+    // lod type and args
+    auto lod_type_arg = dyn_cast<ConstantInt>(args[3]);
+    uint32_t arg_idx = 4; // from here on: arg count and indices are variable
+    assert(lod_type_arg != nullptr && "lod type must be a constant int");
+    auto lod_type = (vulkan_sampling::LOD_TYPE)lod_type_arg->getZExtValue();
+    assert(lod_type <= vulkan_sampling::LOD_TYPE::__MAX_LOD_TYPE &&
+           "invalid lod type");
+    switch (lod_type) {
+    case vulkan_sampling::LOD_TYPE::NO_LOD:
+      // nop
+      break;
+    case vulkan_sampling::LOD_TYPE::EXPLICIT_LOD:
+      // NOTE: SPIR-V supports this, but Vulkan doesn't
+      //       -> this is dealt with elsewhere
+      // operands_mask |= spv::ImageOperandsLodMask;
+      // image_operands.emplace_back(transValue(args[arg_idx++], BB)->getId());
+      ++arg_idx;
+      break;
+    case vulkan_sampling::LOD_TYPE::IMPLICIT_LOD:
+    case vulkan_sampling::LOD_TYPE::IMPLICIT_LOD_WITH_BIAS:
+    case vulkan_sampling::LOD_TYPE::GRADIENT:
+    default:
+      llvm_unreachable("invalid lod type");
+    }
+
+    // sample idx
+    if (DemangledName.find("msaa") != std::string::npos) {
+      // TODO: !
+      // auto sample_idx_arg = args[arg_idx++];
+      // operands_mask |= spv::ImageOperandsSampleMask;
+      // image_operands.emplace_back(transValue(sample_idx_arg, BB)->getId());
+    }
+
+    // sanity check
+    assert(arg_idx == args.size() && "unhandled args");
+
+    // create the image write
+    if (operands_mask != spv::ImageOperandsMaskNone) {
+      // must only be emitted if mask != None + operands are ordered
+      write_operands.emplace_back(operands_mask);
+      for (const auto &id : image_operands) {
+        write_operands.emplace_back(id);
+      }
+    }
+    auto write_sample =
+        BM->addInstTemplate(spv::OpImageWrite, write_operands, BB, nullptr);
+    return {write_sample, write_sample->getOpCode()};
+  } else if (DemangledName.find(kSPIRVName::ImageQuerySize) !=
+             std::string::npos) {
+    std::vector<SPIRVWord> query_operands{loaded_img->getId()};
+
+    // query requires cap
+    BM->addCapability(spv::CapabilityImageQuery);
+
+    // buffer and MSAA images must use the non-LOD variant
+    const auto non_lod_variant =
+        (DemangledName.find("msaa") != std::string::npos ||
+         DemangledName.find("buffer") != std::string::npos);
+
+    auto query_op = spv::OpImageQuerySize;
+    if (!non_lod_variant) {
+      auto lod_arg = transValue(args[1], BB);
+      query_operands.emplace_back(lod_arg->getId());
+      query_op = spv::OpImageQuerySizeLod;
+    }
+
+    // the return type is already correct on the LLVM side, just translate it
+    SPIRVType *ret_type = transType(CI->getType());
+
+    auto img_query =
+        BM->addInstTemplate(query_op, query_operands, BB, ret_type);
+    return {img_query, img_query->getOpCode()};
+  }
+
+  return {nullptr, OpNop};
+}
+
 SPIRVInstruction *
 LLVMToSPIRVBase::transBuiltinToInstWithoutDecoration(Op OC, CallInst *CI,
                                                      SPIRVBasicBlock *BB) {
+  assert(!(SrcLang == spv::SourceLanguageGLSL && isImageOpCode(OC)) &&
+         "should not be here");
+
   if (isGroupOpCode(OC))
     BM->addCapability(CapabilityGroups);
   switch (OC) {
@@ -4497,6 +6740,7 @@ void addPassesForSPIRV(legacy::PassManager &PassMgr,
   PassMgr.add(createOCLTypeToSPIRVLegacy());
   PassMgr.add(createSPIRVLowerOCLBlocksLegacy());
   PassMgr.add(createOCLToSPIRVLegacy());
+  PassMgr.add(createLLVMToSPIRVTransformations());
   PassMgr.add(createSPIRVRegularizeLLVMLegacy());
   PassMgr.add(createSPIRVLowerConstExprLegacy());
   PassMgr.add(createSPIRVLowerBoolLegacy());
@@ -4520,26 +6764,30 @@ bool isValidLLVMModule(Module *M, SPIRVErrorLog &ErrorLog) {
   return true;
 }
 
-bool llvm::writeSpirv(Module *M, std::ostream &OS, std::string &ErrMsg) {
+bool llvm::writeSpirv(Module *M, spv_ostream &OS, std::string &ErrMsg) {
   SPIRV::TranslatorOpts DefaultOpts;
+#if 0 // NOPE
   // To preserve old behavior of the translator, let's enable all extensions
   // by default in this API
   DefaultOpts.enableAllExtensions();
+#endif
   return llvm::writeSpirv(M, DefaultOpts, OS, ErrMsg);
 }
 
 bool llvm::writeSpirv(Module *M, const SPIRV::TranslatorOpts &Opts,
-                      std::ostream &OS, std::string &ErrMsg) {
+                      spv_ostream &OS, std::string &ErrMsg) {
   std::unique_ptr<SPIRVModule> BM(SPIRVModule::createSPIRVModule(Opts));
   if (!isValidLLVMModule(M, BM->getErrorLog()))
     return false;
 
   legacy::PassManager PassMgr;
   addPassesForSPIRV(PassMgr, Opts);
+#if 0 // absolutely DO NOT do this
   // Run loop simplify pass in order to avoid duplicate OpLoopMerge
   // instruction. It can happen in case of continue operand in the loop.
   if (hasLoopMetadata(M))
     PassMgr.add(createLoopSimplifyPass());
+#endif
   PassMgr.add(createLLVMToSPIRVLegacy(BM.get()));
   PassMgr.run(*M);
 
@@ -4551,9 +6799,11 @@ bool llvm::writeSpirv(Module *M, const SPIRV::TranslatorOpts &Opts,
 
 bool llvm::regularizeLlvmForSpirv(Module *M, std::string &ErrMsg) {
   SPIRV::TranslatorOpts DefaultOpts;
+#if 0 // NOPE
   // To preserve old behavior of the translator, let's enable all extensions
   // by default in this API
   DefaultOpts.enableAllExtensions();
+#endif
   return llvm::regularizeLlvmForSpirv(M, ErrMsg, DefaultOpts);
 }
 
diff --git a/lib/SPIRV/SPIRVWriter.h b/lib/SPIRV/SPIRVWriter.h
index 08e23e3..c7f5c78 100644
--- a/lib/SPIRV/SPIRVWriter.h
+++ b/lib/SPIRV/SPIRVWriter.h
@@ -91,6 +91,7 @@ public:
   bool transAlign(Value *V, SPIRVValue *BV);
   std::vector<SPIRVWord> transArguments(CallInst *, SPIRVBasicBlock *,
                                         SPIRVEntry *);
+  bool transVulkanVersion();
   bool transSourceLanguage();
   bool transExtension();
   bool transBuiltinSet();
@@ -132,7 +133,7 @@ public:
                                                        SPIRVInstruction *I);
 
   typedef DenseMap<Type *, SPIRVType *> LLVMToSPIRVTypeMap;
-  typedef DenseMap<Value *, SPIRVValue *> LLVMToSPIRVValueMap;
+  typedef DenseMap<const Value *, SPIRVValue *> LLVMToSPIRVValueMap;
   typedef DenseMap<MDNode *, SmallSet<SPIRVId, 2>> LLVMToSPIRVMetadataMap;
 
   void setOCLTypeToSPIRV(OCLTypeToSPIRVBase *OCLTypeToSPIRV) {
@@ -161,8 +162,15 @@ private:
   bool joinFPContract(Function *F, FPContract C);
   void fpContractUpdateRecursive(Function *F, FPContract FPC);
 
+  // adds a SPIR-V float/int/uint scalar or vector type based on the LLVM type
+  // based on the 'is_signed' signedness - this is different to mapType and
+  // transType, because these won't handle signedness.
+  SPIRVType *addSignPreservingLLVMType(llvm::Type *type,
+                                       const bool is_signed = true);
+
   SPIRVType *mapType(Type *T, SPIRVType *BT);
-  SPIRVValue *mapValue(Value *V, SPIRVValue *BV);
+  SPIRVValue *mapValue(const Value *V, SPIRVValue *BV);
+  SPIRVValue *getSPIRVValue(const Value *V) { return ValueMap[V]; }
   SPIRVType *getSPIRVType(Type *T) { return TypeMap[T]; }
   SPIRVErrorLog &getErrorLog() { return BM->getErrorLog(); }
   llvm::IntegerType *getSizetType(unsigned AS = 0);
@@ -193,7 +201,8 @@ private:
                                SPIRVExtInstSetKind *BuiltinSet = nullptr,
                                SPIRVWord *EntryPoint = nullptr,
                                SmallVectorImpl<std::string> *Dec = nullptr);
-  bool isKernel(Function *F);
+  bool isEntryPoint(Function *F);
+  spv::ExecutionModel getEntryPointType(Function *F, unsigned int SrcLang);
   bool transMetadata();
   bool transOCLMetadata();
   SPIRVInstruction *transBuiltinToInst(StringRef DemangledName, CallInst *CI,
@@ -216,6 +225,48 @@ private:
       const Function *FS,
       const std::unordered_set<const Function *> Funcs) const;
   void collectInputOutputVariables(SPIRVFunction *SF, Function *F);
+
+  void decorateComposite(llvm::Type *llvm_type, SPIRVType *spirv_type);
+
+  bool ignore_next_unreachable{false};
+
+  //
+  struct spirv_global_io_type {
+    bool is_constant{false};
+    bool is_uniform{false};
+    bool is_iub{false};
+    bool is_input{false};
+    bool is_builtin{false};
+    bool is_image{false};
+    bool is_fbo_color{false};
+    bool is_fbo_depth{false};
+    bool is_read_only{false};
+    bool is_write_only{false};
+    bool set_location{false};
+    uint32_t location{0};
+  };
+
+  GlobalVariable *emitShaderGlobal(
+      const Function &F, SPIRVFunction *spirv_func, const std::string &var_name,
+      llvm::Type *llvm_type, uint32_t address_space,
+      const spirv_global_io_type global_type, const std::string &md_info,
+      SPIRVVariable **created_spirv_var = nullptr,
+      spv::BuiltIn builtin = spv::BuiltIn::BuiltInPosition);
+
+  SPIRVVariable *
+  emitShaderSPIRVGlobal(SPIRVFunction *spirv_func, const GlobalVariable &GV,
+                        const std::string &var_name, uint32_t address_space,
+                        const spirv_global_io_type global_type,
+                        const std::string &md_info,
+                        spv::BuiltIn builtin = spv::BuiltIn::BuiltInPosition);
+
+  SPIRVVariable *immutable_samplers{nullptr};
+  std::pair<SPIRVInstruction *, Op>
+  transVulkanImageFunction(CallInst *CI, SPIRVBasicBlock *BB,
+                           const std::string &DemangledName);
+
+  // function image arg -> image type map
+  std::unordered_map<const llvm::Value *, SPIRVType *> image_type_map;
 };
 
 class LLVMToSPIRVPass : public PassInfoMixin<LLVMToSPIRVPass>,
diff --git a/lib/SPIRV/SPIRVWriterPass.cpp b/lib/SPIRV/SPIRVWriterPass.cpp
index 4e211d0..139d147 100644
--- a/lib/SPIRV/SPIRVWriterPass.cpp
+++ b/lib/SPIRV/SPIRVWriterPass.cpp
@@ -18,7 +18,7 @@
 #include "llvm/Pass.h"
 using namespace llvm;
 
-PreservedAnalyses SPIRVWriterPass::run(Module &M) {
+PreservedAnalyses SPIRVWriterPass::run(Module &M, ModuleAnalysisManager&) {
   // FIXME: at the moment LLVM/SPIR-V translation errors are ignored.
   std::string Err;
   writeSpirv(&M, Opts, OS, Err);
@@ -27,12 +27,12 @@ PreservedAnalyses SPIRVWriterPass::run(Module &M) {
 
 namespace {
 class WriteSPIRVPass : public ModulePass {
-  std::ostream &OS; // std::ostream to print on
+  raw_ostream& OS; // std::ostream to print on
   SPIRV::TranslatorOpts Opts;
 
 public:
   static char ID; // Pass identification, replacement for typeid
-  WriteSPIRVPass(std::ostream &OS, const SPIRV::TranslatorOpts &Opts)
+  WriteSPIRVPass(raw_ostream &OS, const SPIRV::TranslatorOpts &Opts)
       : ModulePass(ID), OS(OS), Opts(Opts) {}
 
   StringRef getPassName() const override { return "SPIRV Writer"; }
@@ -48,15 +48,17 @@ public:
 
 char WriteSPIRVPass::ID = 0;
 
-ModulePass *llvm::createSPIRVWriterPass(std::ostream &Str) {
+ModulePass *llvm::createSPIRVWriterPass(raw_ostream &Str) {
   SPIRV::TranslatorOpts DefaultOpts;
+#if 0 // NOPE
   // To preserve old behavior of the translator, let's enable all extensions
   // by default in this API
   DefaultOpts.enableAllExtensions();
+#endif
   return createSPIRVWriterPass(Str, DefaultOpts);
 }
 
-ModulePass *llvm::createSPIRVWriterPass(std::ostream &Str,
+ModulePass *llvm::createSPIRVWriterPass(raw_ostream &Str,
                                         const SPIRV::TranslatorOpts &Opts) {
   return new WriteSPIRVPass(Str, Opts);
 }
diff --git a/lib/SPIRV/SPIRVWriterPass.h b/lib/SPIRV/SPIRVWriterPass.h
index fe80217..bc5a719 100644
--- a/lib/SPIRV/SPIRVWriterPass.h
+++ b/lib/SPIRV/SPIRVWriterPass.h
@@ -15,8 +15,9 @@
 #ifndef SPIRV_SPIRVWRITERPASS_H
 #define SPIRV_SPIRVWRITERPASS_H
 
-#include "LLVMSPIRVOpts.h"
+#include "llvm/../../projects/spirv/include/LLVMSPIRVOpts.h"
 #include "llvm/ADT/StringRef.h"
+#include "llvm/IR/PassManager.h"
 
 namespace llvm {
 class Module;
@@ -26,33 +27,35 @@ class PreservedAnalyses;
 /// \brief Create and return a pass that writes the module to the specified
 /// ostream. Note that this pass is designed for use with the legacy pass
 /// manager.
-ModulePass *createSPIRVWriterPass(std::ostream &Str);
+ModulePass *createSPIRVWriterPass(raw_ostream &Str);
 
 /// \brief Create and return a pass that writes the module to the specified
 /// ostream. Note that this pass is designed for use with the legacy pass
 /// manager.
-ModulePass *createSPIRVWriterPass(std::ostream &Str,
+ModulePass *createSPIRVWriterPass(raw_ostream &Str,
                                   const SPIRV::TranslatorOpts &Opts);
 
 /// \brief Pass for writing a module of IR out to a SPIRV file.
 ///
 /// Note that this is intended for use with the new pass manager. To construct
 /// a pass for the legacy pass manager, use the function above.
-class SPIRVWriterPass {
-  std::ostream &OS;
+class SPIRVWriterPass : public PassInfoMixin<SPIRVWriterPass> {
+  raw_ostream& OS;
   SPIRV::TranslatorOpts Opts;
 
 public:
   /// \brief Construct a SPIRV writer pass around a particular output stream.
-  explicit SPIRVWriterPass(std::ostream &OS) : OS(OS) {
+  explicit SPIRVWriterPass(raw_ostream &OS) : OS(OS) {
+#if 0 // NOPE
     Opts.enableAllExtensions();
+#endif
   }
-  SPIRVWriterPass(std::ostream &OS, const SPIRV::TranslatorOpts &Opts)
+  SPIRVWriterPass(raw_ostream &OS, const SPIRV::TranslatorOpts &Opts)
       : OS(OS), Opts(Opts) {}
 
   /// \brief Run the SPIRV writer pass, and output the module to the selected
   /// output stream.
-  PreservedAnalyses run(Module &M);
+  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);
 
   static StringRef name() { return "SPIRVWriterPass"; }
 };
diff --git a/lib/SPIRV/libSPIRV/GLSL.std.450.h b/lib/SPIRV/libSPIRV/GLSL.std.450.h
new file mode 100644
index 0000000..9ca739f
--- /dev/null
+++ b/lib/SPIRV/libSPIRV/GLSL.std.450.h
@@ -0,0 +1,135 @@
+/*
+** Copyright (c) 2014-2016 The Khronos Group Inc.
+**
+** Permission is hereby granted, free of charge, to any person obtaining a copy
+** of this software and/or associated documentation files (the "Materials"),
+** to deal in the Materials without restriction, including without limitation
+** the rights to use, copy, modify, merge, publish, distribute, sublicense,
+** and/or sell copies of the Materials, and to permit persons to whom the
+** Materials are furnished to do so, subject to the following conditions:
+**
+** The above copyright notice and this permission notice shall be included in
+** all copies or substantial portions of the Materials.
+**
+** MODIFICATIONS TO THIS FILE MAY MEAN IT NO LONGER ACCURATELY REFLECTS KHRONOS
+** STANDARDS. THE UNMODIFIED, NORMATIVE VERSIONS OF KHRONOS SPECIFICATIONS AND
+** HEADER INFORMATION ARE LOCATED AT https://www.khronos.org/registry/ 
+**
+** THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+** FROM,OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS
+** IN THE MATERIALS.
+*/
+
+#ifndef GLSLstd450_H
+#define GLSLstd450_H
+
+namespace GLSLLIB {
+
+static const int GLSLstd450Version = 100;
+static const int GLSLstd450Revision = 3;
+
+enum GLSLstd450 {
+ Bad = 0,              // Don't use
+
+ Round = 1,
+ RoundEven = 2,
+ Trunc = 3,
+ FAbs = 4,
+ SAbs = 5,
+ FSign = 6,
+ SSign = 7,
+ Floor = 8,
+ Ceil = 9,
+ Fract = 10,
+
+ Radians = 11,
+ Degrees = 12,
+ Sin = 13,
+ Cos = 14,
+ Tan = 15,
+ Asin = 16,
+ Acos = 17,
+ Atan = 18,
+ Sinh = 19,
+ Cosh = 20,
+ Tanh = 21,
+ Asinh = 22,
+ Acosh = 23,
+ Atanh = 24,
+ Atan2 = 25,
+
+ Pow = 26,
+ Exp = 27,
+ Log = 28,
+ Exp2 = 29,
+ Log2 = 30,
+ Sqrt = 31,
+ InverseSqrt = 32,
+
+ Determinant = 33,
+ MatrixInverse = 34,
+
+ Modf = 35,            // second operand needs an OpVariable to write to
+ ModfStruct = 36,      // no OpVariable operand
+ FMin = 37,
+ UMin = 38,
+ SMin = 39,
+ FMax = 40,
+ UMax = 41,
+ SMax = 42,
+ FClamp = 43,
+ UClamp = 44,
+ SClamp = 45,
+ FMix = 46,
+ IMix = 47,            // Reserved
+ Step = 48,
+ SmoothStep = 49,
+
+ Fma = 50,
+ Frexp = 51,            // second operand needs an OpVariable to write to
+ FrexpStruct = 52,      // no OpVariable operand
+ Ldexp = 53,
+
+ PackSnorm4x8 = 54,
+ PackUnorm4x8 = 55,
+ PackSnorm2x16 = 56,
+ PackUnorm2x16 = 57,
+ PackHalf2x16 = 58,
+ PackDouble2x32 = 59,
+ UnpackSnorm2x16 = 60,
+ UnpackUnorm2x16 = 61,
+ UnpackHalf2x16 = 62,
+ UnpackSnorm4x8 = 63,
+ UnpackUnorm4x8 = 64,
+ UnpackDouble2x32 = 65,
+
+ Length = 66,
+ Distance = 67,
+ Cross = 68,
+ Normalize = 69,
+ FaceForward = 70,
+ Reflect = 71,
+ Refract = 72,
+
+ FindILsb = 73,
+ FindSMsb = 74,
+ FindUMsb = 75,
+
+ InterpolateAtCentroid = 76,
+ InterpolateAtSample = 77,
+ InterpolateAtOffset = 78,
+
+ NMin = 79,
+ NMax = 80,
+ NClamp = 81,
+
+ Count
+};
+
+} // namespace GLSLLIB
+
+#endif  // #ifndef GLSLstd450_H
diff --git a/lib/SPIRV/libSPIRV/SPIRVDebug.h b/lib/SPIRV/libSPIRV/SPIRVDebug.h
index 4337c75..ba5dba9 100644
--- a/lib/SPIRV/libSPIRV/SPIRVDebug.h
+++ b/lib/SPIRV/libSPIRV/SPIRVDebug.h
@@ -79,9 +79,15 @@ void verifyRegularizationPass(llvm::Module &, const std::string &);
   }
 
 // Output stream for SPIRV debug information.
+#if 1
+inline spv_ostream &spvdbgs() {
+  return llvm::errs();
+}
+#else
 inline spv_ostream &spvdbgs() {
   return std::cerr;
 }
+#endif
 
 #else
 
diff --git a/lib/SPIRV/libSPIRV/SPIRVEntry.cpp b/lib/SPIRV/libSPIRV/SPIRVEntry.cpp
index 443b5a8..af45d7c 100644
--- a/lib/SPIRV/libSPIRV/SPIRVEntry.cpp
+++ b/lib/SPIRV/libSPIRV/SPIRVEntry.cpp
@@ -193,14 +193,15 @@ void SPIRVEntry::encodeAll(spv_ostream &O) const {
 void SPIRVEntry::encodeChildren(spv_ostream &O) const {}
 
 void SPIRVEntry::encodeWordCountOpCode(spv_ostream &O) const {
+  const Op enc_op = (OpCode == spv::internal::OpUndefValueInternal ? OpUndef : OpCode);
 #ifdef _SPIRV_SUPPORT_TEXT_FMT
   if (SPIRVUseTextFormat) {
-    getEncoder(O) << WordCount << OpCode;
+    getEncoder(O) << WordCount << enc_op;
     return;
   }
 #endif
   assert(WordCount < 65536 && "WordCount must fit into 16-bit value");
-  SPIRVWord WordCountOpCode = (WordCount << WordCountShift) | OpCode;
+  SPIRVWord WordCountOpCode = (WordCount << WordCountShift) | enc_op;
   getEncoder(O) << WordCountOpCode;
 }
 // Read words from SPIRV binary and create members for SPIRVEntry.
@@ -254,6 +255,30 @@ void SPIRVEntry::validateBuiltin(SPIRVWord TheSet, SPIRVWord Index) const {
 
 void SPIRVEntry::addDecorate(SPIRVDecorate *Dec) {
   auto Kind = Dec->getDecorateKind();
+
+  // ensure added decorates are unique
+  if (!Decorates.empty() && Dec->getOpCode() == OpDecorate) {
+    auto kind_range = Decorates.equal_range(Kind);
+    if (kind_range.first != Decorates.end()) {
+      for (auto kind_iter = kind_range.first; kind_iter != kind_range.second; ++kind_iter) {
+        if (kind_iter->second->getTargetId() == Dec->getTargetId() &&
+          kind_iter->second->getOpCode() == OpDecorate &&
+          kind_iter->second->getLiteralCount() == Dec->getLiteralCount()) {
+          bool equal_lits = true;
+          for (uint32_t lit_idx = 0, lit_count = kind_iter->second->getLiteralCount(); lit_idx < lit_count; ++lit_idx) {
+            if (kind_iter->second->getLiteral(lit_idx) != Dec->getLiteral(lit_idx)) {
+              equal_lits = false;
+              break;
+            }
+          }
+          if (equal_lits) {
+            return;
+          }
+        }
+      }
+    }
+  }
+
   Decorates.insert(std::make_pair(Kind, Dec));
   Module->addDecorate(Dec);
   if (Kind == spv::DecorationLinkageAttributes) {
diff --git a/lib/SPIRV/libSPIRV/SPIRVEntry.h b/lib/SPIRV/libSPIRV/SPIRVEntry.h
index 2c6f5ca..4ba71d1 100644
--- a/lib/SPIRV/libSPIRV/SPIRVEntry.h
+++ b/lib/SPIRV/libSPIRV/SPIRVEntry.h
@@ -330,7 +330,7 @@ public:
   bool isMemberDecorate() const { return OpCode == OpMemberDecorate; }
   bool isForward() const { return OpCode == internal::OpForward; }
   bool isLabel() const { return OpCode == OpLabel; }
-  bool isUndef() const { return OpCode == OpUndef; }
+  bool isUndef() const { return OpCode == OpUndef || OpCode == internal::OpUndefValueInternal; }
   bool isControlBarrier() const { return OpCode == OpControlBarrier; }
   bool isMemoryBarrier() const { return OpCode == OpMemoryBarrier; }
   bool isVariable() const { return OpCode == OpVariable; }
@@ -428,11 +428,13 @@ protected:
   bool canHaveMemberDecorates() const {
     return OpCode == OpTypeStruct || OpCode == internal::OpForward;
   }
+public:
   MemberDecorateMapType &getMemberDecorates() {
     assert(canHaveMemberDecorates());
     return MemberDecorates;
   }
 
+protected:
   void updateModuleVersion() const;
 
   SPIRVModule *Module;
@@ -984,16 +986,12 @@ private:
 #define _SPIRV_OP(x) typedef SPIRVEntryUnimplemented<Op##x> SPIRV##x;
 _SPIRV_OP(Nop)
 _SPIRV_OP(SourceContinued)
-_SPIRV_OP(TypeRuntimeArray)
 _SPIRV_OP(Image)
 _SPIRV_OP(ImageTexelPointer)
-_SPIRV_OP(ImageSampleDrefImplicitLod)
-_SPIRV_OP(ImageSampleDrefExplicitLod)
 _SPIRV_OP(ImageSampleProjImplicitLod)
 _SPIRV_OP(ImageSampleProjExplicitLod)
 _SPIRV_OP(ImageSampleProjDrefImplicitLod)
 _SPIRV_OP(ImageSampleProjDrefExplicitLod)
-_SPIRV_OP(ImageFetch)
 _SPIRV_OP(ImageGather)
 _SPIRV_OP(ImageDrefGather)
 _SPIRV_OP(QuantizeToF16)
@@ -1003,20 +1001,10 @@ _SPIRV_OP(IAddCarry)
 _SPIRV_OP(ISubBorrow)
 _SPIRV_OP(SMulExtended)
 _SPIRV_OP(UMulExtended)
-_SPIRV_OP(DPdx)
-_SPIRV_OP(DPdy)
-_SPIRV_OP(Fwidth)
-_SPIRV_OP(DPdxFine)
-_SPIRV_OP(DPdyFine)
-_SPIRV_OP(FwidthFine)
-_SPIRV_OP(DPdxCoarse)
-_SPIRV_OP(DPdyCoarse)
-_SPIRV_OP(FwidthCoarse)
 _SPIRV_OP(EmitVertex)
 _SPIRV_OP(EndPrimitive)
 _SPIRV_OP(EmitStreamVertex)
 _SPIRV_OP(EndStreamPrimitive)
-_SPIRV_OP(Kill)
 _SPIRV_OP(ImageSparseSampleImplicitLod)
 _SPIRV_OP(ImageSparseSampleExplicitLod)
 _SPIRV_OP(ImageSparseSampleDrefImplicitLod)
diff --git a/lib/SPIRV/libSPIRV/SPIRVEnum.h b/lib/SPIRV/libSPIRV/SPIRVEnum.h
index 9bf34c1..d1eab68 100644
--- a/lib/SPIRV/libSPIRV/SPIRVEnum.h
+++ b/lib/SPIRV/libSPIRV/SPIRVEnum.h
@@ -78,6 +78,7 @@ enum SPIRVExtInstSetKind {
   SPIRVEIS_OpenCL,
   SPIRVEIS_Debug,
   SPIRVEIS_OpenCL_DebugInfo_100,
+  SPIRVEIS_GLSL,
   SPIRVEIS_Count,
 };
 
@@ -129,6 +130,7 @@ template <> inline void SPIRVMap<SPIRVExtInstSetKind, std::string>::init() {
   add(SPIRVEIS_OpenCL, "OpenCL.std");
   add(SPIRVEIS_Debug, "SPIRV.debug");
   add(SPIRVEIS_OpenCL_DebugInfo_100, "OpenCL.DebugInfo.100");
+  add(SPIRVEIS_GLSL, "GLSL.std.450");
 }
 typedef SPIRVMap<SPIRVExtInstSetKind, std::string> SPIRVBuiltinSetNameMap;
 
@@ -175,7 +177,6 @@ template <> inline void SPIRVMap<SPIRVCapabilityKind, SPIRVCapVec>::init() {
   ADD_VEC_INIT(CapabilityImageRect, {CapabilitySampledRect});
   ADD_VEC_INIT(CapabilitySampledRect, {CapabilityShader});
   ADD_VEC_INIT(CapabilityGenericPointer, {CapabilityAddresses});
-  ADD_VEC_INIT(CapabilityInt8, {CapabilityKernel});
   ADD_VEC_INIT(CapabilityInputAttachment, {CapabilityShader});
   ADD_VEC_INIT(CapabilitySparseResidency, {CapabilityShader});
   ADD_VEC_INIT(CapabilityMinLod, {CapabilityShader});
@@ -197,6 +198,7 @@ template <> inline void SPIRVMap<SPIRVCapabilityKind, SPIRVCapVec>::init() {
                {CapabilitySubgroupAvcMotionEstimationINTEL});
   ADD_VEC_INIT(CapabilitySubgroupAvcMotionEstimationChromaINTEL,
                {CapabilitySubgroupAvcMotionEstimationIntraINTEL});
+  ADD_VEC_INIT(CapabilityMultiView, {CapabilityShader});
 }
 
 template <> inline void SPIRVMap<SPIRVExecutionModelKind, SPIRVCapVec>::init() {
@@ -341,7 +343,9 @@ template <> inline void SPIRVMap<ImageOperandsMask, SPIRVCapVec>::init() {
 
 template <> inline void SPIRVMap<Decoration, SPIRVCapVec>::init() {
   ADD_VEC_INIT(DecorationRelaxedPrecision, {CapabilityShader});
+#if 0 // both Kernel and Shader are valid, but either will already be specified
   ADD_VEC_INIT(DecorationSpecId, {CapabilityKernel});
+#endif
   ADD_VEC_INIT(DecorationBlock, {CapabilityShader});
   ADD_VEC_INIT(DecorationBufferBlock, {CapabilityShader});
   ADD_VEC_INIT(DecorationRowMajor, {CapabilityMatrix});
@@ -474,12 +478,18 @@ template <> inline void SPIRVMap<BuiltIn, SPIRVCapVec>::init() {
   ADD_VEC_INIT(BuiltInEnqueuedWorkgroupSize, {CapabilityKernel});
   ADD_VEC_INIT(BuiltInGlobalOffset, {CapabilityKernel});
   ADD_VEC_INIT(BuiltInGlobalLinearId, {CapabilityKernel});
+#if 0 // both Kernel and Shader
   ADD_VEC_INIT(BuiltInSubgroupSize, {CapabilityKernel});
+#endif
   ADD_VEC_INIT(BuiltInSubgroupMaxSize, {CapabilityKernel});
+#if 0 // both Kernel and Shader
   ADD_VEC_INIT(BuiltInNumSubgroups, {CapabilityKernel});
+#endif
   ADD_VEC_INIT(BuiltInNumEnqueuedSubgroups, {CapabilityKernel});
+#if 0 // both Kernel and Shader
   ADD_VEC_INIT(BuiltInSubgroupId, {CapabilityKernel});
   ADD_VEC_INIT(BuiltInSubgroupLocalInvocationId, {CapabilityKernel});
+#endif
   ADD_VEC_INIT(BuiltInSubgroupEqMask, {CapabilityGroupNonUniformBallot});
   ADD_VEC_INIT(BuiltInSubgroupGeMask, {CapabilityGroupNonUniformBallot});
   ADD_VEC_INIT(BuiltInSubgroupGtMask, {CapabilityGroupNonUniformBallot});
@@ -493,6 +503,7 @@ template <> inline void SPIRVMap<BuiltIn, SPIRVCapVec>::init() {
                {internal::CapabilityHWThreadQueryINTEL});
   ADD_VEC_INIT(internal::BuiltInMaxHWThreadIDPerSubDeviceINTEL,
                {internal::CapabilityHWThreadQueryINTEL});
+  ADD_VEC_INIT(BuiltInViewIndex, {CapabilityMultiView});
 }
 
 template <> inline void SPIRVMap<MemorySemanticsMask, SPIRVCapVec>::init() {
diff --git a/lib/SPIRV/libSPIRV/SPIRVExtInst.h b/lib/SPIRV/libSPIRV/SPIRVExtInst.h
index 9f1aa91..232b6d3 100644
--- a/lib/SPIRV/libSPIRV/SPIRVExtInst.h
+++ b/lib/SPIRV/libSPIRV/SPIRVExtInst.h
@@ -42,6 +42,7 @@
 
 #include "OpenCL.std.h"
 #include "SPIRV.debug.h"
+#include "GLSL.std.450.h"
 #include "SPIRVEnum.h"
 #include "SPIRVUtil.h"
 
@@ -259,6 +260,92 @@ template <> inline void SPIRVMap<SPIRVDebugExtOpKind, std::string>::init() {
 }
 SPIRV_DEF_NAMEMAP(SPIRVDebugExtOpKind, SPIRVDebugExtOpMap)
 
+typedef GLSLLIB::GLSLstd450 GLSLExtOpKind;
+template <> inline void SPIRVMap<GLSLExtOpKind, std::string>::init() {
+  add(GLSLLIB::Acos, "acos");
+  add(GLSLLIB::Acosh, "acosh");
+  add(GLSLLIB::Asin, "asin");
+  add(GLSLLIB::Asinh, "asinh");
+  add(GLSLLIB::Atan, "atan");
+  add(GLSLLIB::Atan2, "atan2");
+  add(GLSLLIB::Atanh, "atanh");
+  add(GLSLLIB::Ceil, "ceil");
+  add(GLSLLIB::Cos, "cos");
+  add(GLSLLIB::Cosh, "cosh");
+  add(GLSLLIB::Cross, "cross");
+  add(GLSLLIB::Degrees, "degrees");
+  add(GLSLLIB::Determinant, "determinant");
+  add(GLSLLIB::Distance, "distance");
+  add(GLSLLIB::Exp, "exp");
+  add(GLSLLIB::Exp2, "exp2");
+  add(GLSLLIB::FAbs, "fabs");
+  add(GLSLLIB::FaceForward, "face_forward");
+  add(GLSLLIB::FClamp, "fclamp");
+  add(GLSLLIB::FindILsb, "find_ilsb");
+  add(GLSLLIB::FindSMsb, "find_smsb");
+  add(GLSLLIB::FindUMsb, "find_umsb");
+  add(GLSLLIB::Floor, "floor");
+  add(GLSLLIB::Fma, "fma");
+  add(GLSLLIB::FMax, "fmax");
+  add(GLSLLIB::FMin, "fmin");
+  add(GLSLLIB::FMix, "fmix");
+  add(GLSLLIB::Fract, "fract");
+  add(GLSLLIB::Frexp, "frexp");
+  add(GLSLLIB::FrexpStruct, "frexp_struct");
+  add(GLSLLIB::FSign, "fsign");
+  add(GLSLLIB::IMix, "imix");
+  add(GLSLLIB::InterpolateAtCentroid, "interpolate_at_centroid");
+  add(GLSLLIB::InterpolateAtOffset, "interpolate_at_offset");
+  add(GLSLLIB::InterpolateAtSample, "interpolate_at_sample");
+  add(GLSLLIB::InverseSqrt, "rsqrt");
+  add(GLSLLIB::Ldexp, "ldexp");
+  add(GLSLLIB::Length, "length");
+  add(GLSLLIB::Log, "log");
+  add(GLSLLIB::Log2, "log2");
+  add(GLSLLIB::MatrixInverse, "matrix_inverse");
+  add(GLSLLIB::Modf, "modf");
+  add(GLSLLIB::ModfStruct, "modf_struct");
+  add(GLSLLIB::NClamp, "nclamp");
+  add(GLSLLIB::NMax, "nmax");
+  add(GLSLLIB::NMin, "nmin");
+  add(GLSLLIB::Normalize, "normalize");
+  add(GLSLLIB::PackDouble2x32, "pack_double_2x32");
+  add(GLSLLIB::PackHalf2x16, "pack_half_2x16");
+  add(GLSLLIB::PackSnorm2x16, "pack_snorm_2x16");
+  add(GLSLLIB::PackSnorm4x8, "pack_snorm4x8");
+  add(GLSLLIB::PackUnorm2x16, "pack_unorm_2x16");
+  add(GLSLLIB::PackUnorm4x8, "pack_unorm_4x8");
+  add(GLSLLIB::Pow, "pow");
+  add(GLSLLIB::Radians, "radians");
+  add(GLSLLIB::Reflect, "reflect");
+  add(GLSLLIB::Refract, "refract");
+  add(GLSLLIB::Round, "round");
+  add(GLSLLIB::RoundEven, "round_even");
+  add(GLSLLIB::SAbs, "s_abs");
+  add(GLSLLIB::SClamp, "s_clamp");
+  add(GLSLLIB::Sin, "sin");
+  add(GLSLLIB::Sinh, "sinh");
+  add(GLSLLIB::SMax, "s_max");
+  add(GLSLLIB::SMin, "s_min");
+  add(GLSLLIB::SmoothStep, "smoothstep");
+  add(GLSLLIB::Sqrt, "sqrt");
+  add(GLSLLIB::SSign, "s_sign");
+  add(GLSLLIB::Step, "step");
+  add(GLSLLIB::Tan, "tan");
+  add(GLSLLIB::Tanh, "tanh");
+  add(GLSLLIB::Trunc, "trunc");
+  add(GLSLLIB::UClamp, "u_clamp");
+  add(GLSLLIB::UMax, "u_max");
+  add(GLSLLIB::UMin, "u_min");
+  add(GLSLLIB::UnpackDouble2x32, "unpack_double_2x32");
+  add(GLSLLIB::UnpackHalf2x16, "unpack_half_2x16");
+  add(GLSLLIB::UnpackSnorm2x16, "unpack_snorm_2x16");
+  add(GLSLLIB::UnpackSnorm4x8, "unpack_snorm_4x8");
+  add(GLSLLIB::UnpackUnorm2x16, "unpack_unorm_2x16");
+  add(GLSLLIB::UnpackUnorm4x8, "unpack_unorm_4x8");
+}
+SPIRV_DEF_NAMEMAP(GLSLExtOpKind, GLSLExtOpMap)
+
 } // namespace SPIRV
 
 #endif // SPIRV_LIBSPIRV_SPIRVEXTINST_H
diff --git a/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp b/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp
index b3d2666..d2c4746 100644
--- a/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp
+++ b/lib/SPIRV/libSPIRV/SPIRVInstruction.cpp
@@ -44,6 +44,8 @@
 #include <unordered_set>
 
 namespace SPIRV {
+std::vector<Capability> SPIRVImageInstBase::image_caps;
+std::vector<Capability> SPIRVImageQueryInstBase::image_query_caps;
 
 // Complete constructor for instruction with type and id
 SPIRVInstruction::SPIRVInstruction(unsigned TheWordCount, Op TheOC,
diff --git a/lib/SPIRV/libSPIRV/SPIRVInstruction.h b/lib/SPIRV/libSPIRV/SPIRVInstruction.h
index 2c47e49..0451035 100644
--- a/lib/SPIRV/libSPIRV/SPIRVInstruction.h
+++ b/lib/SPIRV/libSPIRV/SPIRVInstruction.h
@@ -154,6 +154,20 @@ public:
     return hasDecorate(DecorationSaturatedConversion) ||
            OpCode == OpSatConvertSToU || OpCode == OpSatConvertUToS;
   }
+  bool isTerminationInstruction() const {
+    switch (OpCode) {
+      case OpBranch:
+      case OpBranchConditional:
+      case OpSwitch:
+      case OpReturn:
+      case OpReturnValue:
+      case OpKill:
+      case OpUnreachable:
+        return true;
+      default: break;
+    }
+    return false;
+  }
 
   SPIRVBasicBlock *getBasicBlock() const { return BB; }
 
@@ -294,8 +308,11 @@ public:
   /// Get operand as value.
   /// If the operand is a literal, return it as a uint32 constant.
   SPIRVValue *getOpValue(int I) {
-    return isOperandLiteral(I) ? Module->getLiteralAsConstant(Ops[I])
-                               : getValue(Ops[I]);
+    return isOperandLiteral(I)
+               ? Module->getLiteralAsConstant(
+                     Ops[I], Module->getSourceLanguage(nullptr) ==
+                                 spv::SourceLanguageGLSL)
+               : getValue(Ops[I]);
   }
 
   std::vector<SPIRVValue *> getOperands() override {
@@ -707,6 +724,7 @@ protected:
 
 typedef SPIRVInstNoOperand<OpReturn> SPIRVReturn;
 typedef SPIRVInstNoOperand<OpUnreachable> SPIRVUnreachable;
+typedef SPIRVInstNoOperand<OpKill> SPIRVKill;
 
 class SPIRVReturnValue : public SPIRVInstruction {
 public:
@@ -971,6 +989,22 @@ _SPIRV_OP(Ordered)
 _SPIRV_OP(Unordered)
 #undef _SPIRV_OP
 
+class SPIRVUndefValueInternal : public SPIRVInstruction {
+public:
+  static const Op OC = internal::OpUndefValueInternal;
+  static const SPIRVWord FixedWordCount = 3;
+
+  SPIRVUndefValueInternal(SPIRVType *TheType, SPIRVId TheId, SPIRVBasicBlock *BB)
+      : SPIRVInstruction(3, OC, TheType, TheId, BB) {
+    validate();
+    assert(BB && "Invalid BB");
+  }
+  // Incomplete constructor
+	SPIRVUndefValueInternal() { validate(); }
+
+  _SPIRV_DEF_ENCDEC2(Type, Id)
+};
+
 class SPIRVSelectBase : public SPIRVInstTemplateBase {
 public:
   SPIRVValue *getCondition() { return getValue(Ops[0]); }
@@ -1560,6 +1594,38 @@ _SPIRV_OP(BitCount)
 _SPIRV_OP_INTERNAL(ArithmeticFenceINTEL)
 #undef _SPIRV_OP_INTERNAL
 
+template <Op OC_> class SPIRVDerivativeInst : public SPIRVInstruction {
+public:
+  const static Op OC = OC_;
+  // Complete constructor
+  SPIRVDerivativeInst(SPIRVId TheId, SPIRVValue *PVal, SPIRVBasicBlock *TheBB)
+      : SPIRVInstruction(4, OC, PVal->getType(), TheId, TheBB),
+        PId(PVal->getId()) {
+    validate();
+    assert(TheBB && "Invalid BB");
+  }
+  // Incomplete constructor
+  SPIRVDerivativeInst() : SPIRVInstruction(OC), PId(SPIRVID_INVALID) {}
+
+  _SPIRV_DEF_ENCDEC3(Type, Id, PId)
+
+protected:
+  void validate() const override { SPIRVInstruction::validate(); }
+  SPIRVId PId;
+};
+
+#define _SPIRV_OP(x) typedef SPIRVDerivativeInst<Op##x> SPIRV##x;
+_SPIRV_OP(DPdx)
+_SPIRV_OP(DPdy)
+_SPIRV_OP(Fwidth)
+_SPIRV_OP(DPdxFine)
+_SPIRV_OP(DPdyFine)
+_SPIRV_OP(FwidthFine)
+_SPIRV_OP(DPdxCoarse)
+_SPIRV_OP(DPdyCoarse)
+_SPIRV_OP(FwidthCoarse)
+#undef _SPIRV_OP
+
 class SPIRVAccessChainBase : public SPIRVInstTemplateBase {
 public:
   SPIRVValue *getBase() { return this->getValue(this->Ops[0]); }
@@ -1761,7 +1827,7 @@ public:
     assert(Module && "Invalid module");
     ExtSetKind = Module->getBuiltinSet(ExtSetId);
     assert((ExtSetKind == SPIRVEIS_OpenCL || ExtSetKind == SPIRVEIS_Debug ||
-            ExtSetKind == SPIRVEIS_OpenCL_DebugInfo_100) &&
+            ExtSetKind == SPIRVEIS_OpenCL_DebugInfo_100 || ExtSetKind == SPIRVEIS_GLSL) &&
            "not supported");
   }
   void encode(spv_ostream &O) const override {
@@ -1774,6 +1840,9 @@ public:
     case SPIRVEIS_OpenCL_DebugInfo_100:
       getEncoder(O) << ExtOpDebug;
       break;
+    case SPIRVEIS_GLSL:
+      getEncoder(O) << ExtOpGLSL;
+      break;
     default:
       assert(0 && "not supported");
       getEncoder(O) << ExtOp;
@@ -1791,6 +1860,9 @@ public:
     case SPIRVEIS_OpenCL_DebugInfo_100:
       getDecoder(I) >> ExtOpDebug;
       break;
+    case SPIRVEIS_GLSL:
+      getDecoder(I) >> ExtOpGLSL;
+      break;
     default:
       assert(0 && "not supported");
       getDecoder(I) >> ExtOp;
@@ -1802,27 +1874,35 @@ public:
     validateBuiltin(ExtSetId, ExtOp);
   }
   bool isOperandLiteral(unsigned Index) const override {
-    assert(ExtSetKind == SPIRVEIS_OpenCL &&
+    assert((ExtSetKind == SPIRVEIS_OpenCL || ExtSetKind == SPIRVEIS_GLSL) &&
            "Unsupported extended instruction set");
-    auto EOC = static_cast<OCLExtOpKind>(ExtOp);
-    switch (EOC) {
-    default:
-      return false;
-    case OpenCLLIB::Vloadn:
-    case OpenCLLIB::Vload_halfn:
-    case OpenCLLIB::Vloada_halfn:
-      return Index == 2;
-    case OpenCLLIB::Vstore_half_r:
-    case OpenCLLIB::Vstore_halfn_r:
-    case OpenCLLIB::Vstorea_halfn_r:
-      return Index == 3;
+    if (ExtSetKind == SPIRVEIS_OpenCL) {
+      auto EOC = static_cast<OCLExtOpKind>(ExtOp);
+      switch (EOC) {
+      default:
+        return false;
+      case OpenCLLIB::Vloadn:
+      case OpenCLLIB::Vload_halfn:
+      case OpenCLLIB::Vloada_halfn:
+        return Index == 2;
+      case OpenCLLIB::Vstore_half_r:
+      case OpenCLLIB::Vstore_halfn_r:
+      case OpenCLLIB::Vstorea_halfn_r:
+        return Index == 3;
+      }
+    } else {
+      auto EGLSL = static_cast<GLSLExtOpKind>(ExtOp);
+      switch (EGLSL) { // TODO: necessary?
+      default:
+        return false;
+      }
     }
   }
   std::vector<SPIRVValue *> getArgValues() {
     std::vector<SPIRVValue *> VArgs;
     for (size_t I = 0; I < Args.size(); ++I) {
       if (isOperandLiteral(I))
-        VArgs.push_back(Module->getLiteralAsConstant(Args[I]));
+        VArgs.push_back(Module->getLiteralAsConstant(Args[I], false));
       else
         VArgs.push_back(getValue(Args[I]));
     }
@@ -1843,6 +1923,7 @@ protected:
     SPIRVWord ExtOp;
     OCLExtOpKind ExtOpOCL;
     SPIRVDebugExtOpKind ExtOpDebug;
+    GLSLExtOpKind ExtOpGLSL;
   };
 };
 
@@ -1875,6 +1956,7 @@ protected:
   _SPIRV_DEF_ENCDEC3(Type, Id, Constituents)
   void validate() const override {
     SPIRVInstruction::validate();
+#if 0 // this doesn't work when no entry for "getId()/Id" exists yet
     switch (getValueType(this->getId())->getOpCode()) {
     case OpTypeVector:
       assert(getConstituents().size() > 1 &&
@@ -1886,6 +1968,10 @@ protected:
     default:
       assert(false && "Invalid type");
     }
+#else // -> use type directly instead
+    assert(Type->isTypeArray() || Type->isTypeStruct() || Type->isTypeVector());
+    assert(!Type->isTypeVector() || (Type->isTypeVector() && getConstituents().size() > 1));
+#endif
   }
   std::vector<SPIRVId> Constituents;
 };
@@ -2008,10 +2094,12 @@ protected:
   }
 
   void validate() const override {
+#if 0 // OpCopyMemory doesn't have an ID!
     assert((getValueType(Id) == getValueType(Source)) && "Inconsistent type");
     assert(getValueType(Id)->isTypePointer() && "Invalid type");
     assert(!(getValueType(Id)->getPointerElementType()->isTypeVoid()) &&
            "Invalid type");
+#endif
     SPIRVInstruction::validate();
   }
 
@@ -2637,8 +2725,27 @@ public:
     // Besides, OpAtomicCompareExchangeWeak, OpAtomicFlagTestAndSet and
     // OpAtomicFlagClear instructions require the "kernel" capability. But this
     // capability should be added by setting the OpenCL memory model.
-    if (hasType() && getType()->isTypeInt(64))
-      return {CapabilityInt64Atomics};
+    if (hasType()) {
+      if (getType()->isTypeInt(64)) {
+        return {CapabilityInt64Atomics};
+      } else if (OpCode == spv::OpAtomicFAddEXT) {
+        if (getType()->isTypeFloat(32)) {
+          return {CapabilityAtomicFloat32AddEXT};
+        } else if (getType()->isTypeFloat(64)) {
+          return {CapabilityAtomicFloat64AddEXT};
+        }
+      }
+    }
+    return {};
+  }
+
+  llvm::Optional<ExtensionID> getRequiredExtension() const override {
+    if (auto parent_ext = SPIRVInstTemplateBase::getRequiredExtension(); parent_ext.hasValue()) {
+      return parent_ext.getValue();
+    }
+    if (hasType() && (getType()->isTypeFloat(32) || getType()->isTypeFloat(64))) {
+      return ExtensionID::SPV_EXT_shader_atomic_float_add;
+    }
     return {};
   }
 
@@ -2731,9 +2838,32 @@ _SPIRV_OP(AtomicFMaxEXT, AtomicFMinMaxEXTBase, true, 7)
 #undef _SPIRV_OP
 
 class SPIRVImageInstBase : public SPIRVInstTemplateBase {
+protected:
+  // kernel and shader image caps differ, so this needs to be handled externally
+  static SPIRVCapVec image_caps;
+
 public:
-  SPIRVCapVec getRequiredCapability() const override {
-    return getVec(CapabilityImageBasic);
+  SPIRVCapVec getRequiredCapability() const override { return image_caps; }
+  static void addCap(const Capability cap) {
+    image_caps.emplace_back(cap);
+    std::sort(image_caps.begin(), image_caps.end());
+    image_caps.erase(std::unique(image_caps.begin(), image_caps.end()),
+                     image_caps.end());
+  }
+};
+
+class SPIRVImageQueryInstBase : public SPIRVInstTemplateBase {
+protected:
+  static SPIRVCapVec image_query_caps;
+
+public:
+  SPIRVCapVec getRequiredCapability() const override { return image_query_caps; }
+  static void addCap(const Capability cap) {
+    image_query_caps.emplace_back(cap);
+    std::sort(image_query_caps.begin(), image_query_caps.end());
+    image_query_caps.erase(
+        std::unique(image_query_caps.begin(), image_query_caps.end()),
+        image_query_caps.end());
   }
 };
 
@@ -2743,8 +2873,17 @@ public:
 _SPIRV_OP(SampledImage, true, 5)
 _SPIRV_OP(ImageSampleImplicitLod, true, 5, true)
 _SPIRV_OP(ImageSampleExplicitLod, true, 7, true, 2)
+_SPIRV_OP(ImageSampleDrefImplicitLod, true, 6, true)
+_SPIRV_OP(ImageSampleDrefExplicitLod, true, 8, true)
+_SPIRV_OP(ImageFetch, true, 5, true)
 _SPIRV_OP(ImageRead, true, 5, true, 2)
 _SPIRV_OP(ImageWrite, false, 4, true, 3)
+#undef _SPIRV_OP
+
+#define _SPIRV_OP(x, ...)                                                      \
+  typedef SPIRVInstTemplate<SPIRVImageQueryInstBase, Op##x, __VA_ARGS__>       \
+      SPIRV##x;
+// ImageQuery instructions
 _SPIRV_OP(ImageQueryFormat, true, 4)
 _SPIRV_OP(ImageQueryOrder, true, 4)
 _SPIRV_OP(ImageQuerySizeLod, true, 5)
diff --git a/lib/SPIRV/libSPIRV/SPIRVModule.cpp b/lib/SPIRV/libSPIRV/SPIRVModule.cpp
index 9cd9249..1016106 100644
--- a/lib/SPIRV/libSPIRV/SPIRVModule.cpp
+++ b/lib/SPIRV/libSPIRV/SPIRVModule.cpp
@@ -51,11 +51,22 @@
 #include "SPIRVValue.h"
 
 #include "llvm/ADT/APInt.h"
+#include "llvm/Support/ErrorHandling.h"
 
 #include <set>
 #include <unordered_map>
 #include <unordered_set>
 
+namespace std {
+template <>
+struct hash<pair<SPIRV::SPIRVType *, uint32_t>> : public hash<size_t> {
+  size_t operator()(const pair<SPIRV::SPIRVType *, uint32_t> &value) const
+      noexcept {
+    return (hash<uint32_t>()(value.second) ^ hash<void *>()(value.first));
+  }
+};
+}
+
 namespace SPIRV {
 
 SPIRVModule::SPIRVModule()
@@ -71,10 +82,8 @@ public:
         GeneratorId(SPIRVGEN_KhronosLLVMSPIRVTranslator), GeneratorVer(0),
         InstSchema(SPIRVISCH_Default), SrcLang(SourceLanguageOpenCL_C),
         SrcLangVer(102000) {
-    AddrModel = sizeof(size_t) == 32 ? AddressingModelPhysical32
-                                     : AddressingModelPhysical64;
-    // OpenCL memory model requires Kernel capability
-    setMemoryModel(MemoryModelOpenCL);
+    AddrModel = sizeof(size_t) == 4 ? AddressingModelPhysical32
+                                    : AddressingModelPhysical64;
   }
 
   SPIRVModuleImpl(const SPIRV::TranslatorOpts &Opts) : SPIRVModuleImpl() {
@@ -127,7 +136,9 @@ public:
   std::vector<SPIRVType *>
   getValueTypes(const std::vector<SPIRVId> &) const override;
   SPIRVMemoryModelKind getMemoryModel() const override { return MemoryModel; }
-  SPIRVConstant *getLiteralAsConstant(unsigned Literal) override;
+  SPIRVConstant *getLiteralAsConstant(unsigned Literal, bool is_signed) override;
+  SPIRVConstant *getLiteralAsConstant(float Literal) override;
+  SPIRVConstant *getLiteralAsConstant(double Literal) override;
   unsigned getNumEntryPoints(SPIRVExecutionModelKind EM) const override {
     auto Loc = EntryPointVec.find(EM);
     if (Loc == EntryPointVec.end())
@@ -142,6 +153,10 @@ public:
     assert(I < Loc->second.size());
     return get<SPIRVFunction>(Loc->second[I]);
   }
+  const std::map<SPIRVId, std::vector<SPIRVVariable *>> &
+  getEntryPointIO() const override {
+    return EntryPointIO;
+  }
   unsigned getNumFunctions() const override { return FuncVec.size(); }
   unsigned getNumVariables() const override { return VariableVec.size(); }
   SourceLanguage getSourceLanguage(SPIRVWord *Ver = nullptr) const override {
@@ -216,6 +231,7 @@ public:
                          const std::vector<SPIRVEntry *> &Targets) override;
   void addEntryPoint(SPIRVExecutionModelKind ExecModel,
                      SPIRVId EntryPoint) override;
+  void addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var) override;
   SPIRVForward *addForward(SPIRVType *Ty) override;
   SPIRVForward *addForward(SPIRVId, SPIRVType *Ty) override;
   SPIRVFunction *addFunction(SPIRVFunction *) override;
@@ -226,11 +242,12 @@ public:
   // Type creation functions
   template <class T> T *addType(T *Ty);
   SPIRVTypeArray *addArrayType(SPIRVType *, SPIRVConstant *) override;
+  SPIRVTypeRuntimeArray *addRuntimeArrayType(SPIRVType *) override;
   SPIRVTypeBool *addBoolType() override;
   SPIRVTypeFloat *addFloatType(unsigned BitWidth) override;
   SPIRVTypeFunction *addFunctionType(SPIRVType *,
                                      const std::vector<SPIRVType *> &) override;
-  SPIRVTypeInt *addIntegerType(unsigned BitWidth) override;
+  SPIRVTypeInt *addIntegerType(unsigned BitWidth, bool is_signed) override;
   SPIRVTypeOpaque *addOpaqueType(const std::string &) override;
   SPIRVTypePointer *addPointerType(SPIRVStorageClassKind, SPIRVType *) override;
   SPIRVTypeImage *addImageType(SPIRVType *,
@@ -283,6 +300,7 @@ public:
   SPIRVValue *addIntegerConstant(SPIRVTypeInt *, uint64_t) override;
   SPIRVValue *addNullConstant(SPIRVType *) override;
   SPIRVValue *addUndef(SPIRVType *TheType) override;
+  SPIRVValue *addUndefInst(SPIRVType *TheType, SPIRVBasicBlock *) override;
   SPIRVValue *addSamplerConstant(SPIRVType *TheType, SPIRVWord AddrMode,
                                  SPIRVWord ParametricMode,
                                  SPIRVWord FilterMode) override;
@@ -290,10 +308,19 @@ public:
                                      SPIRVWord PacketAlign,
                                      SPIRVWord Capacity) override;
 
+  // Specialization constants creation functions
+  SPIRVValue *addSpecDoubleConstant(SPIRVTypeFloat *, double) override;
+  SPIRVValue *addSpecFloatConstant(SPIRVTypeFloat *, float) override;
+  SPIRVValue *addSpecIntegerConstant(SPIRVTypeInt *, uint64_t) override;
+  SPIRVValue *addSpecCompositeConstant(SPIRVType *, const std::vector<SPIRVValue *> &) override;
+
   // Instruction creation functions
   SPIRVInstruction *addPtrAccessChainInst(SPIRVType *, SPIRVValue *,
                                           std::vector<SPIRVValue *>,
                                           SPIRVBasicBlock *, bool) override;
+  SPIRVInstruction *addAccessChainInst(SPIRVType *, SPIRVValue *,
+                                       std::vector<SPIRVValue *>,
+                                       SPIRVBasicBlock *, bool) override;
   SPIRVInstruction *addAsyncGroupCopy(SPIRVValue *Scope, SPIRVValue *Dest,
                                       SPIRVValue *Src, SPIRVValue *NumElems,
                                       SPIRVValue *Stride, SPIRVValue *Event,
@@ -440,10 +467,21 @@ public:
   SPIRVInstruction *addVectorInsertDynamicInst(SPIRVValue *, SPIRVValue *,
                                                SPIRVValue *,
                                                SPIRVBasicBlock *) override;
-  SPIRVInstruction *addFPGARegINTELInst(SPIRVType *, SPIRVValue *,
-                                        SPIRVBasicBlock *) override;
   SPIRVInstruction *addSampledImageInst(SPIRVType *, SPIRVValue *, SPIRVValue *,
                                         SPIRVBasicBlock *) override;
+
+  // GLSL/shader functions
+  SPIRVInstruction *addKillInst(SPIRVBasicBlock *) override;
+  SPIRVInstruction *addDerivativeInst(Op op, SPIRVValue *p,
+                                      SPIRVBasicBlock *BB) override;
+  SPIRVInstruction *addBitCountInst(SPIRVType *ret_type, SPIRVValue *p,
+                                    SPIRVBasicBlock *BB) override;
+  SPIRVInstruction *
+  addBitReverseInst(SPIRVType *ret_type, SPIRVValue *p, SPIRVBasicBlock *BB) override;
+
+  // other ext functions
+  SPIRVInstruction *addFPGARegINTELInst(SPIRVType *, SPIRVValue *,
+                                        SPIRVBasicBlock *) override;
   template <typename AliasingInstType>
   SPIRVEntry *getOrAddMemAliasingINTELInst(std::vector<SPIRVId> Args,
                                            llvm::MDNode *MD);
@@ -525,11 +563,40 @@ private:
   SPIRVAsmVector AsmVec;
   SPIRVExecModelIdSetMap EntryPointSet;
   SPIRVExecModelIdVecMap EntryPointVec;
+  std::map<SPIRVId, std::vector<SPIRVVariable *>> EntryPointIO;
   SPIRVStringMap StrMap;
   SPIRVCapMap CapMap;
   SPIRVUnknownStructFieldMap UnknownStructFieldMap;
-  std::map<unsigned, SPIRVTypeInt *> IntTypeMap;
-  std::map<unsigned, SPIRVConstant *> LiteralMap;
+  std::map<uint32_t, SPIRVTypeInt *> IntTypeMap;
+  std::map<uint32_t, SPIRVTypeInt *> SignedIntTypeMap;
+  std::map<uint32_t, SPIRVConstant *> LiteralMap;
+  std::map<uint32_t, SPIRVConstant *> SignedLiteralMap;
+  std::map<float, SPIRVConstant *> FloatLiteralMap;
+  std::map<double, SPIRVConstant *> DoubleLiteralMap;
+  std::map<uint32_t, SPIRVTypeFloat *> FloatTypeMap;
+  std::map<std::pair<SPIRVType *, uint32_t>, SPIRVTypeVector *>
+      VectorTypeMap;
+  std::map<std::pair<SPIRVType *, uint32_t>, SPIRVTypePointer *>
+      PointerTypeMap;
+  std::map<SPIRVTypeImage *, SPIRVTypeSampledImage *>
+      SampledImageTypeMap;
+
+  struct image_type_info {
+    // -> info
+    SPIRVType *sampled_type{nullptr};
+    SPIRVTypeImageDescriptor desc;
+    SPIRVAccessQualifierKind access{
+        SPIRVAccessQualifierKind::AccessQualifierNone};
+
+    // -> created type
+    SPIRVTypeImage *image_type{nullptr};
+  };
+
+  SPIRVTypeVoid *VoidType{nullptr};
+  SPIRVTypeBool *BoolType{nullptr};
+  SPIRVTypeSampler *SamplerType{nullptr};
+
+  std::vector<image_type_info> ImageTypeMap;
   std::vector<SPIRVExtInst *> DebugInstVec;
   std::vector<SPIRVModuleProcessed *> ModuleProcessedVec;
   SPIRVAliasInstMDVec AliasInstMDVec;
@@ -625,13 +692,46 @@ void SPIRVModuleImpl::addCapabilityInternal(SPIRVCapabilityKind Cap) {
   }
 }
 
-SPIRVConstant *SPIRVModuleImpl::getLiteralAsConstant(unsigned Literal) {
-  auto Loc = LiteralMap.find(Literal);
-  if (Loc != LiteralMap.end())
-    return Loc->second;
-  auto Ty = addIntegerType(32);
+SPIRVConstant *SPIRVModuleImpl::getLiteralAsConstant(unsigned Literal,
+                                                     bool is_signed) {
+  if (!is_signed) {
+    auto Loc = LiteralMap.find(Literal);
+    if (Loc != LiteralMap.end())
+      return Loc->second;
+  } else {
+    auto Loc = SignedLiteralMap.find(Literal);
+    if (Loc != SignedLiteralMap.end())
+      return Loc->second;
+  }
+  auto Ty = addIntegerType(32, is_signed);
   auto V = new SPIRVConstant(this, Ty, getId(), static_cast<uint64_t>(Literal));
-  LiteralMap[Literal] = V;
+  if (!is_signed) {
+    LiteralMap[Literal] = V;
+  } else {
+    SignedLiteralMap[Literal] = V;
+  }
+  addConstant(V);
+  return V;
+}
+
+SPIRVConstant *SPIRVModuleImpl::getLiteralAsConstant(float Literal) {
+  auto Loc = FloatLiteralMap.find(Literal);
+  if (Loc != FloatLiteralMap.end())
+    return Loc->second;
+  auto Ty = addFloatType(32);
+  auto V = new SPIRVConstant(this, Ty, getId(), Literal);
+  FloatLiteralMap[Literal] = V;
+  addConstant(V);
+  return V;
+}
+
+SPIRVConstant *SPIRVModuleImpl::getLiteralAsConstant(double Literal) {
+  auto Loc = DoubleLiteralMap.find(Literal);
+  if (Loc != DoubleLiteralMap.end())
+    return Loc->second;
+  auto Ty = addFloatType(64);
+  auto V = new SPIRVConstant(this, Ty, getId(), Literal);
+  DoubleLiteralMap[Literal] = V;
   addConstant(V);
   return V;
 }
@@ -838,7 +938,12 @@ template <class T> T *SPIRVModuleImpl::addType(T *Ty) {
 }
 
 SPIRVTypeVoid *SPIRVModuleImpl::addVoidType() {
-  return addType(new SPIRVTypeVoid(this, getId()));
+  // only ever create one void type
+  if (VoidType != nullptr) {
+    return VoidType;
+  }
+  VoidType = new SPIRVTypeVoid(this, getId());
+  return addType(VoidType);
 }
 
 SPIRVTypeArray *SPIRVModuleImpl::addArrayType(SPIRVType *ElementType,
@@ -846,29 +951,58 @@ SPIRVTypeArray *SPIRVModuleImpl::addArrayType(SPIRVType *ElementType,
   return addType(new SPIRVTypeArray(this, getId(), ElementType, Length));
 }
 
+SPIRVTypeRuntimeArray *
+SPIRVModuleImpl::addRuntimeArrayType(SPIRVType *ElementType) {
+  return addType(new SPIRVTypeRuntimeArray(this, getId(), ElementType));
+}
+
 SPIRVTypeBool *SPIRVModuleImpl::addBoolType() {
-  return addType(new SPIRVTypeBool(this, getId()));
+  // only ever create one bool type
+  if (BoolType != nullptr) {
+    return BoolType;
+  }
+  BoolType = new SPIRVTypeBool(this, getId());
+  return addType(BoolType);
 }
 
-SPIRVTypeInt *SPIRVModuleImpl::addIntegerType(unsigned BitWidth) {
-  auto Loc = IntTypeMap.find(BitWidth);
-  if (Loc != IntTypeMap.end())
-    return Loc->second;
-  auto Ty = new SPIRVTypeInt(this, getId(), BitWidth, false);
-  IntTypeMap[BitWidth] = Ty;
+SPIRVTypeInt *SPIRVModuleImpl::addIntegerType(unsigned BitWidth, bool is_signed) {
+  if (!is_signed) {
+    auto Loc = IntTypeMap.find(BitWidth);
+    if (Loc != IntTypeMap.end())
+      return Loc->second;
+  } else {
+    auto Loc = SignedIntTypeMap.find(BitWidth);
+    if (Loc != SignedIntTypeMap.end())
+      return Loc->second;
+  }
+  auto Ty = new SPIRVTypeInt(this, getId(), BitWidth, is_signed);
+  if (!is_signed) {
+    IntTypeMap[BitWidth] = Ty;
+  } else {
+    SignedIntTypeMap[BitWidth] = Ty;
+  }
   return addType(Ty);
 }
 
 SPIRVTypeFloat *SPIRVModuleImpl::addFloatType(unsigned BitWidth) {
-  SPIRVTypeFloat *T = addType(new SPIRVTypeFloat(this, getId(), BitWidth));
+  auto Loc = FloatTypeMap.find(BitWidth);
+  if (Loc != FloatTypeMap.end())
+    return Loc->second;
+  auto Ty = new SPIRVTypeFloat(this, getId(), BitWidth);
+  FloatTypeMap[BitWidth] = Ty;
+  SPIRVTypeFloat *T = addType(Ty);
   return T;
 }
 
 SPIRVTypePointer *
 SPIRVModuleImpl::addPointerType(SPIRVStorageClassKind StorageClass,
                                 SPIRVType *ElementType) {
-  return addType(
-      new SPIRVTypePointer(this, getId(), StorageClass, ElementType));
+  auto Loc = PointerTypeMap.find({ElementType, StorageClass});
+  if (Loc != PointerTypeMap.end())
+    return Loc->second;
+  auto Ty = new SPIRVTypePointer(this, getId(), StorageClass, ElementType);
+  PointerTypeMap[std::make_pair(ElementType, StorageClass)] = Ty;
+  return addType(Ty);
 }
 
 SPIRVTypeFunction *SPIRVModuleImpl::addFunctionType(
@@ -898,7 +1032,12 @@ void SPIRVModuleImpl::closeStructType(SPIRVTypeStruct *T, bool Packed) {
 
 SPIRVTypeVector *SPIRVModuleImpl::addVectorType(SPIRVType *CompType,
                                                 SPIRVWord CompCount) {
-  return addType(new SPIRVTypeVector(this, getId(), CompType, CompCount));
+  auto Loc = VectorTypeMap.find({CompType, CompCount});
+  if (Loc != VectorTypeMap.end())
+    return Loc->second;
+  auto Ty = new SPIRVTypeVector(this, getId(), CompType, CompCount);
+  VectorTypeMap[std::make_pair(CompType, CompCount)] = Ty;
+  return addType(Ty);
 }
 
 SPIRVTypeJointMatrixINTEL *SPIRVModuleImpl::addJointMatrixINTELType(
@@ -927,20 +1066,46 @@ SPIRVTypePipe *SPIRVModuleImpl::addPipeType() {
 SPIRVTypeImage *
 SPIRVModuleImpl::addImageType(SPIRVType *SampledType,
                               const SPIRVTypeImageDescriptor &Desc) {
-  return addType(new SPIRVTypeImage(
-      this, getId(), SampledType ? SampledType->getId() : 0, Desc));
+  return addImageType(SampledType, Desc, spv::AccessQualifierNone);
 }
 
 SPIRVTypeImage *
 SPIRVModuleImpl::addImageType(SPIRVType *SampledType,
                               const SPIRVTypeImageDescriptor &Desc,
                               SPIRVAccessQualifierKind Acc) {
-  return addType(new SPIRVTypeImage(
-      this, getId(), SampledType ? SampledType->getId() : 0, Desc, Acc));
+  // only ever create one OpTypeImage with the same parameters
+  for (const auto &entry : ImageTypeMap) {
+    if (entry.sampled_type == SampledType &&
+        entry.desc.Arrayed == Desc.Arrayed && entry.desc.Depth == Desc.Depth &&
+        entry.desc.Dim == Desc.Dim && entry.desc.Format == Desc.Format &&
+        entry.desc.MS == Desc.MS && entry.desc.Sampled == Desc.Sampled &&
+        entry.access == Acc) {
+      return entry.image_type;
+    }
+  }
+
+  // doesn't exist yet, create it
+  image_type_info info{
+      .sampled_type = SampledType, .desc = Desc, .access = Acc,
+  };
+  if (Acc != spv::AccessQualifierNone) {
+    info.image_type = addType(new SPIRVTypeImage(
+        this, getId(), SampledType ? SampledType->getId() : 0, Desc, Acc));
+  } else {
+    info.image_type = addType(new SPIRVTypeImage(
+        this, getId(), SampledType ? SampledType->getId() : 0, Desc));
+  }
+  ImageTypeMap.emplace_back(info);
+  return info.image_type;
 }
 
 SPIRVTypeSampler *SPIRVModuleImpl::addSamplerType() {
-  return addType(new SPIRVTypeSampler(this, getId()));
+  // only ever create one sampler type
+  if (SamplerType != nullptr) {
+    return SamplerType;
+  }
+  SamplerType = new SPIRVTypeSampler(this, getId());
+  return addType(SamplerType);
 }
 
 SPIRVTypePipeStorage *SPIRVModuleImpl::addPipeStorageType() {
@@ -948,7 +1113,13 @@ SPIRVTypePipeStorage *SPIRVModuleImpl::addPipeStorageType() {
 }
 
 SPIRVTypeSampledImage *SPIRVModuleImpl::addSampledImageType(SPIRVTypeImage *T) {
-  return addType(new SPIRVTypeSampledImage(this, getId(), T));
+  const auto iter = SampledImageTypeMap.find(T);
+  if (iter != SampledImageTypeMap.end()) {
+    return iter->second;
+  }
+  auto ret = new SPIRVTypeSampledImage(this, getId(), T);
+  SampledImageTypeMap.emplace(T, ret);
+  return addType(ret);
 }
 
 SPIRVTypeVmeImageINTEL *
@@ -1007,6 +1178,21 @@ void SPIRVModuleImpl::addEntryPoint(SPIRVExecutionModelKind ExecModel,
   addCapabilities(SPIRV::getCapability(ExecModel));
 }
 
+void SPIRVModuleImpl::addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var) {
+  assert(EntryPoint != SPIRVID_INVALID && "Invalid entry point");
+  decltype(EntryPointIO)::mapped_type *io_vars = nullptr;
+  const auto ep_iter = EntryPointIO.find(EntryPoint);
+  if (ep_iter != EntryPointIO.end()) {
+    io_vars = &ep_iter->second;
+  } else {
+    const auto empl_iter =
+        EntryPointIO.emplace(EntryPoint, decltype(EntryPointIO)::mapped_type{});
+    assert(empl_iter.second && "failed to insert new entry point i/o");
+    io_vars = &empl_iter.first->second;
+  }
+  io_vars->push_back(var);
+}
+
 SPIRVForward *SPIRVModuleImpl::addForward(SPIRVType *Ty) {
   return add(new SPIRVForward(this, Ty, getId()));
 }
@@ -1055,6 +1241,10 @@ SPIRVValue *SPIRVModuleImpl::addConstant(SPIRVType *Ty, uint64_t V) {
   }
   if (Ty->isTypeInt())
     return addIntegerConstant(static_cast<SPIRVTypeInt *>(Ty), V);
+  if (Ty->isTypeFloat(32))
+    return addFloatConstant(static_cast<SPIRVTypeFloat *>(Ty), *(float *)&V);
+  if (Ty->isTypeFloat(64))
+    return addDoubleConstant(static_cast<SPIRVTypeFloat *>(Ty), *(double *)&V);
   return addConstant(new SPIRVConstant(this, Ty, getId(), V));
 }
 
@@ -1063,19 +1253,34 @@ SPIRVValue *SPIRVModuleImpl::addConstant(SPIRVType *Ty, llvm::APInt V) {
 }
 
 SPIRVValue *SPIRVModuleImpl::addIntegerConstant(SPIRVTypeInt *Ty, uint64_t V) {
-  if (Ty->getBitWidth() == 32) {
-    unsigned I32 = static_cast<unsigned>(V);
+  const auto bit_width = Ty->getBitWidth();
+  if (bit_width == 32) {
+    uint32_t I32 = static_cast<uint32_t>(V);
     assert(I32 == V && "Integer value truncated");
-    return getLiteralAsConstant(I32);
+    return getLiteralAsConstant(I32, Ty->isSigned());
+  }
+  // for signed constants of bit-width 8 and 16, ensure upper bits are set if they are supposed to be negative
+  if (Ty->isSigned()) {
+    if (bit_width == 8 && V > 127) {
+      V |= 0xFFFF'FFFF'FFFF'FF00ull;
+    } else if (bit_width == 16 && V > 32767) {
+      V |= 0xFFFF'FFFF'FFFF'0000ull;
+    }
   }
   return addConstant(new SPIRVConstant(this, Ty, getId(), V));
 }
 
 SPIRVValue *SPIRVModuleImpl::addFloatConstant(SPIRVTypeFloat *Ty, float V) {
+  if (Ty->getBitWidth() == 32) {
+    return getLiteralAsConstant(V);
+  }
   return addConstant(new SPIRVConstant(this, Ty, getId(), V));
 }
 
 SPIRVValue *SPIRVModuleImpl::addDoubleConstant(SPIRVTypeFloat *Ty, double V) {
+  if (Ty->getBitWidth() == 64) {
+    return getLiteralAsConstant(V);
+  }
   return addConstant(new SPIRVConstant(this, Ty, getId(), V));
 }
 
@@ -1162,6 +1367,31 @@ SPIRVValue *SPIRVModuleImpl::addUndef(SPIRVType *TheType) {
   return addConstant(new SPIRVUndef(this, TheType, getId()));
 }
 
+SPIRVValue *SPIRVModuleImpl::addUndefInst(SPIRVType *TheType,
+                                          SPIRVBasicBlock *BB) {
+  return BB->addInstruction(new SPIRVUndefValueInternal(TheType, getId(), BB));
+}
+
+// Specialization constants creation functions
+SPIRVValue *SPIRVModuleImpl::addSpecDoubleConstant(SPIRVTypeFloat *Ty,
+                                                   double V) {
+  return add(new SPIRVSpecConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addSpecFloatConstant(SPIRVTypeFloat *Ty, float V) {
+  return add(new SPIRVSpecConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addSpecIntegerConstant(SPIRVTypeInt *Ty,
+                                                    uint64_t V) {
+  return add(new SPIRVSpecConstant(this, Ty, getId(), V));
+}
+
+SPIRVValue *SPIRVModuleImpl::addSpecCompositeConstant(
+    SPIRVType *Ty, const std::vector<SPIRVValue *> &Elements) {
+  return add(new SPIRVSpecConstantComposite(this, Ty, getId(), Elements));
+}
+
 SPIRVValue *SPIRVModuleImpl::addSpecConstant(SPIRVType *Ty, uint64_t V) {
   if (Ty->isTypeBool()) {
     if (V)
@@ -1473,17 +1703,31 @@ SPIRVInstruction *SPIRVModuleImpl::addSelectInst(SPIRVValue *Condition,
 
 SPIRVInstruction *SPIRVModuleImpl::addSelectionMergeInst(
     SPIRVId MergeBlock, SPIRVWord SelectionControl, SPIRVBasicBlock *BB) {
+  // NOTE: same as addLoopMergeInst, this must come before the terminator
+  auto term_instr = const_cast<SPIRVInstruction *>(BB->getTerminateInstr());
+  if (term_instr && !term_instr->isTerminationInstruction()) {
+    term_instr = nullptr;
+  }
   return addInstruction(
-      new SPIRVSelectionMerge(MergeBlock, SelectionControl, BB), BB);
+      new SPIRVSelectionMerge(MergeBlock, SelectionControl, BB), BB,
+      term_instr);
 }
 
 SPIRVInstruction *SPIRVModuleImpl::addLoopMergeInst(
     SPIRVId MergeBlock, SPIRVId ContinueTarget, SPIRVWord LoopControl,
     std::vector<SPIRVWord> LoopControlParameters, SPIRVBasicBlock *BB) {
+  // NOTE: "getTerminateInstr()" does not return a termination instruction,
+  // but just the current last instruction in the BB
+  // -> check if it's an actual term instruction, null it if not,
+  //    so that we don't add to the LoopMerge in front of a non-term instr
+  auto term_instr = const_cast<SPIRVInstruction *>(BB->getTerminateInstr());
+  if (term_instr && !term_instr->isTerminationInstruction()) {
+    term_instr = nullptr;
+  }
   return addInstruction(
       new SPIRVLoopMerge(MergeBlock, ContinueTarget, LoopControl,
                          LoopControlParameters, BB),
-      BB, const_cast<SPIRVInstruction *>(BB->getTerminateInstr()));
+      BB, term_instr);
 }
 
 SPIRVInstruction *SPIRVModuleImpl::addLoopControlINTELInst(
@@ -1531,6 +1775,37 @@ SPIRVModuleImpl::addPtrAccessChainInst(SPIRVType *Type, SPIRVValue *Base,
       BB);
 }
 
+SPIRVInstruction *
+SPIRVModuleImpl::addAccessChainInst(SPIRVType *Type, SPIRVValue *Base,
+                                    std::vector<SPIRVValue *> Indices,
+                                    SPIRVBasicBlock *BB, bool IsInBounds) {
+  // check if this is a run-time array access (SSBO)
+  bool is_rtarr_access = false;
+  if (Base->getType()->isTypePointer() &&
+      Base->getType()->getPointerElementType()->isTypeStruct()) {
+    auto st_type = (SPIRVTypeStruct *)Base->getType()->getPointerElementType();
+    if (st_type->getStructMemberCount() > 0 &&
+        st_type->getMemberType(0)->isTypeRuntimeArray()) {
+      is_rtarr_access = true;
+    }
+  }
+  if (is_rtarr_access) {
+    // add an additional 0 index in front, because we always wrap SSBO/run-time
+    // array data in a struct
+    Indices.insert(
+        begin(Indices),
+        addIntegerConstant((SPIRVTypeInt *)Indices[0]->getType(), 0));
+  } else if (Indices.size() > 1) {
+    // if it's not a run-time array access, remove the first (0) index
+    Indices.erase(Indices.begin());
+  }
+  return addInstruction(
+      SPIRVInstTemplateBase::create(
+          IsInBounds ? OpInBoundsAccessChain : OpAccessChain, Type, getId(),
+          getVec(Base->getId(), Base->getIds(Indices)), BB, this),
+      BB);
+}
+
 SPIRVInstruction *SPIRVModuleImpl::addAsyncGroupCopy(
     SPIRVValue *Scope, SPIRVValue *Dest, SPIRVValue *Src, SPIRVValue *NumElems,
     SPIRVValue *Stride, SPIRVValue *Event, SPIRVBasicBlock *BB) {
@@ -1661,16 +1936,73 @@ SPIRVInstruction *SPIRVModuleImpl::addVariable(
     SPIRVStorageClassKind StorageClass, SPIRVBasicBlock *BB) {
   SPIRVVariable *Variable = new SPIRVVariable(Type, getId(), Initializer, Name,
                                               StorageClass, BB, this);
-  if (BB)
-    return addInstruction(Variable, BB);
+  if (BB) {
+    // ensure variables are always added at the front
+    SPIRVInstruction* insert_before = nullptr;
+    if (BB->getNumInst() > 0) {
+      insert_before = BB->getInst(0);
+    }
+    return addInstruction(Variable, BB, insert_before);
+  }
 
   add(Variable);
   if (LinkageTy != internal::LinkageTypeInternal)
     Variable->setLinkageType(LinkageTy);
-  Variable->setIsConstant(IsConstant);
+  // shader doesn't have the constant decoration
+  if (SrcLang != spv::SourceLanguageGLSL) {
+    Variable->setIsConstant(IsConstant);
+  }
   return Variable;
 }
 
+SPIRVInstruction *SPIRVModuleImpl::addKillInst(SPIRVBasicBlock *BB) {
+  return addInstruction(new SPIRVKill(BB), BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addDerivativeInst(Op op, SPIRVValue *p,
+                                                     SPIRVBasicBlock *BB) {
+  switch (op) {
+  case spv::OpDPdx:
+    return addInstruction(new SPIRVDPdx(getId(), p, BB), BB);
+  case spv::OpDPdxFine:
+    return addInstruction(new SPIRVDPdxFine(getId(), p, BB), BB);
+  case spv::OpDPdxCoarse:
+    return addInstruction(new SPIRVDPdxCoarse(getId(), p, BB), BB);
+  case spv::OpDPdy:
+    return addInstruction(new SPIRVDPdy(getId(), p, BB), BB);
+  case spv::OpDPdyFine:
+    return addInstruction(new SPIRVDPdyFine(getId(), p, BB), BB);
+  case spv::OpDPdyCoarse:
+    return addInstruction(new SPIRVDPdyCoarse(getId(), p, BB), BB);
+  case spv::OpFwidth:
+    return addInstruction(new SPIRVFwidth(getId(), p, BB), BB);
+  case spv::OpFwidthFine:
+    return addInstruction(new SPIRVFwidthFine(getId(), p, BB), BB);
+  case spv::OpFwidthCoarse:
+    return addInstruction(new SPIRVFwidthCoarse(getId(), p, BB), BB);
+  default:
+    llvm_unreachable("invalid derivative opcode");
+  }
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addBitCountInst(SPIRVType *ret_type,
+                                                   SPIRVValue *p,
+                                                   SPIRVBasicBlock *BB) {
+  return addInstruction(
+      SPIRVInstTemplateBase::create(spv::OpBitCount, ret_type, getId(),
+                                    getVec(p->getId()), BB, this),
+      BB);
+}
+
+SPIRVInstruction *SPIRVModuleImpl::addBitReverseInst(SPIRVType *ret_type,
+                                                     SPIRVValue *p,
+                                                     SPIRVBasicBlock *BB) {
+  return addInstruction(
+      SPIRVInstTemplateBase::create(spv::OpBitReverse, ret_type, getId(),
+                                    getVec(p->getId()), BB, this),
+      BB);
+}
+
 template <class T>
 spv_ostream &operator<<(spv_ostream &O, const std::vector<T *> &V) {
   for (auto &I : V)
@@ -1823,6 +2155,13 @@ spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M) {
 
   for (auto &I : M.getExtension()) {
     assert(!I.empty() && "Invalid extension");
+
+    // skip vk_capability_* "extensions"
+    // we only want these as caps, not extensions
+    if (I.find("vk_capability_") != std::string::npos) {
+      continue;
+    }
+
     O << SPIRVExtension(&M, I);
   }
 
@@ -1831,10 +2170,24 @@ spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M) {
 
   O << SPIRVMemoryModel(&M);
 
-  for (auto &I : MI.EntryPointVec)
-    for (auto &II : I.second)
-      O << SPIRVEntryPoint(&M, I.first, II, M.get<SPIRVFunction>(II)->getName(),
-                           M.get<SPIRVFunction>(II)->getVariables());
+  for (auto &I : MI.EntryPointVec) {
+    for (auto &II : I.second) {
+      if (MI.getSourceLanguage(nullptr) != spv::SourceLanguageGLSL) {
+        O << SPIRVEntryPoint(&M, I.first, II, M.get<SPIRVFunction>(II)->getName(),
+                             M.get<SPIRVFunction>(II)->getVariables());
+      } else {
+        std::vector<SPIRVId> io_vars;
+        const auto ep_iter = MI.getEntryPointIO().find(II);
+        if (ep_iter != MI.getEntryPointIO().end()) {
+          for (const auto& var : ep_iter->second) {
+            io_vars.emplace_back(var->getId());
+          }
+        }
+        O << SPIRVEntryPoint(&M, I.first, II, M.get<SPIRVFunction>(II)->getName(),
+                             io_vars);
+      }
+    }
+  }
 
   for (auto &I : MI.EntryPointVec)
     for (auto &II : I.second)
@@ -1850,6 +2203,7 @@ spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M) {
   O << SPIRVSource(&M);
 
   for (auto &I : MI.NamedId) {
+#if 0
     // Don't output name for entry point since it is redundant
     bool IsEntryPoint = false;
     for (auto &EPS : MI.EntryPointSet)
@@ -1859,6 +2213,9 @@ spv_ostream &operator<<(spv_ostream &O, SPIRVModule &M) {
       }
     if (!IsEntryPoint)
       M.getEntry(I)->encodeName(O);
+#else
+    M.getEntry(I)->encodeName(O);
+#endif
   }
 
   if (M.isAllowedToUseExtension(
@@ -1963,6 +2320,9 @@ static std::string to_string(uint32_t Version) {
   case static_cast<uint32_t>(VersionNumber::SPIRV_1_4):
     Res = "1.4";
     break;
+  case static_cast<uint32_t>(VersionNumber::SPIRV_1_5):
+    Res = "1.5";
+    break;
   default:
     Res = "unknown";
   }
@@ -2132,7 +2492,7 @@ bool isSpirvBinary(const std::string &Img) {
 
 #ifdef _SPIRV_SUPPORT_TEXT_FMT
 
-bool convertSpirv(std::istream &IS, std::ostream &OS, std::string &ErrMsg,
+bool convertSpirv(std::istream &IS, spv_ostream &OS, std::string &ErrMsg,
                   bool FromText, bool ToText) {
   auto SaveOpt = SPIRVUseTextFormat;
   SPIRVUseTextFormat = FromText;
@@ -2142,7 +2502,9 @@ bool convertSpirv(std::istream &IS, std::ostream &OS, std::string &ErrMsg,
   // particular SPIR-V versions: all known SPIR-V versions are allowed, all
   // known SPIR-V extensions are enabled during this conversion
   SPIRV::TranslatorOpts DefaultOpts;
+#if 0 // NOPE
   DefaultOpts.enableAllExtensions();
+#endif
   SPIRVModuleImpl M(DefaultOpts);
   IS >> M;
   if (M.getError(ErrMsg) != SPIRVEC_Success) {
@@ -2176,10 +2538,10 @@ bool convertSpirv(std::string &Input, std::string &Out, std::string &ErrMsg,
     return true;
   }
   std::istringstream IS(Input);
-  std::ostringstream OS;
+  raw_string_ostream OS(Out);
   if (!convertSpirv(IS, OS, ErrMsg, FromText, ToText))
     return false;
-  Out = OS.str();
+  OS.flush();
   return true;
 }
 
diff --git a/lib/SPIRV/libSPIRV/SPIRVModule.h b/lib/SPIRV/libSPIRV/SPIRVModule.h
index d65e9a6..6daf354 100644
--- a/lib/SPIRV/libSPIRV/SPIRVModule.h
+++ b/lib/SPIRV/libSPIRV/SPIRVModule.h
@@ -65,6 +65,7 @@ class SPIRVFunction;
 class SPIRVInstruction;
 class SPIRVType;
 class SPIRVTypeArray;
+class SPIRVTypeRuntimeArray;
 class SPIRVTypeBool;
 class SPIRVTypeFloat;
 class SPIRVTypeFunction;
@@ -135,6 +136,8 @@ public:
   virtual SPIRVExtInstSetKind getBuiltinSet(SPIRVId) const = 0;
   virtual SPIRVFunction *getEntryPoint(SPIRVExecutionModelKind,
                                        unsigned) const = 0;
+  virtual const std::map<SPIRVId, std::vector<SPIRVVariable *>> &
+  getEntryPointIO() const = 0;
   virtual std::set<std::string> &getExtension() = 0;
   virtual SPIRVFunction *getFunction(unsigned) const = 0;
   virtual SPIRVVariable *getVariable(unsigned) const = 0;
@@ -154,7 +157,9 @@ public:
   virtual SPIRVType *getValueType(SPIRVId TheId) const = 0;
   virtual std::vector<SPIRVType *>
   getValueTypes(const std::vector<SPIRVId> &) const = 0;
-  virtual SPIRVConstant *getLiteralAsConstant(unsigned Literal) = 0;
+  virtual SPIRVConstant *getLiteralAsConstant(unsigned Literal, bool is_signed) = 0;
+  virtual SPIRVConstant *getLiteralAsConstant(float Literal) = 0;
+  virtual SPIRVConstant *getLiteralAsConstant(double Literal) = 0;
   virtual bool isEntryPoint(SPIRVExecutionModelKind, SPIRVId) const = 0;
   virtual unsigned short getGeneratorId() const = 0;
   virtual unsigned short getGeneratorVer() const = 0;
@@ -213,6 +218,7 @@ public:
   virtual SPIRVGroupDecorateGeneric *
   addGroupDecorateGeneric(SPIRVGroupDecorateGeneric *GDec) = 0;
   virtual void addEntryPoint(SPIRVExecutionModelKind, SPIRVId) = 0;
+  virtual void addEntryPointIO(SPIRVId EntryPoint, SPIRVVariable *var) = 0;
   virtual SPIRVForward *addForward(SPIRVType *Ty) = 0;
   virtual SPIRVForward *addForward(SPIRVId, SPIRVType *Ty) = 0;
   virtual SPIRVFunction *addFunction(SPIRVFunction *) = 0;
@@ -223,6 +229,7 @@ public:
 
   // Type creation functions
   virtual SPIRVTypeArray *addArrayType(SPIRVType *, SPIRVConstant *) = 0;
+  virtual SPIRVTypeRuntimeArray *addRuntimeArrayType(SPIRVType *) = 0;
   virtual SPIRVTypeBool *addBoolType() = 0;
   virtual SPIRVTypeFloat *addFloatType(unsigned) = 0;
   virtual SPIRVTypeFunction *
@@ -235,7 +242,7 @@ public:
   virtual SPIRVTypeSampler *addSamplerType() = 0;
   virtual SPIRVTypePipeStorage *addPipeStorageType() = 0;
   virtual SPIRVTypeSampledImage *addSampledImageType(SPIRVTypeImage *T) = 0;
-  virtual SPIRVTypeInt *addIntegerType(unsigned) = 0;
+  virtual SPIRVTypeInt *addIntegerType(unsigned, bool is_signed) = 0;
   virtual SPIRVTypeOpaque *addOpaqueType(const std::string &) = 0;
   virtual SPIRVTypePointer *addPointerType(SPIRVStorageClassKind,
                                            SPIRVType *) = 0;
@@ -278,6 +285,7 @@ public:
   virtual SPIRVValue *addIntegerConstant(SPIRVTypeInt *, uint64_t) = 0;
   virtual SPIRVValue *addNullConstant(SPIRVType *) = 0;
   virtual SPIRVValue *addUndef(SPIRVType *TheType) = 0;
+  virtual SPIRVValue *addUndefInst(SPIRVType *TheType, SPIRVBasicBlock *) = 0;
   virtual SPIRVValue *addSamplerConstant(SPIRVType *TheType, SPIRVWord AddrMode,
                                          SPIRVWord ParametricMode,
                                          SPIRVWord FilterMode) = 0;
@@ -286,10 +294,20 @@ public:
                                              SPIRVWord PacketAlign,
                                              SPIRVWord Capacity) = 0;
 
+  // Specialization constants creation functions
+  virtual SPIRVValue *addSpecDoubleConstant(SPIRVTypeFloat *, double) = 0;
+  virtual SPIRVValue *addSpecFloatConstant(SPIRVTypeFloat *, float) = 0;
+  virtual SPIRVValue *addSpecIntegerConstant(SPIRVTypeInt *, uint64_t) = 0;
+  virtual SPIRVValue *
+  addSpecCompositeConstant(SPIRVType *, const std::vector<SPIRVValue *> &) = 0;
+
   // Instruction creation functions
   virtual SPIRVInstruction *addPtrAccessChainInst(SPIRVType *, SPIRVValue *,
                                                   std::vector<SPIRVValue *>,
                                                   SPIRVBasicBlock *, bool) = 0;
+  virtual SPIRVInstruction *addAccessChainInst(SPIRVType *, SPIRVValue *,
+                                               std::vector<SPIRVValue *>,
+                                               SPIRVBasicBlock *, bool) = 0;
   virtual SPIRVInstruction *
   addAsyncGroupCopy(SPIRVValue *Scope, SPIRVValue *Dest, SPIRVValue *Src,
                     SPIRVValue *NumElems, SPIRVValue *Stride, SPIRVValue *Event,
@@ -467,6 +485,17 @@ public:
                                              SPIRVValue *ExpectedValue,
                                              SPIRVBasicBlock *BB) = 0;
 
+  virtual SPIRVInstruction *addBitCountInst(SPIRVType *ret_type, SPIRVValue *p,
+                                            SPIRVBasicBlock *BB) = 0;
+
+  // GLSL/shader functions
+  virtual SPIRVInstruction *addKillInst(SPIRVBasicBlock *) = 0;
+  virtual SPIRVInstruction *addDerivativeInst(Op op, SPIRVValue *p,
+                                              SPIRVBasicBlock *BB) = 0;
+  virtual SPIRVInstruction *addBitReverseInst(SPIRVType *ret_type,
+                                              SPIRVValue *p,
+                                              SPIRVBasicBlock *BB) = 0;
+
   virtual SPIRVId getExtInstSetId(SPIRVExtInstSetKind Kind) const = 0;
 
   virtual bool
diff --git a/lib/SPIRV/libSPIRV/SPIRVOpCode.h b/lib/SPIRV/libSPIRV/SPIRVOpCode.h
index ce5c3df..9cbe577 100644
--- a/lib/SPIRV/libSPIRV/SPIRVOpCode.h
+++ b/lib/SPIRV/libSPIRV/SPIRVOpCode.h
@@ -138,6 +138,14 @@ inline bool isAccessChainOpCode(Op OpCode) {
   return OpCode == OpAccessChain || OpCode == OpInBoundsAccessChain;
 }
 
+inline bool isImageOpCode(Op OpCode) {
+  return (((unsigned)OpCode >= OpSampledImage &&
+           (unsigned)OpCode <= OpImageQuerySamples) ||
+          ((unsigned)OpCode >= OpImageSparseSampleImplicitLod &&
+           (unsigned)OpCode <= OpImageSparseTexelsResident) ||
+          OpCode == OpImageTexelPointer || OpCode == OpImageSparseRead);
+}
+
 inline bool hasExecScope(Op OpCode) {
   unsigned OC = OpCode;
   return (OpGroupWaitEvents <= OC && OC <= OpGroupSMax) ||
diff --git a/lib/SPIRV/libSPIRV/SPIRVOpCodeEnumInternal.h b/lib/SPIRV/libSPIRV/SPIRVOpCodeEnumInternal.h
index 4a97dee..d1a1afe 100644
--- a/lib/SPIRV/libSPIRV/SPIRVOpCodeEnumInternal.h
+++ b/lib/SPIRV/libSPIRV/SPIRVOpCodeEnumInternal.h
@@ -1,6 +1,7 @@
 #include "spirv_internal.hpp"
 
 _SPIRV_OP_INTERNAL(Forward, internal::OpForward)
+_SPIRV_OP_INTERNAL(UndefValueInternal, internal::OpUndefValueInternal)
 _SPIRV_OP_INTERNAL(AliasDomainDeclINTEL, internal::OpAliasDomainDeclINTEL)
 _SPIRV_OP_INTERNAL(AliasScopeDeclINTEL, internal::OpAliasScopeDeclINTEL)
 _SPIRV_OP_INTERNAL(AliasScopeListDeclINTEL, internal::OpAliasScopeListDeclINTEL)
diff --git a/lib/SPIRV/libSPIRV/SPIRVStream.cpp b/lib/SPIRV/libSPIRV/SPIRVStream.cpp
index 555b7a2..d38dfe7 100644
--- a/lib/SPIRV/libSPIRV/SPIRVStream.cpp
+++ b/lib/SPIRV/libSPIRV/SPIRVStream.cpp
@@ -134,6 +134,7 @@ SPIRV_DEF_ENCDEC(Capability)
 SPIRV_DEF_ENCDEC(Decoration)
 SPIRV_DEF_ENCDEC(OCLExtOpKind)
 SPIRV_DEF_ENCDEC(SPIRVDebugExtOpKind)
+SPIRV_DEF_ENCDEC(GLSLExtOpKind)
 SPIRV_DEF_ENCDEC(LinkageType)
 
 // Read a string with padded 0's at the end so that they form a stream of
diff --git a/lib/SPIRV/libSPIRV/SPIRVStream.h b/lib/SPIRV/libSPIRV/SPIRVStream.h
index 0208827..a0558c5 100644
--- a/lib/SPIRV/libSPIRV/SPIRVStream.h
+++ b/lib/SPIRV/libSPIRV/SPIRVStream.h
@@ -226,6 +226,7 @@ SPIRV_DEC_ENCDEC(Capability)
 SPIRV_DEC_ENCDEC(Decoration)
 SPIRV_DEC_ENCDEC(OCLExtOpKind)
 SPIRV_DEC_ENCDEC(SPIRVDebugExtOpKind)
+SPIRV_DEC_ENCDEC(GLSLExtOpKind)
 SPIRV_DEC_ENCDEC(LinkageType)
 
 const SPIRVEncoder &operator<<(const SPIRVEncoder &O, const std::string &Str);
diff --git a/lib/SPIRV/libSPIRV/SPIRVType.cpp b/lib/SPIRV/libSPIRV/SPIRVType.cpp
index 555b863..93280b0 100644
--- a/lib/SPIRV/libSPIRV/SPIRVType.cpp
+++ b/lib/SPIRV/libSPIRV/SPIRVType.cpp
@@ -47,8 +47,13 @@
 namespace SPIRV {
 
 SPIRVType *SPIRVType::getArrayElementType() const {
-  assert(OpCode == OpTypeArray && "Not array type");
-  return static_cast<const SPIRVTypeArray *>(this)->getElementType();
+  assert((OpCode == OpTypeArray || OpCode == OpTypeRuntimeArray) &&
+         "Not array type");
+  if (OpCode == OpTypeArray) {
+    return static_cast<const SPIRVTypeArray *const>(this)->getElementType();
+  }
+  return static_cast<const SPIRVTypeRuntimeArray *const>(this)
+      ->getElementType();
 }
 
 uint64_t SPIRVType::getArrayLength() const {
@@ -146,7 +151,14 @@ SPIRVType *SPIRVType::getScalarType() const {
 }
 
 bool SPIRVType::isTypeVoid() const { return OpCode == OpTypeVoid; }
-bool SPIRVType::isTypeArray() const { return OpCode == OpTypeArray; }
+
+bool SPIRVType::isTypeArray() const {
+  return OpCode == OpTypeArray || OpCode == OpTypeRuntimeArray;
+}
+
+bool SPIRVType::isTypeRuntimeArray() const {
+  return OpCode == OpTypeRuntimeArray;
+}
 
 bool SPIRVType::isTypeBool() const { return OpCode == OpTypeBool; }
 
diff --git a/lib/SPIRV/libSPIRV/SPIRVType.h b/lib/SPIRV/libSPIRV/SPIRVType.h
index 2be2f60..b816ffa 100644
--- a/lib/SPIRV/libSPIRV/SPIRVType.h
+++ b/lib/SPIRV/libSPIRV/SPIRVType.h
@@ -79,6 +79,7 @@ public:
 
   bool isTypeVoid() const;
   bool isTypeArray() const;
+  bool isTypeRuntimeArray() const;
   bool isTypeBool() const;
   bool isTypeComposite() const;
   bool isTypeEvent() const;
@@ -177,6 +178,16 @@ public:
     }
   }
 
+  // gets the signed integer type with the same bit-width as this type
+  SPIRVTypeInt *getSigned() const {
+    return Module->addIntegerType(BitWidth, true);
+  }
+
+  // gets the unsigned integer type with the same bit-width as this type
+  SPIRVTypeInt *getUnsigned() const {
+    return Module->addIntegerType(BitWidth, false);
+  }
+
 protected:
   _SPIRV_DEF_ENCDEC3(Id, BitWidth, IsSigned)
   void validate() const override {
@@ -207,11 +218,15 @@ public:
   SPIRVCapVec getRequiredCapability() const override {
     SPIRVCapVec CV;
     if (isTypeFloat(16)) {
-      CV.push_back(CapabilityFloat16Buffer);
-      auto Extensions = getModule()->getSourceExtension();
-      if (std::any_of(Extensions.begin(), Extensions.end(),
-                      [](const std::string &I) { return I == "cl_khr_fp16"; }))
+      if (Module->getSourceLanguage(nullptr) == spv::SourceLanguageGLSL) {
         CV.push_back(CapabilityFloat16);
+      } else {
+        CV.push_back(CapabilityFloat16Buffer);
+        auto Extensions = getModule()->getSourceExtension();
+        if (std::any_of(Extensions.begin(), Extensions.end(),
+                        [](const std::string &I) { return I == "cl_khr_fp16"; }))
+          CV.push_back(CapabilityFloat16);
+      }
     } else if (isTypeFloat(64))
       CV.push_back(CapabilityFloat64);
     return CV;
@@ -248,6 +263,10 @@ public:
   }
   SPIRVStorageClassKind getStorageClass() const { return ElemStorageClass; }
   SPIRVCapVec getRequiredCapability() const override {
+    // cap requirements are different for shaders and kernels
+    if (Module->getSourceLanguage(nullptr) == spv::SourceLanguageGLSL) {
+      return getCapability(ElemStorageClass);
+    }
     auto Cap = getVec(CapabilityAddresses);
     if (getElementType()->isTypeFloat(16))
       Cap.push_back(CapabilityFloat16Buffer);
@@ -411,6 +430,36 @@ private:
   SPIRVId Length;      // Array Length
 };
 
+class SPIRVTypeRuntimeArray : public SPIRVType {
+public:
+  // Complete constructor
+  SPIRVTypeRuntimeArray(SPIRVModule *M, SPIRVId TheId, SPIRVType *TheElemType)
+      : SPIRVType(M, 3, OpTypeRuntimeArray, TheId), ElemType(TheElemType) {
+    validate();
+  }
+  // Incomplete constructor
+  SPIRVTypeRuntimeArray() : SPIRVType(OpTypeRuntimeArray), ElemType(nullptr) {}
+
+  SPIRVType *getElementType() const { return ElemType; }
+  SPIRVCapVec getRequiredCapability() const override {
+    return getElementType()->getRequiredCapability();
+  }
+  std::vector<SPIRVEntry *> getNonLiteralOperands() const override {
+    std::vector<SPIRVEntry *> Operands(1, ElemType);
+    return Operands;
+  }
+
+protected:
+  _SPIRV_DEF_ENCDEC2(Id, ElemType)
+  void validate() const override {
+    SPIRVEntry::validate();
+    ElemType->validate();
+  }
+
+private:
+  SPIRVType *ElemType; // Element Type
+};
+
 class SPIRVTypeOpaque : public SPIRVType {
 public:
   // Complete constructor
@@ -469,6 +518,10 @@ inline void SPIRVMap<std::string, SPIRVTypeImageDescriptor>::init() {
   _SPIRV_OP(image2d_msaa_depth_t, Dim2D, 1, 0, 1, 0, 0)
   _SPIRV_OP(image2d_array_msaa_depth_t, Dim2D, 1, 1, 1, 0, 0)
   _SPIRV_OP(image3d_t, Dim3D, 0, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_t, DimCube, 0, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_array_t, DimCube, 0, 1, 0, 0, 0)
+  _SPIRV_OP(imagecube_depth_t, DimCube, 1, 0, 0, 0, 0)
+  _SPIRV_OP(imagecube_array_depth_t, DimCube, 1, 1, 0, 0, 0)
 #undef _SPIRV_OP
 }
 typedef SPIRVMap<std::string, SPIRVTypeImageDescriptor> OCLSPIRVImageTypeMap;
@@ -487,36 +540,44 @@ public:
   SPIRVTypeImage(SPIRVModule *M, SPIRVId TheId, SPIRVId TheSampledType,
                  const SPIRVTypeImageDescriptor &TheDesc)
       : SPIRVType(M, FixedWC, OC, TheId), SampledType(TheSampledType),
-        Desc(TheDesc) {
+        Desc(TheDesc), Acc(spv::AccessQualifierNone) {
     validate();
   }
   SPIRVTypeImage(SPIRVModule *M, SPIRVId TheId, SPIRVId TheSampledType,
                  const SPIRVTypeImageDescriptor &TheDesc,
                  SPIRVAccessQualifierKind TheAcc)
       : SPIRVType(M, FixedWC + 1, OC, TheId), SampledType(TheSampledType),
-        Desc(TheDesc) {
-    Acc.push_back(TheAcc);
+        Desc(TheDesc), Acc(TheAcc) {
     validate();
   }
   SPIRVTypeImage() : SPIRVType(OC), SampledType(SPIRVID_INVALID), Desc() {}
   const SPIRVTypeImageDescriptor &getDescriptor() const { return Desc; }
   bool isOCLImage() const { return Desc.Sampled == 0 && Desc.Format == 0; }
-  bool hasAccessQualifier() const { return !Acc.empty(); }
+  bool hasAccessQualifier() const { return Acc != spv::AccessQualifierNone; }
   SPIRVAccessQualifierKind getAccessQualifier() const {
     assert(hasAccessQualifier());
-    return Acc[0];
+    return Acc;
   }
   SPIRVCapVec getRequiredCapability() const override {
     SPIRVCapVec CV;
-    CV.push_back(CapabilityImageBasic);
-    if (Desc.Dim == SPIRVImageDimKind::Dim1D)
+    if (Module->getSourceLanguage(nullptr) != spv::SourceLanguageGLSL) {
+      CV.push_back(CapabilityImageBasic);
+      if (Acc != spv::AccessQualifierNone && Acc == AccessQualifierReadWrite)
+        CV.push_back(CapabilityImageReadWrite);
+      if (Desc.MS)
+        CV.push_back(CapabilityImageMipmap);
+    } else {
+      if (Desc.MS)
+        CV.push_back(CapabilityImageMSArray);
+    }
+    if (Desc.Dim == spv::Dim1D) {
       CV.push_back(CapabilitySampled1D);
-    else if (Desc.Dim == SPIRVImageDimKind::DimBuffer)
+      if (Desc.Sampled == 2) {
+        CV.push_back(CapabilityImage1D);
+      }
+    } else if (Desc.Dim == spv::DimBuffer) {
       CV.push_back(CapabilitySampledBuffer);
-    if (Acc.size() > 0 && Acc[0] == AccessQualifierReadWrite)
-      CV.push_back(CapabilityImageReadWrite);
-    if (Desc.MS)
-      CV.push_back(CapabilityImageMipmap);
+    }
     return CV;
   }
   SPIRVType *getSampledType() const { return get<SPIRVType>(SampledType); }
@@ -526,30 +587,39 @@ public:
   }
 
 protected:
-  _SPIRV_DEF_ENCDEC9(Id, SampledType, Desc.Dim, Desc.Depth, Desc.Arrayed,
-                     Desc.MS, Desc.Sampled, Desc.Format, Acc)
-  // The validation assumes OpenCL image or sampler type.
+  void encode(spv_ostream &O) const override {
+    getEncoder(O) << Id << SampledType << Desc.Dim << Desc.Depth << Desc.Arrayed
+                  << Desc.MS << Desc.Sampled << Desc.Format;
+    if (Acc != spv::AccessQualifierNone)
+      getEncoder(O) << Acc;
+  }
+  void decode(std::istream &I) override {
+    getDecoder(I) >> Id >> SampledType >> Desc.Dim >> Desc.Depth >>
+        Desc.Arrayed >> Desc.MS >> Desc.Sampled >> Desc.Format;
+    // TODO: test this
+    if (WordCount >= 10)
+      getDecoder(I) >> Acc;
+    else
+      Acc = spv::AccessQualifierNone;
+  }
   void validate() const override {
     assert(OpCode == OC);
-    assert(WordCount == FixedWC + Acc.size());
-    assert(SampledType != SPIRVID_INVALID && "Invalid sampled type");
-    assert(Desc.Dim <= 5);
+    assert(WordCount == FixedWC + (Acc != spv::AccessQualifierNone ? 1 : 0));
+    assert(Desc.Dim < DimMax);
     assert(Desc.Depth <= 1);
     assert(Desc.Arrayed <= 1);
     assert(Desc.MS <= 1);
-    assert(Desc.Sampled == 0); // For OCL only
-    assert(Desc.Format == 0);  // For OCL only
-    assert(Acc.size() <= 1);
+    assert(Desc.Sampled <= 2);
+    assert(Desc.Format < ImageFormatMax);
   }
   void setWordCount(SPIRVWord TheWC) override {
     WordCount = TheWC;
-    Acc.resize(WordCount - FixedWC);
   }
 
 private:
   SPIRVId SampledType;
   SPIRVTypeImageDescriptor Desc;
-  std::vector<SPIRVAccessQualifierKind> Acc;
+  SPIRVAccessQualifierKind Acc;
 };
 
 class SPIRVTypeSampler : public SPIRVType {
@@ -911,7 +981,7 @@ protected:
   }
   void setWordCount(SPIRVWord TheWC) override {
     if (TheWC > FixedWC)
-      AccessKind = SPIRVAccessQualifierKind::AccessQualifierMax;
+      AccessKind = SPIRVAccessQualifierKind::AccessQualifierNone;
     WordCount = TheWC;
   }
 
diff --git a/lib/SPIRV/libSPIRV/SPIRVUtil.h b/lib/SPIRV/libSPIRV/SPIRVUtil.h
index 0bbf6b7..0c2e33a 100644
--- a/lib/SPIRV/libSPIRV/SPIRVUtil.h
+++ b/lib/SPIRV/libSPIRV/SPIRVUtil.h
@@ -40,8 +40,13 @@
 #ifndef SPIRV_LIBSPIRV_SPIRVUTIL_H
 #define SPIRV_LIBSPIRV_SPIRVUTIL_H
 
+#if 1
+#include "llvm/Support/raw_ostream.h"
+#define spv_ostream llvm::raw_ostream
+#else
 #include <ostream>
 #define spv_ostream std::ostream
+#endif
 
 #include "llvm/Support/raw_ostream.h"
 
@@ -103,22 +108,26 @@ public:
     return Val;
   }
 
-  static const SPIRVMap &getMap() {
+  static SPIRVMap &getMapMod() {
 #if defined(_MSC_VER) && (_MSC_VER < 1900)
     llvm::sys::ScopedLock mapGuard(MapLock);
 #endif // LLVM_MSC_PREREQ(1900)
-    static const SPIRVMap Map(false);
+    static SPIRVMap Map(false);
     return Map;
   }
 
-  static const SPIRVMap &getRMap() {
+  static SPIRVMap &getRMapMod() {
 #if defined(_MSC_VER) && (_MSC_VER < 1900)
     llvm::sys::ScopedLock mapGuard(MapLock);
 #endif // LLVM_MSC_PREREQ(1900)
-    static const SPIRVMap Map(true);
+    static SPIRVMap Map(true);
     return Map;
   }
 
+  static const SPIRVMap &getMap() { return getMapMod(); }
+
+  static const SPIRVMap &getRMap() { return getRMapMod(); }
+
   static void foreach (std::function<void(Ty1, Ty2)> F) {
     for (auto &I : getMap().Map)
       F(I.first, I.second);
@@ -152,6 +161,14 @@ public:
       *Val = Loc->second;
     return true;
   }
+
+  static void replace(Ty1 Key, Ty2 Val) {
+    SPIRVMap &Map = getMapMod();
+    SPIRVMap &RMap = getRMapMod();
+    Map.Map[Key] = Val;
+    RMap.RevMap[Val] = Key;
+  }
+
   SPIRVMap() : IsReverse(false) {}
 
 protected:
diff --git a/lib/SPIRV/libSPIRV/spirv_internal.hpp b/lib/SPIRV/libSPIRV/spirv_internal.hpp
index e82a286..67152ff 100644
--- a/lib/SPIRV/libSPIRV/spirv_internal.hpp
+++ b/lib/SPIRV/libSPIRV/spirv_internal.hpp
@@ -47,6 +47,7 @@ enum InternalOp {
   IOpJointMatrixMadINTEL = 6122,
   IOpArithmeticFenceINTEL = 6145,
   IOpPrev = OpMax - 2,
+  IOpUndefValueInternal,
   IOpForward
 };
 
@@ -114,6 +115,7 @@ _SPIRV_OP(BuiltIn, MaxHWThreadIDPerSubDeviceINTEL)
 #undef _SPIRV_OP
 
 constexpr Op OpForward = static_cast<Op>(IOpForward);
+constexpr Op OpUndefValueInternal = static_cast<Op>(IOpUndefValueInternal);
 constexpr Op OpAliasDomainDeclINTEL = static_cast<Op>(IOpAliasDomainDeclINTEL);
 constexpr Op OpAliasScopeDeclINTEL = static_cast<Op>(IOpAliasScopeDeclINTEL);
 constexpr Op OpAliasScopeListDeclINTEL =
diff --git a/tools/llvm-spirv/llvm-spirv.cpp b/tools/llvm-spirv/llvm-spirv.cpp
index 4fabac2..b286c88 100644
--- a/tools/llvm-spirv/llvm-spirv.cpp
+++ b/tools/llvm-spirv/llvm-spirv.cpp
@@ -105,7 +105,8 @@ static cl::opt<VersionNumber> MaxSPIRVVersion(
                clEnumValN(VersionNumber::SPIRV_1_1, "1.1", "SPIR-V 1.1"),
                clEnumValN(VersionNumber::SPIRV_1_2, "1.2", "SPIR-V 1.2"),
                clEnumValN(VersionNumber::SPIRV_1_3, "1.3", "SPIR-V 1.3"),
-               clEnumValN(VersionNumber::SPIRV_1_4, "1.4", "SPIR-V 1.4")),
+               clEnumValN(VersionNumber::SPIRV_1_4, "1.4", "SPIR-V 1.4"),
+               clEnumValN(VersionNumber::SPIRV_1_5, "1.5", "SPIR-V 1.5")),
     cl::init(VersionNumber::MaximumVersion));
 
 static cl::list<std::string>
@@ -249,10 +250,11 @@ static int convertLLVMToSPIRV(const SPIRV::TranslatorOpts &Opts) {
   std::string Err;
   bool Success = false;
   if (OutputFile != "-") {
-    std::ofstream OutFile(OutputFile, std::ios::binary);
+    std::error_code EC {};
+    raw_fd_ostream OutFile(OutputFile, EC);
     Success = writeSpirv(M.get(), Opts, OutFile, Err);
   } else {
-    Success = writeSpirv(M.get(), Opts, std::cout, Err);
+    Success = writeSpirv(M.get(), Opts, llvm::outs(), Err);
   }
 
   if (!Success) {
@@ -323,7 +325,7 @@ static int convertSPIRV() {
     }
   }
 
-  auto Action = [&](std::ostream &OFS) {
+  auto Action = [&](llvm::raw_ostream &OFS) {
     std::string Err;
     if (!SPIRV::convertSpirv(IFS, OFS, Err, ToBinary, ToText)) {
       errs() << "Fails to convert SPIR-V : " << Err << '\n';
@@ -333,16 +335,18 @@ static int convertSPIRV() {
   };
 
   if (OutputFile == "-")
-    return Action(std::cout);
+    return Action(llvm::outs());
 
   // Open the output file in binary mode in case we convert text to SPIRV binary
   if (ToBinary) {
-    std::ofstream OFS(OutputFile, std::ios::binary);
+    std::error_code EC;
+    llvm::raw_fd_ostream OFS(OutputFile, EC);
     return Action(OFS);
   }
 
   // Convert SPIRV binary to text
-  std::ofstream OFS(OutputFile);
+  std::error_code EC;
+  llvm::raw_fd_ostream OFS(OutputFile, EC);
   return Action(OFS);
 }
 #endif
