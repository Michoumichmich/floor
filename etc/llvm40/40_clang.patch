diff --git a/.gitignore b/.gitignore
index fc84248..bac408a 100644
--- a/.gitignore
+++ b/.gitignore
@@ -18,6 +18,7 @@
 # vim swap files
 .*.sw?
 .sw?
+.DS_Store
 
 #==============================================================================#
 # Explicit files to ignore (only matches one).
diff --git a/include/clang-c/Index.h b/include/clang-c/Index.h
index 192560e..f046d66 100644
--- a/include/clang-c/Index.h
+++ b/include/clang-c/Index.h
@@ -2373,7 +2373,7 @@ enum CXCursorKind {
   CXCursor_NoDuplicateAttr               = 411,
   CXCursor_CUDAConstantAttr              = 412,
   CXCursor_CUDADeviceAttr                = 413,
-  CXCursor_CUDAGlobalAttr                = 414,
+  CXCursor_ComputeKernelAttr             = 414,
   CXCursor_CUDAHostAttr                  = 415,
   CXCursor_CUDASharedAttr                = 416,
   CXCursor_VisibilityAttr                = 417,
@@ -3023,9 +3023,13 @@ enum CXCallingConv {
   CXCallingConv_X86_64Win64 = 10,
   CXCallingConv_X86_64SysV = 11,
   CXCallingConv_X86VectorCall = 12,
-  CXCallingConv_Swift = 13,
-  CXCallingConv_PreserveMost = 14,
-  CXCallingConv_PreserveAll = 15,
+  CXCallingConv_FloorFunction = 13,
+  CXCallingConv_FloorKernel = 14,
+  CXCallingConv_FloorVertex = 15,
+  CXCallingConv_FloorFragment = 16,
+  CXCallingConv_Swift = 17,
+  CXCallingConv_PreserveMost = 18,
+  CXCallingConv_PreserveAll = 19,
 
   CXCallingConv_Invalid = 100,
   CXCallingConv_Unexposed = 200
diff --git a/include/clang/AST/ASTContext.h b/include/clang/AST/ASTContext.h
index 45127ac..09f00a5 100644
--- a/include/clang/AST/ASTContext.h
+++ b/include/clang/AST/ASTContext.h
@@ -440,6 +440,8 @@ private:
   ///  this ASTContext object.
   LangOptions &LangOpts;
 
+  bool disabledFPContract;
+
   /// \brief Blacklist object that is used by sanitizers to decide which
   /// entities should not be instrumented.
   std::unique_ptr<SanitizerBlacklist> SanitizerBL;
@@ -481,6 +483,8 @@ public:
   IntrusiveRefCntPtr<ExternalASTSource> ExternalSource;
   ASTMutationListener *Listener;
 
+  OpenCLOptions OpenCLFeatures;
+
   /// \brief Contains parents of a node.
   typedef llvm::SmallVector<ast_type_traits::DynTypedNode, 2> ParentVector;
 
@@ -630,6 +634,10 @@ public:
     return *SanitizerBL;
   }
 
+  void disableFPContract() { disabledFPContract = true; }
+
+  bool isFPContractDisabled() const { return disabledFPContract; }
+
   DiagnosticsEngine &getDiagnostics() const;
 
   FullSourceLoc getFullLoc(SourceLocation Loc) const {
diff --git a/include/clang/AST/Decl.h b/include/clang/AST/Decl.h
index 77bbdb2..5cc745c 100644
--- a/include/clang/AST/Decl.h
+++ b/include/clang/AST/Decl.h
@@ -806,7 +806,7 @@ private:
     friend class VarDecl;
     friend class ASTDeclReader;
 
-    unsigned SClass : 3;
+    unsigned SClass : 4;
     unsigned TSCSpec : 2;
     unsigned InitStyle : 2;
   };
@@ -988,6 +988,7 @@ public:
   /// storage.
   bool hasExternalStorage() const {
     return getStorageClass() == SC_Extern ||
+           getStorageClass() == SC_OpenCLConstantExtern ||
            getStorageClass() == SC_PrivateExtern;
   }
 
diff --git a/include/clang/AST/Expr.h b/include/clang/AST/Expr.h
index 7f98f00..93421a2 100644
--- a/include/clang/AST/Expr.h
+++ b/include/clang/AST/Expr.h
@@ -4811,6 +4811,16 @@ public:
     BI_First = 0
   };
 
+  // The ABI values for various atomic memory orderings.
+  enum AtomicOrderingKind {
+    AO_ABI_memory_order_relaxed = 0,
+    AO_ABI_memory_order_consume = 1,
+    AO_ABI_memory_order_acquire = 2,
+    AO_ABI_memory_order_release = 3,
+    AO_ABI_memory_order_acq_rel = 4,
+    AO_ABI_memory_order_seq_cst = 5
+  };
+
 private:
   enum { PTR, ORDER, VAL1, ORDER_FAIL, VAL2, WEAK, END_EXPR };
   Stmt* SubExprs[END_EXPR];
diff --git a/include/clang/AST/Mangle.h b/include/clang/AST/Mangle.h
index 7a45d88..b7099aa 100644
--- a/include/clang/AST/Mangle.h
+++ b/include/clang/AST/Mangle.h
@@ -146,6 +146,9 @@ public:
   /// across translation units so it can be used with LTO.
   virtual void mangleTypeName(QualType T, raw_ostream &) = 0;
 
+  virtual void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) {}
+  virtual void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) {}
+
   /// @}
 };
 
diff --git a/include/clang/AST/OperationKinds.def b/include/clang/AST/OperationKinds.def
index 03a61e9..af2c02c 100644
--- a/include/clang/AST/OperationKinds.def
+++ b/include/clang/AST/OperationKinds.def
@@ -321,10 +321,13 @@ CAST_OPERATION(BuiltinFnToFnPtr)
 // Convert a zero value for OpenCL event_t initialization.
 CAST_OPERATION(ZeroToOCLEvent)
 
+// Convert a zero value for OpenCL queue_t initialization.
+CAST_OPERATION(ZeroToOCLQueue)
+
 // Convert a pointer to a different address space.
 CAST_OPERATION(AddressSpaceConversion)
 
-// Convert an integer initializer to an OpenCL sampler.
+// Convert an integer initializer to an OpenCL sampler.
 CAST_OPERATION(IntToOCLSampler)
 
 //===- Binary Operations  -------------------------------------------------===//
diff --git a/include/clang/AST/Type.h b/include/clang/AST/Type.h
index 6bbba48..50e1f8a 100644
--- a/include/clang/AST/Type.h
+++ b/include/clang/AST/Type.h
@@ -429,10 +429,10 @@ public:
   ///   every address space is a superset of itself.
   /// CL2.0 adds:
   ///   __generic is a superset of any address space except for __constant.
-  bool isAddressSpaceSupersetOf(Qualifiers other) const {
+  bool isAddressSpaceSupersetOf(Qualifiers other, bool check_as = true) const {
     return
         // Address spaces must match exactly.
-        getAddressSpace() == other.getAddressSpace() ||
+		((check_as && getAddressSpace() == other.getAddressSpace()) || !check_as) ||
         // Otherwise in OpenCLC v2.0 s6.5.5: every address space except
         // for __constant can be used as __generic.
         (getAddressSpace() == LangAS::opencl_generic &&
@@ -442,8 +442,8 @@ public:
   /// Determines if these qualifiers compatibly include another set.
   /// Generally this answers the question of whether an object with the other
   /// qualifiers can be safely used as an object with these qualifiers.
-  bool compatiblyIncludes(Qualifiers other) const {
-    return isAddressSpaceSupersetOf(other) &&
+  bool compatiblyIncludes(Qualifiers other, bool check_as = true) const {
+    return isAddressSpaceSupersetOf(other, check_as) &&
            // ObjC GC qualifiers can match, be added, or be removed, but can't
            // be changed.
            (getObjCGCAttr() == other.getObjCGCAttr() || !hasObjCGCAttr() ||
@@ -1646,6 +1646,7 @@ public:
   bool isComplexType() const;      // C99 6.2.5p11 (complex)
   bool isAnyComplexType() const;   // C99 6.2.5p11 (complex) + Complex Int.
   bool isFloatingType() const;     // C99 6.2.5p11 (real floating + complex)
+  bool isDoubleType() const;       // (double + long double)
   bool isHalfType() const;         // OpenCL 6.1.1.1, NEON (IEEE 754-2008 half)
   bool isRealType() const;         // C99 6.2.5p17 (real floating + integer)
   bool isArithmeticType() const;   // C99 6.2.5p18 (integer + floating)
@@ -1655,6 +1656,12 @@ public:
   bool isFundamentalType() const;
   bool isCompoundType() const;
 
+  // Vector categories
+  bool isFloatingVecType() const;
+  bool isDoubleVecType() const;
+  bool isIntegerVecType() const;
+  bool isRealVecType() const;
+
   // Type Predicates: Check to see if this type is structurally the specified
   // type, ignoring typedefs and qualifiers.
   bool isFunctionType() const;
@@ -1737,12 +1744,16 @@ public:
 
   bool isImageType() const;                     // Any OpenCL image type
 
+  bool isAggregateImageType() const;            // struct/class containing only image*_t members
+  bool isArrayImageType(bool single_field_arr) const; // array of aggregate images
+
   bool isSamplerT() const;                      // OpenCL sampler_t
   bool isEventT() const;                        // OpenCL event_t
   bool isClkEventT() const;                     // OpenCL clk_event_t
   bool isQueueT() const;                        // OpenCL queue_t
   bool isNDRangeT() const;                      // OpenCL ndrange_t
   bool isReserveIDT() const;                    // OpenCL reserve_id_t
+  bool isExecType() const;                      // OpenCL 2.0 execution model types
 
   bool isPipeType() const;                      // OpenCL pipe type
   bool isOpenCLSpecificType() const;            // Any OpenCL specific type
@@ -3799,6 +3810,9 @@ public:
     attr_sysv_abi,
     attr_preserve_most,
     attr_preserve_all,
+    attr_floor_vertex,
+    attr_floor_fragment,
+    attr_floor_kernel,
     attr_ptr32,
     attr_ptr64,
     attr_sptr,
@@ -5406,7 +5420,7 @@ inline FunctionType::ExtInfo getFunctionExtInfo(QualType t) {
 inline bool QualType::isMoreQualifiedThan(QualType other) const {
   Qualifiers MyQuals = getQualifiers();
   Qualifiers OtherQuals = other.getQualifiers();
-  return (MyQuals != OtherQuals && MyQuals.compatiblyIncludes(OtherQuals));
+  return (MyQuals != OtherQuals && MyQuals.compatiblyIncludes(OtherQuals, false));
 }
 
 /// Determine whether this type is at last
@@ -5420,7 +5434,7 @@ inline bool QualType::isAtLeastAsQualifiedAs(QualType other) const {
   if (getUnqualifiedType()->isVoidType())
     OtherQuals.removeUnaligned();
 
-  return getQualifiers().compatiblyIncludes(OtherQuals);
+  return getQualifiers().compatiblyIncludes(OtherQuals, false);
 }
 
 /// If Type is a reference type (e.g., const
@@ -5598,9 +5612,9 @@ inline bool Type::isObjCBuiltinType() const {
 }
 
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-  inline bool Type::is##Id##Type() const { \
-    return isSpecificBuiltinType(BuiltinType::Id); \
-  }
+inline bool Type::is##Id##Type() const { \
+  return isSpecificBuiltinType(BuiltinType::Id); \
+}
 #include "clang/Basic/OpenCLImageTypes.def"
 
 inline bool Type::isSamplerT() const {
@@ -5627,6 +5641,11 @@ inline bool Type::isReserveIDT() const {
   return isSpecificBuiltinType(BuiltinType::OCLReserveID);
 }
 
+inline bool Type::isExecType() const {
+ return isSpecificBuiltinType(BuiltinType::OCLQueue) ||
+        isSpecificBuiltinType(BuiltinType::OCLClkEvent);
+}
+
 inline bool Type::isImageType() const {
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) is##Id##Type() ||
   return
@@ -5640,7 +5659,8 @@ inline bool Type::isPipeType() const {
 
 inline bool Type::isOpenCLSpecificType() const {
   return isSamplerT() || isEventT() || isImageType() || isClkEventT() ||
-         isQueueT() || isNDRangeT() || isReserveIDT() || isPipeType();
+         isQueueT() || isNDRangeT() || isReserveIDT() || isPipeType() ||
+         isAggregateImageType();
 }
 
 inline bool Type::isTemplateTypeParmType() const {
diff --git a/include/clang/Basic/Attr.td b/include/clang/Basic/Attr.td
index 7da1efe..89bd090 100644
--- a/include/clang/Basic/Attr.td
+++ b/include/clang/Basic/Attr.td
@@ -118,7 +118,7 @@ def FunctionLike : SubsetSubject<DeclBase,
                                   [{S->getFunctionType(false) != nullptr}]>;
 
 def OpenCLKernelFunction : SubsetSubject<Function, [{
-  S->hasAttr<OpenCLKernelAttr>()
+  S->hasAttr<ComputeKernelAttr>()
 }]>;
 
 // HasFunctionProto is a more strict version of FunctionLike, so it should
@@ -599,13 +599,6 @@ def Constructor : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAConstant : InheritableAttr {
-  let Spellings = [GNU<"constant">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDACudartBuiltin : IgnoredAttr {
   let Spellings = [GNU<"cudart_builtin">];
   let LangOpts = [CUDA];
@@ -633,13 +626,6 @@ def CUDADeviceBuiltinTextureType : IgnoredAttr {
   let LangOpts = [CUDA];
 }
 
-def CUDAGlobal : InheritableAttr {
-  let Spellings = [GNU<"global">];
-  let Subjects = SubjectList<[Function]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDAHost : InheritableAttr {
   let Spellings = [GNU<"host">];
   let Subjects = SubjectList<[Function]>;
@@ -666,13 +652,6 @@ def CUDALaunchBounds : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAShared : InheritableAttr {
-  let Spellings = [GNU<"shared">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def C11NoReturn : InheritableAttr {
   let Spellings = [Keyword<"_Noreturn">];
   let Subjects = SubjectList<[Function], ErrorDiag>;
@@ -686,12 +665,30 @@ def CXX11NoReturn : InheritableAttr {
   let Documentation = [CXX11NoReturnDocs];
 }
 
-def OpenCLKernel : InheritableAttr {
-  let Spellings = [Keyword<"__kernel">, Keyword<"kernel">];
+def ComputeKernel : InheritableAttr {
+  let Spellings = [GNU<"compute_kernel">, CXX11<"","compute_kernel", 200809>];
   let Subjects = SubjectList<[Function], ErrorDiag>;
   let Documentation = [Undocumented];
 }
 
+def GraphicsVertexShader : InheritableAttr {
+  let Spellings = [GNU<"vertex_shader">, CXX11<"","vertex_shader", 200809>];
+  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def GraphicsFragmentShader : InheritableAttr {
+  let Spellings = [GNU<"fragment_shader">, CXX11<"","fragment_shader", 200809>];
+  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def RetRange : InheritableAttr {
+  let Spellings = [GNU<"range">, CXX11<"","range", 200809>];
+  let Args = [ExprArgument<"LowerBound">, ExprArgument<"UpperBound">];
+  let Documentation = [Undocumented];
+}
+
 def OpenCLUnrollHint : InheritableAttr {
   let Spellings = [GNU<"opencl_unroll_hint">];
   let Args = [UnsignedArgument<"UnrollHint">];
@@ -700,43 +697,41 @@ def OpenCLUnrollHint : InheritableAttr {
 
 // This attribute is both a type attribute, and a declaration attribute (for
 // parameter variables).
-def OpenCLAccess : Attr {
-  let Spellings = [Keyword<"__read_only">, Keyword<"read_only">,
-                   Keyword<"__write_only">, Keyword<"write_only">,
-                   Keyword<"__read_write">, Keyword<"read_write">];
-  let Subjects = SubjectList<[ParmVar, TypedefName], ErrorDiag,
-                             "ExpectedParameterOrTypedef">;
-  let Accessors = [Accessor<"isReadOnly", [Keyword<"__read_only">,
-                                           Keyword<"read_only">]>,
-                   Accessor<"isReadWrite", [Keyword<"__read_write">,
-                                            Keyword<"read_write">]>,
-                   Accessor<"isWriteOnly", [Keyword<"__write_only">,
-                                            Keyword<"write_only">]>];
-  let Documentation = [OpenCLAccessDocs];
-}
-
-def OpenCLPrivateAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__private">, Keyword<"private">];
+def ImageAccess : Attr {
+  let Spellings = [GNU<"image_read_only">, CXX11<"","image_read_only", 200809>,
+                   GNU<"image_write_only">, CXX11<"","image_write_only", 200809>,
+                   GNU<"image_read_write">, CXX11<"","image_read_write", 200809>];
+  let Accessors = [Accessor<"isReadOnly", [GNU<"image_read_only">,
+										   CXX11<"","image_read_only", 200809>]>,
+                   Accessor<"isReadWrite", [GNU<"image_read_write">,
+											CXX11<"","image_read_write", 200809>]>,
+                   Accessor<"isWriteOnly", [GNU<"image_write_only">,
+											CXX11<"","image_write_only", 200809>]>];
+  let Documentation = [Undocumented];
+}
+
+def PrivateAddressSpace : TypeAttr {
+  let Spellings = [GNU<"private_as">, CXX11<"","private_as", 200809>];
   let Documentation = [OpenCLAddressSpacePrivateDocs];
 }
 
-def OpenCLGlobalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__global">, Keyword<"global">];
+def GlobalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"global_as">, CXX11<"","global_as", 200809>];
   let Documentation = [OpenCLAddressSpaceGlobalDocs];
 }
 
-def OpenCLLocalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__local">, Keyword<"local">];
+def LocalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"local_as">, CXX11<"","local_as", 200809>];
   let Documentation = [OpenCLAddressSpaceLocalDocs];
 }
 
-def OpenCLConstantAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__constant">, Keyword<"constant">];
+def ConstantAddressSpace : TypeAttr {
+  let Spellings = [GNU<"constant_as">, CXX11<"","constant_as", 200809>];
   let Documentation = [OpenCLAddressSpaceConstantDocs];
 }
 
-def OpenCLGenericAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__generic">, Keyword<"generic">];
+def GenericAddressSpace : TypeAttr {
+  let Spellings = [GNU<"generic_as">, CXX11<"","generic_as", 200809>];
   let Documentation = [OpenCLAddressSpaceGenericDocs];
 }
 
@@ -755,6 +750,79 @@ def RenderScriptKernel : Attr {
   let LangOpts = [RenderScript];
 }
 
+// CUDA address space attrs are not type attrs, so they need to be handled specially
+def CUDAShared : InheritableAttr {
+  let Spellings = [GNU<"local_cuda">, CXX11<"","local_cuda", 200809>];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def CUDAConstant : InheritableAttr {
+  let Spellings = [GNU<"constant_cuda">, CXX11<"","constant_cuda", 200809>];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def FloorImageDataType : InheritableAttr {
+  let Spellings = [GNU<"floor_image">, CXX11<"","floor_image", 200809>];
+  let Args = [TypeArgument<"ImageDataType">];
+  let TemplateDependent = 1;
+  let Documentation = [Undocumented];
+}
+
+// on aggregate types this signals that they can be converted/coerced to the corresponding clang/llvm vector type
+def VectorCompat : InheritableAttr {
+  let Spellings = [GNU<"vector_compat">, CXX11<"","vector_compat", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// fbo color output location
+def GraphicsFBOColorLocation : InheritableAttr {
+  let Spellings = [GNU<"color">, CXX11<"","color", 200809>];
+  let Args = [ExprArgument<"ColorLocation">];
+  let TemplateDependent = 1;
+  let AdditionalMembers = [{
+  unsigned int eval_location = 0;
+  unsigned int getEvalLocation() const {
+    return eval_location;
+  }
+  void setEvalLocation(unsigned int loc) {
+    eval_location = loc;
+  }
+  }];
+  let Documentation = [Undocumented];
+}
+
+// fbo explicit writable depth with depth type
+def GraphicsFBODepthType : InheritableAttr {
+  let Spellings = [GNU<"depth">, CXX11<"","depth", 200809>];
+  let Args = [EnumArgument<"DepthQualifier", "DepthQualifierType",
+                           ["any", "greater", "less"],
+                           ["FBODepthTypeAny", "FBODepthTypeGreater", "FBODepthTypeLess"]>];
+  let Documentation = [Undocumented];
+}
+
+// vertex output position (used in vertex output structs)
+def GraphicsVertexPosition : InheritableAttr {
+  let Spellings = [GNU<"position">, CXX11<"","position", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// vertex/point output size (used in vertex output structs)
+def GraphicsPointSize : InheritableAttr {
+  let Spellings = [GNU<"point_size">, CXX11<"","point_size", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// stage input (just fragment shader input right now)
+def GraphicsStageInput : Attr {
+  let Spellings = [GNU<"stage_input">, CXX11<"","stage_input", 200809>];
+  let Subjects = SubjectList<[ParmVar], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
 def Deprecated : InheritableAttr {
   let Spellings = [GCC<"deprecated">, Declspec<"deprecated">,
                    CXX11<"","deprecated", 201309>];
diff --git a/include/clang/Basic/Builtins.def b/include/clang/Basic/Builtins.def
index 96bb359..37c9c4e 100644
--- a/include/clang/Basic/Builtins.def
+++ b/include/clang/Basic/Builtins.def
@@ -119,9 +119,11 @@ BUILTIN(__builtin_frexpl, "LdLdi*", "Fn")
 BUILTIN(__builtin_huge_val, "d", "nc")
 BUILTIN(__builtin_huge_valf, "f", "nc")
 BUILTIN(__builtin_huge_vall, "Ld", "nc")
+BUILTIN(__builtin_huge_valh, "h", "nc")
 BUILTIN(__builtin_inf  , "d"   , "nc")
 BUILTIN(__builtin_inff , "f"   , "nc")
 BUILTIN(__builtin_infl , "Ld"  , "nc")
+BUILTIN(__builtin_infh , "h"   , "nc")
 BUILTIN(__builtin_labs , "LiLi"  , "Fnc")
 BUILTIN(__builtin_llabs, "LLiLLi", "Fnc")
 BUILTIN(__builtin_ldexp , "ddi"  , "Fnc")
@@ -133,9 +135,11 @@ BUILTIN(__builtin_modfl, "LdLdLd*", "Fn")
 BUILTIN(__builtin_nan,  "dcC*" , "ncF")
 BUILTIN(__builtin_nanf, "fcC*" , "ncF")
 BUILTIN(__builtin_nanl, "LdcC*", "ncF")
+BUILTIN(__builtin_nanh, "hcC*" , "ncF")
 BUILTIN(__builtin_nans,  "dcC*" , "ncF")
 BUILTIN(__builtin_nansf, "fcC*" , "ncF")
 BUILTIN(__builtin_nansl, "LdcC*", "ncF")
+BUILTIN(__builtin_nansh, "hcC*" , "ncF")
 BUILTIN(__builtin_powi , "ddi"  , "Fnc")
 BUILTIN(__builtin_powif, "ffi"  , "Fnc")
 BUILTIN(__builtin_powil, "LdLdi", "Fnc")
diff --git a/include/clang/Basic/Cuda.h b/include/clang/Basic/Cuda.h
index ad1139b..c0a514a 100644
--- a/include/clang/Basic/Cuda.h
+++ b/include/clang/Basic/Cuda.h
@@ -21,6 +21,7 @@ enum class CudaVersion {
   CUDA_70,
   CUDA_75,
   CUDA_80,
+  CUDA_90,
 };
 const char *CudaVersionToString(CudaVersion V);
 
@@ -41,6 +42,8 @@ enum class CudaArch {
   SM_60,
   SM_61,
   SM_62,
+  SM_70,
+  SM_72,
 };
 const char *CudaArchToString(CudaArch A);
 
@@ -60,6 +63,8 @@ enum class CudaVirtualArch {
   COMPUTE_60,
   COMPUTE_61,
   COMPUTE_62,
+  COMPUTE_70,
+  COMPUTE_72,
 };
 const char *CudaVirtualArchToString(CudaVirtualArch A);
 
diff --git a/include/clang/Basic/DiagnosticDriverKinds.td b/include/clang/Basic/DiagnosticDriverKinds.td
index 33d2af0..9f3ab24 100644
--- a/include/clang/Basic/DiagnosticDriverKinds.td
+++ b/include/clang/Basic/DiagnosticDriverKinds.td
@@ -99,6 +99,8 @@ def err_drv_invalid_argument_to_fdebug_prefix_map : Error<
   "invalid argument '%0' to -fdebug-prefix-map">;
 def err_drv_malformed_sanitizer_blacklist : Error<
   "malformed sanitizer blacklist: '%0'">;
+def err_drv_floor_function_info : Error<
+  "unable to open floor function info file">, DefaultFatal;
 
 def err_target_unsupported_arch
   : Error<"the target architecture '%0' is not supported by the target '%1'">;
diff --git a/include/clang/Basic/DiagnosticGroups.td b/include/clang/Basic/DiagnosticGroups.td
index d480235..00de79f 100644
--- a/include/clang/Basic/DiagnosticGroups.td
+++ b/include/clang/Basic/DiagnosticGroups.td
@@ -872,12 +872,12 @@ def CudaCompat : DiagGroup<"cuda-compat">;
 // A warning group for things that will change semantics in the future.
 def FutureCompat : DiagGroup<"future-compat">;
 
+// A warning group for warnings about code that clang accepts when
+// compiling OpenCL C/C++ but which is not compatible with the SPIR spec.
+def SpirCompat : DiagGroup<"spir-compat">;
+
 def InvalidOrNonExistentDirectory : DiagGroup<"invalid-or-nonexistent-directory">;
 
 def OptionIgnored : DiagGroup<"option-ignored">;
 
 def UnknownArgument : DiagGroup<"unknown-argument">;
-
-// A warning group for warnings about code that clang accepts when
-// compiling OpenCL C/C++ but which is not compatible with the SPIR spec.
-def SpirCompat : DiagGroup<"spir-compat">;
\ No newline at end of file
diff --git a/include/clang/Basic/DiagnosticIDs.h b/include/clang/Basic/DiagnosticIDs.h
index fcd04a0..d13ae4c 100644
--- a/include/clang/Basic/DiagnosticIDs.h
+++ b/include/clang/Basic/DiagnosticIDs.h
@@ -36,7 +36,7 @@ namespace clang {
       DIAG_START_AST           = DIAG_START_PARSE           +  500,
       DIAG_START_COMMENT       = DIAG_START_AST             +  110,
       DIAG_START_SEMA          = DIAG_START_COMMENT         +  100,
-      DIAG_START_ANALYSIS      = DIAG_START_SEMA            + 3500,
+      DIAG_START_ANALYSIS      = DIAG_START_SEMA            + 4000,
       DIAG_UPPER_LIMIT         = DIAG_START_ANALYSIS        +  100
     };
 
diff --git a/include/clang/Basic/DiagnosticParseKinds.td b/include/clang/Basic/DiagnosticParseKinds.td
index 34280b9..0c4a4f4 100644
--- a/include/clang/Basic/DiagnosticParseKinds.td
+++ b/include/clang/Basic/DiagnosticParseKinds.td
@@ -960,8 +960,12 @@ def warn_pragma_unsupported_extension : Warning<
   "unsupported OpenCL extension %0 - ignoring">, InGroup<IgnoredPragmas>;
 def warn_pragma_extension_is_core : Warning<
   "OpenCL extension %0 is core feature or supported optional core feature - ignoring">, InGroup<DiagGroup<"pedantic-core-features">>, DefaultIgnore;
+def err_pragma_enabled_unsupported : Error<
+  "OpenCL extension %0 is unsupported">;
 
 // OpenCL errors.
+def err_opencl_address_of_label : Error<
+  "OpenCL does not support address of label ('&&') GNU extension">;
 def err_opencl_taking_function_address_parser : Error<
   "taking address of function is not allowed">;
 def err_opencl_logical_exclusive_or : Error<
diff --git a/include/clang/Basic/DiagnosticSemaKinds.td b/include/clang/Basic/DiagnosticSemaKinds.td
index bf6e6ec..21de9ec 100644
--- a/include/clang/Basic/DiagnosticSemaKinds.td
+++ b/include/clang/Basic/DiagnosticSemaKinds.td
@@ -327,6 +327,8 @@ def warn_implicit_function_decl : Warning<
 def ext_implicit_function_decl : ExtWarn<
   "implicit declaration of function %0 is invalid in C99">,
   InGroup<ImplicitFunctionDeclare>;
+def err_opencl_implicit_function_decl : Error<
+  "implicit declaration of function %0 is invalid in OpenCL">;
 def note_function_suggestion : Note<"did you mean %0?">;
 
 def err_ellipsis_first_param : Error<
@@ -644,6 +646,7 @@ def ext_main_used : Extension<
 /// parser diagnostics
 def ext_no_declarators : ExtWarn<"declaration does not declare anything">,
   InGroup<MissingDeclarations>;
+def err_no_declarators : Error<"declaration does not declare anything">;
 def ext_typedef_without_a_name : ExtWarn<"typedef requires a name">,
   InGroup<MissingDeclarations>;
 def err_typedef_not_identifier : Error<"typedef name must be an identifier">;
@@ -658,9 +661,14 @@ def err_object_cannot_be_passed_returned_by_value : Error<
   "; did you forget * in %1?">;
 def err_parameters_retval_cannot_have_fp16_type : Error<
   "%select{parameters|function return value}0 cannot have __fp16 type; did you forget * ?">;
+def err_opencl_dereferencing : Error<
+  "dereferencing pointer of type %0 is not allowed">;
 def err_opencl_half_load_store : Error<
   "%select{loading directly from|assigning directly to}0 pointer to type %1 is not allowed">;
+def err_opencl_subscript : Error<
+  "subscript to array of type %0 is not allowed">;
 def err_opencl_cast_to_half : Error<"casting to type %0 is not allowed">;
+def err_opencl_cast_from_half : Error<"casting from type %0 is not allowed">;
 def err_opencl_half_declaration : Error<
   "declaring variable of type %0 is not allowed">;
 def err_opencl_half_param : Error<
@@ -7484,6 +7492,18 @@ def err_builtin_annotation_first_arg : Error<
 def err_builtin_annotation_second_arg : Error<
   "second argument to __builtin_annotation must be a non-wide string constant">;
 
+// Builtin pipe
+def err_builtin_pipe_first_arg : Error<
+  "first argument to %0 must be a pipe type">;
+def err_builtin_pipe_argument_type_mismatch : Error<
+  "argument type doesn't match pipe type">;
+def err_builtin_pipe_args_num_mismatch : Error<
+  "invalid number of arguments to function: %0">;
+def err_builtin_pipe_invalid_arg : Error<
+  "invalid argument type to function %0 (expecting: %1)">;
+def err_builtin_pipe_invalid_access_modifier : Error<"invalid pipe access modifier (expecting %0)">;
+
+
 // CFString checking
 def err_cfstring_literal_not_string_constant : Error<
   "CFString literal is not a string constant">;
@@ -7956,6 +7976,49 @@ def err_sampler_initializer_not_integer : Error<
   "sampler_t initialization requires 32-bit integer, not %0">;
 def warn_sampler_initializer_invalid_bits : Warning<
   "sampler initializer has invalid %0 bits">, InGroup<SpirCompat>, DefaultIgnore;
+def err_event_initialization : Error<
+  "cannot initialize event_t">;
+def err_event_argument_not_null : Error<
+  "event_t variable or NULL required - got %0">;
+def err_opencl_missing_type_specifier : Error<
+  "type specifier missing">;
+def err_program_scope_variable_non_constant : Error<
+  "program scope variables are required to be declared in constant address space">;
+def err_program_scope_variable_non_constant_or_global : Error<
+  "program scope variables are required to be declared either in constant or global address space">;
+def err_half_variables : Error<
+  "half type variables are not allowed in OpenCL">;
+def err_invalid_vector_promotion : Error<
+  "cannot apply default argument promotion on a vector">;
+def err_implicit_pointer_address_space_cast : Error<
+  "illegal implicit conversion between two pointers with different address "
+  "spaces">;
+def err_static_variables : Error<
+  "static storage class can be specified only for global and constant variables">;
+def err_enqueue_kernel_num_args_mismatch : Error<
+  "number of local_size argument doesn't match the block's prototype">;
+def err_variadic_enqueue_kernel : Error<
+  "variadic arguments passed to 'enqueue_kernel' has to be of type 'unsigned int'">;
+def err_kernel_arg_address_space : Error<
+  "pointer arguments to kernel functions must reside in '__global', '__constant' or '__local' address space">;
+def err_opencl_pointer_to_image : Error<
+  "pointer to image is invalid in OpenCL">;
+def err_scalar_type_rank_greater_than_vector_type : Error<
+  "scalar operand type has greater rank than the type of the vector element. (%0 and %1)">;
+// Images.
+def err_sampler_initializer_not_constant : Error<
+  "sampler_t initialization requires compile time constant">;
+def err_opencl_image3d_writes : Error<
+  "image3d_t access qualifier write_only requires"
+  " cl_khr_3d_image_writes extension to be enabled">;
+def warn_opencl_image_access_non_image : Warning<
+  "using image access qualifier with non-image type">;
+def err_opencl_image_access_read_write : Error<
+  "image access qualifier read_write is reserved for future use">;
+def err_depth_image_requires_ext : Error<
+  "use of depth image type requires extension cl_khr_depth_images">;
+def err_msaa_image_requires_ext : Error<
+  "use of multi-sample image type requires extension cl_khr_gl_msaa_sharing">;
 def err_sampler_argument_required : Error<
   "sampler_t variable required - got %0">;
 def err_wrong_sampler_addressspace: Error<
@@ -7964,10 +8027,44 @@ def error_opencl_cast_non_zero_to_event_t : Error<
   "cannot cast non-zero value '%0' to 'event_t'">;
 def err_opencl_global_invalid_addr_space : Error<
   "%select{program scope|static local|extern}0 variable must reside in %1 address space">;
+def err_read_write_with_samplers : Error <
+  "reading from an image declared with 'read_write' qualifier using a sampler is prohibited">;
+def err_image_type_can_be_used_only_as_parameter : Error <
+  "An image type can only be used as a type of a function parameter">;
+// Atomics.
+def err_atomic_init_addressspace : Error<
+  "initialization of atomic variables is restricted to variables in global address space">;
+def err_atomic_init_constant : Error<
+  "atomic variable can only be assigned to a compile time constant"
+  " in the declaration statement in the program scope">;
+// Blocks.
+def err_invalid_block_as_parameter : Error<
+  "block parameter given must take pointers to local memory as parameters (prototype is %0)">;
+def err_block_proto_variadic : Error<
+  "Invalid block prototype, variadic arguments are not allowed">;
+def err_invalid_block_array : Error<
+  "Array of block is invalid in OpenCL">;
+def err_ternary_with_block : Error<
+  "blocks cannot be used as expressions in ternary expressions">;
+// Pipes.
+def err_pipe_can_be_used_only_as_parameter : Error<
+  "pipes can be used only as function parameters">;
+def err_read_write_not_allowed_for_pipes : Error<
+  "read_write access qualifier can't be specified for pipes">;
+def err_mismatch_access_qualifiers : Error<
+  "passing '%0' to '%1' mismatch access qualifiers">;
 def err_missing_actual_pipe_type : Error<
   "missing actual type specifier for pipe">;
+def err_multiple_access_qualifiers : Error<
+  "multiple access qualifiers">;
 def err_reference_pipe_type : Error <
   "pipes packet types cannot be of reference type">;
+def err_nosvm_attr_not_pointer : Error<
+  "nosvm attribute should be used with pointer variables only">;
+def err_nosvm_opencl_version : Error<
+  "nosvm attribute supported in OpenCL 2.0 and above">;
+def warn_ocl_bultin_potential_ambiguity : Warning<
+  "implicit conversion from integral type to floating point type for overloadable function might lead to ambiguity">;
 def err_opencl_no_main : Error<"%select{function|kernel}0 cannot be called 'main'">;
 def err_opencl_kernel_attr :
   Error<"attribute %0 can only be applied to a kernel function">;
@@ -7975,9 +8072,6 @@ def err_opencl_return_value_with_address_space : Error<
   "return value cannot be qualified with address space">;
 def err_opencl_constant_no_init : Error<
   "variable in constant address space must be initialized">;
-def err_atomic_init_constant : Error<
-  "atomic variable can only be assigned to a compile time constant"
-  " in the declaration statement in the program scope">;
 def err_opencl_implicit_vector_conversion : Error<
   "implicit conversions between vector types (%0 and %1) are not permitted">;
 def err_opencl_block_proto_variadic : Error<
@@ -8458,6 +8552,8 @@ def note_related_result_type_inferred : Note<
 def note_related_result_type_explicit : Note<
   "%select{overridden|current}0 method is explicitly declared 'instancetype'"
   "%select{| and is expected to return an instance of its class type}0">;
+def err_invalid_type_for_program_scope_var : Error<
+  "the %0 type cannot be used to declare a program scope variable">;
 
 }
 
diff --git a/include/clang/Basic/LangOptions.def b/include/clang/Basic/LangOptions.def
index 764e9bc..aab5e10 100644
--- a/include/clang/Basic/LangOptions.def
+++ b/include/clang/Basic/LangOptions.def
@@ -178,6 +178,8 @@ ENUM_LANGOPT(DefaultCallingConv, DefaultCallingConvention, 3, DCC_None, "default
 LANGOPT(ShortEnums        , 1, 0, "short enum types")
 
 LANGOPT(OpenCL            , 1, 0, "OpenCL")
+LANGOPT(Metal             , 1, 0, "Metal")
+LANGOPT(Vulkan            , 1, 0, "Vulkan")
 LANGOPT(OpenCLVersion     , 32, 0, "OpenCL version")
 LANGOPT(NativeHalfType    , 1, 0, "Native half type support")
 LANGOPT(NativeHalfArgsAndReturns, 1, 0, "Native half args and returns")
@@ -256,6 +258,10 @@ LANGOPT(SanitizeAddressFieldPadding, 2, 0, "controls how aggressive is ASan "
                                            "field padding (0: none, 1:least "
                                            "aggressive, 2: more aggressive)")
 
+LANGOPT(CLEnableHalf            , 1, 0, "cl-enable-half flag used")
+LANGOPT(CLSamplerOpaque, 1, 0, "Emit sampler as a pointer to opaque structure")
+LANGOPT(CLVerifySPIR            , 1, 0, "cl-verify-spir flag used")
+
 #undef LANGOPT
 #undef COMPATIBLE_LANGOPT
 #undef BENIGN_LANGOPT
diff --git a/include/clang/Basic/LangOptions.h b/include/clang/Basic/LangOptions.h
index 6ec499f..e3b3c9a 100644
--- a/include/clang/Basic/LangOptions.h
+++ b/include/clang/Basic/LangOptions.h
@@ -20,6 +20,7 @@
 #include "clang/Basic/ObjCRuntime.h"
 #include "clang/Basic/Sanitizers.h"
 #include "clang/Basic/Visibility.h"
+#include "clang/Basic/OpenCLOptions.h"
 #include <string>
 #include <vector>
 
@@ -82,6 +83,10 @@ public:
     MSVC2015 = 19
   };
 
+  std::fstream* floor_function_info { nullptr };
+  unsigned int floor_image_capabilities { 0 };
+  bool metal_no_array_image { false };
+
 public:
   /// \brief Set of enabled sanitizers.
   SanitizerSet Sanitize;
diff --git a/include/clang/Basic/OpenCLExtensions.def b/include/clang/Basic/OpenCLExtensions.def
index 360fec4..9db39c4 100644
--- a/include/clang/Basic/OpenCLExtensions.def
+++ b/include/clang/Basic/OpenCLExtensions.def
@@ -67,10 +67,12 @@ OPENCLEXT_INTERNAL(cl_khr_spir, 120, ~0U)
 // OpenCL 2.0.
 OPENCLEXT_INTERNAL(cl_khr_egl_event, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_egl_image, 200, ~0U)
-OPENCLEXT_INTERNAL(cl_khr_mipmap_image, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_srgb_image_writes, 200, ~0U)
-OPENCLEXT_INTERNAL(cl_khr_subgroups, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_terminate_context, 200, ~0U)
+// technically OpenCL 2.0, but Intel supports these with OpenCL/SPIR 1.2
+OPENCLEXT_INTERNAL(cl_khr_mipmap_image, 120, ~0U)
+OPENCLEXT_INTERNAL(cl_khr_mipmap_image_writes, 120, ~0U)
+OPENCLEXT_INTERNAL(cl_khr_subgroups, 120, ~0U)
 
 // Clang Extensions.
 OPENCLEXT_INTERNAL(cl_clang_storage_class_specifiers, 100, ~0U)
@@ -79,6 +81,15 @@ OPENCLEXT_INTERNAL(cl_clang_storage_class_specifiers, 100, ~0U)
 OPENCLEXT_INTERNAL(cl_amd_media_ops, 100, ~0U)
 OPENCLEXT_INTERNAL(cl_amd_media_ops2, 100, ~0U)
 
+// Intel Vendor Extensions
+OPENCLEXT_INTERNAL(cl_intel_subgroups, 120, ~0U)
+
+// Vulkan capabilities and extensions
+OPENCLEXT_INTERNAL(vk_capability_int16, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_int64, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_float16, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_float64, 100, ~0U)
+
 #undef OPENCLEXT_INTERNAL
 
 #ifdef OPENCLEXT
diff --git a/include/clang/Basic/OpenCLImageTypes.def b/include/clang/Basic/OpenCLImageTypes.def
index 9b92992..8b6f578 100644
--- a/include/clang/Basic/OpenCLImageTypes.def
+++ b/include/clang/Basic/OpenCLImageTypes.def
@@ -11,27 +11,42 @@
 //    GENERIC_IMAGE_TYPE(Type, Id) - a generic image with its Id without an 
 //      access type
 //    IMAGE_TYPE(Type, Id, SingletonId, AccessType, CGSuffix) - an image type
-//      with given ID, singleton ID access type and a codegen suffix  
+//      with given ID, singleton ID access type and a codegen suffix
 
 #ifdef GENERIC_IMAGE_TYPE
 
 #define IMAGE_READ_TYPE(Type, Id) GENERIC_IMAGE_TYPE(Type, Id)
-#define IMAGE_WRITE_TYPE(Type, Id) 
-#define IMAGE_READ_WRITE_TYPE(Type, Id) 
+#define IMAGE_WRITE_TYPE(Type, Id)
+#define IMAGE_READ_WRITE_TYPE(Type, Id)
+
+#else
+
+// NOTE/TODO:
+// this new method of using ro/wo/rw specific image types does not yet
+// work everywhere, is generally incompatible to SPIR 1.2 itself, and I'll
+// not backport this for clang/llvm 3.5
+// -> use the new facilities, but keep using the old/standard type names
+#if 1
+
+#define IMAGE_READ_TYPE(Type, Id) IMAGE_TYPE(Type, Id, Id##Ty, , )
+#define IMAGE_WRITE_TYPE(Type, Id)
+#define IMAGE_READ_WRITE_TYPE(Type, Id)
 
 #else
 
 #ifndef IMAGE_READ_TYPE
 #define IMAGE_READ_TYPE(Type, Id) \
-          IMAGE_TYPE(Type, Id##RO, Id##ROTy,  read_only, ro)
+          IMAGE_TYPE(Type, Id##RO, Id##ROTy,  read_only, _ro)
 #endif
 #ifndef IMAGE_WRITE_TYPE
 #define IMAGE_WRITE_TYPE(Type, Id) \
-          IMAGE_TYPE(Type, Id##WO, Id##WOTy, write_only, wo)
+          IMAGE_TYPE(Type, Id##WO, Id##WOTy, write_only, _wo)
 #endif
 #ifndef IMAGE_READ_WRITE_TYPE
 #define IMAGE_READ_WRITE_TYPE(Type, Id) \
-          IMAGE_TYPE(Type, Id##RW, Id##RWTy, read_write, rw)
+          IMAGE_TYPE(Type, Id##RW, Id##RWTy, read_write, _rw)
+#endif
+
 #endif
 
 #endif
@@ -48,6 +63,10 @@ IMAGE_READ_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA)
 IMAGE_READ_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth)
 IMAGE_READ_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth)
 IMAGE_READ_TYPE(image3d, OCLImage3d)
+IMAGE_READ_TYPE(imagecube, OCLImageCube)
+IMAGE_READ_TYPE(imagecube_array, OCLImageCubeArray)
+IMAGE_READ_TYPE(imagecube_depth, OCLImageCubeDepth)
+IMAGE_READ_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth)
 
 IMAGE_WRITE_TYPE(image1d, OCLImage1d)
 IMAGE_WRITE_TYPE(image1d_array, OCLImage1dArray)
@@ -61,6 +80,10 @@ IMAGE_WRITE_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA)
 IMAGE_WRITE_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth)
 IMAGE_WRITE_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth)
 IMAGE_WRITE_TYPE(image3d, OCLImage3d)
+IMAGE_WRITE_TYPE(imagecube, OCLImageCube)
+IMAGE_WRITE_TYPE(imagecube_array, OCLImageCubeArray)
+IMAGE_WRITE_TYPE(imagecube_depth, OCLImageCubeDepth)
+IMAGE_WRITE_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth)
 
 IMAGE_READ_WRITE_TYPE(image1d, OCLImage1d)
 IMAGE_READ_WRITE_TYPE(image1d_array, OCLImage1dArray)
@@ -74,9 +97,13 @@ IMAGE_READ_WRITE_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA)
 IMAGE_READ_WRITE_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth)
 IMAGE_READ_WRITE_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth)
 IMAGE_READ_WRITE_TYPE(image3d, OCLImage3d)
+IMAGE_READ_WRITE_TYPE(imagecube, OCLImageCube)
+IMAGE_READ_WRITE_TYPE(imagecube_array, OCLImageCubeArray)
+IMAGE_READ_WRITE_TYPE(imagecube_depth, OCLImageCubeDepth)
+IMAGE_READ_WRITE_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth)
 
 #undef IMAGE_TYPE
 #undef GENERIC_IMAGE_TYPE
 #undef IMAGE_READ_TYPE
 #undef IMAGE_WRITE_TYPE
-#undef IMAGE_READ_WRITE_TYPE
\ No newline at end of file
+#undef IMAGE_READ_WRITE_TYPE
diff --git a/include/clang/Basic/Specifiers.h b/include/clang/Basic/Specifiers.h
index fffd4b1..7731542 100644
--- a/include/clang/Basic/Specifiers.h
+++ b/include/clang/Basic/Specifiers.h
@@ -76,7 +76,12 @@ namespace clang {
     TST_atomic,           // C11 _Atomic
 #define GENERIC_IMAGE_TYPE(ImgType, Id) TST_##ImgType##_t, // OpenCL image types
 #include "clang/Basic/OpenCLImageTypes.def"
-    TST_error // erroneous type
+    TST_sampler_t,        // OpenCL sampler_t
+    TST_event_t,          // OpenCL event_t
+    TST_queue_t,          // OpenCL queue_t
+    TST_clk_event_t,      // OpenCL clk_event_t
+    TST_reserve_id_t,     // OpenCL reserve_id_t
+    TST_error         // erroneous type
   };
 
   /// \brief Structure that packs information about the type specifiers that
@@ -206,6 +211,9 @@ namespace clang {
     SC_PrivateExtern,
 
     // These are only legal on variables.
+    // TODO: are these wanted/unproblematic? (SC_OpenCLWorkGroupLocal was removed due to issues)
+    SC_OpenCLConstant,
+    SC_OpenCLConstantExtern,
     SC_Auto,
     SC_Register
   };
@@ -240,8 +248,12 @@ namespace clang {
     CC_AAPCS,       // __attribute__((pcs("aapcs")))
     CC_AAPCS_VFP,   // __attribute__((pcs("aapcs-vfp")))
     CC_IntelOclBicc, // __attribute__((intel_ocl_bicc))
-    CC_SpirFunction, // default for OpenCL functions on SPIR target
-    CC_OpenCLKernel, // inferred for OpenCL kernels
+	// NOTE: don't go above 15 for anything that is actually used by clang
+    CC_FloorFunction, // default for OpenCL/SPIR, Metal/AIR, CUDA and Vulkan/SPIR-V functions (non entry points)
+    CC_FloorKernel,   // inferred for OpenCL/SPIR, Metal/AIR, CUDA and Vulkan/SPIR-V kernels
+    CC_FloorVertex,   // inferred for Metal/AIR and Vulkan/SPIR-V vertex shaders
+    CC_FloorFragment, // inferred for Metal/AIR and Vulkan/SPIR-V fragment shaders
+    // ^^^ 14
     CC_Swift,        // __attribute__((swiftcall))
     CC_PreserveMost, // __attribute__((preserve_most))
     CC_PreserveAll,  // __attribute__((preserve_all))
@@ -256,8 +268,10 @@ namespace clang {
     case CC_X86ThisCall:
     case CC_X86Pascal:
     case CC_X86VectorCall:
-    case CC_SpirFunction:
-    case CC_OpenCLKernel:
+    case CC_FloorFunction:
+    case CC_FloorKernel:
+    case CC_FloorVertex:
+    case CC_FloorFragment:
     case CC_Swift:
       return false;
     default:
diff --git a/include/clang/Basic/TokenKinds.def b/include/clang/Basic/TokenKinds.def
index 82cb6c2..5de1179 100644
--- a/include/clang/Basic/TokenKinds.def
+++ b/include/clang/Basic/TokenKinds.def
@@ -507,38 +507,21 @@ KEYWORD(__forceinline               , KEYMS)
 KEYWORD(__unaligned                 , KEYMS)
 KEYWORD(__super                     , KEYMS)
 
-// OpenCL address space qualifiers
-KEYWORD(__global                    , KEYOPENCL)
-KEYWORD(__local                     , KEYOPENCL)
-KEYWORD(__constant                  , KEYOPENCL)
-KEYWORD(__private                   , KEYOPENCL)
-KEYWORD(__generic                   , KEYOPENCL)
-ALIAS("global", __global            , KEYOPENCL)
-ALIAS("local", __local              , KEYOPENCL)
-ALIAS("constant", __constant        , KEYOPENCL)
-ALIAS("private", __private          , KEYOPENCL)
-ALIAS("generic", __generic          , KEYOPENCL)
-// OpenCL function qualifiers
-KEYWORD(__kernel                    , KEYOPENCL)
-ALIAS("kernel", __kernel            , KEYOPENCL)
-// OpenCL access qualifiers
-KEYWORD(__read_only                 , KEYOPENCL)
-KEYWORD(__write_only                , KEYOPENCL)
-KEYWORD(__read_write                , KEYOPENCL)
-ALIAS("read_only", __read_only      , KEYOPENCL)
-ALIAS("write_only", __write_only    , KEYOPENCL)
-ALIAS("read_write", __read_write    , KEYOPENCL)
 // OpenCL builtins
-KEYWORD(__builtin_astype            , KEYOPENCL)
-KEYWORD(vec_step                    , KEYOPENCL|KEYALTIVEC|KEYZVECTOR)
-#define GENERIC_IMAGE_TYPE(ImgType, Id) KEYWORD(ImgType##_t, KEYOPENCL)
-#include "clang/Basic/OpenCLImageTypes.def"
+KEYWORD(__builtin_astype            , KEYCXX|KEYOPENCL)
+KEYWORD(sampler_t                   , KEYCXX|KEYOPENCL)
+KEYWORD(event_t                     , KEYCXX|KEYOPENCL)
+KEYWORD(vec_step                    , KEYCXX|KEYOPENCL|KEYALTIVEC|KEYZVECTOR)
+
+// OpenCL 2.0
+KEYWORD(queue_t                     , KEYCXX|KEYOPENCL)
+KEYWORD(clk_event_t                 , KEYCXX|KEYOPENCL)
+KEYWORD(reserve_id_t                , KEYCXX|KEYOPENCL)
+KEYWORD(pipe                        , KEYCXX|KEYOPENCL)
 
 // OpenMP Type Traits
 KEYWORD(__builtin_omp_required_simd_align, KEYALL)
 
-KEYWORD(pipe                        , KEYOPENCL)
-
 // Borland Extensions.
 KEYWORD(__pascal                    , KEYALL)
 
diff --git a/include/clang/CodeGen/BackendUtil.h b/include/clang/CodeGen/BackendUtil.h
index 01721d3..8681cd5 100644
--- a/include/clang/CodeGen/BackendUtil.h
+++ b/include/clang/CodeGen/BackendUtil.h
@@ -26,12 +26,16 @@ namespace clang {
   class LangOptions;
 
   enum BackendAction {
-    Backend_EmitAssembly,  ///< Emit native assembly files
-    Backend_EmitBC,        ///< Emit LLVM bitcode files
-    Backend_EmitLL,        ///< Emit human-readable LLVM assembly
-    Backend_EmitNothing,   ///< Don't emit anything (benchmarking mode)
-    Backend_EmitMCNull,    ///< Run CodeGen, but don't emit anything
-    Backend_EmitObj        ///< Emit native object files
+    Backend_EmitAssembly,          ///< Emit native assembly files
+    Backend_EmitBC,                ///< Emit LLVM bitcode files
+    Backend_EmitBC32,              ///< Emit LLVM 3.2 bitcode files
+    Backend_EmitBC35,              ///< Emit LLVM 3.5 bitcode files
+    Backend_EmitSPIRV,             ///< Emit SPIR-V bitcode files
+    Backend_EmitSPIRVContainer,    ///< Emit container with SPIR-V bitcode files
+    Backend_EmitLL,                ///< Emit human-readable LLVM assembly
+    Backend_EmitNothing,           ///< Don't emit anything (benchmarking mode)
+    Backend_EmitMCNull,            ///< Run CodeGen, but don't emit anything
+    Backend_EmitObj                ///< Emit native object files
   };
 
   void EmitBackendOutput(DiagnosticsEngine &Diags, const CodeGenOptions &CGOpts,
diff --git a/include/clang/CodeGen/CodeGenAction.h b/include/clang/CodeGen/CodeGenAction.h
index cc38e24..8cabc1e 100644
--- a/include/clang/CodeGen/CodeGenAction.h
+++ b/include/clang/CodeGen/CodeGenAction.h
@@ -78,6 +78,30 @@ public:
   EmitBCAction(llvm::LLVMContext *_VMContext = nullptr);
 };
 
+class EmitBC32Action : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitBC32Action(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitBC35Action : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitBC35Action(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitSPIRVAction : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitSPIRVAction(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitSPIRVContainerAction : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitSPIRVContainerAction(llvm::LLVMContext *_VMContext = nullptr);
+};
+
 class EmitLLVMAction : public CodeGenAction {
   virtual void anchor();
 public:
diff --git a/include/clang/Driver/CC1Options.td b/include/clang/Driver/CC1Options.td
index f2cfc11..b31c95f 100644
--- a/include/clang/Driver/CC1Options.td
+++ b/include/clang/Driver/CC1Options.td
@@ -465,6 +465,10 @@ def emit_pch : Flag<["-"], "emit-pch">,
   HelpText<"Generate pre-compiled header file">;
 def emit_llvm_bc : Flag<["-"], "emit-llvm-bc">,
   HelpText<"Build ASTs then convert to LLVM, emit .bc file">;
+def emit_spirv : Flag<["-"], "emit-spirv">,
+  HelpText<"Build ASTs then convert to LLVM, then convert to SPIR-V, emit .spv file">;
+def emit_spirv_container : Flag<["-"], "emit-spirv-container">,
+  HelpText<"Build ASTs then convert to LLVM, then convert to multiple SPIR-V modules, emit .spvc file">;
 def emit_llvm_only : Flag<["-"], "emit-llvm-only">,
   HelpText<"Build ASTs and convert to LLVM, discarding output">;
 def emit_codegen_only : Flag<["-"], "emit-codegen-only">,
@@ -671,6 +675,35 @@ def detailed_preprocessing_record : Flag<["-"], "detailed-preprocessing-record">
   HelpText<"include a detailed record of preprocessing actions">;
 
 //===----------------------------------------------------------------------===//
+// libfloor Options (applying to OpenCL, CUDA, Metal and Vulkan)
+//===----------------------------------------------------------------------===//
+
+// TODO: move all of this stuff to Options.td?
+def floor_function_info : Joined<["-"], "floor-function-info=">,
+  HelpText<"floor function info output file">;
+def floor_image_capabilities : Joined<["-"], "floor-image-capabilities=">,
+  HelpText<"image read and write capabilities">;
+
+//===----------------------------------------------------------------------===//
+// OpenCL Options
+//===----------------------------------------------------------------------===//
+
+def cl_enable_half : Flag<["-"], "cl-enable-half">,
+  HelpText<"OpenCL only. This option enables the dereferencing of half pointers">;
+
+// SPIR generator options
+def cl_spir_compile_options : Separate<["-"], "cl-spir-compile-options">,
+  HelpText<"SPIR compilation options to record in metadata">;
+def cl_sampler_type : Separate<["-"], "cl-sampler-type">,
+  HelpText<"OpenCL only. Specify type of sampler to emit. Valid values: \"opaque\"(default), \"i32\"">;
+
+def cl_verify_spir : Flag<["-"], "cl-verify-spir">,
+  HelpText<"OpenCL/SPIR only. Runs the Khronos SPIR verifier on the final LLVM IR.">;
+
+def cl_spir_intel_workarounds : Flag<["-"], "cl-spir-intel-workarounds">,
+  HelpText<"Enable Intel SPIR specific fixes and workarounds">;
+
+//===----------------------------------------------------------------------===//
 // CUDA Options
 //===----------------------------------------------------------------------===//
 
@@ -684,6 +717,21 @@ def fno_cuda_host_device_constexpr : Flag<["-"], "fno-cuda-host-device-constexpr
   HelpText<"Don't treat unattributed constexpr functions as __host__ __device__.">;
 
 //===----------------------------------------------------------------------===//
+// AIR/Metal Options
+//===----------------------------------------------------------------------===//
+
+def metal_intel_workarounds : Flag<["-"], "metal-intel-workarounds">,
+  HelpText<"Enable Intel GPU specific fixes and workarounds">;
+def metal_nvidia_workarounds : Flag<["-"], "metal-nvidia-workarounds">,
+  HelpText<"Enable Nvidia GPU specific fixes and workarounds">;
+def metal_no_array_image : Flag<["-"], "metal-no-array-image">,
+  HelpText<"Disables native support for array of images">;
+
+//===----------------------------------------------------------------------===//
+// Vulkan Options
+//===----------------------------------------------------------------------===//
+
+//===----------------------------------------------------------------------===//
 // OpenMP Options
 //===----------------------------------------------------------------------===//
 
diff --git a/include/clang/Driver/Options.td b/include/clang/Driver/Options.td
index 44e588d..a4d6a72 100644
--- a/include/clang/Driver/Options.td
+++ b/include/clang/Driver/Options.td
@@ -452,6 +452,14 @@ def emit_ast : Flag<["-"], "emit-ast">,
   HelpText<"Emit Clang AST files for source inputs">;
 def emit_llvm : Flag<["-"], "emit-llvm">, Flags<[CC1Option]>, Group<Action_Group>,
   HelpText<"Use the LLVM representation for assembler and object files">;
+def llvm_bc_32 : Flag<["-"], "llvm-bc-32">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output LLVM 3.2 compatible bitcode">;
+def llvm_bc_35 : Flag<["-"], "llvm-bc-35">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output LLVM 3.5 compatible bitcode">;
+def llvm_spirv : Flag<["-"], "llvm-spirv">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output SPIR-V compatible bitcode">;
+def llvm_spirv_container : Flag<["-"], "llvm-spirv-container">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output a container with SPIR-V compatible bitcode modules">;
 def exported__symbols__list : Separate<["-"], "exported_symbols_list">;
 def e : JoinedOrSeparate<["-"], "e">;
 def fPIC : Flag<["-"], "fPIC">, Group<f_Group>;
diff --git a/include/clang/Driver/Types.def b/include/clang/Driver/Types.def
index f2ff194..4f3aba3 100644
--- a/include/clang/Driver/Types.def
+++ b/include/clang/Driver/Types.def
@@ -42,6 +42,8 @@
 TYPE("cpp-output",               PP_C,         INVALID,         "i",     "u")
 TYPE("c",                        C,            PP_C,            "c",     "u")
 TYPE("cl",                       CL,           PP_C,            "cl",    "u")
+TYPE("metal",                    METAL,        PP_CXX,          "cpp",   "u")
+TYPE("vulkan",                   VULKAN,       PP_CXX,          "cpp",   "u")
 TYPE("cuda-cpp-output",          PP_CUDA,      INVALID,         "cui",   "u")
 TYPE("cuda",                     CUDA,         PP_CUDA,         "cu",    "u")
 TYPE("cuda",                     CUDA_DEVICE,  PP_CUDA,         "cu",    "")
@@ -59,6 +61,8 @@ TYPE("renderscript",             RenderScript, PP_C,            "rs",    "u")
 TYPE("c-header-cpp-output",      PP_CHeader,   INVALID,         "i",     "p")
 TYPE("c-header",                 CHeader,      PP_CHeader,      "h",     "pu")
 TYPE("cl-header",                CLHeader,     PP_CHeader,      "h",     "pu")
+TYPE("metal-header",             MetalHeader,  PP_CXXHeader,    "h",     "pu")
+TYPE("vulkan-header",            VulkanHeader, PP_CXXHeader,    "h",     "pu")
 TYPE("objective-c-header-cpp-output", PP_ObjCHeader, INVALID,   "mi",    "p")
 TYPE("objective-c-header",       ObjCHeader,   PP_ObjCHeader,   "h",     "pu")
 TYPE("c++-header-cpp-output",    PP_CXXHeader, INVALID,         "ii",    "p")
@@ -78,6 +82,8 @@ TYPE("java",                     Java,         INVALID,         nullptr, "u")
 // outputs should use the standard suffixes.
 TYPE("ir",                       LLVM_IR,      INVALID,         "ll",    "u")
 TYPE("ir",                       LLVM_BC,      INVALID,         "bc",    "u")
+TYPE("ir",                       LLVM_BC_32,   INVALID,         "bc",    "u")
+TYPE("ir",                       LLVM_BC_35,   INVALID,         "bc",    "u")
 TYPE("lto-ir",                   LTO_IR,       INVALID,         "s",     "")
 TYPE("lto-bc",                   LTO_BC,       INVALID,         "o",     "")
 
@@ -95,4 +101,6 @@ TYPE("image",                    Image,        INVALID,         "out",   "")
 TYPE("dSYM",                     dSYM,         INVALID,         "dSYM",  "A")
 TYPE("dependencies",             Dependencies, INVALID,         "d",     "")
 TYPE("cuda-fatbin",              CUDA_FATBIN,  INVALID,         "fatbin","A")
+TYPE("spirv",                    SPIRV,        INVALID,         "spv",   "u")
+TYPE("spirvc",                   SPIRVC,       INVALID,         "spvc",  "u")
 TYPE("none",                     Nothing,      INVALID,         nullptr, "u")
diff --git a/include/clang/Frontend/CodeGenOptions.def b/include/clang/Frontend/CodeGenOptions.def
index 4dd634c..35658f9 100644
--- a/include/clang/Frontend/CodeGenOptions.def
+++ b/include/clang/Frontend/CodeGenOptions.def
@@ -65,6 +65,10 @@ CODEGENOPT(EmitDeclMetadata  , 1, 0) ///< Emit special metadata indicating what
 CODEGENOPT(EmitGcovArcs      , 1, 0) ///< Emit coverage data files, aka. GCDA.
 CODEGENOPT(EmitGcovNotes     , 1, 0) ///< Emit coverage "notes" files, aka GCNO.
 CODEGENOPT(EmitOpenCLArgMetadata , 1, 0) ///< Emit OpenCL kernel arg metadata.
+CODEGENOPT(MetalIntelWorkarounds , 1, 0) ///< Enable Intel GPU specific fixes and workarounds.
+CODEGENOPT(MetalNvidiaWorkarounds , 1, 0) ///< Enable Nvidia GPU specific fixes and workarounds.
+CODEGENOPT(MetalNoArrayImage , 1, 0) ///< Disable native array of images support.
+CODEGENOPT(SPIRIntelWorkarounds , 1, 0) ///< Enable Intel SPIR specific fixes and workarounds.
 CODEGENOPT(EmulatedTLS       , 1, 0) ///< Set when -femulated-tls is enabled.
 /// \brief FP_CONTRACT mode (on/off/fast).
 ENUM_CODEGENOPT(FPContractMode, FPContractModeKind, 2, FPC_On)
@@ -170,6 +174,11 @@ CODEGENOPT(VectorizeBB       , 1, 0) ///< Run basic block vectorizer.
 CODEGENOPT(VectorizeLoop     , 1, 0) ///< Run loop vectorizer.
 CODEGENOPT(VectorizeSLP      , 1, 0) ///< Run SLP vectorizer.
 
+CODEGENOPT(DenormsAreZero    , 1, 0) ///< Allow flushing of denorms to zero.
+CODEGENOPT(CorrectFPDivideSqrt , 1, 0) ///< Single precision divide and sqrt are
+                                       ///< correctly rounded.
+CODEGENOPT(OptDisable        , 1, 0) ///< Disables all optimizations.
+
   /// Attempt to use register sized accesses to bit-fields in structures, when
   /// possible.
 CODEGENOPT(UseRegisterSizedBitfieldAccess , 1, 0)
diff --git a/include/clang/Frontend/CodeGenOptions.h b/include/clang/Frontend/CodeGenOptions.h
index 0bdc1ef..23b9014 100644
--- a/include/clang/Frontend/CodeGenOptions.h
+++ b/include/clang/Frontend/CodeGenOptions.h
@@ -149,6 +149,9 @@ public:
   /// A list of command-line options to forward to the LLVM backend.
   std::vector<std::string> BackendOptions;
 
+  /// OpenCL compile options to embed in the SPIR metadata
+  std::string SPIRCompileOptions;
+
   /// A list of dependent libraries.
   std::vector<std::string> DependentLibraries;
 
diff --git a/include/clang/Frontend/FrontendOptions.h b/include/clang/Frontend/FrontendOptions.h
index a75523f..1057410 100644
--- a/include/clang/Frontend/FrontendOptions.h
+++ b/include/clang/Frontend/FrontendOptions.h
@@ -34,6 +34,10 @@ namespace frontend {
     DumpTokens,             ///< Dump out preprocessed tokens.
     EmitAssembly,           ///< Emit a .s file.
     EmitBC,                 ///< Emit a .bc file.
+    EmitBC32,               ///< Emit a LLVM 3.2 .bc file.
+    EmitBC35,               ///< Emit a LLVM 3.5 .bc file.
+    EmitSPIRV,              ///< Emit a .spv file.
+    EmitSPIRVContainer,     ///< Emit a .spvc container file.
     EmitHTML,               ///< Translate input source into HTML.
     EmitLLVM,               ///< Emit a .ll file.
     EmitLLVMOnly,           ///< Generate LLVM IR, but do not emit anything.
@@ -72,6 +76,8 @@ enum InputKind {
   IK_PreprocessedObjC,
   IK_PreprocessedObjCXX,
   IK_OpenCL,
+  IK_Metal,
+  IK_Vulkan,
   IK_CUDA,
   IK_PreprocessedCuda,
   IK_RenderScript,
diff --git a/include/clang/Frontend/LangStandards.def b/include/clang/Frontend/LangStandards.def
index a303693..a7977a3 100644
--- a/include/clang/Frontend/LangStandards.def
+++ b/include/clang/Frontend/LangStandards.def
@@ -19,14 +19,6 @@
 /// \param FEATURES - The standard features as flags, these are enums from the
 /// clang::frontend namespace, which is assumed to be be available.
 
-/// LANGSTANDARD_ALIAS(IDENT, ALIAS)
-/// \param IDENT - The name of the standard as a C++ identifier.
-/// \param ALIAS - The alias of the standard.
-
-#ifndef LANGSTANDARD_ALIAS
-#define LANGSTANDARD_ALIAS(IDENT, ALIAS)
-#endif
-
 // C89-ish modes.
 LANGSTANDARD(c89, "c89",
              "ISO C 1990",
@@ -140,29 +132,39 @@ LANGSTANDARD(gnucxx1z, "gnu++1z",
              Digraphs | HexFloat | GNUMode)
 
 // OpenCL
-LANGSTANDARD(opencl, "cl",
+LANGSTANDARD(opencl, "CL",
              "OpenCL 1.0",
-             LineComment | C99 | Digraphs | HexFloat)
-LANGSTANDARD(opencl11, "cl1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+LANGSTANDARD(opencl11, "CL1.1",
              "OpenCL 1.1",
-             LineComment | C99 | Digraphs | HexFloat)
-LANGSTANDARD(opencl12, "cl1.2",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+LANGSTANDARD(opencl12, "CL1.2",
              "OpenCL 1.2",
-             LineComment | C99 | Digraphs | HexFloat)
-LANGSTANDARD(opencl20, "cl2.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+LANGSTANDARD(opencl20, "CL2.0",
              "OpenCL 2.0",
-             LineComment | C99 | Digraphs | HexFloat)
-
-LANGSTANDARD_ALIAS(opencl, "CL")
-LANGSTANDARD_ALIAS(opencl11, "CL1.1")
-LANGSTANDARD_ALIAS(opencl12, "CL1.2")
-LANGSTANDARD_ALIAS(opencl20, "CL2.0")
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+LANGSTANDARD(opencl21, "CL2.1",
+             "OpenCL 2.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+LANGSTANDARD(opencl22, "CL2.2",
+             "OpenCL 2.2",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+
+// Metal
+LANGSTANDARD(metal11, "metal1.1",
+             "Metal 1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
+
+// Vulkan C++
+LANGSTANDARD(vulkan10, "vulkan1.0",
+             "Vulkan C++ 1.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
 
 // CUDA
 LANGSTANDARD(cuda, "cuda",
              "NVIDIA CUDA(tm)",
-             LineComment | CPlusPlus | Digraphs)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus1z | Digraphs | HexFloat | GNUMode)
 
 #undef LANGSTANDARD
-#undef LANGSTANDARD_ALIAS
 
diff --git a/include/clang/Lex/Preprocessor.h b/include/clang/Lex/Preprocessor.h
index 66ff490..bf60f8f 100644
--- a/include/clang/Lex/Preprocessor.h
+++ b/include/clang/Lex/Preprocessor.h
@@ -105,6 +105,7 @@ class Preprocessor : public RefCountedBase<Preprocessor> {
   std::unique_ptr<ScratchBuffer> ScratchBuf;
   HeaderSearch      &HeaderInfo;
   ModuleLoader      &TheModuleLoader;
+  OpenCLOptions     SupportedPragmas;
 
   /// \brief External source of macros.
   ExternalPreprocessorSource *ExternalSource;
@@ -695,6 +696,12 @@ public:
   DiagnosticsEngine &getDiagnostics() const { return *Diags; }
   void setDiagnostics(DiagnosticsEngine &D) { Diags = &D; }
 
+  const OpenCLOptions &getSupportedPragmas() const { return SupportedPragmas; }
+  void setSupportedPragmas(const OpenCLOptions &opts)
+  {
+    SupportedPragmas = opts;
+  }
+
   const LangOptions &getLangOpts() const { return LangOpts; }
   const TargetInfo &getTargetInfo() const { return *Target; }
   const TargetInfo *getAuxTargetInfo() const { return AuxTarget; }
diff --git a/include/clang/Lex/PreprocessorOptions.h b/include/clang/Lex/PreprocessorOptions.h
index de652cc..9c2d90b 100644
--- a/include/clang/Lex/PreprocessorOptions.h
+++ b/include/clang/Lex/PreprocessorOptions.h
@@ -19,6 +19,7 @@
 #include <string>
 #include <utility>
 #include <vector>
+#include "clang/Basic/LangOptions.h"
 
 namespace llvm {
   class MemoryBuffer;
@@ -54,6 +55,9 @@ public:
   /// definitions and expansions.
   unsigned DetailedRecord : 1;
 
+  /// Initialize the preprocessor list of supported pragmas
+  OpenCLOptions SupportedPragmas;
+
   /// The implicit PCH included at the start of the translation unit, or empty.
   std::string ImplicitPCHInclude;
 
diff --git a/include/clang/Parse/Parser.h b/include/clang/Parse/Parser.h
index b44a209..b0a73e4 100644
--- a/include/clang/Parse/Parser.h
+++ b/include/clang/Parse/Parser.h
@@ -1435,10 +1435,12 @@ private:
   ExprResult ParseCastExpression(bool isUnaryExpression,
                                  bool isAddressOfOperand,
                                  bool &NotCastExpr,
-                                 TypeCastState isTypeCast);
+                                 TypeCastState isTypeCast,
+                                 bool isVectorLiteral = false);
   ExprResult ParseCastExpression(bool isUnaryExpression,
                                  bool isAddressOfOperand = false,
-                                 TypeCastState isTypeCast = NotTypeCast);
+                                 TypeCastState isTypeCast = NotTypeCast,
+                                 bool isVectorLiteral = false);
 
   /// Returns true if the next token cannot start an expression.
   bool isNotExpressionStart();
diff --git a/include/clang/Sema/DeclSpec.h b/include/clang/Sema/DeclSpec.h
index df434ec..35395a3 100644
--- a/include/clang/Sema/DeclSpec.h
+++ b/include/clang/Sema/DeclSpec.h
@@ -303,6 +303,11 @@ public:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) \
   static const TST TST_##ImgType##_t = clang::TST_##ImgType##_t;
 #include "clang/Basic/OpenCLImageTypes.def"
+  static const TST TST_sampler_t = clang::TST_sampler_t;
+  static const TST TST_event_t = clang::TST_event_t;
+  static const TST TST_queue_t = clang::TST_queue_t;
+  static const TST TST_clk_event_t = clang::TST_clk_event_t;
+  static const TST TST_reserve_id_t = clang::TST_reserve_id_t;
   static const TST TST_error = clang::TST_error;
 
   // type-qualifiers
diff --git a/include/clang/Sema/Initialization.h b/include/clang/Sema/Initialization.h
index b26bd7c..8b4379d 100644
--- a/include/clang/Sema/Initialization.h
+++ b/include/clang/Sema/Initialization.h
@@ -718,6 +718,8 @@ public:
     SK_StdInitializerListConstructorCall,
     /// \brief Initialize an OpenCL sampler from an integer.
     SK_OCLSamplerInit,
+    /// \brief Initialize queue_t from 0.
+    SK_OCLZeroQueue,
     /// \brief Passing zero to a function where OpenCL event_t is expected.
     SK_OCLZeroEvent
   };
@@ -1104,6 +1106,9 @@ public:
   /// constant.
   void AddOCLZeroEventStep(QualType T);
 
+  /// \brief Add a step to initialize an OpenCL queue_t from 0.
+  void AddOCLZeroQueueStep(QualType T);
+
   /// \brief Add steps to unwrap a initializer list for a reference around a
   /// single element and rewrap it at the end.
   void RewrapReferenceInitList(QualType T, InitListExpr *Syntactic);
diff --git a/include/clang/Sema/Overload.h b/include/clang/Sema/Overload.h
index ce01ff9..b3bd9c7 100644
--- a/include/clang/Sema/Overload.h
+++ b/include/clang/Sema/Overload.h
@@ -83,6 +83,8 @@ namespace clang {
     ICK_TransparentUnionConversion, ///< Transparent Union Conversions
     ICK_Writeback_Conversion,  ///< Objective-C ARC writeback conversion
     ICK_Zero_Event_Conversion, ///< Zero constant to event (OpenCL1.2 6.12.10)
+    ICK_Zero_Queue_Conversion, ///< Zero constant to queue
+    ICK_Int_Sampler_Conversion, ///< Integer constant to OpenCL sampler
     ICK_C_Only_Conversion,     ///< Conversions allowed in C, but not C++
     ICK_Num_Conversion_Kinds,  ///< The number of conversion kinds
   };
@@ -95,6 +97,7 @@ namespace clang {
     ICR_Exact_Match = 0,         ///< Exact Match
     ICR_Promotion,               ///< Promotion
     ICR_Conversion,              ///< Conversion
+    ICR_OCL_Scalar_Widening,     ///< OpenCL Scalar Widening
     ICR_Complex_Real_Conversion, ///< Complex <-> Real conversion
     ICR_Writeback_Conversion,    ///< ObjC ARC writeback conversion
     ICR_C_Conversion             ///< Conversion only allowed in the C standard.
@@ -580,6 +583,8 @@ namespace clang {
     /// (CUDA) This candidate was not viable because the callee
     /// was not accessible from the caller's target (i.e. host->device,
     /// global->host, device->host).
+    /// (OpenCL) This candidate was not viable because the callee
+    /// uses extensions that are not enabled or supported.
     ovl_fail_bad_target,
 
     /// This candidate function was not viable because an enable_if
diff --git a/include/clang/Sema/Sema.h b/include/clang/Sema/Sema.h
index 668399bf..50b147b 100644
--- a/include/clang/Sema/Sema.h
+++ b/include/clang/Sema/Sema.h
@@ -8034,6 +8034,10 @@ public:
   /// \param Init First part of the for loop.
   void ActOnOpenMPLoopInitialization(SourceLocation ForLoc, Stmt *Init);
 
+  /// Adds a color(location) attribute to a particular declaration.
+  void AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E,
+                                       unsigned SpellingListIndex);
+
   // OpenMP directives and clauses.
   /// \brief Called on correct id-expression from the '#pragma omp
   /// threadprivate'.
diff --git a/include/clang/Sema/SemaInternal.h b/include/clang/Sema/SemaInternal.h
index 76567f3..3a619ba 100644
--- a/include/clang/Sema/SemaInternal.h
+++ b/include/clang/Sema/SemaInternal.h
@@ -56,7 +56,7 @@ inline bool DeclAttrsMatchCUDAMode(const LangOptions &LangOpts, Decl *D) {
     return true;
   bool isDeviceSideDecl = D->hasAttr<CUDADeviceAttr>() ||
                           D->hasAttr<CUDASharedAttr>() ||
-                          D->hasAttr<CUDAGlobalAttr>();
+                          D->hasAttr<ComputeKernelAttr>();
   return isDeviceSideDecl == LangOpts.CUDAIsDevice;
 }
 
diff --git a/lib/AST/ASTContext.cpp b/lib/AST/ASTContext.cpp
index 425aeac..4c3de8b 100644
--- a/lib/AST/ASTContext.cpp
+++ b/lib/AST/ASTContext.cpp
@@ -747,6 +747,7 @@ ASTContext::ASTContext(LangOptions &LOpts, SourceManager &SM,
       cudaConfigureCallDecl(nullptr), FirstLocalImport(), LastLocalImport(),
       ExternCContext(nullptr), MakeIntegerSeqDecl(nullptr),
       TypePackElementDecl(nullptr), SourceMgr(SM), LangOpts(LOpts),
+      disabledFPContract(false),
       SanitizerBL(new SanitizerBlacklist(LangOpts.SanitizerBlacklistFiles, SM)),
       AddrSpaceMap(nullptr), Target(nullptr), AuxTarget(nullptr),
       PrintingPolicy(LOpts), Idents(idents), Selectors(sels),
@@ -1740,9 +1741,14 @@ TypeInfo ASTContext::getTypeInfoImpl(const Type *T) const {
       Align = Target->getPointerAlign(0);
       break;
     case BuiltinType::OCLSampler: {
+      // TODO/NOTE: Samplers are modeled as integers for now.
+      Width = Target->getIntWidth();
+      Align = Target->getIntAlign();
+#if 0 // -> use this when treating samplers as pointers
       auto AS = getTargetAddressSpace(LangAS::opencl_constant);
       Width = Target->getPointerWidth(AS);
       Align = Target->getPointerAlign(AS);
+#endif
       break;
     }
     case BuiltinType::OCLEvent:
@@ -7590,13 +7596,34 @@ QualType ASTContext::mergeFunctionTypes(QualType lhs, QualType rhs,
   if (lproto && rproto) { // two C99 style function prototypes
     assert(!lproto->hasExceptionSpec() && !rproto->hasExceptionSpec() &&
            "C++ shouldn't be here");
-    // Compatible functions must have the same number of parameters
-    if (lproto->getNumParams() != rproto->getNumParams())
-      return QualType();
+    unsigned lproto_nargs = lproto->getNumParams();
+    unsigned rproto_nargs = rproto->getNumParams();
 
-    // Variadic and non-variadic functions aren't compatible
-    if (lproto->isVariadic() != rproto->isVariadic())
-      return QualType();
+    if ( LangOpts.OpenCLVersion < 200 || !lproto->isVariadic() ) {
+      // Compatible functions must have the same number of arguments
+      if (lproto_nargs != rproto_nargs)
+        return QualType();
+
+      // Variadic and non-variadic functions aren't compatible
+      if (lproto->isVariadic() != rproto->isVariadic())
+        return QualType();
+
+    } else {
+
+      if ( !lproto->isVariadic() && !lproto->isVariadic() ) {
+        if (lproto_nargs != rproto_nargs)
+          return QualType();
+
+      } else if ( lproto->isVariadic() ) {
+        if (lproto_nargs > rproto_nargs)
+          return QualType();
+
+      } else if ( rproto->isVariadic() ) {
+        if (lproto_nargs < rproto_nargs)
+          return QualType();
+
+      }
+    }
 
     if (lproto->getTypeQuals() != rproto->getTypeQuals())
       return QualType();
@@ -8503,7 +8530,7 @@ static GVALinkage basicGVALinkageForFunction(const ASTContext &Context,
   if (!FD->isInlined())
     return External;
 
-  if ((!Context.getLangOpts().CPlusPlus &&
+  if ((!Context.getLangOpts().CPlusPlus && !Context.getLangOpts().OpenCL &&
        !Context.getTargetInfo().getCXXABI().isMicrosoft() &&
        !FD->hasAttr<DLLExportAttr>()) ||
       FD->hasAttr<GNUInlineAttr>()) {
@@ -8538,7 +8565,7 @@ static GVALinkage adjustGVALinkageForAttributes(const ASTContext &Context,
     if (L == GVA_DiscardableODR)
       return GVA_StrongODR;
   } else if (Context.getLangOpts().CUDA && Context.getLangOpts().CUDAIsDevice &&
-             D->hasAttr<CUDAGlobalAttr>()) {
+             D->hasAttr<ComputeKernelAttr>()) {
     // Device-side functions with __global__ attribute must always be
     // visible externally so they can be launched from host.
     if (L == GVA_DiscardableODR || L == GVA_Internal)
diff --git a/lib/AST/Decl.cpp b/lib/AST/Decl.cpp
index cfdd557..b60a12c 100644
--- a/lib/AST/Decl.cpp
+++ b/lib/AST/Decl.cpp
@@ -1776,6 +1776,8 @@ const char *VarDecl::getStorageClassSpecifierString(StorageClass SC) {
   case SC_None:                 break;
   case SC_Auto:                 return "auto";
   case SC_Extern:               return "extern";
+  case SC_OpenCLConstantExtern: return "<<opencl-constant-extern>>";
+  case SC_OpenCLConstant:       return "<<opencl-constant>>";
   case SC_PrivateExtern:        return "__private_extern__";
   case SC_Register:             return "register";
   case SC_Static:               return "static";
diff --git a/lib/AST/DeclPrinter.cpp b/lib/AST/DeclPrinter.cpp
index 7e78699..606b875 100644
--- a/lib/AST/DeclPrinter.cpp
+++ b/lib/AST/DeclPrinter.cpp
@@ -458,6 +458,7 @@ void DeclPrinter::VisitFunctionDecl(FunctionDecl *D) {
     case SC_Static: Out << "static "; break;
     case SC_PrivateExtern: Out << "__private_extern__ "; break;
     case SC_Auto: case SC_Register:
+    case SC_OpenCLConstant: case SC_OpenCLConstantExtern:
       llvm_unreachable("invalid for functions");
     }
 
diff --git a/lib/AST/Expr.cpp b/lib/AST/Expr.cpp
index 15386ae..446d2cf 100644
--- a/lib/AST/Expr.cpp
+++ b/lib/AST/Expr.cpp
@@ -1569,6 +1569,7 @@ bool CastExpr::CastConsistency() const {
   case CK_ARCReclaimReturnedObject:
   case CK_ARCExtendBlockObject:
   case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_IntToOCLSampler:
     assert(!getType()->isBooleanType() && "unheralded conversion to bool");
     goto CheckNoBasePath;
diff --git a/lib/AST/ExprConstant.cpp b/lib/AST/ExprConstant.cpp
index 107913e..b0876a3 100644
--- a/lib/AST/ExprConstant.cpp
+++ b/lib/AST/ExprConstant.cpp
@@ -976,7 +976,8 @@ CallStackFrame::~CallStackFrame() {
 APValue &CallStackFrame::createTemporary(const void *Key,
                                          bool IsLifetimeExtended) {
   APValue &Result = Temporaries[Key];
-  assert(Result.isUninit() && "temporary created multiple times");
+  // TODO: fix this!
+  //assert(Result.isUninit() && "temporary created multiple times");
   Info.CleanupStack.push_back(Cleanup(&Result, IsLifetimeExtended));
   return Result;
 }
@@ -6203,7 +6204,8 @@ public:
     : ExprEvaluatorBaseTy(info), Result(result) {}
 
   bool Success(const llvm::APSInt &SI, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() &&
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     assert(SI.isSigned() == E->getType()->isSignedIntegerOrEnumerationType() &&
            "Invalid evaluation result.");
@@ -6217,7 +6219,8 @@ public:
   }
 
   bool Success(const llvm::APInt &I, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() && 
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     assert(I.getBitWidth() == Info.Ctx.getIntWidth(E->getType()) &&
            "Invalid evaluation result.");
@@ -6231,7 +6234,8 @@ public:
   }
 
   bool Success(uint64_t Value, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() && 
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     Result = APValue(Info.Ctx.MakeIntValue(Value, E->getType()));
     return true;
@@ -8069,11 +8073,19 @@ bool IntExprEvaluator::VisitCastExpr(const CastExpr *E) {
   case CK_IntegralComplexToFloatingComplex:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_NonAtomicToAtomic:
   case CK_AddressSpaceConversion:
-  case CK_IntToOCLSampler:
     llvm_unreachable("invalid cast kind for integral value");
 
+  case CK_IntToOCLSampler: {
+    llvm::APSInt result;
+    if(!SubExpr->EvaluateAsInt(result, Info.Ctx)) {
+      return false;
+    }
+    return Success(result, E);
+  }
+
   case CK_BitCast:
   case CK_Dependent:
   case CK_LValueBitCast:
@@ -8295,9 +8307,11 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_huge_val:
   case Builtin::BI__builtin_huge_valf:
   case Builtin::BI__builtin_huge_vall:
+  case Builtin::BI__builtin_huge_valh:
   case Builtin::BI__builtin_inf:
   case Builtin::BI__builtin_inff:
-  case Builtin::BI__builtin_infl: {
+  case Builtin::BI__builtin_infl:
+  case Builtin::BI__builtin_infh: {
     const llvm::fltSemantics &Sem =
       Info.Ctx.getFloatTypeSemantics(E->getType());
     Result = llvm::APFloat::getInf(Sem);
@@ -8307,6 +8321,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nans:
   case Builtin::BI__builtin_nansf:
   case Builtin::BI__builtin_nansl:
+  case Builtin::BI__builtin_nansh:
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
                                true, Result))
       return Error(E);
@@ -8315,6 +8330,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nan:
   case Builtin::BI__builtin_nanf:
   case Builtin::BI__builtin_nanl:
+  case Builtin::BI__builtin_nanh:
     // If this is __builtin_nan() turn this into a nan, otherwise we
     // can't constant fold it.
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
@@ -8561,6 +8577,7 @@ bool ComplexExprEvaluator::VisitCastExpr(const CastExpr *E) {
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_NonAtomicToAtomic:
   case CK_AddressSpaceConversion:
   case CK_IntToOCLSampler:
@@ -9073,6 +9090,9 @@ static bool Evaluate(APValue &Result, EvalInfo &Info, const Expr *E) {
   } else if (T->isAtomicType()) {
     if (!EvaluateAtomic(E, Result, Info))
       return false;
+  } else if (T->isSamplerT()) {
+    if (!IntExprEvaluator(Info, Result).Visit(E))
+      return false;
   } else if (Info.getLangOpts().CPlusPlus11) {
     Info.FFDiag(E, diag::note_constexpr_nonliteral) << E->getType();
     return false;
diff --git a/lib/AST/ItaniumMangle.cpp b/lib/AST/ItaniumMangle.cpp
index 67d217e..2af4d3d 100644
--- a/lib/AST/ItaniumMangle.cpp
+++ b/lib/AST/ItaniumMangle.cpp
@@ -176,6 +176,9 @@ public:
 
   void mangleStringLiteral(const StringLiteral *, raw_ostream &) override;
 
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) override;
+  void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) override;
+
   bool getNextDiscriminator(const NamedDecl *ND, unsigned &disc) {
     // Lambda closure types are already numbered.
     if (isLambda(ND))
@@ -438,6 +441,7 @@ public:
   void mangleName(const NamedDecl *ND);
   void mangleType(QualType T);
   void mangleNameOrStandardSubstitution(const NamedDecl *ND);
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD);
   
 private:
 
@@ -2116,10 +2120,11 @@ void CXXNameMangler::mangleQualifiers(Qualifiers Quals) {
     } else {
       switch (AS) {
       default: llvm_unreachable("Not a language specific address space");
-      //  <OpenCL-addrspace> ::= "CL" [ "global" | "local" | "constant" ]
+      //  <OpenCL-addrspace> ::= "CL" [ "global" | "local" | "constant" | "generic" ]
       case LangAS::opencl_global:   ASString = "CLglobal";   break;
       case LangAS::opencl_local:    ASString = "CLlocal";    break;
       case LangAS::opencl_constant: ASString = "CLconstant"; break;
+      case LangAS::opencl_generic:  ASString = "CLgeneric";  break;
       //  <CUDA-addrspace> ::= "CU" [ "device" | "constant" | "shared" ]
       case LangAS::cuda_device:     ASString = "CUdevice";   break;
       case LangAS::cuda_constant:   ASString = "CUconstant"; break;
@@ -2202,7 +2207,7 @@ static bool isTypeSubstitutable(Qualifiers Quals, const Type *Ty) {
   if (Ty->isSpecificBuiltinType(BuiltinType::ObjCSel))
     return true;
   if (Ty->isOpenCLSpecificType())
-    return true;
+    return false;
   if (Ty->isBuiltinType())
     return false;
 
@@ -2250,7 +2255,9 @@ void CXXNameMangler::mangleType(QualType T) {
   Qualifiers quals = split.Quals;
   const Type *ty = split.Ty;
 
-  bool isSubstitutable = isTypeSubstitutable(quals, ty);
+  bool isSubstitutable =
+      isTypeSubstitutable(quals, ty) &&
+      !(Context.getASTContext().getLangOpts().OpenCL && isa<ExtVectorType>(T));
   if (isSubstitutable && mangleSubstitution(T))
     return;
 
@@ -2294,6 +2301,30 @@ void CXXNameMangler::mangleNameOrStandardSubstitution(const NamedDecl *ND) {
     mangleName(ND);
 }
 
+void CXXNameMangler::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD) {
+	const DeclContext *DC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(D));
+	const DeclContext *PDC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(RD));
+	
+	if(const auto II = D->getIdentifier()) {
+		// TODO: need actual parent field entry for all nested types
+		if(DC->getParent()->Equals(PDC)) {
+			mangleSourceName(II);
+		}
+	}
+	
+	// top level: mangle directly (without enclosing record decl / PDC)
+	// all else: mangle nested type as well
+	if(!DC->getParent()->Equals(PDC)) {
+		if (GetLocalClassDecl(D)) {
+			mangleLocalName(D, nullptr);
+		}
+		else {
+			mangleNestedName(D, DC, nullptr);
+		}
+	}
+	mangleType(D->getType());
+}
+
 void CXXNameMangler::mangleType(const BuiltinType *T) {
   //  <type>         ::= <builtin-type>
   //  <builtin-type> ::= v  # void
@@ -2324,7 +2355,7 @@ void CXXNameMangler::mangleType(const BuiltinType *T) {
   //                 ::= Ds # char16_t
   //                 ::= Dn # std::nullptr_t (i.e., decltype(nullptr))
   //                 ::= u <source-name>    # vendor extended type
-  std::string type_name;
+  //std::string type_name;
   switch (T->getKind()) {
   case BuiltinType::Void:
     Out << 'v';
@@ -2424,10 +2455,11 @@ void CXXNameMangler::mangleType(const BuiltinType *T) {
     Out << "13objc_selector";
     break;
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-  case BuiltinType::Id: \
-    type_name = "ocl_" #ImgType "_" #Suffix; \
+  case BuiltinType::Id: { \
+    const std::string type_name = "ocl_" #ImgType; \
     Out << type_name.size() << type_name; \
-    break;
+    break; \
+  }
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
     Out << "11ocl_sampler";
@@ -2465,8 +2497,10 @@ StringRef CXXNameMangler::getCallingConvQualifierName(CallingConv CC) {
   case CC_AAPCS:
   case CC_AAPCS_VFP:
   case CC_IntelOclBicc:
-  case CC_SpirFunction:
-  case CC_OpenCLKernel:
+  case CC_FloorFunction:
+  case CC_FloorKernel:
+  case CC_FloorVertex:
+  case CC_FloorFragment:
   case CC_PreserveMost:
   case CC_PreserveAll:
     // FIXME: we should be mangling all of the above.
@@ -4695,6 +4729,26 @@ void ItaniumMangleContextImpl::mangleStringLiteral(const StringLiteral *, raw_os
   llvm_unreachable("Can't mangle string literals");
 }
 
+void ItaniumMangleContextImpl::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &Out) {
+	assert(isa<FieldDecl>(D) &&
+		   "Invalid mangleName() call, argument is not a field decl!");
+	
+	PrettyStackTraceDecl CrashInfo(D, SourceLocation(),
+								   getASTContext().getSourceManager(),
+								   "Mangling declaration");
+	
+	CXXNameMangler Mangler(*this, Out, D);
+	Mangler.mangleMetalFieldName(D, RD);
+}
+
+void ItaniumMangleContextImpl::mangleMetalGeneric(const std::string& name, QualType Ty,
+												  const CXXRecordDecl* RD, raw_ostream &Out) {
+	CXXNameMangler Mangler(*this, Out, nullptr);
+	Out << name.size();
+	Out << name;
+	Mangler.mangleType(Ty);
+}
+
 ItaniumMangleContext *
 ItaniumMangleContext::create(ASTContext &Context, DiagnosticsEngine &Diags) {
   return new ItaniumMangleContextImpl(Context, Diags);
diff --git a/lib/AST/MicrosoftMangle.cpp b/lib/AST/MicrosoftMangle.cpp
index 479ac44..c1fee1c 100644
--- a/lib/AST/MicrosoftMangle.cpp
+++ b/lib/AST/MicrosoftMangle.cpp
@@ -1742,7 +1742,7 @@ void MicrosoftCXXNameMangler::mangleType(const BuiltinType *T, Qualifiers,
 
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case BuiltinType::Id: \
-    Out << "PAUocl_" #ImgType "_" #Suffix "@@"; \
+    Out << "PAUocl_" #ImgType #Suffix "@@"; \
     break;
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
diff --git a/lib/AST/Type.cpp b/lib/AST/Type.cpp
index 4c1d4ec..dba0de2 100644
--- a/lib/AST/Type.cpp
+++ b/lib/AST/Type.cpp
@@ -1788,6 +1788,13 @@ bool Type::isFloatingType() const {
   return false;
 }
 
+bool Type::isDoubleType() const {
+  if (const BuiltinType *BT = dyn_cast<BuiltinType>(CanonicalType))
+    return BT->getKind() >= BuiltinType::Double &&
+           BT->getKind() <= BuiltinType::LongDouble;
+  return false;
+}
+
 bool Type::hasFloatingRepresentation() const {
   if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
     return VT->getElementType()->isFloatingType();
@@ -1810,6 +1817,30 @@ bool Type::isRealType() const {
   return false;
 }
 
+bool Type::isFloatingVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isFloatingType();
+  return false;
+}
+
+bool Type::isDoubleVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isDoubleType();
+  return false;
+}
+
+bool Type::isIntegerVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isIntegerType();
+  return false;
+}
+
+bool Type::isRealVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isRealType();
+  return false;
+}
+
 bool Type::isArithmeticType() const {
   if (const BuiltinType *BT = dyn_cast<BuiltinType>(CanonicalType))
     return BT->getKind() >= BuiltinType::Bool &&
@@ -2155,6 +2186,9 @@ bool Type::isLiteralType(const ASTContext &Ctx) const {
   if (isDependentType())
     return false;
 
+  if (Ctx.getLangOpts().OpenCL && isSamplerT())
+    return true;
+
   // C++1y [basic.types]p10:
   //   A type is a literal type if it is:
   //   -- cv void; or
@@ -2588,10 +2622,17 @@ StringRef BuiltinType::getName(const PrintingPolicy &Policy) const {
     return "Class";
   case ObjCSel:
     return "SEL";
+#if 0 // TODO: enable this again when using ro/wo/rw image types
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case Id: \
     return "__" #Access " " #ImgType "_t";
 #include "clang/Basic/OpenCLImageTypes.def"
+#else
+#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
+  case Id: \
+    return #ImgType "_t";
+#include "clang/Basic/OpenCLImageTypes.def"
+#endif
   case OCLSampler:
     return "sampler_t";
   case OCLEvent:
@@ -2640,8 +2681,10 @@ StringRef FunctionType::getNameForCallConv(CallingConv CC) {
   case CC_AAPCS: return "aapcs";
   case CC_AAPCS_VFP: return "aapcs-vfp";
   case CC_IntelOclBicc: return "intel_ocl_bicc";
-  case CC_SpirFunction: return "spir_function";
-  case CC_OpenCLKernel: return "opencl_kernel";
+  case CC_FloorFunction: return "floor_function";
+  case CC_FloorKernel: return "floor_kernel";
+  case CC_FloorVertex: return "floor_vertex";
+  case CC_FloorFragment: return "floor_fragment";
   case CC_Swift: return "swiftcall";
   case CC_PreserveMost: return "preserve_most";
   case CC_PreserveAll: return "preserve_all";
@@ -2999,6 +3042,9 @@ bool AttributedType::isQualifier() const {
   case AttributedType::attr_preserve_all:
   case AttributedType::attr_ms_abi:
   case AttributedType::attr_sysv_abi:
+  case AttributedType::attr_floor_vertex:
+  case AttributedType::attr_floor_fragment:
+  case AttributedType::attr_floor_kernel:
   case AttributedType::attr_ptr32:
   case AttributedType::attr_ptr64:
   case AttributedType::attr_sptr:
@@ -3053,6 +3099,9 @@ bool AttributedType::isCallingConv() const {
   case attr_pascal:
   case attr_ms_abi:
   case attr_sysv_abi:
+  case attr_floor_vertex:
+  case attr_floor_fragment:
+  case attr_floor_kernel:
   case attr_inteloclbicc:
   case attr_preserve_most:
   case attr_preserve_all:
@@ -3789,3 +3838,102 @@ QualType::DestructionKind QualType::isDestructedTypeImpl(QualType type) {
 CXXRecordDecl *MemberPointerType::getMostRecentCXXRecordDecl() const {
   return getClass()->getAsCXXRecordDecl()->getMostRecentDecl();
 }
+
+static std::pair<bool, bool> isAggregateImageTypeRecurse(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return { false, false };
+	
+	// union is not allowed
+	if(decl->isUnion()) return { false, false };
+	
+	// must have definition
+	if(!decl->hasDefinition()) return { false, false };
+	
+	// iterate over all fields/members and check if all are image types
+	bool has_any_image = false;
+	for(const auto& field : decl->fields()) {
+		// direct image type or array thereof
+		if(!field->getType()->isImageType() &&
+		   !field->getType()->isArrayImageType(false)) {
+			return { false, false };
+		}
+		has_any_image = true;
+	}
+	
+	// iterate over / recurse into all bases, check if they only consist of image types
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = isAggregateImageTypeRecurse(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.first) {
+			return { false, false };
+		}
+		has_any_image |= base_ret.second;
+	}
+	
+	// all passed
+	return { true, has_any_image };
+}
+
+bool Type::isAggregateImageType() const {
+  // must be struct or class, union is not allowed
+  if(!isStructureOrClassType()) return false;
+
+  // check class/struct itself + all inherited base classes/structs
+  const auto valid_and_has_image = isAggregateImageTypeRecurse(getAsCXXRecordDecl());
+  return valid_and_has_image.first && valid_and_has_image.second;
+}
+
+// TODO: this probably isn't right (also detects other arrays)
+bool Type::isArrayImageType(bool single_field_arr) const {
+  // only check/match this for C-style arrays of builtin images
+  if(!single_field_arr) {
+    if(isPointerType() && getPointeeType()->isArrayType()) {
+      return getPointeeType()->isArrayImageType(single_field_arr);
+    }
+
+    // simple C-style array that contains an image type
+    if(isArrayType()) {
+      return (getAsArrayTypeUnsafe()->getElementType()->isAggregateImageType() ||
+              getAsArrayTypeUnsafe()->getElementType()->isImageType());
+    }
+  }
+
+  // must be struct or class, union is not allowed
+  if(!isStructureOrClassType()) return false;
+
+  // must be a cxx rdecl
+  const auto decl = getAsCXXRecordDecl();
+  if(!decl) return false;
+
+  // must have definition
+  if(!decl->hasDefinition()) return false;
+
+  // must have at least one field
+  const auto field_count = std::distance(decl->field_begin(), decl->field_end());
+  if(field_count == 0) return false;
+
+  // handle "array of agg images" (single_field_arr == true) and "agg image with array of *images" (false)
+  if(single_field_arr) {
+    if(field_count != 1) return false;
+
+    // field must be an array
+    const QualType arr_field_type = decl->field_begin()->getType();
+    if(!arr_field_type->isArrayType()) return false;
+
+    // element type must be an aggregate image type
+    return arr_field_type->getArrayElementTypeNoTypeQual()->isAggregateImageType();
+  }
+  else {
+    // must have an array field
+    bool has_array = false;
+    QualType arr_field_type;
+    for(const auto& field : decl->fields()) {
+      arr_field_type = field->getType();
+      has_array = arr_field_type->isArrayType();
+      if(has_array) break;
+    }
+    if(!has_array) return false;
+
+    // either the enclosing/parent type or the array field type must be an aggregate image type
+    return (isAggregateType() ||
+            arr_field_type->getArrayElementTypeNoTypeQual()->isAggregateImageType());
+  }
+}
diff --git a/lib/AST/TypePrinter.cpp b/lib/AST/TypePrinter.cpp
index 065a2db..cae9edd 100644
--- a/lib/AST/TypePrinter.cpp
+++ b/lib/AST/TypePrinter.cpp
@@ -724,9 +724,17 @@ void TypePrinter::printFunctionProtoAfter(const FunctionProtoType *T,
     case CC_X86_64SysV:
       OS << " __attribute__((sysv_abi))";
       break;
-    case CC_SpirFunction:
-    case CC_OpenCLKernel:
-      // Do nothing. These CCs are not available as attributes.
+    case CC_FloorFunction:
+      OS << "floor_function";
+      break;
+    case CC_FloorKernel:
+      OS << "floor_kernel";
+      break;
+    case CC_FloorVertex:
+      OS << "floor_vertex";
+      break;
+    case CC_FloorFragment:
+      OS << "floor_fragment";
       break;
     case CC_Swift:
       OS << " __attribute__((swiftcall))";
@@ -1338,6 +1346,9 @@ void TypePrinter::printAttributedAfter(const AttributedType *T,
   case AttributedType::attr_pascal: OS << "pascal"; break;
   case AttributedType::attr_ms_abi: OS << "ms_abi"; break;
   case AttributedType::attr_sysv_abi: OS << "sysv_abi"; break;
+  case AttributedType::attr_floor_vertex: OS << "floor_vertex"; break;
+  case AttributedType::attr_floor_fragment: OS << "floor_fragment"; break;
+  case AttributedType::attr_floor_kernel: OS << "floor_kernel"; break;
   case AttributedType::attr_pcs:
   case AttributedType::attr_pcs_vfp: {
     OS << "pcs(";
diff --git a/lib/Basic/Cuda.cpp b/lib/Basic/Cuda.cpp
index 3264078..e09938d 100644
--- a/lib/Basic/Cuda.cpp
+++ b/lib/Basic/Cuda.cpp
@@ -16,6 +16,8 @@ const char *CudaVersionToString(CudaVersion V) {
     return "7.5";
   case CudaVersion::CUDA_80:
     return "8.0";
+  case CudaVersion::CUDA_90:
+    return "9.0";
   }
   llvm_unreachable("invalid enum");
 }
@@ -48,6 +50,10 @@ const char *CudaArchToString(CudaArch A) {
     return "sm_61";
   case CudaArch::SM_62:
     return "sm_62";
+  case CudaArch::SM_70:
+    return "sm_70";
+  case CudaArch::SM_72:
+    return "sm_72";
   }
   llvm_unreachable("invalid enum");
 }
@@ -66,6 +72,8 @@ CudaArch StringToCudaArch(llvm::StringRef S) {
       .Case("sm_60", CudaArch::SM_60)
       .Case("sm_61", CudaArch::SM_61)
       .Case("sm_62", CudaArch::SM_62)
+      .Case("sm_70", CudaArch::SM_70)
+      .Case("sm_72", CudaArch::SM_72)
       .Default(CudaArch::UNKNOWN);
 }
 
@@ -95,6 +103,10 @@ const char *CudaVirtualArchToString(CudaVirtualArch A) {
     return "compute_61";
   case CudaVirtualArch::COMPUTE_62:
     return "compute_62";
+  case CudaVirtualArch::COMPUTE_70:
+    return "compute_70";
+  case CudaVirtualArch::COMPUTE_72:
+    return "compute_72";
   }
   llvm_unreachable("invalid enum");
 }
@@ -112,6 +124,8 @@ CudaVirtualArch StringToCudaVirtualArch(llvm::StringRef S) {
       .Case("compute_60", CudaVirtualArch::COMPUTE_60)
       .Case("compute_61", CudaVirtualArch::COMPUTE_61)
       .Case("compute_62", CudaVirtualArch::COMPUTE_62)
+      .Case("compute_70", CudaVirtualArch::COMPUTE_70)
+      .Case("compute_72", CudaVirtualArch::COMPUTE_72)
       .Default(CudaVirtualArch::UNKNOWN);
 }
 
@@ -142,6 +156,10 @@ CudaVirtualArch VirtualArchForCudaArch(CudaArch A) {
     return CudaVirtualArch::COMPUTE_61;
   case CudaArch::SM_62:
     return CudaVirtualArch::COMPUTE_62;
+  case CudaArch::SM_70:
+    return CudaVirtualArch::COMPUTE_70;
+  case CudaArch::SM_72:
+    return CudaVirtualArch::COMPUTE_72;
   }
   llvm_unreachable("invalid enum");
 }
@@ -159,11 +177,14 @@ CudaVersion MinVersionForCudaArch(CudaArch A) {
   case CudaArch::SM_50:
   case CudaArch::SM_52:
   case CudaArch::SM_53:
-    return CudaVersion::CUDA_70;
+    return CudaVersion::CUDA_75;
   case CudaArch::SM_60:
   case CudaArch::SM_61:
   case CudaArch::SM_62:
     return CudaVersion::CUDA_80;
+  case CudaArch::SM_70:
+  case CudaArch::SM_72:
+    return CudaVersion::CUDA_90;
   }
   llvm_unreachable("invalid enum");
 }
diff --git a/lib/Basic/TargetInfo.cpp b/lib/Basic/TargetInfo.cpp
index 592b877..510fa46 100644
--- a/lib/Basic/TargetInfo.cpp
+++ b/lib/Basic/TargetInfo.cpp
@@ -293,7 +293,8 @@ void TargetInfo::adjust(const LangOptions &Opts) {
     // OpenCL standard only mentions these as "reserved".
     IntWidth = IntAlign = 32;
     LongWidth = LongAlign = 64;
-    LongLongWidth = LongLongAlign = 128;
+    //LongLongWidth = LongLongAlign = 128; // NOTE: there is no 128-bit type support in OpenCL!
+    LongLongWidth = LongLongAlign = LongWidth;
     HalfWidth = HalfAlign = 16;
     FloatWidth = FloatAlign = 32;
 
@@ -304,7 +305,8 @@ void TargetInfo::adjust(const LangOptions &Opts) {
       DoubleWidth = DoubleAlign = 64;
       DoubleFormat = &llvm::APFloat::IEEEdouble;
     }
-    LongDoubleWidth = LongDoubleAlign = 128;
+    //LongDoubleWidth = LongDoubleAlign = 128; // NOTE: there is no 128-bit type support in OpenCL!
+    LongDoubleWidth = LongDoubleAlign = DoubleWidth;
 
     unsigned MaxPointerWidth = getMaxPointerWidth();
     assert(MaxPointerWidth == 32 || MaxPointerWidth == 64);
diff --git a/lib/Basic/Targets.cpp b/lib/Basic/Targets.cpp
index 36e6d45..633c29b 100644
--- a/lib/Basic/Targets.cpp
+++ b/lib/Basic/Targets.cpp
@@ -1816,6 +1816,10 @@ public:
           return "610";
         case CudaArch::SM_62:
           return "620";
+        case CudaArch::SM_70:
+          return "700";
+        case CudaArch::SM_72:
+          return "720";
         }
         llvm_unreachable("unhandled CudaArch");
       }();
@@ -1846,6 +1850,7 @@ public:
     case 'l':
     case 'f':
     case 'd':
+    case 'b':
       Info.setAllowsRegister();
       return true;
     }
@@ -1875,6 +1880,20 @@ public:
     Opts.cl_khr_local_int32_base_atomics = 1;
     Opts.cl_khr_local_int32_extended_atomics = 1;
   }
+
+  CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+    return CCCR_Warning;
+  }
+
+  CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
+    return CC_FloorFunction;
+  }
 };
 
 const Builtin::Info NVPTXTargetInfo::BuiltinInfo[] = {
@@ -2172,7 +2191,7 @@ public:
       default:
         return CCCR_Warning;
       case CC_C:
-      case CC_OpenCLKernel:
+      case CC_FloorKernel:
         return CCCR_OK;
     }
   }
@@ -7959,18 +7978,29 @@ static const unsigned SPIRAddrSpaceMap[] = {
     0, // cuda_constant
     0  // cuda_shared
 };
+// Vulkan/SPIR-V can't use global/CrossWorkgroup, but uses Uniform instead
+static const unsigned VulkanAddrSpaceMap[] = {
+    5, // opencl_global == SPIRAS_Uniform
+    3, // opencl_local
+    2, // opencl_constant
+    4, // opencl_generic
+    0, // cuda_device
+    0, // cuda_constant
+    0  // cuda_shared
+};
 class SPIRTargetInfo : public TargetInfo {
+private:
+  // true for spir-unknown-* and spir64-unknown-* (-> false for AIR/Metal)
+  const bool is_pure_spir;
+  const bool is_vulkan;
 public:
   SPIRTargetInfo(const llvm::Triple &Triple, const TargetOptions &)
-      : TargetInfo(Triple) {
-    assert(getTriple().getOS() == llvm::Triple::UnknownOS &&
-           "SPIR target must use unknown OS");
-    assert(getTriple().getEnvironment() == llvm::Triple::UnknownEnvironment &&
-           "SPIR target must use unknown environment type");
+      : TargetInfo(Triple), is_pure_spir(Triple.getVendorName().str() == "unknown"),
+        is_vulkan(Triple.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan) {
     BigEndian = false;
     TLSSupported = false;
     LongWidth = LongAlign = 64;
-    AddrSpaceMap = &SPIRAddrSpaceMap;
+    AddrSpaceMap = (!is_vulkan ? &SPIRAddrSpaceMap : &VulkanAddrSpaceMap);
     UseAddrSpaceMapMangling = true;
     // Define available target features
     // These must be defined in sorted order!
@@ -7984,6 +8014,9 @@ public:
     return Feature == "spir";
   }
 
+  bool isCLZForZeroUndef() const override { return false; }
+  bool isVulkan() const { return is_vulkan; }
+
   ArrayRef<Builtin::Info> getTargetBuiltins() const override { return None; }
   const char *getClobbers() const override { return ""; }
   ArrayRef<const char *> getGCCRegNames() const override { return None; }
@@ -7999,12 +8032,18 @@ public:
   }
 
   CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
-    return (CC == CC_SpirFunction || CC == CC_OpenCLKernel) ? CCCR_OK
-                                                            : CCCR_Warning;
+    if (!is_pure_spir) return CCCR_OK;
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+    return CCCR_Warning;
   }
 
   CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
-    return CC_SpirFunction;
+    return (is_pure_spir ? CC_FloorFunction : CC_C);
   }
 
   void setSupportedOpenCLOpts() override {
@@ -8022,7 +8061,8 @@ public:
     SizeType = TargetInfo::UnsignedInt;
     PtrDiffType = IntPtrType = TargetInfo::SignedInt;
     resetDataLayout("e-p:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-"
-                    "v96:128-v192:256-v256:256-v512:512-v1024:1024");
+                    "v96:128-v192:256-v256:256-v512:512-v1024:1024"
+                    "-n8:16:32:64");
   }
   void getTargetDefines(const LangOptions &Opts,
                         MacroBuilder &Builder) const override {
@@ -8038,7 +8078,8 @@ public:
     SizeType = TargetInfo::UnsignedLong;
     PtrDiffType = IntPtrType = TargetInfo::SignedLong;
     resetDataLayout("e-i64:64-v16:16-v24:32-v32:32-v48:64-"
-                    "v96:128-v192:256-v256:256-v512:512-v1024:1024");
+                    "v96:128-v192:256-v256:256-v512:512-v1024:1024"
+                    "-n8:16:32:64");
   }
   void getTargetDefines(const LangOptions &Opts,
                         MacroBuilder &Builder) const override {
@@ -8046,6 +8087,40 @@ public:
   }
 };
 
+class AIR64TargetInfo : public SPIRTargetInfo {
+public:
+  AIR64TargetInfo(const llvm::Triple &Triple, const TargetOptions &TO) : SPIRTargetInfo(Triple, TO) {
+    PointerWidth = PointerAlign = 64;
+    SizeType     = TargetInfo::UnsignedLong;
+    PtrDiffType = IntPtrType = TargetInfo::SignedLong;
+    if(Triple.getOS() == llvm::Triple::IOS) {
+      resetDataLayout("e-i64:64-f80:128-v16:16-v24:32-v32:32-v48:64-"
+                      "v96:128-v192:256-v256:256-v512:512-v1024:1024-n8:16:32");
+    }
+    else { // os x, or default
+      resetDataLayout("e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-f80:128:128-v16:16:16-v24:32:32-v32:32:32-v48:64:64-v64:64:64-v96:128:128-v128:128:128-v192:256:256-v256:256:256-v512:512:512-v1024:1024:1024-f80:128:128-n8:16:32");
+    }
+  }
+  void getTargetDefines(const LangOptions &Opts,
+                        MacroBuilder &Builder) const override {
+    DefineStd(Builder, "AIR64", Opts);
+  }
+
+  CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+    return CCCR_Warning;
+  }
+
+  CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
+    return CC_FloorFunction;
+  }
+};
+
 class XCoreTargetInfo : public TargetInfo {
   static const Builtin::Info BuiltinInfo[];
 public:
@@ -8580,18 +8655,12 @@ static TargetInfo *AllocateTarget(const llvm::Triple &Triple,
       return new X86_64TargetInfo(Triple, Opts);
     }
 
-  case llvm::Triple::spir: {
-    if (Triple.getOS() != llvm::Triple::UnknownOS ||
-        Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-      return nullptr;
+  case llvm::Triple::spir:
     return new SPIR32TargetInfo(Triple, Opts);
-  }
-  case llvm::Triple::spir64: {
-    if (Triple.getOS() != llvm::Triple::UnknownOS ||
-        Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-      return nullptr;
+  case llvm::Triple::spir64:
     return new SPIR64TargetInfo(Triple, Opts);
-  }
+  case llvm::Triple::air64:
+    return new AIR64TargetInfo(Triple, Opts);
   case llvm::Triple::wasm32:
     if (!(Triple == llvm::Triple("wasm32-unknown-unknown")))
       return nullptr;
diff --git a/lib/CodeGen/BackendUtil.cpp b/lib/CodeGen/BackendUtil.cpp
index 06f2136..4fe56f7 100644
--- a/lib/CodeGen/BackendUtil.cpp
+++ b/lib/CodeGen/BackendUtil.cpp
@@ -35,6 +35,7 @@
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Support/MemoryBuffer.h"
 #include "llvm/Support/PrettyStackTrace.h"
+#include "llvm/Support/SPIRV.h"
 #include "llvm/Support/TargetRegistry.h"
 #include "llvm/Support/Timer.h"
 #include "llvm/Support/raw_ostream.h"
@@ -50,6 +51,7 @@
 #include "llvm/Transforms/Scalar/GVN.h"
 #include "llvm/Transforms/Utils/SymbolRewriter.h"
 #include <memory>
+#include <fstream>
 using namespace clang;
 using namespace llvm;
 
@@ -311,8 +313,13 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
     break;
   case CodeGenOptions::NormalInlining:
   case CodeGenOptions::OnlyHintInlining: {
-    PMBuilder.Inliner =
-        createFunctionInliningPass(OptLevel, CodeGenOpts.OptimizeSize);
+    // always inline everything for metal/cuda/opencl/vulkan, otherwise we run into trouble when fixing the IR
+    if (LangOpts.Metal || LangOpts.CUDA || LangOpts.OpenCL || LangOpts.Vulkan) {
+      PMBuilder.Inliner = createEverythingInlinerPass();
+    }
+    else {
+      PMBuilder.Inliner = createFunctionInliningPass(OptLevel, CodeGenOpts.OptimizeSize);
+    }
     break;
   }
   case CodeGenOptions::OnlyAlwaysInlining:
@@ -345,6 +352,47 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
           TM->addEarlyAsPossiblePasses(PM);
         });
 
+  // close floor function info file, this is no longer needed
+  if ((LangOpts.Metal || LangOpts.CUDA || LangOpts.OpenCL || LangOpts.Vulkan) &&
+      LangOpts.floor_function_info != nullptr) {
+    LangOpts.floor_function_info->close();
+    delete LangOpts.floor_function_info;
+  }
+
+  PMBuilder.floor_image_capabilities = LangOpts.floor_image_capabilities;
+
+  PMBuilder.EnableAddressSpaceFix = LangOpts.OpenCL;
+  if(PMBuilder.EnableAddressSpaceFix && OptLevel == 0) {
+    unsigned DiagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "compiling OpenCL/Metal/Vulkan with -O0 is not possible!");
+    Diags.Report(DiagID);
+    return;
+  }
+
+  // only enable this for CUDA
+  PMBuilder.EnableCUDAPasses = LangOpts.CUDA;
+
+  // only enable this for Metal/AIR
+  PMBuilder.EnableMetalPasses = LangOpts.Metal;
+  PMBuilder.EnableMetalIntelWorkarounds = CodeGenOpts.MetalIntelWorkarounds;
+  PMBuilder.EnableMetalNvidiaWorkarounds = CodeGenOpts.MetalNvidiaWorkarounds;
+
+  // only enable this for OpenCL/SPIR and Vulkan/SPIR-V (don't want this for Metal)
+  PMBuilder.EnableSPIRPasses = (LangOpts.OpenCL &&
+                                (Triple(TheModule->getTargetTriple()).getArch() == Triple::spir64 ||
+                                 Triple(TheModule->getTargetTriple()).getArch() == Triple::spir));
+  PMBuilder.EnableSPIRIntelWorkarounds = CodeGenOpts.SPIRIntelWorkarounds;
+  PMBuilder.EnableVerifySPIR = PMBuilder.EnableSPIRPasses && LangOpts.CLVerifySPIR;
+
+  // only enable this for Vulkan/SPIR-V
+  PMBuilder.EnableVulkanPasses = (PMBuilder.EnableSPIRPasses &&
+                                  Triple(TheModule->getTargetTriple()).getEnvironment() == Triple::Vulkan);
+  if (PMBuilder.EnableVulkanPasses) {
+    // don't enable any vectorization for vulkan, this would lead to illegal pointer bitcasts
+    PMBuilder.BBVectorize = false;
+    PMBuilder.SLPVectorize = false;
+    PMBuilder.LoopVectorize = false;
+  }
+
   PMBuilder.addExtension(PassManagerBuilder::EP_EarlyAsPossible,
                          addAddDiscriminatorsPass);
 
@@ -424,6 +472,10 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
   if (!CodeGenOpts.RewriteMapFiles.empty())
     addSymbolRewriterPass(CodeGenOpts, &MPM);
 
+  if (LangOpts.OpenCL || LangOpts.CUDA) {
+    MPM.add(createInternalizePass());
+  }
+
   if (!CodeGenOpts.DisableGCov &&
       (CodeGenOpts.EmitGcovArcs || CodeGenOpts.EmitGcovNotes)) {
     // Not using 'GCOVOptions::getDefault' allows us to avoid exiting if
@@ -655,6 +707,10 @@ void EmitAssemblyHelper::EmitAssembly(BackendAction Action,
 
   bool UsesCodeGen = (Action != Backend_EmitNothing &&
                       Action != Backend_EmitBC &&
+                      Action != Backend_EmitBC32 &&
+                      Action != Backend_EmitBC35 &&
+                      Action != Backend_EmitSPIRV &&
+                      Action != Backend_EmitSPIRVContainer &&
                       Action != Backend_EmitLL);
   CreateTargetMachine(UsesCodeGen);
 
@@ -687,6 +743,22 @@ void EmitAssemblyHelper::EmitAssembly(BackendAction Action,
         CodeGenOpts.EmitSummaryIndex));
     break;
 
+  case Backend_EmitBC32:
+    PerModulePasses.add(createBitcode32WriterPass(*OS));
+    break;
+
+  case Backend_EmitBC35:
+    PerModulePasses.add(createBitcode35WriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRV:
+    PerModulePasses.add(createSPIRVWriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRVContainer:
+    PerModulePasses.add(createSPIRVContainerWriterPass(*OS));
+    break;
+
   case Backend_EmitLL:
     PerModulePasses.add(
         createPrintModulePass(*OS, "", CodeGenOpts.EmitLLVMUseLists));
diff --git a/lib/CodeGen/CGBlocks.cpp b/lib/CodeGen/CGBlocks.cpp
index e3658ab..f152dcc 100644
--- a/lib/CodeGen/CGBlocks.cpp
+++ b/lib/CodeGen/CGBlocks.cpp
@@ -14,6 +14,7 @@
 #include "CGBlocks.h"
 #include "CGDebugInfo.h"
 #include "CGObjCRuntime.h"
+#include "CGOpenCLRuntime.h"
 #include "CodeGenFunction.h"
 #include "CodeGenModule.h"
 #include "clang/AST/DeclObjC.h"
@@ -110,8 +111,15 @@ static llvm::Constant *buildBlockDescriptor(CodeGenModule &CGM,
   // Signature.  Mandatory ObjC-style method descriptor @encode sequence.
   std::string typeAtEncoding =
     CGM.getContext().getObjCEncodingForBlock(blockInfo.getBlockExpr());
-  elements.push_back(llvm::ConstantExpr::getBitCast(
-    CGM.GetAddrOfConstantCString(typeAtEncoding).getPointer(), i8p));
+
+  if (C.getLangOpts().OpenCL) {
+    elements.push_back(llvm::ConstantExpr::getAddrSpaceCast(
+                            CGM.GetAddrOfConstantCString(typeAtEncoding).getPointer(), i8p));
+  }
+  else {
+    elements.push_back(llvm::ConstantExpr::getBitCast(
+                            CGM.GetAddrOfConstantCString(typeAtEncoding).getPointer(), i8p));
+  }
   
   // GC layout.
   if (C.getLangOpts().ObjC1) {
@@ -329,7 +337,10 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
   const BlockDecl *block = info.getBlockDecl();
 
   SmallVector<llvm::Type*, 8> elementTypes;
-  initializeForBlockHeader(CGM, info, elementTypes);
+
+  // OpenCL doesn't use block header (Guy)
+  if (!CGM.getLangOpts().OpenCL)
+    initializeForBlockHeader(CGM, info, elementTypes);
 
   if (!block->hasCaptures()) {
     info.StructureType =
@@ -517,7 +528,9 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
   
   // At this point, we just have to add padding if the end align still
   // isn't aligned right.
-  if (endAlign < maxFieldAlign) {
+  if (CGM.getLangOpts().OpenCL && blockSize.getQuantity() == 0)
+    endAlign = maxFieldAlign;
+  else if (endAlign < maxFieldAlign) {
     CharUnits newBlockSize = blockSize.alignTo(maxFieldAlign);
     CharUnits padding = newBlockSize - blockSize;
 
@@ -534,7 +547,7 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
   }
 
   assert(endAlign >= maxFieldAlign);
-  assert(endAlign == getLowBit(blockSize));
+  assert((CGM.getLangOpts().OpenCL && blockSize.isZero()) || (endAlign == getLowBit(blockSize)));
   // Slam everything else on now.  This works because they have
   // strictly decreasing alignment and we expect that size is always a
   // multiple of alignment.
@@ -584,6 +597,11 @@ static void enterBlockScope(CodeGenFunction &CGF, BlockDecl *block) {
   blockInfo.LocalAddress = CGF.CreateTempAlloca(blockInfo.StructureType,
                                                 blockInfo.BlockAlign, "block");
 
+  if (CGF.getLangOpts().OpenCL) {
+    blockInfo.LocalAddress.getPointer()->setName("captured");
+    return;
+  }
+
   // If there are cleanups to emit, enter them (but inactive).
   if (!blockInfo.NeedsCopyDispose) return;
 
@@ -695,6 +713,24 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const BlockExpr *blockExpr) {
   return EmitBlockLiteral(*blockInfo);
 }
 
+llvm::Value *CodeGenFunction::GenerateOCLBlockBind(llvm::Constant *blockFunc,
+                                                   int ctxSize,
+                                                   int ctxAlign,
+                                                   llvm::Value *ctx) {
+    llvm::Type *ArgTys[] = {VoidPtrTy, IntTy, IntTy, VoidPtrTy};
+    llvm::FunctionType *FTy = llvm::FunctionType::get(
+                                            CGM.getOpenCLRuntime().getBlockType(),
+                                            llvm::ArrayRef<llvm::Type*>(ArgTys),
+                                            false);
+    return Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_block_bind"),
+                              {
+                                blockFunc,
+                                Builder.getInt32(ctxSize),
+                                Builder.getInt32(ctxAlign),
+                                ctx
+                              });
+}
+
 llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
   // Using the computed layout, generate the actual block function.
   bool isLambdaConv = blockInfo.getBlockDecl()->isConversionFromLambda();
@@ -704,27 +740,7 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
                                                        isLambdaConv);
   blockFn = llvm::ConstantExpr::getBitCast(blockFn, VoidPtrTy);
 
-  // If there is nothing to capture, we can emit this as a global block.
-  if (blockInfo.CanBeGlobal)
-    return buildGlobalBlock(CGM, blockInfo, blockFn);
-
-  // Otherwise, we have to emit this as a local block.
-
-  llvm::Constant *isa = CGM.getNSConcreteStackBlock();
-  isa = llvm::ConstantExpr::getBitCast(isa, VoidPtrTy);
-
-  // Build the block descriptor.
-  llvm::Constant *descriptor = buildBlockDescriptor(CGM, blockInfo);
-
   Address blockAddr = blockInfo.LocalAddress;
-  assert(blockAddr.isValid() && "block has no address!");
-
-  // Compute the initial on-stack block flags.
-  BlockFlags flags = BLOCK_HAS_SIGNATURE;
-  if (blockInfo.HasCapturedVariableLayout) flags |= BLOCK_HAS_EXTENDED_LAYOUT;
-  if (blockInfo.NeedsCopyDispose) flags |= BLOCK_HAS_COPY_DISPOSE;
-  if (blockInfo.HasCXXObject) flags |= BLOCK_HAS_CXX_OBJ;
-  if (blockInfo.UsesStret) flags |= BLOCK_USE_STRET;
 
   auto projectField =
     [&](unsigned index, CharUnits offset, const Twine &name) -> Address {
@@ -736,25 +752,53 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
       Builder.CreateStore(value, projectField(index, offset, name));
     };
 
-  // Initialize the block header.
-  {
-    // We assume all the header fields are densely packed.
-    unsigned index = 0;
-    CharUnits offset;
-    auto addHeaderField =
-      [&](llvm::Value *value, CharUnits size, const Twine &name) {
-        storeField(value, index, offset, name);
-        offset += size;
-        index++;
-      };
-
-    addHeaderField(isa, getPointerSize(), "block.isa");
-    addHeaderField(llvm::ConstantInt::get(IntTy, flags.getBitMask()),
-                   getIntSize(), "block.flags");
-    addHeaderField(llvm::ConstantInt::get(IntTy, 0),
-                   getIntSize(), "block.reserved");
-    addHeaderField(blockFn, getPointerSize(), "block.invoke");
-    addHeaderField(descriptor, getPointerSize(), "block.descriptor");
+  if (CGM.getLangOpts().OpenCL) {
+    if (blockInfo.CanBeGlobal)
+      return GenerateOCLBlockBind(blockFn, blockInfo.BlockSize.getQuantity(),
+                                  blockInfo.BlockAlign.getQuantity(),
+                                  llvm::Constant::getNullValue(VoidPtrTy));
+  } else {
+    // If there is nothing to capture, we can emit this as a global block.
+    if (blockInfo.CanBeGlobal)
+      return buildGlobalBlock(CGM, blockInfo, blockFn);
+
+    // Otherwise, we have to emit this as a local block.
+
+    llvm::Constant *isa = CGM.getNSConcreteStackBlock();
+    isa = llvm::ConstantExpr::getBitCast(isa, VoidPtrTy);
+
+    // Build the block descriptor.
+    llvm::Constant *descriptor = buildBlockDescriptor(CGM, blockInfo);
+    blockAddr = blockInfo.LocalAddress;
+    assert(blockAddr.isValid() && "block has no address!");
+
+    // Compute the initial on-stack block flags.
+    BlockFlags flags = BLOCK_HAS_SIGNATURE;
+    if (blockInfo.HasCapturedVariableLayout) flags |= BLOCK_HAS_EXTENDED_LAYOUT;
+    if (blockInfo.NeedsCopyDispose) flags |= BLOCK_HAS_COPY_DISPOSE;
+    if (blockInfo.HasCXXObject) flags |= BLOCK_HAS_CXX_OBJ;
+    if (blockInfo.UsesStret) flags |= BLOCK_USE_STRET;
+
+    // Initialize the block header.
+    {
+      // We assume all the header fields are densely packed.
+      unsigned index = 0;
+      CharUnits offset;
+      auto addHeaderField =
+        [&](llvm::Value *value, CharUnits size, const Twine &name) {
+          storeField(value, index, offset, name);
+          offset += size;
+          index++;
+        };
+
+      addHeaderField(isa, getPointerSize(), "block.isa");
+      addHeaderField(llvm::ConstantInt::get(IntTy, flags.getBitMask()),
+                     getIntSize(), "block.flags");
+      addHeaderField(llvm::ConstantInt::get(IntTy, 0),
+                     getIntSize(), "block.reserved");
+      addHeaderField(blockFn, getPointerSize(), "block.invoke");
+      addHeaderField(descriptor, getPointerSize(), "block.descriptor");
+    }
   }
 
   // Finally, capture all the values into the block.
@@ -899,8 +943,13 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
   // Cast to the converted block-pointer type, which happens (somewhat
   // unfortunately) to be a pointer to function type.
   llvm::Value *result =
-    Builder.CreateBitCast(blockAddr.getPointer(),
-                          ConvertType(blockInfo.getBlockExpr()->getType()));
+      (CGM.getLangOpts().OpenCL)
+          ? GenerateOCLBlockBind(
+                blockFn, blockInfo.BlockSize.getQuantity(),
+                blockInfo.BlockAlign.getQuantity(),
+                Builder.CreateBitCast(blockInfo.LocalAddress.getPointer(), VoidPtrTy))
+          : Builder.CreateBitCast(
+                blockAddr.getPointer(), ConvertType(blockInfo.getBlockExpr()->getType()));
 
   return result;
 }
@@ -967,19 +1016,33 @@ RValue CodeGenFunction::EmitBlockCallExpr(const CallExpr *E,
 
   llvm::Value *Callee = EmitScalarExpr(E->getCallee());
 
-  // Get a pointer to the generic block literal.
-  llvm::Type *BlockLiteralTy =
-    llvm::PointerType::getUnqual(CGM.getGenericBlockLiteralType());
+  llvm::Value *Func;
+  llvm::Value *BlockLiteral;
+  llvm::Value *FuncPtr = nullptr;
+
+  if (CGM.getLangOpts().OpenCL) {
+    llvm::Type *ArgTy[] = {CGM.getOpenCLRuntime().getBlockType()};
+    llvm::FunctionType *FTy = llvm::FunctionType::get(
+                                            VoidPtrTy,
+                                            llvm::ArrayRef<llvm::Type*>(ArgTy),
+                                            false);
+    Func = Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_get_block_invoke"), Callee);
+    BlockLiteral = Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_get_block_context"), Callee);
+  } else {
+    // Get a pointer to the generic block literal.
+    llvm::Type *BlockLiteralTy =
+      llvm::PointerType::getUnqual(CGM.getGenericBlockLiteralType());
 
-  // Bitcast the callee to a block literal.
-  llvm::Value *BlockLiteral =
-    Builder.CreateBitCast(Callee, BlockLiteralTy, "block.literal");
+    // Bitcast the callee to a block literal.
+    BlockLiteral =
+      Builder.CreateBitCast(Callee, BlockLiteralTy, "block.literal");
 
-  // Get the function pointer from the literal.
-  llvm::Value *FuncPtr =
-    Builder.CreateStructGEP(CGM.getGenericBlockLiteralType(), BlockLiteral, 3);
+    // Get the function pointer from the literal.
+    FuncPtr =
+      Builder.CreateStructGEP(CGM.getGenericBlockLiteralType(), BlockLiteral, 3);
 
-  BlockLiteral = Builder.CreateBitCast(BlockLiteral, VoidPtrTy);
+    BlockLiteral = Builder.CreateBitCast(BlockLiteral, VoidPtrTy);
+  }
 
   // Add the block literal.
   CallArgList Args;
@@ -990,8 +1053,11 @@ RValue CodeGenFunction::EmitBlockCallExpr(const CallExpr *E,
   // And the rest of the arguments.
   EmitCallArgs(Args, FnType->getAs<FunctionProtoType>(), E->arguments());
 
-  // Load the function.
-  llvm::Value *Func = Builder.CreateAlignedLoad(FuncPtr, getPointerAlign());
+  if (!CGM.getLangOpts().OpenCL) {
+    assert(FuncPtr);
+    // Load the function.
+    Func = Builder.CreateAlignedLoad(FuncPtr, getPointerAlign());
+  }
 
   const FunctionType *FuncTy = FnType->castAs<FunctionType>();
   const CGFunctionInfo &FnInfo =
@@ -1058,6 +1124,13 @@ CodeGenModule::GetAddrOfGlobalBlock(const BlockExpr *blockExpr,
                                                            LocalDeclMap,
                                                            false);
   }
+
+  if (getLangOpts().OpenCL) {
+    // In OpenCL, we bind the block lazily, so here we just generate the
+    // block invoke function
+    return blockFn;
+  }
+
   blockFn = llvm::ConstantExpr::getBitCast(blockFn, VoidPtrTy);
 
   return buildGlobalBlock(*this, blockInfo, blockFn);
diff --git a/lib/CodeGen/CGBuiltin.cpp b/lib/CodeGen/CGBuiltin.cpp
index c06fcf7..f0e6a75 100644
--- a/lib/CodeGen/CGBuiltin.cpp
+++ b/lib/CodeGen/CGBuiltin.cpp
@@ -15,9 +15,11 @@
 #include "CGCXXABI.h"
 #include "CGObjCRuntime.h"
 #include "CodeGenModule.h"
+#include "CGOpenCLRuntime.h"
 #include "TargetInfo.h"
 #include "clang/AST/ASTContext.h"
 #include "clang/AST/Decl.h"
+#include "clang/AST/Expr.h"
 #include "clang/Basic/TargetBuiltins.h"
 #include "clang/Basic/TargetInfo.h"
 #include "clang/CodeGen/CGFunctionInfo.h"
@@ -1409,29 +1411,31 @@ RValue CodeGenFunction::EmitBuiltinExpr(const FunctionDecl *FD,
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       AtomicRMWInst *Result = nullptr;
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
                                          llvm::AtomicOrdering::Monotonic);
         break;
-      case 1: // memory_order_consume
-      case 2: // memory_order_acquire
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_consume:
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acquire:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::Acquire);
         break;
-      case 3: // memory_order_release
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::Release);
         break;
-      case 4: // memory_order_acq_rel
-
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acq_rel:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::AcquireRelease);
         break;
-      case 5: // memory_order_seq_cst
-        Result = Builder.CreateAtomicRMW(
-            llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
-            llvm::AtomicOrdering::SequentiallyConsistent);
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
+                                         llvm::AtomicOrdering::SequentiallyConsistent);
         break;
       }
       Result->setVolatile(Volatile);
@@ -1492,14 +1496,14 @@ RValue CodeGenFunction::EmitBuiltinExpr(const FunctionDecl *FD,
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       StoreInst *Store = Builder.CreateStore(NewVal, Ptr, Volatile);
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         Store->setOrdering(llvm::AtomicOrdering::Monotonic);
         break;
-      case 3:  // memory_order_release
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:
         Store->setOrdering(llvm::AtomicOrdering::Release);
         break;
-      case 5:  // memory_order_seq_cst
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:
         Store->setOrdering(llvm::AtomicOrdering::SequentiallyConsistent);
         break;
       }
@@ -1549,22 +1553,21 @@ RValue CodeGenFunction::EmitBuiltinExpr(const FunctionDecl *FD,
     if (isa<llvm::ConstantInt>(Order)) {
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         break;
-      case 1:  // memory_order_consume
-      case 2:  // memory_order_acquire
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_consume:
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acquire:
         Builder.CreateFence(llvm::AtomicOrdering::Acquire, Scope);
         break;
-      case 3:  // memory_order_release
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:
         Builder.CreateFence(llvm::AtomicOrdering::Release, Scope);
         break;
-      case 4:  // memory_order_acq_rel
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acq_rel:
         Builder.CreateFence(llvm::AtomicOrdering::AcquireRelease, Scope);
         break;
-      case 5:  // memory_order_seq_cst
-        Builder.CreateFence(llvm::AtomicOrdering::SequentiallyConsistent,
-                            Scope);
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:
+        Builder.CreateFence(llvm::AtomicOrdering::SequentiallyConsistent, Scope);
         break;
       }
       return RValue::get(nullptr);
diff --git a/lib/CodeGen/CGCall.cpp b/lib/CodeGen/CGCall.cpp
index 94261bf..f50b4a6 100644
--- a/lib/CodeGen/CGCall.cpp
+++ b/lib/CodeGen/CGCall.cpp
@@ -57,8 +57,10 @@ unsigned CodeGenTypes::ClangCallConvToLLVMCallConv(CallingConv CC) {
   case CC_X86Pascal: return llvm::CallingConv::C;
   // TODO: Add support for __vectorcall to LLVM.
   case CC_X86VectorCall: return llvm::CallingConv::X86_VectorCall;
-  case CC_SpirFunction: return llvm::CallingConv::SPIR_FUNC;
-  case CC_OpenCLKernel: return CGM.getTargetCodeGenInfo().getOpenCLKernelCallingConv();
+  case CC_FloorFunction: return llvm::CallingConv::FLOOR_FUNC;
+  case CC_FloorKernel: return llvm::CallingConv::FLOOR_KERNEL;
+  case CC_FloorVertex: return llvm::CallingConv::FLOOR_VERTEX;
+  case CC_FloorFragment: return llvm::CallingConv::FLOOR_FRAGMENT;
   case CC_PreserveMost: return llvm::CallingConv::PreserveMost;
   case CC_PreserveAll: return llvm::CallingConv::PreserveAll;
   case CC_Swift: return llvm::CallingConv::Swift;
@@ -193,6 +195,15 @@ static CallingConv getCallingConventionForDecl(const Decl *D, bool IsWindows) {
   if (D->hasAttr<SysVABIAttr>())
     return IsWindows ? CC_X86_64SysV : CC_C;
 
+  if (D->hasAttr<GraphicsVertexShaderAttr>())
+    return CC_FloorVertex;
+
+  if (D->hasAttr<GraphicsFragmentShaderAttr>())
+    return CC_FloorFragment;
+
+  if (D->hasAttr<ComputeKernelAttr>())
+    return CC_FloorKernel;
+
   if (D->hasAttr<PreserveMostAttr>())
     return CC_PreserveMost;
 
@@ -776,6 +787,10 @@ struct TypeExpansion {
     TEK_Record,
     // For complex types, real and imaginary parts are expanded recursively.
     TEK_Complex,
+    // Special libfloor vector compat expansion (aggregate -> clang/llvm vector).
+    TEK_FloorVectorCompat,
+    // Special libfloor aggregate/record expansion.
+    TEK_FloorAggregate,
     // All other types are not expandable.
     TEK_None
   };
@@ -820,6 +835,31 @@ struct ComplexExpansion : TypeExpansion {
   }
 };
 
+struct FloorVectorCompatExpansion : TypeExpansion {
+  QualType orig_type;
+  QualType vector_type;
+
+  FloorVectorCompatExpansion(QualType orig_type_, QualType vector_type_)
+      : TypeExpansion(TEK_FloorVectorCompat), orig_type(orig_type_), vector_type(vector_type_) {}
+  static bool classof(const TypeExpansion *TE) {
+    return TE->Kind == TEK_FloorVectorCompat;
+  }
+};
+
+struct FloorAggregateExpansion : TypeExpansion {
+  SmallVector<const CXXBaseSpecifier *, 1> bases;
+  SmallVector<const FieldDecl *, 1> field_decls;
+  std::vector<CodeGenTypes::aggregate_scalar_entry> fields;
+
+  FloorAggregateExpansion(SmallVector<const CXXBaseSpecifier *, 1> &&bases_,
+                          SmallVector<const FieldDecl *, 1> &&field_decls_,
+                          std::vector<CodeGenTypes::aggregate_scalar_entry> &&fields_)
+      : TypeExpansion(TEK_FloorAggregate), bases(bases_), field_decls(field_decls_), fields(fields_) {}
+  static bool classof(const TypeExpansion *TE) {
+    return TE->Kind == TEK_FloorAggregate;
+  }
+};
+
 struct NoExpansion : TypeExpansion {
   NoExpansion() : TypeExpansion(TEK_None) {}
   static bool classof(const TypeExpansion *TE) {
@@ -829,12 +869,61 @@ struct NoExpansion : TypeExpansion {
 }  // namespace
 
 static std::unique_ptr<TypeExpansion>
-getTypeExpansion(QualType Ty, const ASTContext &Context) {
+getTypeExpansion(QualType Ty, const ASTContext &Context,
+                 const CodeGenTypes& CGT, const CallingConv CC) {
   if (const ConstantArrayType *AT = Context.getAsConstantArrayType(Ty)) {
     return llvm::make_unique<ConstantArrayExpansion>(
         AT->getElementType(), AT->getSize().getZExtValue());
   }
-  if (const RecordType *RT = Ty->getAs<RecordType>()) {
+  const RecordType *RT = Ty->getAs<RecordType>();
+  const CXXRecordDecl* cxx_rdecl = (RT != nullptr ? RT->getAsCXXRecordDecl() : nullptr);
+  if (cxx_rdecl) {
+    // libfloor vector compat expansion (metal/vulkan vertex/fragment shader only, or vulkan compute shader)
+    if (cxx_rdecl->hasAttr<VectorCompatAttr>() &&
+        ((Context.getLangOpts().Metal && (CC == CallingConv::CC_FloorVertex ||
+                                          CC == CallingConv::CC_FloorFragment)) ||
+         (Context.getLangOpts().Vulkan && (CC == CallingConv::CC_FloorKernel ||
+                                           CC == CallingConv::CC_FloorVertex ||
+                                           CC == CallingConv::CC_FloorFragment)))) {
+      const auto vec_type = CGT.get_compat_vector_type(cxx_rdecl);
+      return llvm::make_unique<FloorVectorCompatExpansion>(Ty, vec_type);
+    }
+    // libfloor aggregate expansion:
+    // * any aggregate image type
+    // * any aggregate if calling a metal vertex/fragment shader function
+    // similar to (non-union) record expansion below, but also stores some additional information
+    if ((Ty->isAggregateImageType() ||
+         ((Context.getLangOpts().Metal && (CC == CallingConv::CC_FloorVertex ||
+                                           CC == CallingConv::CC_FloorFragment)) ||
+          (Context.getLangOpts().Vulkan && (CC == CallingConv::CC_FloorKernel ||
+                                            CC == CallingConv::CC_FloorVertex ||
+                                            CC == CallingConv::CC_FloorFragment)))) &&
+        !cxx_rdecl->isUnion()) {
+      SmallVector<const CXXBaseSpecifier *, 1> bases;
+      SmallVector<const FieldDecl *, 1> field_decls;
+
+      assert(!cxx_rdecl->isDynamicClass() &&
+             "cannot expand vtable pointers in dynamic classes");
+      for (const CXXBaseSpecifier &BS : cxx_rdecl->bases()) {
+        bases.push_back(&BS);
+      }
+
+      for (const auto *FD : cxx_rdecl->fields()) {
+        // Skip zero length bitfields.
+        if (FD->isBitField() && FD->getBitWidthValue(Context) == 0)
+          continue;
+        assert(!FD->isBitField() &&
+               "Cannot expand structure with bit-field members.");
+        field_decls.push_back(FD);
+      }
+
+      auto fields = CGT.get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl, false, false,
+                                                    !(Context.getLangOpts().Vulkan ||
+                                                      Context.getLangOpts().Metal));
+      return llvm::make_unique<FloorAggregateExpansion>(std::move(bases), std::move(field_decls), std::move(fields));
+    }
+  }
+  if (RT) {
     SmallVector<const CXXBaseSpecifier *, 1> Bases;
     SmallVector<const FieldDecl *, 1> Fields;
     const RecordDecl *RD = RT->getDecl();
@@ -886,17 +975,24 @@ getTypeExpansion(QualType Ty, const ASTContext &Context) {
   return llvm::make_unique<NoExpansion>();
 }
 
-static int getExpansionSize(QualType Ty, const ASTContext &Context) {
-  auto Exp = getTypeExpansion(Ty, Context);
+static int getExpansionSize(QualType Ty, const ASTContext &Context,
+                            const CodeGenTypes& CGT, const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, Context, CGT, CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
-    return CAExp->NumElts * getExpansionSize(CAExp->EltTy, Context);
+    return CAExp->NumElts * getExpansionSize(CAExp->EltTy, Context, CGT, CC);
+  }
+  if (isa<FloorVectorCompatExpansion>(Exp.get())) {
+    return 1;
+  }
+  if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    return FAExp->fields.size();
   }
   if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     int Res = 0;
     for (auto BS : RExp->Bases)
-      Res += getExpansionSize(BS->getType(), Context);
+      Res += getExpansionSize(BS->getType(), Context, CGT, CC);
     for (auto FD : RExp->Fields)
-      Res += getExpansionSize(FD->getType(), Context);
+      Res += getExpansionSize(FD->getType(), Context, CGT, CC);
     return Res;
   }
   if (isa<ComplexExpansion>(Exp.get()))
@@ -907,17 +1003,30 @@ static int getExpansionSize(QualType Ty, const ASTContext &Context) {
 
 void
 CodeGenTypes::getExpandedTypes(QualType Ty,
-                               SmallVectorImpl<llvm::Type *>::iterator &TI) {
-  auto Exp = getTypeExpansion(Ty, Context);
+                               SmallVectorImpl<llvm::Type *>::iterator &TI,
+                               const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, Context, *this, CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     for (int i = 0, n = CAExp->NumElts; i < n; i++) {
-      getExpandedTypes(CAExp->EltTy, TI);
+      getExpandedTypes(CAExp->EltTy, TI, CC);
+    }
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    *TI++ = ConvertType(FVCExp->vector_type);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    for(const auto& field : FAExp->fields) {
+      auto conv_type = ConvertType(field.type);;
+      if (field.type->isArrayImageType(false)) {
+        *TI++ = (!conv_type->isPointerTy() ?
+                  llvm::PointerType::get(conv_type, 0) : conv_type);
+      } else {
+        *TI++ = conv_type;
+      }
     }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     for (auto BS : RExp->Bases)
-      getExpandedTypes(BS->getType(), TI);
+      getExpandedTypes(BS->getType(), TI, CC);
     for (auto FD : RExp->Fields)
-      getExpandedTypes(FD->getType(), TI);
+      getExpandedTypes(FD->getType(), TI, CC);
   } else if (auto CExp = dyn_cast<ComplexExpansion>(Exp.get())) {
     llvm::Type *EltTy = ConvertType(CExp->EltTy);
     *TI++ = EltTy;
@@ -943,18 +1052,55 @@ static void forConstantArrayExpansion(CodeGenFunction &CGF,
   }
 }
 
-void CodeGenFunction::ExpandTypeFromArgs(
-    QualType Ty, LValue LV, SmallVectorImpl<llvm::Value *>::iterator &AI) {
+void CodeGenFunction::ExpandTypeFromArgs(QualType Ty, LValue LV,
+                                         SmallVectorImpl<llvm::Value *>::iterator &AI,
+                                         const CallingConv CC) {
   assert(LV.isSimple() &&
          "Unexpected non-simple lvalue during struct expansion.");
 
-  auto Exp = getTypeExpansion(Ty, getContext());
+  auto Exp = getTypeExpansion(Ty, getContext(), getTypes(), CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     forConstantArrayExpansion(*this, CAExp, LV.getAddress(),
                               [&](Address EltAddr) {
       LValue LV = MakeAddrLValue(EltAddr, CAExp->EltTy);
-      ExpandTypeFromArgs(CAExp->EltTy, LV, AI);
+      ExpandTypeFromArgs(CAExp->EltTy, LV, AI, CC);
     });
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    LValue VecLV = MakeAddrLValue(LV.getAddress(), FVCExp->vector_type);
+    ExpandTypeFromArgs(FVCExp->vector_type, VecLV, AI, CC);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    // TODO: should this recurse into bases with ExpandTypeFromArgs or do this manually?
+    Address This = LV.getAddress();
+    for (const CXXBaseSpecifier *BS : FAExp->bases) {
+      // Perform a single step derived-to-base conversion.
+      Address Base =
+          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,
+                                /*NullCheckValue=*/false, SourceLocation());
+      LValue SubLV = MakeAddrLValue(Base, BS->getType());
+
+      // Recurse onto bases.
+      ExpandTypeFromArgs(BS->getType(), SubLV, AI, CC);
+    }
+
+    for(const auto& field : FAExp->fields) {
+      if(field.is_in_base) continue; // already handled
+      // TODO: non-image arrays -> these have no FD
+      if (field.field_decl) {
+        // array of images
+        if (field.type->isArrayImageType(false)) {
+          LValue SubLV = EmitLValueForField(LV, field.field_decl);
+          Builder.CreateStore(*AI++, SubLV.getAddress());
+        }
+        // all else
+        else {
+          LValue SubLV = EmitLValueForFieldInitialization(LV, field.field_decl);
+          ExpandTypeFromArgs(SubLV.getType(), SubLV, AI, CC);
+        }
+      } else {
+        // will probably fail, but still try -> TODO above
+        EmitStoreThroughLValue(RValue::get(*AI++), LV);
+      }
+    }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     Address This = LV.getAddress();
     for (const CXXBaseSpecifier *BS : RExp->Bases) {
@@ -965,12 +1111,12 @@ void CodeGenFunction::ExpandTypeFromArgs(
       LValue SubLV = MakeAddrLValue(Base, BS->getType());
 
       // Recurse onto bases.
-      ExpandTypeFromArgs(BS->getType(), SubLV, AI);
+      ExpandTypeFromArgs(BS->getType(), SubLV, AI, CC);
     }
     for (auto FD : RExp->Fields) {
       // FIXME: What are the right qualifiers here?
       LValue SubLV = EmitLValueForFieldInitialization(LV, FD);
-      ExpandTypeFromArgs(FD->getType(), SubLV, AI);
+      ExpandTypeFromArgs(FD->getType(), SubLV, AI, CC);
     }
   } else if (isa<ComplexExpansion>(Exp.get())) {
     auto realValue = *AI++;
@@ -984,15 +1130,44 @@ void CodeGenFunction::ExpandTypeFromArgs(
 
 void CodeGenFunction::ExpandTypeToArgs(
     QualType Ty, RValue RV, llvm::FunctionType *IRFuncTy,
-    SmallVectorImpl<llvm::Value *> &IRCallArgs, unsigned &IRCallArgPos) {
-  auto Exp = getTypeExpansion(Ty, getContext());
+    SmallVectorImpl<llvm::Value *> &IRCallArgs, unsigned &IRCallArgPos,
+    const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, getContext(), getTypes(), CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     forConstantArrayExpansion(*this, CAExp, RV.getAggregateAddress(),
                               [&](Address EltAddr) {
       RValue EltRV =
           convertTempToRValue(EltAddr, CAExp->EltTy, SourceLocation());
-      ExpandTypeToArgs(CAExp->EltTy, EltRV, IRFuncTy, IRCallArgs, IRCallArgPos);
+      ExpandTypeToArgs(CAExp->EltTy, EltRV, IRFuncTy, IRCallArgs, IRCallArgPos, CC);
     });
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    const auto llvm_vec_type = getTypes().ConvertType(FVCExp->vector_type);
+    auto vec_ptr = Builder.CreateBitCast(RV.getAggregateAddress().getPointer(),
+                                         llvm::PointerType::get(llvm_vec_type, Ty.getAddressSpace()));
+    Address vec_ptr_addr(vec_ptr, RV.getAggregateAddress().getAlignment());
+    IRCallArgs[IRCallArgPos++] = Builder.CreateLoad(vec_ptr_addr);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    // TODO: should this recurse into bases with ExpandTypeToArgs or do this manually?
+    Address This = RV.getAggregateAddress();
+    for (const CXXBaseSpecifier *BS : FAExp->bases) {
+      // Perform a single step derived-to-base conversion.
+      Address Base =
+          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,
+                                /*NullCheckValue=*/false, SourceLocation());
+      RValue BaseRV = RValue::getAggregate(Base);
+
+      // Recurse onto bases.
+      ExpandTypeToArgs(BS->getType(), BaseRV, IRFuncTy, IRCallArgs,
+                       IRCallArgPos, CC);
+    }
+
+    LValue LV = MakeAddrLValue(This, Ty);
+    for(const auto& field : FAExp->fields) {
+      if(field.is_in_base) continue; // already handled
+      // TODO: arrays -> these have no FD
+      RValue FldRV = EmitRValueForField(LV, field.field_decl, SourceLocation());
+      ExpandTypeToArgs(field.field_decl->getType(), FldRV, IRFuncTy, IRCallArgs, IRCallArgPos, CC);
+    }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     Address This = RV.getAggregateAddress();
     for (const CXXBaseSpecifier *BS : RExp->Bases) {
@@ -1004,14 +1179,14 @@ void CodeGenFunction::ExpandTypeToArgs(
 
       // Recurse onto bases.
       ExpandTypeToArgs(BS->getType(), BaseRV, IRFuncTy, IRCallArgs,
-                       IRCallArgPos);
+                       IRCallArgPos, CC);
     }
 
     LValue LV = MakeAddrLValue(This, Ty);
     for (auto FD : RExp->Fields) {
       RValue FldRV = EmitRValueForField(LV, FD, SourceLocation());
       ExpandTypeToArgs(FD->getType(), FldRV, IRFuncTy, IRCallArgs,
-                       IRCallArgPos);
+                       IRCallArgPos, CC);
     }
   } else if (isa<ComplexExpansion>(Exp.get())) {
     ComplexPairTy CV = RV.getComplexVal();
@@ -1303,11 +1478,11 @@ class ClangToLLVMArgMapping {
   SmallVector<IRArgs, 8> ArgInfo;
 
 public:
-  ClangToLLVMArgMapping(const ASTContext &Context, const CGFunctionInfo &FI,
+  ClangToLLVMArgMapping(const ASTContext &Context, const CGFunctionInfo &FI, const CodeGenTypes& CGT,
                         bool OnlyRequiredArgs = false)
       : InallocaArgNo(InvalidIndex), SRetArgNo(InvalidIndex), TotalIRArgs(0),
         ArgInfo(OnlyRequiredArgs ? FI.getNumRequiredArgs() : FI.arg_size()) {
-    construct(Context, FI, OnlyRequiredArgs);
+    construct(Context, FI, CGT, OnlyRequiredArgs);
   }
 
   bool hasInallocaArg() const { return InallocaArgNo != InvalidIndex; }
@@ -1342,12 +1517,13 @@ public:
   }
 
 private:
-  void construct(const ASTContext &Context, const CGFunctionInfo &FI,
+  void construct(const ASTContext &Context, const CGFunctionInfo &FI, const CodeGenTypes& CGT,
                  bool OnlyRequiredArgs);
 };
 
 void ClangToLLVMArgMapping::construct(const ASTContext &Context,
                                       const CGFunctionInfo &FI,
+                                      const CodeGenTypes& CGT,
                                       bool OnlyRequiredArgs) {
   unsigned IRArgNo = 0;
   bool SwapThisWithSRet = false;
@@ -1395,7 +1571,7 @@ void ClangToLLVMArgMapping::construct(const ASTContext &Context,
       IRArgs.NumberOfArgs = AI.getCoerceAndExpandTypeSequence().size();
       break;
     case ABIArgInfo::Expand:
-      IRArgs.NumberOfArgs = getExpansionSize(ArgType, Context);
+      IRArgs.NumberOfArgs = getExpansionSize(ArgType, Context, CGT, FI.getASTCallingConvention());
       break;
     }
 
@@ -1502,7 +1678,7 @@ CodeGenTypes::GetFunctionType(const CGFunctionInfo &FI) {
     break;
   }
 
-  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, true);
+  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, *this, true);
   SmallVector<llvm::Type*, 8> ArgTypes(IRFunctionArgs.totalIRArgs());
 
   // Add type for sret argument.
@@ -1578,7 +1754,7 @@ CodeGenTypes::GetFunctionType(const CGFunctionInfo &FI) {
 
     case ABIArgInfo::Expand:
       auto ArgTypesIter = ArgTypes.begin() + FirstIRArg;
-      getExpandedTypes(it->type, ArgTypesIter);
+      getExpandedTypes(it->type, ArgTypesIter, FI.getASTCallingConvention());
       assert(ArgTypesIter == ArgTypes.begin() + FirstIRArg + NumIRArgs);
       break;
     }
@@ -1802,7 +1978,7 @@ void CodeGenModule::ConstructAttributeList(
       FuncAttrs.addAttribute("nvptx-f32ftz", "true");
   }
 
-  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI);
+  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, getTypes());
 
   QualType RetTy = FI.getReturnType();
   const ABIArgInfo &RetAI = FI.getReturnInfo();
@@ -2095,7 +2271,7 @@ void CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,
   // FIXME: We no longer need the types from FunctionArgList; lift up and
   // simplify.
 
-  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), FI);
+  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), FI, getTypes());
   // Flattened function arguments.
   SmallVector<llvm::Value *, 16> FnArgs;
   FnArgs.reserve(IRFunctionArgs.totalIRArgs());
@@ -2413,7 +2589,7 @@ void CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,
       ArgVals.push_back(ParamValue::forIndirect(Alloca));
 
       auto FnArgIter = FnArgs.begin() + FirstIRArg;
-      ExpandTypeFromArgs(Ty, LV, FnArgIter);
+      ExpandTypeFromArgs(Ty, LV, FnArgIter, FI.getASTCallingConvention());
       assert(FnArgIter == FnArgs.begin() + FirstIRArg + NumIRArgs);
       for (unsigned i = 0, e = NumIRArgs; i != e; ++i) {
         auto AI = FnArgs[FirstIRArg + i];
@@ -3551,7 +3727,7 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     return Builder.CreateStructGEP(ArgMemory, FieldIndex, FieldOffset);
   };
 
-  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), CallInfo);
+  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), CallInfo, getTypes());
   SmallVector<llvm::Value *, 16> IRCallArgs(IRFunctionArgs.totalIRArgs());
 
   // If the call returns a temporary with struct return, create a temporary
@@ -3714,9 +3890,14 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
         // If the argument doesn't match, perform a bitcast to coerce it.  This
         // can happen due to trivial type mismatches.
         if (FirstIRArg < IRFuncTy->getNumParams() &&
-            V->getType() != IRFuncTy->getParamType(FirstIRArg))
-          V = Builder.CreateBitCast(V, IRFuncTy->getParamType(FirstIRArg));
-
+            V->getType() != IRFuncTy->getParamType(FirstIRArg)) {
+          const auto src_as = V->getType()->getPointerAddressSpace();
+          auto param_type = IRFuncTy->getParamType(FirstIRArg);
+          if(src_as > 0 && src_as != param_type->getPointerAddressSpace()) {
+            param_type = llvm::PointerType::get(cast<llvm::PointerType>(param_type->getScalarType())->getElementType(), src_as);
+          }
+          V = Builder.CreateBitCast(V, param_type);
+        }
         IRCallArgs[FirstIRArg] = V;
         break;
       }
@@ -3822,7 +4003,8 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
 
     case ABIArgInfo::Expand:
       unsigned IRArgPos = FirstIRArg;
-      ExpandTypeToArgs(I->Ty, RV, IRFuncTy, IRCallArgs, IRArgPos);
+      ExpandTypeToArgs(I->Ty, RV, IRFuncTy, IRCallArgs, IRArgPos,
+                       CallInfo.getASTCallingConvention());
       assert(IRArgPos == FirstIRArg + NumIRArgs);
       break;
     }
@@ -3901,8 +4083,17 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     if (IRFunctionArgs.hasInallocaArg() &&
         i == IRFunctionArgs.getInallocaArgNo())
       continue;
-    if (i < IRFuncTy->getNumParams())
+    if (i < IRFuncTy->getNumParams()) {
+      if (getLangOpts().OpenCL &&
+          IRFuncTy->getParamType(i)->isPointerTy() &&
+          IRCallArgs[i]->getType()->isPointerTy() &&
+          llvm::PointerType::get(IRFuncTy->getParamType(i)->getPointerElementType(), 0) ==
+          llvm::PointerType::get(IRCallArgs[i]->getType()->getPointerElementType(), 0)) {
+        // ignore address space mismatches for opencl/metal/vulkan
+        continue;
+      }
       assert(IRCallArgs[i]->getType() == IRFuncTy->getParamType(i));
+    }
   }
 
   unsigned CallingConv;
@@ -4075,6 +4266,13 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
             DestPtr = CreateMemTemp(RetTy, "agg.tmp");
             DestIsVolatile = false;
           }
+
+          // handle [[vector_compat]] stores from an aggregate to a vector type
+          if(DestPtr.getType()->getPointerElementType()->isVectorTy()) {
+            CreateCoercedStore(CI, DestPtr, DestIsVolatile, *this);
+            return RValue::get(DestPtr.getPointer());
+          }
+
           BuildAggStore(*this, CI, DestPtr, DestIsVolatile);
           return RValue::getAggregate(DestPtr);
         }
@@ -4127,6 +4325,27 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     }
   }
 
+  // add LLVM [lower bound, upper bound] attribute if possible
+  if (llvm::CallInst *Call = dyn_cast<llvm::CallInst>(CI)) {
+    if (TargetDecl && Call->getType()->isIntegerTy()) {
+      RetRangeAttr* range_attr = TargetDecl->getAttr<RetRangeAttr>();
+      if (range_attr != nullptr) {
+        llvm::APSInt lower_bound(64), upper_bound(64);
+        lower_bound = range_attr->getLowerBound()->EvaluateKnownConstInt(getContext());
+        upper_bound = range_attr->getUpperBound()->EvaluateKnownConstInt(getContext());
+        llvm::Metadata* range_md[2] {
+          llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Call->getType(),
+                                                               lower_bound.getZExtValue(),
+                                                               lower_bound.isSigned())),
+          llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Call->getType(),
+                                                               upper_bound.getZExtValue(),
+                                                               upper_bound.isSigned()))
+        };
+        Call->setMetadata(llvm::LLVMContext::MD_range, llvm::MDNode::get(getLLVMContext(), range_md));
+      }
+    }
+  }
+
   return Ret;
 }
 
diff --git a/lib/CodeGen/CGClass.cpp b/lib/CodeGen/CGClass.cpp
index 4d69c3f..2e0263d 100644
--- a/lib/CodeGen/CGClass.cpp
+++ b/lib/CodeGen/CGClass.cpp
@@ -298,9 +298,16 @@ Address CodeGenFunction::GetAddressOfBaseClass(
     VBase = nullptr; // we no longer have a virtual step
   }
 
-  // Get the base pointer type.
+  // Get the base pointer type, and keep the Values address space if it has one
+  const auto val_type = Value.getType();
+  unsigned val_as = 0;
+  if(val_type != nullptr &&
+     val_type->isPointerTy() &&
+     val_type->getPointerAddressSpace() != 0) {
+    val_as = val_type->getPointerAddressSpace();
+  }
   llvm::Type *BasePtrTy =
-    ConvertType((PathEnd[-1])->getType())->getPointerTo();
+    ConvertType((PathEnd[-1])->getType())->getPointerTo(val_as);
 
   QualType DerivedTy = getContext().getRecordType(Derived);
   CharUnits DerivedAlign = CGM.getClassPointerAlignment(Derived);
diff --git a/lib/CodeGen/CGDebugInfo.cpp b/lib/CodeGen/CGDebugInfo.cpp
index 2f250d8..2972473 100644
--- a/lib/CodeGen/CGDebugInfo.cpp
+++ b/lib/CodeGen/CGDebugInfo.cpp
@@ -515,7 +515,7 @@ llvm::DIType *CGDebugInfo::CreateType(const BuiltinType *BT) {
 
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case BuiltinType::Id: \
-    return getOrCreateStructPtrType("opencl_" #ImgType "_" #Suffix "_t", \
+    return getOrCreateStructPtrType("opencl_" #ImgType #Suffix "_t", \
                                     SingletonId);
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
@@ -579,13 +579,19 @@ llvm::DIType *CGDebugInfo::CreateType(const BuiltinType *BT) {
 
   switch (BT->getKind()) {
   case BuiltinType::Long:
-    BTName = "long int";
+    if (CGM.getLangOpts().OpenCL)
+      BTName = "long";
+    else
+      BTName = "long int";
     break;
   case BuiltinType::LongLong:
     BTName = "long long int";
     break;
   case BuiltinType::ULong:
-    BTName = "long unsigned int";
+    if (CGM.getLangOpts().OpenCL)
+      BTName = "unsigned long";
+    else
+      BTName = "long unsigned int";
     break;
   case BuiltinType::ULongLong:
     BTName = "long long unsigned int";
@@ -888,8 +894,10 @@ static unsigned getDwarfCC(CallingConv CC) {
   case CC_AAPCS:
   case CC_AAPCS_VFP:
   case CC_IntelOclBicc:
-  case CC_SpirFunction:
-  case CC_OpenCLKernel:
+  case CC_FloorFunction:
+  case CC_FloorKernel:
+  case CC_FloorVertex:
+  case CC_FloorFragment:
   case CC_Swift:
   case CC_PreserveMost:
   case CC_PreserveAll:
@@ -2204,6 +2212,8 @@ llvm::DIType *CGDebugInfo::CreateType(const AtomicType *Ty, llvm::DIFile *U) {
 
 llvm::DIType* CGDebugInfo::CreateType(const PipeType *Ty,
                                      llvm::DIFile *U) {
+  // Ignore the atomic wrapping
+  // FIXME: What is the correct representation?
   return getOrCreateType(Ty->getElementType(), U);
 }
 
diff --git a/lib/CodeGen/CGDecl.cpp b/lib/CodeGen/CGDecl.cpp
index 037b135..6ab3409 100644
--- a/lib/CodeGen/CGDecl.cpp
+++ b/lib/CodeGen/CGDecl.cpp
@@ -160,7 +160,9 @@ void CodeGenFunction::EmitVarDecl(const VarDecl &D) {
     // Don't emit it now, allow it to be emitted lazily on its first use.
     return;
 
-  if (D.getType().getAddressSpace() == LangAS::opencl_local)
+  if (D.getType().getAddressSpace() == LangAS::opencl_local ||
+      // TODO: -> SC_OpenCLConstant TODO
+      (D.getStorageClass() == SC_OpenCLConstant))
     return CGM.getOpenCLRuntime().EmitWorkGroupLocalVarDecl(*this, D);
 
   assert(D.hasLocalStorage());
@@ -168,8 +170,14 @@ void CodeGenFunction::EmitVarDecl(const VarDecl &D) {
 }
 
 static std::string getStaticDeclName(CodeGenModule &CGM, const VarDecl &D) {
-  if (CGM.getLangOpts().CPlusPlus)
+  // don't cxx mangle OpenCL "local" variables (only affects SPIR - Metal/AIR and SPIR-V/Vulkan uses cxx mangling)
+  if (CGM.getLangOpts().CPlusPlus &&
+      !(D.getType().getAddressSpace() == LangAS::opencl_local &&
+        CGM.getContext().getLangOpts().OpenCL &&
+        !CGM.getContext().getLangOpts().Metal &&
+        !CGM.getContext().getLangOpts().Vulkan)) {
     return CGM.getMangledName(&D).str();
+  }
 
   // If this isn't C++, we don't need a mangled name, just a pretty one.
   assert(!D.isExternallyVisible() && "name shouldn't matter");
diff --git a/lib/CodeGen/CGExpr.cpp b/lib/CodeGen/CGExpr.cpp
index 89df63d..f3b9084 100644
--- a/lib/CodeGen/CGExpr.cpp
+++ b/lib/CodeGen/CGExpr.cpp
@@ -1267,6 +1267,7 @@ llvm::Value *CodeGenFunction::EmitLoadOfScalar(Address Addr, bool Volatile,
                                                QualType TBAABaseType,
                                                uint64_t TBAAOffset,
                                                bool isNontemporal) {
+#if 0 // incorrect and not at all beneficial for compute backends
   // For better performance, handle vector loads differently.
   if (Ty->isVectorType()) {
     const llvm::Type *EltTy = Addr.getElementType();
@@ -1289,6 +1290,7 @@ llvm::Value *CodeGenFunction::EmitLoadOfScalar(Address Addr, bool Volatile,
       return EmitFromMemory(V, Ty);
     }
   }
+#endif
 
   // Atomic operations have to be done on integral types.
   LValue AtomicLValue =
@@ -1382,6 +1384,7 @@ void CodeGenFunction::EmitStoreOfScalar(llvm::Value *Value, Address Addr,
   // Handle vectors differently to get better performance.
   if (Ty->isVectorType()) {
     llvm::Type *SrcTy = Value->getType();
+#if 0 // incorrect and not at all beneficial for compute backends
     auto *VecTy = cast<llvm::VectorType>(SrcTy);
     // Handle vec3 special.
     if (VecTy->getNumElements() == 3) {
@@ -1395,6 +1398,7 @@ void CodeGenFunction::EmitStoreOfScalar(llvm::Value *Value, Address Addr,
                                           MaskV, "extractVec");
       SrcTy = llvm::VectorType::get(VecTy->getElementType(), 4);
     }
+#endif
     if (Addr.getElementType() != SrcTy) {
       Addr = Builder.CreateElementBitCast(Addr, SrcTy, "storetmp");
     }
@@ -2141,8 +2145,19 @@ LValue CodeGenFunction::EmitDeclRefLValue(const DeclRefExpr *E) {
 
   if (const auto *VD = dyn_cast<VarDecl>(ND)) {
     // Check if this is a global variable.
-    if (VD->hasLinkage() || VD->isStaticDataMember())
+    if (VD->hasLinkage() || VD->isStaticDataMember()) {
+      if (CGM.getLangOpts().OpenCL && VD->getType()->isBlockPointerType()) {
+        // Look up the block function and bind it with NULL
+        llvm::Constant *blockFnc = CGM.GetOCLGlobalBlockFunction(VD);
+        blockFnc = llvm::ConstantExpr::getBitCast(blockFnc, Int8PtrTy);
+        llvm::Value *block = GenerateOCLBlockBind(blockFnc, 0, 0, llvm::Constant::getNullValue(Int8PtrTy));
+        Address addr = CreateMemTemp(VD->getType());
+        llvm::Value *Ptr = addr.getPointer();
+        Builder.CreateStore(block, addr);
+        return MakeNaturalAlignAddrLValue(Ptr, VD->getType());
+      }
       return EmitGlobalVarDeclLValue(*this, E, VD);
+    }
 
     Address addr = Address::invalid();
 
@@ -3291,11 +3306,11 @@ LValue CodeGenFunction::EmitLValueForLambdaField(const FieldDecl *Field) {
 ///
 /// The resulting address doesn't necessarily have the right type.
 static Address emitAddrOfFieldStorage(CodeGenFunction &CGF, Address base,
-                                      const FieldDecl *field) {
+                                      const FieldDecl *field, llvm::Type* elem_type) {
   const RecordDecl *rec = field->getParent();
   
   unsigned idx =
-    CGF.CGM.getTypes().getCGRecordLayout(rec).getLLVMFieldNo(field);
+    CGF.CGM.getTypes().getCGRecordLayout(rec, elem_type).getLLVMFieldNo(field);
 
   CharUnits offset;
   // Adjust the alignment down to the given offset.
@@ -3315,36 +3330,37 @@ static Address emitAddrOfFieldStorage(CodeGenFunction &CGF, Address base,
 
 LValue CodeGenFunction::EmitLValueForField(LValue base,
                                            const FieldDecl *field) {
+  Address addr = base.getAddress();
+  llvm::Type* elem_type = addr.getType()->getPointerElementType();
+  const RecordDecl *rec = field->getParent();
+  const CGRecordLayout &RL = CGM.getTypes().getCGRecordLayout(rec, elem_type);
   AlignmentSource fieldAlignSource =
     getFieldAlignmentSource(base.getAlignmentSource());
 
   if (field->isBitField()) {
-    const CGRecordLayout &RL =
-      CGM.getTypes().getCGRecordLayout(field->getParent());
     const CGBitFieldInfo &Info = RL.getBitFieldInfo(field);
-    Address Addr = base.getAddress();
     unsigned Idx = RL.getLLVMFieldNo(field);
     if (Idx != 0)
       // For structs, we GEP to the field that the record layout suggests.
-      Addr = Builder.CreateStructGEP(Addr, Idx, Info.StorageOffset,
+      addr = Builder.CreateStructGEP(addr, Idx, Info.StorageOffset,
                                      field->getName());
     // Get the access type.
     llvm::Type *FieldIntTy =
       llvm::Type::getIntNTy(getLLVMContext(), Info.StorageSize);
-    if (Addr.getElementType() != FieldIntTy)
-      Addr = Builder.CreateElementBitCast(Addr, FieldIntTy);
+    if (addr.getElementType() != FieldIntTy)
+      addr = Builder.CreateElementBitCast(addr, FieldIntTy);
+
+    // TODO: (clang/llvm 3.8) check if address space is correct
 
     QualType fieldType =
       field->getType().withCVRQualifiers(base.getVRQualifiers());
-    return LValue::MakeBitfield(Addr, Info, fieldType, fieldAlignSource);
+    return LValue::MakeBitfield(addr, Info, fieldType, fieldAlignSource);
   }
 
-  const RecordDecl *rec = field->getParent();
   QualType type = field->getType();
 
   bool mayAlias = rec->hasAttr<MayAliasAttr>();
 
-  Address addr = base.getAddress();
   unsigned cvr = base.getVRQualifiers();
   bool TBAAPath = CGM.getCodeGenOpts().StructPathTBAA;
   if (rec->isUnion()) {
@@ -3354,7 +3370,7 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
     TBAAPath = false;
   } else {
     // For structs, we GEP to the field that the record layout suggests.
-    addr = emitAddrOfFieldStorage(*this, addr, field);
+    addr = emitAddrOfFieldStorage(*this, addr, field, elem_type);
 
     // If this is a reference field, load the reference right now.
     if (const ReferenceType *refType = type->getAs<ReferenceType>()) {
@@ -3432,7 +3448,8 @@ CodeGenFunction::EmitLValueForFieldInitialization(LValue Base,
   if (!FieldType->isReferenceType())
     return EmitLValueForField(Base, Field);
 
-  Address V = emitAddrOfFieldStorage(*this, Base.getAddress(), Field);
+  llvm::Type* elem_type = Base.getAddress().getType()->getPointerElementType();
+  Address V = emitAddrOfFieldStorage(*this, Base.getAddress(), Field, elem_type);
 
   // Make sure that the address is pointing to the right type.
   llvm::Type *llvmType = ConvertTypeForMem(FieldType);
@@ -3607,7 +3624,6 @@ LValue CodeGenFunction::EmitCastLValue(const CastExpr *E) {
   case CK_ARCExtendBlockObject:
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_AddressSpaceConversion:
-  case CK_IntToOCLSampler:
     return EmitUnsupportedLValue(E, "unexpected cast lvalue");
 
   case CK_Dependent:
@@ -3703,6 +3719,10 @@ LValue CodeGenFunction::EmitCastLValue(const CastExpr *E) {
   }
   case CK_ZeroToOCLEvent:
     llvm_unreachable("NULL to OpenCL event lvalue cast is not valid");
+  case CK_ZeroToOCLQueue:
+    llvm_unreachable("NULL to OpenCL queue lvalue cast is not valid");
+  case CK_IntToOCLSampler:
+    llvm_unreachable("int to OpenCL sampler lvalue cast is not valid");
   }
 
   llvm_unreachable("Unhandled lvalue cast kind?");
diff --git a/lib/CodeGen/CGExprAgg.cpp b/lib/CodeGen/CGExprAgg.cpp
index f51330c..5cb6fcd 100644
--- a/lib/CodeGen/CGExprAgg.cpp
+++ b/lib/CodeGen/CGExprAgg.cpp
@@ -749,6 +749,7 @@ void AggExprEmitter::VisitCastExpr(CastExpr *E) {
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_AddressSpaceConversion:
   case CK_IntToOCLSampler:
     llvm_unreachable("cast kind invalid for aggregate types");
@@ -1466,13 +1467,14 @@ void CodeGenFunction::EmitAggregateCopy(Address DestPtr,
   if (getLangOpts().CPlusPlus) {
     if (const RecordType *RT = Ty->getAs<RecordType>()) {
       CXXRecordDecl *Record = cast<CXXRecordDecl>(RT->getDecl());
-      assert((Record->hasTrivialCopyConstructor() || 
+      // TODO: fix this!
+      /*assert((Record->hasTrivialCopyConstructor() ||
               Record->hasTrivialCopyAssignment() ||
               Record->hasTrivialMoveConstructor() ||
               Record->hasTrivialMoveAssignment() ||
               Record->isUnion()) &&
              "Trying to aggregate-copy a type without a trivial copy/move "
-             "constructor or assignment operator");
+             "constructor or assignment operator");*/
       // Ignore empty classes in C++.
       if (Record->isEmpty())
         return;
diff --git a/lib/CodeGen/CGExprCXX.cpp b/lib/CodeGen/CGExprCXX.cpp
index eec2ace..70050c7 100644
--- a/lib/CodeGen/CGExprCXX.cpp
+++ b/lib/CodeGen/CGExprCXX.cpp
@@ -24,6 +24,8 @@
 using namespace clang;
 using namespace CodeGen;
 
+// TODO: fix other This uses?
+
 static RequiredArgs
 commonEmitCXXMemberOrOperatorCall(CodeGenFunction &CGF, const CXXMethodDecl *MD,
                                   llvm::Value *This, llvm::Value *ImplicitParam,
@@ -46,7 +48,9 @@ commonEmitCXXMemberOrOperatorCall(CodeGenFunction &CGF, const CXXMethodDecl *MD,
       CallLoc, This, CGF.getContext().getRecordType(MD->getParent()));
 
   // Push the this ptr.
-  Args.add(RValue::get(This), MD->getThisType(CGF.getContext()));
+  auto this_type = CGF.getContext().getAddrSpaceQualType(MD->getThisType(CGF.getContext()),
+                                                         This->getType()->getPointerAddressSpace());
+  Args.add(RValue::get(This), this_type);
 
   // If there is an implicit parameter (e.g. VTT), emit it.
   if (ImplicitParam) {
diff --git a/lib/CodeGen/CGExprComplex.cpp b/lib/CodeGen/CGExprComplex.cpp
index af7f190..074d98b 100644
--- a/lib/CodeGen/CGExprComplex.cpp
+++ b/lib/CodeGen/CGExprComplex.cpp
@@ -480,8 +480,9 @@ ComplexPairTy ComplexExprEmitter::EmitCast(CastKind CK, Expr *Op,
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLEvent:
-  case CK_AddressSpaceConversion:
+  case CK_ZeroToOCLQueue:
   case CK_IntToOCLSampler:
+  case CK_AddressSpaceConversion:
     llvm_unreachable("invalid cast kind for complex value");
 
   case CK_FloatingRealToComplex:
diff --git a/lib/CodeGen/CGExprConstant.cpp b/lib/CodeGen/CGExprConstant.cpp
index 0e818e9..c84bd48 100644
--- a/lib/CodeGen/CGExprConstant.cpp
+++ b/lib/CodeGen/CGExprConstant.cpp
@@ -690,8 +690,11 @@ public:
     case CK_ConstructorConversion:
       return C;
 
-    case CK_IntToOCLSampler:
-      llvm_unreachable("global sampler variables are not generated");
+    case CK_IntToOCLSampler: {
+      if (!CGM.getLangOpts().CLSamplerOpaque)
+        return C;
+      return CGM.createIntToSamplerConversion(subExpr, CGF);
+    }
 
     case CK_Dependent: llvm_unreachable("saw dependent cast!");
 
@@ -752,6 +755,7 @@ public:
     case CK_FloatingToBoolean:
     case CK_FloatingCast:
     case CK_ZeroToOCLEvent:
+    case CK_ZeroToOCLQueue:
       return nullptr;
     }
     llvm_unreachable("Invalid CastKind");
diff --git a/lib/CodeGen/CGExprScalar.cpp b/lib/CodeGen/CGExprScalar.cpp
index e70c31a..85bfccf 100644
--- a/lib/CodeGen/CGExprScalar.cpp
+++ b/lib/CodeGen/CGExprScalar.cpp
@@ -1379,8 +1379,14 @@ Value *ScalarExprEmitter::VisitCastExpr(CastExpr *CE) {
     llvm::Type *DstTy = ConvertType(DestTy);
     if (SrcTy->isPtrOrPtrVectorTy() && DstTy->isPtrOrPtrVectorTy() &&
         SrcTy->getPointerAddressSpace() != DstTy->getPointerAddressSpace()) {
-      llvm_unreachable("wrong cast for pointers in different address spaces"
-                       "(must be an address space cast)!");
+      // allow this with opencl/metal/vulkan
+      if (CGF.getLangOpts().OpenCL) {
+        llvm::Type *MidTy = CGF.CGM.getDataLayout().getIntPtrType(SrcTy);
+        return Builder.CreateIntToPtr(Builder.CreatePtrToInt(Src, MidTy), DstTy);
+      } else {
+        llvm_unreachable("wrong cast for pointers in different address spaces"
+                         "(must be an address space cast)!");
+      }
     }
 
     if (CGF.SanOpts.has(SanitizerKind::CFIUnrelatedCast)) {
@@ -1574,8 +1580,25 @@ Value *ScalarExprEmitter::VisitCastExpr(CastExpr *CE) {
     return llvm::Constant::getNullValue(ConvertType(DestTy));
   }
 
-  case CK_IntToOCLSampler:
-    return CGF.CGM.createOpenCLIntToSamplerConversion(E, CGF);
+  case CK_ZeroToOCLQueue: {
+    assert(DestTy->isQueueT() && "CK_ZeroToOCLQueue cast on non queue_t type");
+    return llvm::Constant::getNullValue(ConvertType(DestTy));
+  }
+
+  case CK_IntToOCLSampler: {
+    assert(DestTy->isSamplerT() && "CK_IntToOCLSampler cast to non sampler type");
+    if (!CGF.CGM.getLangOpts().CLSamplerOpaque)
+      return Visit(E);
+    if (const CastExpr* SCE = dyn_cast<CastExpr>(E)) {
+      if (const DeclRefExpr *DRE = cast<DeclRefExpr>(SCE->getSubExpr())) {
+        if (const VarDecl *VD = cast<VarDecl>(DRE->getDecl())) {
+          assert(VD->getInit() && "Invalid sampler initializer");
+          E = const_cast<Expr*>(VD->getInit());
+        }
+      }
+    }
+    return CGF.CGM.createIntToSamplerConversion(E, &CGF);
+  }
 
   } // end of switch
 
@@ -2495,9 +2518,9 @@ static Value *emitPointerArithmetic(CodeGenFunction &CGF,
   // GNU void* casts amount to no-ops since our void* type is i8*, but this is
   // future proof.
   if (elementType->isVoidType() || elementType->isFunctionType()) {
-    Value *result = CGF.Builder.CreateBitCast(pointer, CGF.VoidPtrTy);
+    Value *result = CGF.Builder.CreatePointerCast(pointer, CGF.VoidPtrTy);
     result = CGF.Builder.CreateGEP(result, index, "add.ptr");
-    return CGF.Builder.CreateBitCast(result, pointer->getType());
+    return CGF.Builder.CreatePointerCast(result, pointer->getType());
   }
 
   if (CGF.getLangOpts().isSignedOverflowDefined())
@@ -3267,35 +3290,9 @@ VisitAbstractConditionalOperator(const AbstractConditionalOperator *E) {
     llvm::Type *condType = ConvertType(condExpr->getType());
     llvm::VectorType *vecTy = cast<llvm::VectorType>(condType);
 
-    unsigned numElem = vecTy->getNumElements();
-    llvm::Type *elemType = vecTy->getElementType();
-
     llvm::Value *zeroVec = llvm::Constant::getNullValue(vecTy);
     llvm::Value *TestMSB = Builder.CreateICmpSLT(CondV, zeroVec);
-    llvm::Value *tmp = Builder.CreateSExt(TestMSB,
-                                          llvm::VectorType::get(elemType,
-                                                                numElem),
-                                          "sext");
-    llvm::Value *tmp2 = Builder.CreateNot(tmp);
-
-    // Cast float to int to perform ANDs if necessary.
-    llvm::Value *RHSTmp = RHS;
-    llvm::Value *LHSTmp = LHS;
-    bool wasCast = false;
-    llvm::VectorType *rhsVTy = cast<llvm::VectorType>(RHS->getType());
-    if (rhsVTy->getElementType()->isFloatingPointTy()) {
-      RHSTmp = Builder.CreateBitCast(RHS, tmp2->getType());
-      LHSTmp = Builder.CreateBitCast(LHS, tmp->getType());
-      wasCast = true;
-    }
-
-    llvm::Value *tmp3 = Builder.CreateAnd(RHSTmp, tmp2);
-    llvm::Value *tmp4 = Builder.CreateAnd(LHSTmp, tmp);
-    llvm::Value *tmp5 = Builder.CreateOr(tmp3, tmp4, "cond");
-    if (wasCast)
-      tmp5 = Builder.CreateBitCast(tmp5, RHS->getType());
-
-    return tmp5;
+    return Builder.CreateSelect(TestMSB, LHS, RHS);
   }
 
   // If this is a really simple expression (like x ? 4 : 5), emit this as a
@@ -3437,6 +3434,9 @@ Value *ScalarExprEmitter::VisitAsTypeExpr(AsTypeExpr *E) {
     return Src;
   }
 
+  if (SrcTy->isPointerTy() || DstTy->isPointerTy())
+    return Builder.CreatePointerCast(Src, DstTy, "astype");
+
   return Builder.CreateBitCast(Src, DstTy, "astype");
 }
 
diff --git a/lib/CodeGen/CGOpenCLRuntime.cpp b/lib/CodeGen/CGOpenCLRuntime.cpp
index 8983fde..2888293 100644
--- a/lib/CodeGen/CGOpenCLRuntime.cpp
+++ b/lib/CodeGen/CGOpenCLRuntime.cpp
@@ -37,38 +37,168 @@ llvm::Type *CGOpenCLRuntime::convertOpenCLSpecificType(const Type *T) {
   llvm::LLVMContext& Ctx = CGM.getLLVMContext();
   uint32_t ImgAddrSpc = CGM.getContext().getTargetAddressSpace(
     CGM.getTarget().getOpenCLImageAddrSpace());
-  switch (cast<BuiltinType>(T)->getKind()) {
-  default: 
-    llvm_unreachable("Unexpected opencl builtin type!");
-    return nullptr;
+
+  // OpenCL/SPIR and SPIR-V/Vulkan
+  if(!CGM.getLangOpts().Metal) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+    default:
+      llvm_unreachable("Unexpected opencl builtin type!");
+      return nullptr;
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-  case BuiltinType::Id: \
-    return llvm::PointerType::get( \
-        llvm::StructType::create(Ctx, "opencl." #ImgType "_" #Suffix "_t"), \
-        ImgAddrSpc);
+    case BuiltinType::Id: \
+      return llvm::PointerType::get( \
+          llvm::StructType::create(Ctx, "opencl." #ImgType #Suffix "_t"), \
+          ImgAddrSpc);
 #include "clang/Basic/OpenCLImageTypes.def"
-  case BuiltinType::OCLSampler:
-    return getSamplerType();
-  case BuiltinType::OCLEvent:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.event_t"), 0);
-  case BuiltinType::OCLClkEvent:
-    return llvm::PointerType::get(
-        llvm::StructType::create(Ctx, "opencl.clk_event_t"), 0);
-  case BuiltinType::OCLQueue:
-    return llvm::PointerType::get(
-        llvm::StructType::create(Ctx, "opencl.queue_t"), 0);
-  case BuiltinType::OCLNDRange:
-    return llvm::PointerType::get(
-        llvm::StructType::create(Ctx, "opencl.ndrange_t"), 0);
-  case BuiltinType::OCLReserveID:
-    return llvm::PointerType::get(
-        llvm::StructType::create(Ctx, "opencl.reserve_id_t"), 0);
+    case BuiltinType::OCLSampler:
+      if (CGM.getLangOpts().CLSamplerOpaque)
+        return llvm::PointerType::get(llvm::StructType::create(
+                             Ctx, "spirv.Sampler"),
+                             CGM.getContext().getTargetAddressSpace(
+                             LangAS::opencl_constant));
+      else
+        return llvm::IntegerType::get(Ctx, 32);
+    case BuiltinType::OCLEvent:
+      return llvm::PointerType::get(llvm::StructType::create(
+                             Ctx, "opencl.event_t"), 0);
+    case BuiltinType::OCLClkEvent:
+      return llvm::PointerType::get(
+          llvm::StructType::create(Ctx, "opencl.clk_event_t"), 0);
+    case BuiltinType::OCLQueue:
+      return llvm::PointerType::get(
+          llvm::StructType::create(Ctx, "opencl.queue_t"), 0);
+    case BuiltinType::OCLNDRange:
+      return llvm::PointerType::get(
+          llvm::StructType::create(Ctx, "opencl.ndrange_t"), 0);
+    case BuiltinType::OCLReserveID:
+      return llvm::PointerType::get(
+          llvm::StructType::create(Ctx, "opencl.reserve_id_t"), 0);
+    }
+  }
+  // Metal/AIR
+  else if(CGM.getLangOpts().Metal) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+      default:
+        llvm_unreachable("Unexpected metal builtin type!");
+        return nullptr;
+#if 0 // TODO: enable this again when using ro/wo/rw image types
+      case BuiltinType::OCLImage1dRO:
+      case BuiltinType::OCLImage1dWO:
+      case BuiltinType::OCLImage1dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dArrayRO:
+      case BuiltinType::OCLImage1dArrayWO:
+      case BuiltinType::OCLImage1dArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dBufferRO:
+      case BuiltinType::OCLImage1dBufferWO:
+      case BuiltinType::OCLImage1dBufferRW:
+        llvm_unreachable("Unsupported image type (1D-buffer is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dRO:
+      case BuiltinType::OCLImage2dWO:
+      case BuiltinType::OCLImage2dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayRO:
+      case BuiltinType::OCLImage2dArrayWO:
+      case BuiltinType::OCLImage2dArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dDepthRO:
+      case BuiltinType::OCLImage2dDepthWO:
+      case BuiltinType::OCLImage2dDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayDepthRO:
+      case BuiltinType::OCLImage2dArrayDepthWO:
+      case BuiltinType::OCLImage2dArrayDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAARO:
+      case BuiltinType::OCLImage2dMSAAWO:
+      case BuiltinType::OCLImage2dMSAARW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAARO:
+      case BuiltinType::OCLImage2dArrayMSAAWO:
+      case BuiltinType::OCLImage2dArrayMSAARW:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dMSAADepthRO:
+      case BuiltinType::OCLImage2dMSAADepthWO:
+      case BuiltinType::OCLImage2dMSAADepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepthRO:
+      case BuiltinType::OCLImage2dArrayMSAADepthWO:
+      case BuiltinType::OCLImage2dArrayMSAADepthRW:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA-Depth is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImageCubeRO:
+      case BuiltinType::OCLImageCubeWO:
+      case BuiltinType::OCLImageCubeRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArrayRO:
+      case BuiltinType::OCLImageCubeArrayWO:
+      case BuiltinType::OCLImageCubeArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeDepthRO:
+      case BuiltinType::OCLImageCubeDepthWO:
+      case BuiltinType::OCLImageCubeDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArrayDepthRO:
+      case BuiltinType::OCLImageCubeArrayDepthWO:
+      case BuiltinType::OCLImageCubeArrayDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage3dRO:
+      case BuiltinType::OCLImage3dWO:
+      case BuiltinType::OCLImage3dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_3d_t"), ImgAddrSpc);
+#else
+      case BuiltinType::OCLImage1d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dBuffer:
+        llvm_unreachable("Unsupported image type (1D-buffer is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAA:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepth:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA-Depth is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImageCube:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage3d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_3d_t"), ImgAddrSpc);
+#endif
+      case BuiltinType::OCLSampler:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._sampler_t"),
+                                      CGM.getContext().getTargetAddressSpace(LangAS::opencl_constant));
+      case BuiltinType::OCLEvent:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._event_t"), 0);
+    }
   }
+  llvm_unreachable("Unexpected builtin type!");
+  return nullptr;
 }
 
 llvm::Type *CGOpenCLRuntime::getPipeType() {
-  if (!PipeTy){
+  if (!PipeTy) {
     uint32_t PipeAddrSpc =
       CGM.getContext().getTargetAddressSpace(LangAS::opencl_global);
     PipeTy = llvm::PointerType::get(llvm::StructType::create(
@@ -78,11 +208,86 @@ llvm::Type *CGOpenCLRuntime::getPipeType() {
   return PipeTy;
 }
 
-llvm::PointerType *CGOpenCLRuntime::getSamplerType() {
-  if (!SamplerTy)
-    SamplerTy = llvm::PointerType::get(llvm::StructType::create(
-      CGM.getLLVMContext(), "opencl.sampler_t"),
-      CGM.getContext().getTargetAddressSpace(
-      LangAS::opencl_constant));
-  return SamplerTy;
+llvm::Type *CGOpenCLRuntime::getBlockType() {
+  if (!BlockTy) {
+    // TODO: correct address space?
+    BlockTy = llvm::PointerType::get(llvm::StructType::create(
+                                     CGM.getLLVMContext(), "opencl.block"), 0);
+  }
+
+  return BlockTy;
+}
+
+llvm::Value *CGOpenCLRuntime::getPipeElemSize(const Expr *PipeArg) {
+  const PipeType* PipeTy = PipeArg->getType()->getAs<PipeType>();
+  // The type of the last (implicit) argument to be passed.
+  llvm::Type *Int32Ty = llvm::IntegerType::getInt32Ty(CGM.getLLVMContext());
+  unsigned TypeSizeInBits = CGM.getContext().getTypeSize(
+                                                      PipeTy->getElementType());
+  return llvm::ConstantInt::get(Int32Ty,
+                                TypeSizeInBits/8, // Size in bytes.
+                                false);
+}
+
+llvm::Value *CGOpenCLRuntime::getPipeElemAlign(const Expr *PipeArg) {
+  const PipeType* PipeTy = PipeArg->getType()->getAs<PipeType>();
+  // The type of the last (implicit) argument to be passed.
+  llvm::Type *Int32Ty = llvm::IntegerType::getInt32Ty(CGM.getLLVMContext());
+  unsigned TypeSizeInBits = CGM.getContext().getTypeAlign(
+                                                      PipeTy->getElementType());
+  return llvm::ConstantInt::get(Int32Ty,
+                                TypeSizeInBits/8, // Size in bytes.
+                                false);
+}
+
+//
+// Ocl20Mangler
+//
+
+Ocl20Mangler::Ocl20Mangler(llvm::SmallVectorImpl<char>& SS): MangledString(&SS) {}
+
+Ocl20Mangler& Ocl20Mangler::appendReservedId() {
+  this->appendString("13ocl_reserveid");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPipe() {
+  this->appendString("8ocl_pipe");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendInt() {
+  MangledString->push_back('i');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendUint() {
+  MangledString->push_back('j');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendVoid() {
+  MangledString->push_back('v');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPointer() {
+  this->appendString("P");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPointer(int addressSpace) {
+  assert(addressSpace >=0 && addressSpace <= 4 &&
+         "Illegal address space for OpenCL");
+  if (!addressSpace)
+    return appendPointer();
+
+  this->appendString("PU3AS");
+  MangledString->push_back('0' + addressSpace);
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendString(llvm::StringRef S) {
+  MangledString->append(S.begin(), S.end());
+  return *this;
 }
diff --git a/lib/CodeGen/CGOpenCLRuntime.h b/lib/CodeGen/CGOpenCLRuntime.h
index 41ead10..1c47af9 100644
--- a/lib/CodeGen/CGOpenCLRuntime.h
+++ b/lib/CodeGen/CGOpenCLRuntime.h
@@ -34,10 +34,11 @@ protected:
   CodeGenModule &CGM;
   llvm::Type *PipeTy;
   llvm::PointerType *SamplerTy;
+  llvm::Type *BlockTy;
 
 public:
   CGOpenCLRuntime(CodeGenModule &CGM) : CGM(CGM), PipeTy(nullptr),
-    SamplerTy(nullptr) {}
+    SamplerTy(nullptr), BlockTy(nullptr) {}
   virtual ~CGOpenCLRuntime();
 
   /// Emit the IR required for a work-group-local variable declaration, and add
@@ -50,7 +51,52 @@ public:
 
   virtual llvm::Type *getPipeType();
 
-  llvm::PointerType *getSamplerType();
+  virtual llvm::Type *getBlockType();
+
+  // \brief Returnes a value which indicates the size in bytes of the pipe
+  // element.
+  llvm::Value *getPipeElemSize(const Expr *PipeArg);
+  llvm::Value *getPipeElemAlign(const Expr *PipeArg);
+};
+
+class Ocl20Mangler {
+public:
+  Ocl20Mangler(llvm::SmallVectorImpl<char>&);
+
+  // \brief Appends the mangled representation of reserve_id_t parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendReservedId();
+
+  // \brief Appends the mangled representation of pipe_t parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendPipe();
+
+  // \brief Appends the mangled representation of 'int' parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendInt();
+
+  // \brief Appends the mangled representation of 'unsigned int' parameter to the
+  // mangled string.
+  Ocl20Mangler& appendUint();
+
+  // \brief Appends the mangled representation of a pointer.
+  Ocl20Mangler& appendPointer();
+
+  // \brief Appends the mangled representation of void.
+  Ocl20Mangler& appendVoid();
+
+  // \brief Appends the mangled representation of a pointer with a given address
+  // space.
+  // \param addressSapace The address space of the pointer. Valid values are
+  // [0,4].
+  Ocl20Mangler& appendPointer(int addressSapace);
+
+private:
+
+  // \brief Appends the given string to the mangled prototype.
+  Ocl20Mangler& appendString(llvm::StringRef);
+
+  llvm::SmallVectorImpl<char> *MangledString;
 };
 
 }
diff --git a/lib/CodeGen/CGRecordLayoutBuilder.cpp b/lib/CodeGen/CGRecordLayoutBuilder.cpp
index 7d530a2..87eb328 100644
--- a/lib/CodeGen/CGRecordLayoutBuilder.cpp
+++ b/lib/CodeGen/CGRecordLayoutBuilder.cpp
@@ -812,6 +812,42 @@ CGRecordLayout *CodeGenTypes::ComputeRecordLayout(const RecordDecl *D,
   return RL;
 }
 
+void CodeGenTypes::create_flattened_cg_layout(const CXXRecordDecl* D, llvm::StructType* Ty,
+											  const std::vector<CodeGenTypes::aggregate_scalar_entry>& fields) {
+	bool zero_init = true;
+	for(const auto& field : fields) {
+		// vector types (or replaced vector types) are always zero initializable
+		if(field.type->isExtVectorType() ||
+		   field.type->isVectorType()) {
+			continue;
+		}
+		
+		// else: need to make some calls based on the field decl type
+		const Type *Type = field.field_decl->getType()->getBaseElementTypeUnsafe();
+		if (const MemberPointerType *MPT = Type->getAs<MemberPointerType>()) {
+			if(!TheCXXABI.isZeroInitializable(MPT)) {
+				zero_init = false;
+				break;
+			}
+		}
+		else if (const CXXRecordDecl* cxx_rdecl = Type->getAsCXXRecordDecl()) {
+			if(!isZeroInitializable(cxx_rdecl)) {
+				zero_init = false;
+				break;
+			}
+		}
+		// else: it is zero initializable
+	}
+	
+	CGRecordLayout *RL = new CGRecordLayout(Ty, Ty, zero_init, zero_init);
+	uint32_t field_idx = 0;
+	for(const auto& field : fields) {
+		RL->FieldInfo.insert({ field.field_decl, field_idx++ });
+	}
+	
+	FlattenedCGRecordLayouts.insert({ Ty, RL });
+}
+
 void CGRecordLayout::print(raw_ostream &OS) const {
   OS << "<CGRecordLayout\n";
   OS << "  LLVMType:" << *CompleteObjectType << "\n";
diff --git a/lib/CodeGen/CGSPIRMetadataAdder.cpp b/lib/CodeGen/CGSPIRMetadataAdder.cpp
new file mode 100644
index 0000000..f4a1f9d
--- /dev/null
+++ b/lib/CodeGen/CGSPIRMetadataAdder.cpp
@@ -0,0 +1,318 @@
+//===- SPIRMetadataAdder.cpp - Add SPIR related module scope metadata -----===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+//
+//===----------------------------------------------------------------------===//
+
+
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SmallString.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/IR/TypeFinder.h"
+#include "CGSPIRMetadataAdder.h"
+#include <set>
+
+using namespace llvm;
+using namespace clang;
+using namespace CodeGen;
+
+static const char *ImageTypeNames[] = {
+  "opencl.image1d_t", "opencl.image1d_array_t", "opencl.image1d_buffer_t",
+  "opencl.image2d_t", "opencl.image2d_array_t",
+  "opencl.image2d_depth_t", "opencl.image2d_array_depth_t",
+  "opencl.image2d_msaa_t", "opencl.image2d_array_msaa_t",
+  "opencl.image2d_msaa_depth_t", "opencl.image2d_array_msaa_depth_t",
+  "opencl.image3d_t",
+  "opencl.imagecube_t", "opencl.imagecube_array_t",
+  "opencl.imagecube_depth_t", "opencl.imagecube_array_depth_t",
+};
+
+static const char *ImageDepthTypeNames[] = {
+  "opencl.image2d_depth_t", "opencl.image2d_array_depth_t"
+};
+
+static const char *ImageMSAATypeNames[] = {
+  "opencl.image2d_msaa_t", "opencl.image2d_array_msaa_t",
+  "opencl.image2d_msaa_depth_t", "opencl.image2d_array_msaa_depth_t"
+};
+
+struct OCLExtensionsTy {
+#define OPENCLEXT(nm)  unsigned _##nm : 1;
+#include "clang/Basic/OpenCLExtensions.def"
+
+  OCLExtensionsTy() {
+#define OPENCLEXT(nm)   _##nm = 0;
+#include "clang/Basic/OpenCLExtensions.def"
+  }
+};
+
+typedef void (*func_call_handler)(CallInst *callInstr, OCLExtensionsTy &exts);
+
+void baseAtomics64(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isIntegerTy() &&
+      firstArgType->getPointerElementType()->getScalarSizeInBits() == 64)
+    exts._cl_khr_int64_base_atomics = 1;
+}
+
+void extAtomics64(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isIntegerTy() &&
+      firstArgType->getPointerElementType()->getScalarSizeInBits() == 64)
+    exts._cl_khr_int64_extended_atomics = 1;
+}
+
+void image3DWrite(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isStructTy() &&
+      !firstArgType->getPointerElementType()->getStructName().compare("opencl.image3d_t"))
+    exts._cl_khr_3d_image_writes = 1;
+}
+
+typedef struct {
+  const char *funcName;
+  func_call_handler handler;
+} funcCallHandlersTy;
+
+static const funcCallHandlersTy funcCallHandlers[] = {
+  {"_Z8atom_add", baseAtomics64},
+  {"_Z8atom_sub", baseAtomics64},
+  {"_Z9atom_xchg", baseAtomics64},
+  {"_Z8atom_inc", baseAtomics64},
+  {"_Z8atom_dec", baseAtomics64},
+  {"_Z12atom_cmpxchg", baseAtomics64},
+  {"_Z8atom_min", extAtomics64},
+  {"_Z8atom_max", extAtomics64},
+  {"_Z8atom_and", extAtomics64},
+  {"_Z7atom_or", extAtomics64},
+  {"_Z8atom_xor", extAtomics64},
+  {"_Z12write_imagef", image3DWrite},
+  {"_Z12write_imagei", image3DWrite},
+  {"_Z13write_imageui", image3DWrite}
+};
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs);
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs, std::set<llvm::Type*> &typesList) {
+  if (ty1 == ty2)
+    return true;
+
+  if (ty1->isVectorTy())
+    return searchTypeInType(ty1->getVectorElementType(), ty2, ignorePtrs, typesList);
+
+  if (ty1->isArrayTy())
+    return searchTypeInType(ty1->getArrayElementType(), ty2, ignorePtrs, typesList);
+
+  if (!ignorePtrs && ty1->isPointerTy()) {
+    // prevent infinte loop (such a struct that conatinc pointer to itself)
+    std::set<llvm::Type*>::iterator itr = typesList.find(ty1->getPointerElementType());
+    if ( itr != typesList.end() ) {
+      return false;
+    }
+    return searchTypeInType(ty1->getPointerElementType(), ty2, ignorePtrs, typesList);
+  }
+
+  if (ty1->isStructTy()) {
+    typesList.insert( ty1 );
+    llvm::StructType *strTy = dyn_cast<llvm::StructType>(ty1);
+
+    for (StructType::element_iterator EI = strTy->element_begin(),
+         EE = strTy->element_end(); EI != EE; ++EI)
+      if (searchTypeInType((*EI), ty2, ignorePtrs, typesList))
+        return true;
+  }
+
+  if (ty1->isFunctionTy()) {
+    typesList.insert( ty1 );
+    FunctionType *FuncTy = dyn_cast<llvm::FunctionType>(ty1);
+
+    if (searchTypeInType(FuncTy->getReturnType(), ty2, ignorePtrs))
+      return true;
+
+    for (FunctionType::param_iterator PI = FuncTy->param_begin(),
+         PE = FuncTy->param_end(); PI != PE; ++PI)
+      if (searchTypeInType((*PI), ty2, ignorePtrs))
+        return true;
+  }
+
+  return false;
+}
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs) {
+  std::set<llvm::Type*> typesList;
+  return searchTypeInType( ty1, ty2, ignorePtrs, typesList);
+}
+
+static void FunctionAddSPIRMetadata(Function &F, bool &bUseDoubles, OCLExtensionsTy &sUsedExts);
+
+void clang::CodeGen::AddSPIRMetadata(Module &M, int OCLVersion, std::list<std::string> sBuildOptions, const OpenCLOptions& cl_options) {
+  Type *pDoubleType = Type::getDoubleTy(M.getContext());
+  Type *pHalfType = Type::getHalfTy(M.getContext());
+
+  OCLExtensionsTy sUsedExts;
+
+  bool bUseDoubles = false;
+  bool bUseImages  = false;
+
+  for (Module::global_iterator GI = M.global_begin(), GE = M.global_end();
+       GI != GE; ++GI) {
+    if (searchTypeInType(GI->getType(), pDoubleType, false))
+      bUseDoubles = true;
+    if (searchTypeInType(GI->getType(), pHalfType, true))
+      sUsedExts._cl_khr_fp16 = true;
+  }
+
+  //check if image types are defined
+  for (size_t i = 0; i < sizeof(ImageTypeNames)/sizeof(ImageTypeNames[0]); i++) {
+    if (M.getTypeByName(ImageTypeNames[i])) {
+      bUseImages = true;
+      break;
+    }
+  }
+
+  //check if depth image types are defined
+  for (size_t i = 0; i < sizeof(ImageDepthTypeNames)/sizeof(ImageDepthTypeNames[0]); i++) {
+    if (M.getTypeByName(ImageDepthTypeNames[i])) {
+      sUsedExts._cl_khr_depth_images = true;
+      break;
+    }
+  }
+
+  //check if msaa image types are defined
+  for (size_t i = 0; i < sizeof(ImageMSAATypeNames)/sizeof(ImageMSAATypeNames[0]); i++) {
+    if (M.getTypeByName(ImageMSAATypeNames[i])) {
+      sUsedExts._cl_khr_gl_msaa_sharing = true;
+      break;
+    }
+  }
+
+  // scan all functions
+  for (Module::iterator FI = M.begin(), FE = M.end();
+       FI != FE; ++FI) {
+    FunctionAddSPIRMetadata(*FI, bUseDoubles, sUsedExts);
+  }
+
+  // enable/add explicitly enabled pragma extensions
+#define OPENCLEXT(nm) if (cl_options.nm) sUsedExts._##nm = true;
+#include "clang/Basic/OpenCLExtensions.def"
+
+  // Add SPIR version (1.2)
+  llvm::Metadata *SPIRVerElts[] = {
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), 1)),
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), 2))
+  };
+  llvm::NamedMDNode *SPIRVerMD =
+    M.getOrInsertNamedMetadata("opencl.spir.version");
+  SPIRVerMD->addOperand(llvm::MDNode::get(M.getContext(), SPIRVerElts));
+
+  // Add OpenCL version
+  llvm::Metadata *OCLVerElts[] = {
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), OCLVersion / 100)),
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), (OCLVersion % 100) / 10))
+  };
+  llvm::NamedMDNode *OCLVerMD =
+    M.getOrInsertNamedMetadata("opencl.ocl.version");
+  OCLVerMD->addOperand(llvm::MDNode::get(M.getContext(), OCLVerElts));
+
+  // Add used extensions
+  llvm::SmallVector<llvm::Metadata*, 5> OCLExtElts;
+
+#define OPENCLEXT(nm)  if (sUsedExts._##nm) \
+  OCLExtElts.push_back(llvm::MDString::get(M.getContext(), #nm));
+#include "clang/Basic/OpenCLExtensions.def"
+
+  llvm::NamedMDNode *OCLExtMD =
+    M.getOrInsertNamedMetadata("opencl.used.extensions");
+
+  OCLExtMD->addOperand(llvm::MDNode::get(M.getContext(), OCLExtElts));
+
+  // Add used optional core features
+  llvm::SmallVector<llvm::Metadata*, 5> OCLOptCoreElts;
+
+  // TODO: flag for this?
+  if (bUseDoubles)
+    OCLOptCoreElts.push_back(llvm::MDString::get(M.getContext(), "cl_doubles"));
+
+  if (bUseImages)
+    OCLOptCoreElts.push_back(llvm::MDString::get(M.getContext(), "cl_images"));
+
+  llvm::NamedMDNode *OptCoreMD =
+    M.getOrInsertNamedMetadata("opencl.used.optional.core.features");
+  OptCoreMD->addOperand(llvm::MDNode::get(M.getContext(), OCLOptCoreElts));
+
+  // Add build options
+  llvm::NamedMDNode *OCLCompOptsMD =
+    M.getOrInsertNamedMetadata("opencl.compiler.options");
+      llvm::SmallVector<llvm::Metadata*,5> OCLBuildOptions;
+  // TODO: should probably parse clang args, -cl-spir-compile-options doesn't seem to work?
+  sBuildOptions.push_back("-cl-kernel-arg-info");
+  sBuildOptions.push_back("-cl-mad-enable");
+  sBuildOptions.push_back("-cl-denorms-are-zero");
+  sBuildOptions.push_back("-cl-unsafe-math-optimizations");
+  for (std::list<std::string>::const_iterator it = sBuildOptions.begin(),
+       e = sBuildOptions.end(); it != e ; ++it) {
+    OCLBuildOptions.push_back(llvm::MDString::get(M.getContext(), *it));
+  }
+  OCLCompOptsMD->addOperand(llvm::MDNode::get(M.getContext(), OCLBuildOptions));
+}
+
+static void FunctionAddSPIRMetadata(Function &F, bool &bUseDoubles, OCLExtensionsTy &sUsedExts) {
+  Type *pDoubleType = Type::getDoubleTy(F.getParent()->getContext());
+  Type *pHalfType = Type::getHalfTy(F.getParent()->getContext());
+
+  for (Function::arg_iterator AI = F.arg_begin(), AE = F.arg_end();
+       AI != AE; ++AI) {
+    if (searchTypeInType(AI->getType(), pDoubleType, false))
+      bUseDoubles = true;
+    if (searchTypeInType(AI->getType(), pHalfType, true))
+      sUsedExts._cl_khr_fp16 = true;
+  }
+
+  for (Function::iterator BB = F.begin(), E = F.end(); BB != E; ++BB)
+    for (BasicBlock::iterator I = BB->begin(), E = BB->end(); I != E; ++I) {
+      if (searchTypeInType(I->getType(), pDoubleType, false))
+        if (!(dyn_cast<FPExtInst>(I)))
+          bUseDoubles = true;
+      if (searchTypeInType(I->getType(), pHalfType, true))
+        sUsedExts._cl_khr_fp16 = true;
+
+      for (Instruction::op_iterator OI = (*I).op_begin(), OE = (*I).op_end();
+           OI != OE; ++OI) {
+        if (searchTypeInType((*OI)->getType(), pDoubleType, false))
+          if (!(dyn_cast<CallInst>(I) &&
+                dyn_cast<CallInst>(I)->getCalledFunction() &&
+                dyn_cast<CallInst>(I)->getCalledFunction()->isVarArg()))
+            bUseDoubles = true;
+        if (searchTypeInType((*OI)->getType(), pHalfType, true))
+          sUsedExts._cl_khr_fp16 = true;
+      }
+
+      CallInst* pCallInst = dyn_cast<CallInst>(I);
+      if (pCallInst && pCallInst->getCalledFunction()) {
+        std::string funcName = pCallInst->getCalledFunction()->getName().str();
+
+        for (size_t i = 0; i < sizeof(funcCallHandlers)/sizeof(funcCallHandlers[0]); i++) {
+          if (funcName.find(funcCallHandlers[i].funcName) == 0)
+            funcCallHandlers[i].handler(pCallInst, sUsedExts);
+        }
+      }
+    }
+}
diff --git a/lib/CodeGen/CGSPIRMetadataAdder.h b/lib/CodeGen/CGSPIRMetadataAdder.h
new file mode 100644
index 0000000..863ee98
--- /dev/null
+++ b/lib/CodeGen/CGSPIRMetadataAdder.h
@@ -0,0 +1,29 @@
+//===- SPIRMetadataAdder.h - Add SPIR related module scope metadata -------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/IR/Module.h"
+#include "clang/Basic/LangOptions.h"
+#include <list>
+#include <string>
+
+#ifndef CLANG_CODEGEN_SPIRMETADATAADDER_H
+#define CLANG_CODEGEN_SPIRMETADATAADDER_H
+
+namespace clang {
+
+namespace CodeGen {
+
+  void AddSPIRMetadata(llvm::Module &M, int OCLVersion, std::list<std::string> sBuildOptions, const OpenCLOptions& cl_options);
+
+} // end namespace CodeGen
+} // end namespace clang
+#endif
diff --git a/lib/CodeGen/CGStmt.cpp b/lib/CodeGen/CGStmt.cpp
index aa457ad..aa2885f 100644
--- a/lib/CodeGen/CGStmt.cpp
+++ b/lib/CodeGen/CGStmt.cpp
@@ -2094,6 +2094,7 @@ void CodeGenFunction::EmitAsmStmt(const AsmStmt &S) {
                                           llvm::ConstantAsMetadata::get(Loc)));
   }
 
+#if 0 // TODO: don't do this pessimistically, check asm code for convergent instructions instead
   if (getLangOpts().CUDA && getLangOpts().CUDAIsDevice) {
     // Conservatively, mark all inline asm blocks in CUDA as convergent
     // (meaning, they may call an intrinsically convergent op, such as bar.sync,
@@ -2101,6 +2102,7 @@ void CodeGenFunction::EmitAsmStmt(const AsmStmt &S) {
     Result->addAttribute(llvm::AttributeSet::FunctionIndex,
                          llvm::Attribute::Convergent);
   }
+#endif
 
   // Extract all of the register value results from the asm.
   std::vector<llvm::Value*> RegResults;
diff --git a/lib/CodeGen/CMakeLists.txt b/lib/CodeGen/CMakeLists.txt
index 175d9ae..951fe82 100644
--- a/lib/CodeGen/CMakeLists.txt
+++ b/lib/CodeGen/CMakeLists.txt
@@ -2,6 +2,8 @@ set(LLVM_LINK_COMPONENTS
   Analysis
   BitReader
   BitWriter
+  BitWriter32
+  BitWriter35
   Core
   Coverage
   IPO
@@ -15,6 +17,7 @@ set(LLVM_LINK_COMPONENTS
   Object
   ProfileData
   ScalarOpts
+  SPIRVlib
   Support
   Target
   TransformUtils
@@ -61,6 +64,7 @@ add_clang_library(clangCodeGen
   CGOpenMPRuntime.cpp
   CGOpenMPRuntimeNVPTX.cpp
   CGRecordLayoutBuilder.cpp
+  CGSPIRMetadataAdder.cpp
   CGStmt.cpp
   CGStmtOpenMP.cpp
   CGVTT.cpp
diff --git a/lib/CodeGen/CodeGenAction.cpp b/lib/CodeGen/CodeGenAction.cpp
index dd80390..4e3b676 100644
--- a/lib/CodeGen/CodeGenAction.cpp
+++ b/lib/CodeGen/CodeGenAction.cpp
@@ -714,7 +714,13 @@ GetOutputStream(CompilerInstance &CI, StringRef InFile, BackendAction Action) {
   case Backend_EmitLL:
     return CI.createDefaultOutputFile(false, InFile, "ll");
   case Backend_EmitBC:
+  case Backend_EmitBC32:
+  case Backend_EmitBC35:
     return CI.createDefaultOutputFile(true, InFile, "bc");
+  case Backend_EmitSPIRV:
+    return CI.createDefaultOutputFile(true, InFile, "spv");
+  case Backend_EmitSPIRVContainer:
+    return CI.createDefaultOutputFile(true, InFile, "spvc");
   case Backend_EmitNothing:
     return nullptr;
   case Backend_EmitMCNull:
@@ -877,6 +883,22 @@ void EmitBCAction::anchor() { }
 EmitBCAction::EmitBCAction(llvm::LLVMContext *_VMContext)
   : CodeGenAction(Backend_EmitBC, _VMContext) {}
 
+void EmitBC32Action::anchor() { }
+EmitBC32Action::EmitBC32Action(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitBC32, _VMContext) {}
+
+void EmitBC35Action::anchor() { }
+EmitBC35Action::EmitBC35Action(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitBC35, _VMContext) {}
+
+void EmitSPIRVAction::anchor() { }
+EmitSPIRVAction::EmitSPIRVAction(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitSPIRV, _VMContext) {}
+
+void EmitSPIRVContainerAction::anchor() { }
+EmitSPIRVContainerAction::EmitSPIRVContainerAction(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitSPIRVContainer, _VMContext) {}
+
 void EmitLLVMAction::anchor() { }
 EmitLLVMAction::EmitLLVMAction(llvm::LLVMContext *_VMContext)
   : CodeGenAction(Backend_EmitLL, _VMContext) {}
diff --git a/lib/CodeGen/CodeGenFunction.cpp b/lib/CodeGen/CodeGenFunction.cpp
index 183ee12..e82c4f8 100644
--- a/lib/CodeGen/CodeGenFunction.cpp
+++ b/lib/CodeGen/CodeGenFunction.cpp
@@ -34,6 +34,9 @@
 #include "llvm/IR/Intrinsics.h"
 #include "llvm/IR/MDBuilder.h"
 #include "llvm/IR/Operator.h"
+#include <sstream>
+#include <unordered_set>
+#include <fstream>
 using namespace clang;
 using namespace CodeGen;
 
@@ -436,185 +439,1783 @@ void CodeGenFunction::EmitMCountInstrumentation() {
   EmitNounwindRuntimeCall(MCountFn);
 }
 
-// OpenCL v1.2 s5.6.4.6 allows the compiler to store kernel argument
-// information in the program executable. The argument information stored
-// includes the argument name, its type, the address and access qualifiers used.
-static void GenOpenCLArgMetadata(const FunctionDecl *FD, llvm::Function *Fn,
-                                 CodeGenModule &CGM, llvm::LLVMContext &Context,
-                                 CGBuilderTy &Builder, ASTContext &ASTCtx) {
-  // Create MDNodes that represent the kernel arg metadata.
-  // Each MDNode is a list in the form of "key", N number of values which is
-  // the same number of values as their are kernel arguments.
-
-  const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
-
-  // MDNode for the kernel argument address space qualifiers.
-  SmallVector<llvm::Metadata *, 8> addressQuals;
-
-  // MDNode for the kernel argument access qualifiers (images only).
-  SmallVector<llvm::Metadata *, 8> accessQuals;
-
-  // MDNode for the kernel argument type names.
-  SmallVector<llvm::Metadata *, 8> argTypeNames;
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained fields
+static std::vector<RecordDecl::field_iterator> get_aggregate_fields(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	//
+	std::vector<RecordDecl::field_iterator> ret;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_fields(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.empty()) {
+			ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+		}
+	}
+	
+	// iterate over all fields/members
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		ret.push_back(iter);
+	}
+	
+	return ret;
+}
 
-  // MDNode for the kernel argument base type names.
-  SmallVector<llvm::Metadata *, 8> argBaseTypeNames;
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained image types
+// NOTE: will return an empty vector if not a proper aggregate image
+static std::vector<RecordDecl::field_iterator> get_aggregate_image_fields(const CXXRecordDecl* decl) {
+	// extract all fields, then check if all are image types (if one isn't, fail)
+	const auto ret = get_aggregate_fields(decl);
+	for(const auto& iter : ret) {
+		if(!iter->getType()->isImageType() &&
+		   !iter->getType()->isArrayImageType(false)) {
+			return {};
+		}
+	}
+	return ret;
+}
 
-  // MDNode for the kernel argument type qualifiers.
-  SmallVector<llvm::Metadata *, 8> argTypeQuals;
+static std::pair<FieldDecl*, uint32_t> get_array_image_info(const CXXRecordDecl* decl, const ASTContext& ASTCtx) {
+	const auto ret = get_aggregate_fields(decl);
+	if(ret.size() != 1) return { nullptr, 0 };
+	
+	FieldDecl* arr_field_decl = *ret[0];
+	const ConstantArrayType *CAT = ASTCtx.getAsConstantArrayType(arr_field_decl->getType());
+	if(!CAT) return { nullptr, 0 };
+	
+	auto img_cxx_rdecl = CAT->getElementType()->getAsCXXRecordDecl();
+	if(!img_cxx_rdecl) return { nullptr, 0 };
+	
+	auto img_fields = get_aggregate_fields(img_cxx_rdecl);
+	if(img_fields.size() != 1) return { nullptr, 0 };
+	
+	return { *img_fields[0], uint32_t(CAT->getSize().getZExtValue()) };
+}
 
-  // MDNode for the kernel argument names.
-  SmallVector<llvm::Metadata *, 8> argNames;
+// will recurse through the specified class/struct decl and its base classes,
+// returning the first image access attribute that it encounters (or nullptr if none)
+static const ImageAccessAttr* get_aggregate_access_attr(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return nullptr;
+	
+	// must have definition
+	if(!decl->hasDefinition()) return nullptr;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_access_attr(base.getTypeSourceInfo()->getType()->getAsCXXRecordDecl());
+		if(base_ret != nullptr) {
+			return base_ret;
+		}
+	}
+	
+	// iterate over all fields/members and return the first access attr
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		// try direct attr first
+		const ImageAccessAttr* access_attr = iter->getAttr<ImageAccessAttr>();
+		if(access_attr != nullptr) {
+			return access_attr;
+		}
+		
+		// then check if this is a c++ decl (struct/union/class) and check if it has the attr
+		const auto as_decl = iter->getType()->getAsCXXRecordDecl();
+		if(as_decl != nullptr) {
+			access_attr = as_decl->getAttr<ImageAccessAttr>();
+			if(access_attr != nullptr) {
+				return access_attr;
+			}
+		}
+	}
+	
+	return nullptr;
+}
 
-  for (unsigned i = 0, e = FD->getNumParams(); i != e; ++i) {
-    const ParmVarDecl *parm = FD->getParamDecl(i);
-    QualType ty = parm->getType();
-    std::string typeQuals;
 
-    if (ty->isPointerType()) {
-      QualType pointeeTy = ty->getPointeeType();
+// Metadata values extractors.
+static std::string getScalarMetadataValue(const clang::Type *Ty,
+										  const PrintingPolicy &Policy) {
+	assert(Ty && "NULL type");
+
+	if (Ty->isHalfType()) return "half";
+	
+	if (!Ty->isUnsignedIntegerType()) {
+		return QualType(Ty, 0).getAsString(Policy);
+	}
+	
+	std::string TyName = QualType(Ty, 0).getAsString();
+	if (llvm::StringRef(TyName).startswith("unsigned")) {
+		// Replace unsigned <ty> with u<ty>
+		TyName.erase(1, 8);
+	}
+	
+	return TyName;
+}
+static std::string getVectorMetadataValue(const clang::ExtVectorType *Ty,
+										  const PrintingPolicy &Policy) {
+	assert(Ty && "NULL type");
+
+	const clang::VectorType *VTy = llvm::dyn_cast<clang::VectorType>(Ty);
+	assert(VTy && "Cast to vector failed");
+	
+	std::stringstream Ret;
+	Ret << getScalarMetadataValue(VTy->getElementType().getTypePtr(), Policy);
+	Ret << VTy->getNumElements();
+	
+	return Ret.str();
+}
 
-      // Get address qualifier.
-      addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(
-          ASTCtx.getTargetAddressSpace(pointeeTy.getAddressSpace()))));
+// Returns true if the given module has SPIR (32/64) target
+static bool isSpirTarget(const llvm::Module *M) {
+  assert (M && "NULL module given");
+  return llvm::StringRef(M->getTargetTriple()).startswith("spir");
+}
 
-      // Get argument type name.
-      std::string typeName =
-          pointeeTy.getUnqualifiedType().getAsString(Policy) + "*";
+static std::string getPipeMetadataValue(const clang::PipeType *Ty,
+                                        const PrintingPolicy &Policy) {
+  assert(Ty && "Null type");
 
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (pointeeTy.isCanonical() && pos != std::string::npos)
-        typeName.erase(pos+1, 8);
+  const clang::QualType ElemTy = Ty->getElementType();
+  if (const clang::ExtVectorType *VTy = ElemTy->getAs<ExtVectorType>())
+    return getVectorMetadataValue(VTy, Policy);
 
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
+  return getScalarMetadataValue(ElemTy.getTypePtr(), Policy);
+}
 
-      std::string baseTypeName =
-          pointeeTy.getUnqualifiedType().getCanonicalType().getAsString(
-              Policy) +
-          "*";
+// NOTE/TODO: unused for now, until pipe metadata generation works correctly
+/*static llvm::MDString *getAccessAttribute(const ParmVarDecl *PDecl,
+                                          llvm::LLVMContext &Context) {
+  if (PDecl->hasAttr<ImageAccessAttr>() &&
+    PDecl->getAttr<ImageAccessAttr>()->isWriteOnly())
+    return llvm::MDString::get(Context, "write_only");
 
-      // Turn "unsigned type" to "utype"
-      pos = baseTypeName.find("unsigned");
-      if (pos != std::string::npos)
-        baseTypeName.erase(pos+1, 8);
+  if (PDecl->hasAttr<ImageAccessAttr>() &&
+    PDecl->getAttr<ImageAccessAttr>()->isReadWrite())
+    return llvm::MDString::get(Context, "read_write");
 
-      argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTypeName));
+  return llvm::MDString::get(Context, "read_only");
+}*/
 
-      // Get argument type qualifiers:
-      if (ty.isRestrictQualified())
-        typeQuals = "restrict";
-      if (pointeeTy.isConstQualified() ||
-          (pointeeTy.getAddressSpace() == LangAS::opencl_constant))
-        typeQuals += typeQuals.empty() ? "const" : " const";
-      if (pointeeTy.isVolatileQualified())
-        typeQuals += typeQuals.empty() ? "volatile" : " volatile";
-    } else {
-      uint32_t AddrSpc = 0;
-      bool isPipe = ty->isPipeType();
-      if (ty->isImageType() || isPipe)
-        AddrSpc =
-          CGM.getContext().getTargetAddressSpace(LangAS::opencl_global);
-
-      addressQuals.push_back(
-          llvm::ConstantAsMetadata::get(Builder.getInt32(AddrSpc)));
-
-      // Get argument type name.
-      std::string typeName;
-      if (isPipe)
-        typeName = ty.getCanonicalType()->getAs<PipeType>()->getElementType()
-                     .getAsString(Policy);
-      else
-        typeName = ty.getUnqualifiedType().getAsString(Policy);
-
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (ty.isCanonical() && pos != std::string::npos)
-        typeName.erase(pos+1, 8);
-
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
-
-      std::string baseTypeName;
-      if (isPipe)
-        baseTypeName = ty.getCanonicalType()->getAs<PipeType>()
-                          ->getElementType().getCanonicalType()
-                          .getAsString(Policy);
-      else
-        baseTypeName =
-          ty.getUnqualifiedType().getCanonicalType().getAsString(Policy);
-
-      // Turn "unsigned type" to "utype"
-      pos = baseTypeName.find("unsigned");
-      if (pos != std::string::npos)
-        baseTypeName.erase(pos+1, 8);
-
-      argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTypeName));
-
-      // Get argument type qualifiers:
-      if (ty.isConstQualified())
-        typeQuals = "const";
-      if (ty.isVolatileQualified())
-        typeQuals += typeQuals.empty() ? "volatile" : " volatile";
-      if (isPipe)
-        typeQuals = "pipe";
-    }
+// OpenCL v1.2 s5.6.4.6 allows the compiler to store kernel argument
+// information in the program executable. The argument information stored
+// includes the argument name, its type, the address and access qualifiers used.
+static void GenOpenCLArgMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+                                 CodeGenModule &CGM, llvm::LLVMContext &Context,
+                                 SmallVector<llvm::Metadata *, 5> &kernelMDArgs,
+                                 CGBuilderTy &Builder, ASTContext &ASTCtx) {
+	// Create MDNodes that represent the kernel arg metadata.
+	// Each MDNode is a list in the form of "key", N number of values which is
+	// the same number of values as their are kernel arguments.
+
+	const bool EmitVerbose = CGM.getCodeGenOpts().EmitOpenCLArgMetadata;
+
+	if (!isSpirTarget(Fn->getParent()) && !EmitVerbose) {
+		return;
+	}
+	
+	// MDNode for the kernel argument address space qualifiers.
+	SmallVector<llvm::Metadata*, 8> addressQuals;
+	addressQuals.push_back(llvm::MDString::get(Context, "kernel_arg_addr_space"));
+	
+	// MDNode for the kernel argument access qualifiers (images only).
+	SmallVector<llvm::Metadata*, 8> accessQuals;
+	accessQuals.push_back(llvm::MDString::get(Context, "kernel_arg_access_qual"));
+	
+	// MDNode for the kernel argument type names.
+	SmallVector<llvm::Metadata*, 8> argTypeNames;
+	argTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_type"));
+	
+	// MDNode for the kernel argument base type names.
+	SmallVector<llvm::Metadata*, 8> argBaseTypeNames;
+	argBaseTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_base_type"));
+	
+	// MDNode for the kernel argument type qualifiers.
+	SmallVector<llvm::Metadata*, 8> argTypeQuals;
+	argTypeQuals.push_back(llvm::MDString::get(Context, "kernel_arg_type_qual"));
+	
+	// MDNode for the kernel argument names.
+	SmallVector<llvm::Metadata*, 8> argNames;
+	if (EmitVerbose) {
+		argNames.push_back(llvm::MDString::get(Context, "kernel_arg_name"));
+	}
+	// TODO: proper handling of EmitVerbose + kernel arg names
+	
+	const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
+	
+	// Creates a canonical name for complex types. In case of anonymous types, the
+	// function appends the meta-type name as prefix: e.g., in case the type is
+	// defined as: typedef struct {...} S, the method returns struct S.
+	static const auto canonicalName = [](const std::string &TyName,
+										 const std::string &MetaTyName) {
+		if (StringRef(TyName).startswith(MetaTyName)) {
+			return TyName;
+		}
+		
+		return std::string(MetaTyName) + " __" + TyName;
+	};
+	
+	static const auto getComplexMetadataValue = [](const clang::Type *Ty,
+												   const PrintingPolicy &Policy) {
+		std::string TyName = QualType(Ty, 0).getCanonicalType().getAsString();
+		
+		if (Ty->isStructureOrClassType()) {
+			return canonicalName(TyName, "struct");
+		}
+		
+		if (Ty->isUnionType()) {
+			return canonicalName(TyName, "union");
+		}
+		
+		if (Ty->isEnumeralType()) {
+			return canonicalName(TyName, "enum");
+		}
+		
+		return getScalarMetadataValue(Ty, Policy);
+	};
+	
+	static const auto getPointerOrRefMetadataValue = [](const clang::Type *PTy,
+														bool CanTy,
+														const PrintingPolicy &Policy) {
+		assert(PTy && "Null type");
+		
+		std::string Ret;
+		
+		if (const ExtVectorType *VTy = llvm::dyn_cast<ExtVectorType>(PTy)) {
+			Ret = getVectorMetadataValue(VTy, Policy);
+		}
+		else {
+			Ret = CanTy ? getComplexMetadataValue(PTy, Policy) : getScalarMetadataValue(PTy, Policy);
+		}
+		
+		return Ret + "*";
+	};
+	
+	const auto add_image_arg = [&Builder, &Context, &CGM, &Policy,
+								&addressQuals, &accessQuals, &argTypeNames, &argBaseTypeNames,
+								&argNames, &argTypeQuals](const clang::QualType& type,
+														  const ImageAccessAttr* access_attr,
+														  const std::string& name) {
+		// image is always in global address space
+		addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getContext().getTargetAddressSpace(LangAS::opencl_global))));
+		
+		// set access qualifier
+		if (access_attr && access_attr->isWriteOnly()) {
+			accessQuals.push_back(llvm::MDString::get(Context, "write_only"));
+		}
+		else if (access_attr && access_attr->isReadWrite()) {
+			accessQuals.push_back(llvm::MDString::get(Context, "read_write"));
+		}
+		else {
+			accessQuals.push_back(llvm::MDString::get(Context, "read_only"));
+		}
+		
+		// image type / base type
+		// NOTE: always set base type, because types in image aggregates might be "weird", but should be considered normal
+		const QualType baseTy = type.isCanonical() ? type : type.getCanonicalType();
+		const auto type_name = getComplexMetadataValue(baseTy.getTypePtr(), Policy);
+		argTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		argBaseTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		
+		// set arg name
+		argNames.push_back(llvm::MDString::get(Context, name));
+		
+		// type quals is always empty for images
+		argTypeQuals.push_back(llvm::MDString::get(Context, ""));
+	};
+	
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const bool IsCanonical = clang_type.isCanonical();
+		
+		// pointer / buffer
+		if (clang_type->isPointerType() || clang_type->isReferenceType()) {
+			// Get argument type name.
+			std::string tyName;
+			if (const PointerType *PTy = dyn_cast<PointerType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(PTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else if (const ReferenceType *RTy = dyn_cast<ReferenceType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(RTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else if (const DecayedType *DTy = dyn_cast<DecayedType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(DTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else {
+				tyName = getScalarMetadataValue(clang_type.getTypePtr(), Policy);
+			}
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			std::string baseTyName;
+			if (IsCanonical) baseTyName = tyName;
+			else {
+				QualType can_pointee_type;
+				if(clang_type->isPointerType()) {
+					can_pointee_type = clang_type.getCanonicalType()->getAs<PointerType>()->getPointeeType();
+				}
+				else { // ref
+					can_pointee_type = clang_type.getCanonicalType()->getAs<ReferenceType>()->getPointeeType();
+				}
+				baseTyName = getPointerOrRefMetadataValue(can_pointee_type.getTypePtr(), true, Policy);
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get address qualifier.
+			QualType pointeeTy = clang_type->getPointeeType();
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(ASTCtx.getTargetAddressSpace(pointeeTy.getAddressSpace()))));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isRestrictQualified()) {
+				typeQuals = "restrict";
+			}
+			if (pointeeTy.isConstQualified() ||
+				(pointeeTy.getAddressSpace() == LangAS::opencl_constant)) {
+				typeQuals += typeQuals.empty() ? "const" : " const";
+			}
+			if (pointeeTy.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			accessQuals.push_back(llvm::MDString::get(Context, "none"));
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+		// normal image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getName().str());
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto decl = clang_type->getAsCXXRecordDecl();
+			const auto agg_images = get_aggregate_image_fields(decl);
+			
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				const auto img_type = img->getType();
+				
+				add_image_arg(img_type, img->getAttr<ImageAccessAttr>(),
+							  base_name + std::to_string(img_idx));
+				++img_idx;
+			}
+		}
+		else if (clang_type->isPipeType()) {
+			// Get argument type name.
+			std::string tyName = getPipeMetadataValue(clang_type->getAs<PipeType>(), Policy);
+			
+			// Acquiring the base type of the parameter.
+			std::string baseTyName;
+			if (IsCanonical) {
+				baseTyName = tyName;
+			}
+			else {
+				baseTyName = getPipeMetadataValue(clang_type.getCanonicalType()->getAs<PipeType>(), Policy);
+			}
+			
+			// Get address qualifier.
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(ASTCtx.getTargetAddressSpace(LangAS::opencl_global))));
+			
+			// Get argument type qualifiers.
+			std::string typeQuals = "pipe";
+			
+			// Adding the type and base type to the metadata.
+			assert(!tyName.empty() && "Empty type name");
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			assert(!baseTyName.empty() && "Empty base type name");
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			// TODO: Get image access qualifier: (also for pipe?)
+			//accessQuals.push_back(getAccessAttribute(parm, Context));
+			
+			if (EmitVerbose) {
+				// Get argument name.
+				argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+			}
+		}
+		// kernel parameter
+		else {
+			// TODO: merge pipe functionality
+			
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(0 /* private address space*/)));
+			
+			// Get argument type name.
+			std::string tyName = getScalarMetadataValue(clang_type.getTypePtr(), Policy);
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			QualType baseTy = IsCanonical ? clang_type : clang_type.getCanonicalType();
+			std::string baseTyName;
+			if (clang_type->isVectorType()) {
+				baseTyName = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(baseTy.getTypePtr()), Policy);
+			}
+			else {
+				baseTyName = getComplexMetadataValue(baseTy.getTypePtr(), Policy);
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isConstQualified()) {
+				typeQuals = "const";
+			}
+			if (clang_type.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			accessQuals.push_back(llvm::MDString::get(Context, "none"));
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+	}
+	
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, addressQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, accessQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argBaseTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeQuals));
+	if(EmitVerbose) {
+		kernelMDArgs.push_back(llvm::MDNode::get(Context, argNames));
+	}
+}
 
-    argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
-
-    // Get image and pipe access qualifier:
-    if (ty->isImageType()|| ty->isPipeType()) {
-      const OpenCLAccessAttr *A = parm->getAttr<OpenCLAccessAttr>();
-      if (A && A->isWriteOnly())
-        accessQuals.push_back(llvm::MDString::get(Context, "write_only"));
-      else if (A && A->isReadWrite())
-        accessQuals.push_back(llvm::MDString::get(Context, "read_write"));
-      else
-        accessQuals.push_back(llvm::MDString::get(Context, "read_only"));
-    } else
-      accessQuals.push_back(llvm::MDString::get(Context, "none"));
+static void GenVulkanMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+                              CodeGenModule &CGM,llvm::LLVMContext &Context,
+                              CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	
+	SmallVector<llvm::Metadata*, 8> stage_infos;
+	stage_infos.push_back(llvm::MDString::get(Context, FD->getName()));
+	
+	static const std::string prefix_builtin = "builtin:";
+	static const std::string prefix_stage = "stage:";
+	static const std::string prefix_arg = "arg:";
+	
+	//
+	const auto handle_stage_input_output = [&Context, &CGM, &stage_infos,
+											&is_kernel, &is_vertex, &is_fragment,
+											&FD, &Fn](const QualType& clang_type,
+													  llvm::Type* llvm_type,
+													  const bool is_return,
+													  uint32_t* arg_idx) {
+		assert((arg_idx != nullptr && !is_return) || (arg_idx == nullptr && is_return) && "invalid args");
+		
+		const bool is_vertex_io = (is_return && is_vertex) || (!is_return && is_fragment);
+		const bool is_fragment_io = (is_return && is_fragment);
+		
+		const auto add_fbo_output = [&stage_infos, &Context](const QualType& type, const uint32_t location) {
+			const auto canon_data_type = type.getCanonicalType();
+			std::string output_type_str = "float";
+			if(canon_data_type->isIntegerType()) output_type_str = "int";
+			if(canon_data_type->isUnsignedIntegerType()) output_type_str = "uint";
+			stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "fbo_output:" + output_type_str + ":" + std::to_string(location)));
+		};
+		
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		if(cxx_rdecl) {
+			if(!cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				
+				// fbo output location resolve/computation needs to happen in two passes:
+				// * gather all fixed/attr locations, make sure none conflict
+				// * used fixed locations + generate automatic location for non-fixed outputs
+				std::unordered_set<uint32_t> fbo_locations;
+				if(is_fragment_io) {
+					for(const auto& field : fields) {
+						if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+							const auto loc_attr = field.getAttr<GraphicsFBOColorLocationAttr>();
+							if(!fbo_locations.insert(loc_attr->getEvalLocation()).second) {
+								// TODO: should have been detected earlier ...
+								CGM.Error(loc_attr->getLocation(), StringRef("location already in use"));
+								// TODO: add note of prev location?
+								return;
+							}
+						}
+					}
+				}
+				
+				uint32_t struct_arg_idx = 0, fbo_location = 0;
+				for(const auto& field : fields) {
+					llvm::Type* field_llvm_type = nullptr;
+					// get llvm type from function args (if !return), else get it from the struct type itself
+					if(arg_idx) {
+						field_llvm_type = next(Fn->getArgumentList().begin(), *arg_idx)->getType();
+					}
+					else {
+						field_llvm_type = llvm_type->getStructElementType(struct_arg_idx++);
+					}
+					
+					if(is_vertex_io) {
+						if(field.hasAttr<GraphicsVertexPositionAttr>()) {
+							stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+						}
+						else if(field.hasAttr<GraphicsPointSizeAttr>()) {
+							stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "point_size"));
+						}
+						else {
+							stage_infos.push_back(llvm::MDString::get(Context, "none"));
+						}
+					}
+					else if(is_fragment_io) {
+						if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+							add_fbo_output(field.type, field.getAttr<GraphicsFBOColorLocationAttr>()->getEvalLocation());
+						}
+						else if(field.hasAttr<GraphicsFBODepthTypeAttr>()) {
+							const auto depth_attr = field.getAttr<GraphicsFBODepthTypeAttr>();
+							if(!field.type->isFloatingType()) {
+								// TODO: should have been detected earlier ...
+								CGM.Error(depth_attr->getLocation(),
+										  StringRef("depth attribute can only be applied to floating point types"));
+								return;
+							}
+							
+							// TODO: add/handle!
+							std::string depth_qual = "depth_qualifier:";
+							switch(depth_attr->getDepthQualifier()) {
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeAny: depth_qual += "any"; break;
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeLess: depth_qual += "less"; break;
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeGreater: depth_qual += "greater"; break;
+							}
+						}
+						else {
+							for(;;) {
+								if(fbo_locations.count(fbo_location) > 0) {
+									++fbo_location;
+								}
+								else break;
+							}
+							add_fbo_output(field.type, fbo_location);
+							++fbo_location;
+						}
+					}
+					
+					// next
+					if(arg_idx) ++*arg_idx;
+				}
+				if(arg_idx) --*arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// stage defaults (can only be those)
+				if(is_vertex_io) {
+					stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+				}
+				else if(is_fragment_io) {
+					add_fbo_output(clang_type, 0);
+				}
+			}
+		}
+		else if(!clang_type->isVoidType()) {
+			// TODO: anything else?
+			// stage defaults (can only be those)
+			if(is_vertex_io) {
+				stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+			}
+			else if(is_fragment_io) {
+				add_fbo_output(clang_type, 0);
+			}
+		}
+		else return;
+	};
+	
+	//
+	stage_infos.push_back(llvm::MDString::get(Context, "stage_input"));
+	
+	const auto add_image_arg = [&stage_infos,
+								&Context, &ASTCtx, &CGM](const clang::QualType& type,
+														 const ImageAccessAttr* access_attr,
+														 const FloorImageDataTypeAttr* data_type,
+														 const std::string& name,
+														 const uint32_t elem_count = 1) {
+		std::string access_str = "read";
+		if(access_attr && access_attr->isWriteOnly()) {
+			access_str = "write";
+		}
+		else if(access_attr && access_attr->isReadWrite()) {
+			assert(false && "read/write is not supported");
+		}
+		
+		std::string sample_type_str = "float";
+		if(data_type) {
+			const auto canon_data_type = data_type->getImageDataType().getCanonicalType();
+			if(canon_data_type->isIntegerType()) sample_type_str = "int";
+			if(canon_data_type->isUnsignedIntegerType()) sample_type_str = "uint";
+			// else: just assume float
+		}
+		
+		stage_infos.push_back(llvm::MDString::get(Context, (prefix_arg + access_str +
+															":" + std::to_string(elem_count) +
+															":" + sample_type_str)));
+	};
+	
+	unsigned int arg_idx = 0;
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		
+		// stage input
+		if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			handle_stage_input_output(clang_type, llvm_type, false, &arg_idx);
+		}
+		// image array
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, ASTCtx);
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(array_image_info.first->getType(),
+							  array_image_info.first->getAttr<ImageAccessAttr>(),
+							  array_image_info.first->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  array_image_info.second);
+			}
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(clang_type->getAsCXXRecordDecl());
+			for(const auto& img : agg_images) {
+				uint32_t elem_count = 1;
+				if(img->getType()->isPointerType()) {
+					elem_count = ASTCtx.getAsConstantArrayType(img->getType()->getPointeeType())->getSize().getZExtValue();
+				}
+				add_image_arg(img->getType(),
+							  img->getAttr<ImageAccessAttr>(),
+							  img->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  elem_count);
+				
+				// next llvm arg
+				++arg_idx;
+			}
+			// fix up llvm arg count (will inc again after this)
+			--arg_idx;
+		}
+		// anything else
+		else {
+			stage_infos.push_back(llvm::MDString::get(Context, "none"));
+		}
+		
+		// next llvm arg
+		++arg_idx;
+	}
+	
+	// add fixed input
+	if(is_kernel) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "global_invocation_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "local_invocation_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "workgroup_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "num_workgroups"));
+	}
+	else if(is_vertex) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "vertex_index"));
+	}
+	else if(is_fragment) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "point_coord"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "frag_coord"));
+	}
+	
+	// handle return value
+	stage_infos.push_back(llvm::MDString::get(Context, "stage_output"));
+	if(is_vertex || is_fragment) {
+		handle_stage_input_output(FD->getReturnType(), Fn->getReturnType(), true, nullptr);
+	}
+	
+	// add to global stage_io node
+	auto stage_infos_node = llvm::MDNode::get(Context, stage_infos);
+	auto vk_stage_io = CGM.getModule().getOrInsertNamedMetadata("vulkan.stage_io");
+	vk_stage_io->addOperand(stage_infos_node);
+}
 
-    // Get argument name.
-    argNames.push_back(llvm::MDString::get(Context, parm->getName()));
-  }
+static void GenAIRMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+						   const CGFunctionInfo &FnInfo,
+						   CodeGenModule &CGM,llvm::LLVMContext &Context,
+						   SmallVector <llvm::Metadata*, 5> &kernelMDArgs,
+						   CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	
+	//
+	SmallVector<llvm::Metadata*, 4> stage_infos;
+	SmallVector<llvm::Metadata*, 8> arg_infos;
+	
+	//
+	const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
+	const auto make_type_name = [&Policy](const clang::QualType& type) {
+		// NOTE: air wants the type w/o qualifiers
+		const auto base_unq_type = type.getTypePtr()->getBaseElementTypeUnsafe();
+		const auto unqualified_type = base_unq_type->getCanonicalTypeInternal();
+		std::string type_name = "";
+		if(type->isVectorType()) {
+			type_name = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(unqualified_type.getTypePtr()), Policy);
+		}
+		else if(type->isHalfType()) type_name = "half";
+		else type_name = unqualified_type.getAsString(Policy);
+		// Turn "unsigned type" to "utype"
+		const auto pos = type_name.find("unsigned");
+		if(pos != std::string::npos) type_name.erase(pos + 1, 8);
+		return type_name;
+	};
+	
+	//
+	auto abi_arg_info_iter = FnInfo.arg_begin();
+	unsigned int arg_idx = 0, buffer_idx = 0, tex_idx = 0;
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+
+		const auto add_image_arg = [&Builder, &tex_idx, &arg_infos, &arg_idx, &parm,
+									&Context, &ASTCtx, &CGM](const clang::QualType& type,
+															 const ImageAccessAttr* access_attr,
+															 const FloorImageDataTypeAttr* data_type,
+															 const std::string& name,
+															 const uint32_t elem_count = 1) {
+			SmallVector<llvm::Metadata*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.texture"));
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(tex_idx)));
+			tex_idx += elem_count;
+			// #4: index count/range
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(elem_count)));
+			// #5: access type (sample = 0, read = 1 or write = 2)
+			// note that "read" is essentially a subset of "sample" -> use "sample" for r/o
+			if(access_attr && access_attr->isWriteOnly()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else if(access_attr && access_attr->isReadWrite()) {
+				// TODO: this isn't really supported
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.sample"));
+			}
+			
+			// #6/#7: texture type
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// proper type is necessary for metal debugging purposes
+			std::string tex_type_name = "";
+			if(elem_count > 1) {
+				tex_type_name += "array<";
+			}
+			const auto builtin_type = type->getAs<BuiltinType>();
+			if(!builtin_type) {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image type (not a builtin type)!"));
+				return;
+			}
+			switch(builtin_type->getKind()) {
+				case BuiltinType::OCLImage1d:
+					tex_type_name += "texture1d";
+					break;
+				case BuiltinType::OCLImage1dArray:
+					tex_type_name += "texture1d_array";
+					break;
+				case BuiltinType::OCLImage2d:
+					tex_type_name += "texture2d";
+					break;
+				case BuiltinType::OCLImage2dArray:
+					tex_type_name += "texture2d_array";
+					break;
+				case BuiltinType::OCLImage2dDepth:
+					tex_type_name += "depth2d";
+					break;
+				case BuiltinType::OCLImage2dArrayDepth:
+					tex_type_name += "depth2d_array";
+					break;
+				case BuiltinType::OCLImage2dMSAA:
+					tex_type_name += "texture2d_ms";
+					break;
+				case BuiltinType::OCLImage2dMSAADepth:
+					tex_type_name += "depth2d_ms";
+					break;
+				case BuiltinType::OCLImage3d:
+					tex_type_name += "texture3d";
+					break;
+				case BuiltinType::OCLImageCube:
+					tex_type_name += "texturecube";
+					break;
+				case BuiltinType::OCLImageCubeArray:
+					tex_type_name += "texturecube_array";
+					break;
+				case BuiltinType::OCLImageCubeDepth:
+					tex_type_name += "depthcube";
+					break;
+				case BuiltinType::OCLImageCubeArrayDepth:
+					tex_type_name += "depthcube_array";
+					break;
+				default:
+					CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image type!"));
+					return;
+			}
+			
+			tex_type_name += "<";
+			std::string sample_type_str = "float";
+			if(data_type) {
+				const auto canon_data_type = data_type->getImageDataType().getCanonicalType();
+				if(canon_data_type->isIntegerType()) sample_type_str = "int";
+				if(canon_data_type->isUnsignedIntegerType()) sample_type_str = "uint";
+				// else: just assume float
+			}
+			tex_type_name += sample_type_str;
+			tex_type_name += ",";
+			if(access_attr && access_attr->isReadOnly()) {
+				tex_type_name += "sample";
+			}
+			else tex_type_name += "write";
+			tex_type_name += ">";
+			
+			if(elem_count > 1) {
+				tex_type_name += ", " + std::to_string(elem_count) + ">";
+			}
+			
+			arg_info.push_back(llvm::MDString::get(Context, tex_type_name));
+			
+			// #8/#9: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, StringRef(name)));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		};
+		
+		// pointer / buffer
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			SmallVector<llvm::Metadata*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.buffer"));
+			
+			// references / single-object parameters also store/require the buffer_size
+			if(clang_type->isReferenceType()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.buffer_size"));
+				arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type))));
+			}
+			
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(buffer_idx)));
+			++buffer_idx;
+			// #4: index count/range
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(1)));
+			// #5: access (read/read_write, TODO: write?)
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			if(clang_pointee_type.isConstQualified() ||
+			   (clang_pointee_type.getAddressSpace() == LangAS::opencl_constant)) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read_write"));
+			}
+			
+			// #6/#7: struct info
+			if(const auto pointee_rdecl = clang_pointee_type->getAsCXXRecordDecl()) {
+				SmallVector<llvm::Metadata*, 16> struct_info;
+				// TODO: this is not ideal and doesn't handle properly handle unions
+				const auto fields = get_aggregate_fields(pointee_rdecl);
+				bool ignore = false;
+				for(const auto& field : fields) {
+					if(field->isAnonymousStructOrUnion() ||
+					   field->isBitField()) {
+						ignore = true;
+						break;
+					}
+				}
+				
+				// TODO/NOTE: ignore anonymous structs/unions and bitfields for now
+				if(!ignore) {
+					SmallVector<llvm::Metadata*, 16> struct_info;
+					arg_info.push_back(llvm::MDString::get(Context, "air.struct_type_info"));
+					
+					uint32_t offset = 0;
+					for(const auto& field : fields) {
+						// #0: offset
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(offset)));
+						// #1: sizeof
+						const auto llvm_mem_type = CGM.getTypes().ConvertTypeForMem(field->getType()); // TODO: should use this _everywhere_ instead of llvm type tracking/matching!
+						const auto size = (uint32_t)CGM.getDataLayout().getTypeStoreSize(llvm_mem_type);
+						offset += size;
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(size)));
+						// #2: TODO? array or padding maybe?
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(0)));
+						// #3: type name
+						struct_info.push_back(llvm::MDString::get(Context, make_type_name(field->getType())));
+						// #4: name/identifier
+						struct_info.push_back(llvm::MDString::get(Context, field->getName()));
+					}
+					arg_info.push_back(llvm::MDNode::get(Context, struct_info));
+				}
+			}
+			
+			// #8/#9: type size
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_size"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type))));
+			// #10/#11: type alignment
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_align_size"));
+			// max out at 16, anything higher is unreasonable
+			// TODO: make sure this is POT
+			const auto align_size = std::min(CGM.getDataLayout().getTypeAllocSize(pointee_type), uint64_t(16));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(align_size)));
+			//getPrimitiveSizeInBits
+			// #12/#13: type name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// NOTE: air wants the pointed-to/pointee type here
+			arg_info.push_back(llvm::MDString::get(Context, make_type_name(clang_type->getPointeeType())));
+			// #14/#15: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, parm->getName()));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		}
+		// image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getAttr<FloorImageDataTypeAttr>(), parm->getName().str());
+		}
+		// image array
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, ASTCtx);
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(array_image_info.first->getType(),
+							  array_image_info.first->getAttr<ImageAccessAttr>(),
+							  array_image_info.first->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  array_image_info.second);
+			}
+			else {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image array!"));
+				return;
+			}
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				add_image_arg(img->getType(),
+							  img->getAttr<ImageAccessAttr>(),
+							  img->getAttr<FloorImageDataTypeAttr>(),
+							  base_name + std::to_string(img_idx));
+				++img_idx;
+				
+				// next llvm arg
+				++arg_idx;
+			}
+			// fix up llvm arg count (will inc again after this)
+			--arg_idx;
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					SmallVector<llvm::Metadata*, 16> arg_info;
+					
+					// #0: param index
+					arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+					
+					// #1: type
+					// TODO: handle perspective/center correctly
+					if(field.hasAttr<GraphicsVertexPositionAttr>()) {
+						arg_info.push_back(llvm::MDString::get(Context, "air.position"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.no_perspective"));
+					}
+					else {
+						arg_info.push_back(llvm::MDString::get(Context, "air.fragment_input"));
+						arg_info.push_back(llvm::MDString::get(Context, StringRef(field.mangled_name)));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.perspective"));
+					}
+					
+					// type name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					arg_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// arg name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					arg_info.push_back(llvm::MDString::get(Context, field.name));
+					arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+					
+					// next
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// TODO: add as-is
+			}
+		}
+		// unsupported simple kernel parameter
+		else {
+			CGM.Error(parm->getSourceRange().getBegin(),
+					  StringRef("metal kernel parameter must be a pointer or an image type!"));
+			return;
+		}
+		
+		// next llvm arg
+		++abi_arg_info_iter;
+		++arg_idx;
+	}
+	
+	// limits check
+	// https://developer.apple.com/metal/limits/
+	const bool is_osx = (CGM.getModule().getTargetTriple().find("macosx") != std::string::npos);
+	const uint32_t buf_limit = 31;
+	const uint32_t tex_limit = (is_osx ? 128 : 31);
+	if(buffer_idx > buf_limit) {
+		CGM.Error(FD->getSourceRange().getBegin(),
+				  StringRef("can't use more than " + std::to_string(buf_limit) + " buffers per function"));
+		return;
+	}
+	if(tex_idx > tex_limit) {
+		CGM.Error(FD->getSourceRange().getBegin(),
+				  StringRef("can't use more than " + std::to_string(tex_limit) + " images per function"));
+		return;
+	}
+	
+	//
+	if(is_kernel) {
+		// add id handling arg metadata
+		// NOTE: the actual args are later added by MetalFinal + the order in here must match the order in MetalFinal
+		const auto add_id_arg = [&arg_idx, &arg_infos, &Builder, &Context](const char* name, const char* air_name) {
+			SmallVector<llvm::Metadata*, 6> arg_info;
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			arg_info.push_back(llvm::MDString::get(Context, air_name));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			arg_info.push_back(llvm::MDString::get(Context, "uint3"));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, name));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+			
+			// next llvm arg
+			++arg_idx;
+		};
+		add_id_arg("__metal__global_id__", "air.thread_position_in_grid");
+		add_id_arg("__metal__global_size__", "air.threads_per_grid");
+		add_id_arg("__metal__local_id__", "air.thread_position_in_threadgroup");
+		add_id_arg("__metal__local_size__", "air.threads_per_threadgroup");
+		add_id_arg("__metal__group_id__", "air.threadgroup_position_in_grid");
+		add_id_arg("__metal__group_size__", "air.threadgroups_per_grid");
+	}
+	else if(is_vertex) {
+		// TODO: instance id
+		
+		SmallVector<llvm::Metadata*, 6> arg_info;
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+		arg_info.push_back(llvm::MDString::get(Context, "air.vertex_id"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "uint"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__vertex_id__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_vs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const bool force_position = false) {
+			SmallVector<llvm::Metadata*, 6> ret_info;
+			
+			if(entry.hasAttr<GraphicsVertexPositionAttr>() || force_position) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.position"));
+			}
+			else if(entry.hasAttr<GraphicsPointSizeAttr>()) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.point_size"));
+			}
+			else {
+				ret_info.push_back(llvm::MDString::get(Context, "air.vertex_output"));
+				ret_info.push_back(llvm::MDString::get(Context, StringRef(entry.mangled_name)));
+			}
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			ret_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			ret_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, ret_info));
+		};
+		
+		// vertex output
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			for(const auto& field : fields) {
+				add_vs_output(field);
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			// direct output: always vertex position, no mangled name
+			add_vs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()),
+				false
+			}, true);
+		}
+	}
+	else if(is_fragment) {
+		// TODO: other stuff
+		
+		SmallVector<llvm::Metadata*, 6> arg_info;
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+		arg_info.push_back(llvm::MDString::get(Context, "air.point_coord"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "float2"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__point_coord__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_fs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const unsigned int& location) {
+			SmallVector<llvm::Metadata*, 6> rtt_info;
+			
+			// #0/1: render target location index
+			rtt_info.push_back(llvm::MDString::get(Context, "air.render_target"));
+			rtt_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(location)));
+			
+			// #2/3: type name
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			// #4/#5: name/identifier
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, rtt_info));
+		};
+		
+		// render targets / return types
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			
+			// fbo output location resolve/computation needs to happen in two passes:
+			// * gather all fixed/attr locations, make sure none conflict
+			// * used fixed locations + generate automatic location for non-fixed outputs
+			std::unordered_set<unsigned int> fbo_locations;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					const auto loc_attr = field.getAttr<GraphicsFBOColorLocationAttr>();
+					if(!fbo_locations.insert(loc_attr->getEvalLocation()).second) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(loc_attr->getLocation(), StringRef("location already in use"));
+						// TODO: add note of prev location?
+						return;
+					}
+				}
+			}
+			
+			unsigned int location = 0;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					add_fs_output(field, field.getAttr<GraphicsFBOColorLocationAttr>()->getEvalLocation());
+				}
+				else if(field.hasAttr<GraphicsFBODepthTypeAttr>()) {
+					const auto depth_attr = field.getAttr<GraphicsFBODepthTypeAttr>();
+					if(!field.type->isFloatingType()) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(depth_attr->getLocation(),
+								  StringRef("depth attribute can only be applied to floating point types"));
+						return;
+					}
+					
+					SmallVector<llvm::Metadata*, 7> depth_info;
+					
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth"));
+					
+					// #1/2: depth qualifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth_qualifier"));
+					std::string depth_qual = "air.";
+					switch(depth_attr->getDepthQualifier()) {
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeAny: depth_qual += "any"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeLess: depth_qual += "less"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeGreater: depth_qual += "greater"; break;
+					}
+					depth_info.push_back(llvm::MDString::get(Context, depth_qual));
+					
+					// #3/4: type name
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					depth_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// #5/#6: name/identifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					depth_info.push_back(llvm::MDString::get(Context, field.name));
+					
+					stage_infos.push_back(llvm::MDNode::get(Context, depth_info));
+				}
+				else {
+					for(;;) {
+						if(fbo_locations.count(location) > 0) {
+							++location;
+						}
+						else break;
+					}
+					add_fs_output(field, location);
+					++location;
+				}
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			add_fs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()),
+				false
+			}, 0);
+		}
+	}
+
+	// insert into kernel metadata
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, stage_infos));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, arg_infos));
+}
 
-  Fn->setMetadata("kernel_arg_addr_space",
-                  llvm::MDNode::get(Context, addressQuals));
-  Fn->setMetadata("kernel_arg_access_qual",
-                  llvm::MDNode::get(Context, accessQuals));
-  Fn->setMetadata("kernel_arg_type",
-                  llvm::MDNode::get(Context, argTypeNames));
-  Fn->setMetadata("kernel_arg_base_type",
-                  llvm::MDNode::get(Context, argBaseTypeNames));
-  Fn->setMetadata("kernel_arg_type_qual",
-                  llvm::MDNode::get(Context, argTypeQuals));
-  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata)
-    Fn->setMetadata("kernel_arg_name",
-                    llvm::MDNode::get(Context, argNames));
+void CodeGenFunction::EmitFloorKernelMetadata(const FunctionDecl *FD,
+											  llvm::Function *Fn,
+											  const FunctionArgList &Args,
+											  const CGFunctionInfo &FnInfo) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	if(!is_kernel && !is_vertex && !is_fragment) {
+		return;
+	}
+
+ 	if(getLangOpts().floor_function_info == nullptr) {
+ 		return;
+ 	}
+ 	std::fstream& file = *getLangOpts().floor_function_info;
+	std::stringstream info;
+	
+	const PrintingPolicy &Policy = getContext().getPrintingPolicy();
+	
+	// #0: info version
+	info << "2,";
+	// #1: function name
+	info << Fn->getName().str() << ",";
+	// #2: function type
+	info << (is_kernel ? "1" : (is_vertex ? "2" : "3")) << ",";
+	
+	// iterate over clang function decl parameters
+	// NOTE: in case of struct expansion, this doesn't match the llvm parameters
+	// (which is why it iterates over the original clang list!)
+	unsigned int arg_idx = 0;
+	auto abi_arg_info_iter = FnInfo.arg_begin();
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		
+		enum class FLOOR_ARG_INFO : uint64_t {
+			// 0 == invalid!
+			NONE						= (0ull),
+			
+			// sets: -------- 000000-- -------- 00000xxx 00000000 00000000 00000000 00000000
+			__AS_SHIFT					= (32ull),
+			__AS_MASK					= (0x0000000700000000ull),
+			AS_NONE						= NONE,
+			AS_GLOBAL					= (1ull << __AS_SHIFT),
+			AS_LOCAL					= (2ull << __AS_SHIFT),
+			AS_CONSTANT					= (3ull << __AS_SHIFT),
+			AS_IMAGE					= (4ull << __AS_SHIFT),
+			
+			// sets: -------- 000000-- xxxxxxxx 00000--- 00000000 00000000 00000000 00000000
+			__IMG_TYPE_SHIFT			= (40ull),
+			__IMG_TYPE_MASK				= (0x0000FF0000000000ull),
+			IMG_1D						= (1ull << __IMG_TYPE_SHIFT),
+			IMG_1D_ARRAY				= (2ull << __IMG_TYPE_SHIFT),
+			IMG_1D_BUFFER				= (3ull << __IMG_TYPE_SHIFT),
+			IMG_2D						= (4ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY				= (5ull << __IMG_TYPE_SHIFT),
+			IMG_2D_DEPTH				= (6ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_DEPTH			= (7ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA					= (8ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA			= (9ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA_DEPTH			= (10ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA_DEPTH		= (11ull << __IMG_TYPE_SHIFT),
+			IMG_3D						= (12ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE					= (13ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY				= (14ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_DEPTH				= (15ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY_DEPTH		= (16ull << __IMG_TYPE_SHIFT),
+			
+			// sets: -------- 000000xx -------- 00000--- 00000000 00000000 00000000 00000000
+			__IMG_ACCESS_SHIFT			= (48ull),
+			__IMG_ACCESS_MASK			= (0x0003000000000000ull),
+			IMG_ACCESS_READ				= (1ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_WRITE			= (2ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_READ_WRITE		= (IMG_ACCESS_READ | IMG_ACCESS_WRITE),
+			
+			// sets: xxxxxxxx 000000-- -------- 00000--- 00000000 00000000 00000000 00000000
+			__SPECIAL_TYPE_SHIFT		= (56ull),
+			__SPECIAL_TYPE_MASK			= (0xFF00000000000000ull),
+			STAGE_INPUT					= (1ull << __SPECIAL_TYPE_SHIFT),
+			PUSH_CONSTANT				= (2ull << __SPECIAL_TYPE_SHIFT),
+			SSBO						= (3ull << __SPECIAL_TYPE_SHIFT),
+			IMAGE_ARRAY					= (4ull << __SPECIAL_TYPE_SHIFT),
+		};
+		static const auto to_fas = [](const unsigned& addr_space) {
+			if(addr_space == LangAS::opencl_global) {
+				return FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			else if(addr_space == LangAS::opencl_local) {
+				return FLOOR_ARG_INFO::AS_LOCAL;
+			}
+			else if(addr_space == LangAS::opencl_constant) {
+				return FLOOR_ARG_INFO::AS_CONSTANT;
+			}
+			return FLOOR_ARG_INFO::AS_NONE;
+		};
+		
+		const auto compute_type_size = [this, &parm, &Fn](llvm::Type* type) {
+			if(!type->isSized()) {
+				auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "%0");
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), err_diagID) << "parameter uses a type with an unknown size (NOTE: this can happen when internal vector/array type conversion/replacement has failed)";
+				
+				auto param_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM type: %0");
+				std::string param_type = "";
+				llvm::raw_string_ostream param_type_stream(param_type);
+				type->print(param_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), param_note_diagID) << param_type_stream.str();
+				
+				auto func_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+				std::string fun_type = "";
+				llvm::raw_string_ostream fun_type_stream(fun_type);
+				Fn->getFunctionType()->print(fun_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), func_note_diagID) << fun_type_stream.str();
+				
+				return uint64_t(0);
+			}
+			return CGM.getDataLayout().getTypeStoreSize(type);
+		};
+		
+		static const auto get_image_access = [](const ImageAccessAttr* access_attr) {
+			if(access_attr != nullptr) {
+				if(access_attr->isWriteOnly()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_WRITE;
+				}
+				else if(access_attr->isReadWrite()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE;
+				}
+			}
+			return FLOOR_ARG_INFO::IMG_ACCESS_READ;
+		};
+		static const auto img_type_to_floor_type = [](const clang::Type* type) {
+			const auto builtin_type = type->getAs<BuiltinType>();
+			if(!builtin_type) {
+				return (FLOOR_ARG_INFO)~0ull;
+			}
+			switch(builtin_type->getKind()) {
+				case BuiltinType::OCLImage1d:
+					return FLOOR_ARG_INFO::IMG_1D;
+				case BuiltinType::OCLImage1dArray:
+					return FLOOR_ARG_INFO::IMG_1D_ARRAY;
+				case BuiltinType::OCLImage1dBuffer:
+					return FLOOR_ARG_INFO::IMG_1D_BUFFER;
+				case BuiltinType::OCLImage2d:
+					return FLOOR_ARG_INFO::IMG_2D;
+				case BuiltinType::OCLImage2dArray:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY;
+				case BuiltinType::OCLImage2dDepth:
+					return FLOOR_ARG_INFO::IMG_2D_DEPTH;
+				case BuiltinType::OCLImage2dArrayDepth:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_DEPTH;
+				case BuiltinType::OCLImage2dMSAA:
+					return FLOOR_ARG_INFO::IMG_2D_MSAA;
+				case BuiltinType::OCLImage2dArrayMSAA:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA;
+				case BuiltinType::OCLImage2dMSAADepth:
+					return FLOOR_ARG_INFO::IMG_2D_MSAA_DEPTH;
+				case BuiltinType::OCLImage2dArrayMSAADepth:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA_DEPTH;
+				case BuiltinType::OCLImage3d:
+					return FLOOR_ARG_INFO::IMG_3D;
+				case BuiltinType::OCLImageCube:
+					return FLOOR_ARG_INFO::IMG_CUBE;
+				case BuiltinType::OCLImageCubeArray:
+					return FLOOR_ARG_INFO::IMG_CUBE_ARRAY;
+				case BuiltinType::OCLImageCubeDepth:
+					return FLOOR_ARG_INFO::IMG_CUBE_DEPTH;
+				case BuiltinType::OCLImageCubeArrayDepth:
+					return FLOOR_ARG_INFO::IMG_CUBE_ARRAY_DEPTH;
+				default: break;
+			}
+			return (FLOOR_ARG_INFO)~0ull;
+		};
+ 		const auto add_image_arg = [this, &info](const FLOOR_ARG_INFO& floor_img_type,
+ 												 const FLOOR_ARG_INFO& access,
+												 const uint32_t elem_count = 1) {
+			uint64_t arg_info = uint64_t(FLOOR_ARG_INFO::AS_IMAGE);
+			arg_info |= uint64_t(floor_img_type);
+			arg_info |= uint64_t(access);
+			if(elem_count > 1) {
+				arg_info |= elem_count;
+				arg_info |= uint64_t(FLOOR_ARG_INFO::IMAGE_ARRAY);
+			}
+			info << arg_info << ",";
+		};
+		// anything that isn't a pointer or special type
+		const auto add_normal_arg = [this, &info,
+									 &compute_type_size](llvm::Type* llvm_type,
+														 const clang::QualType& clang_type,
+														 const FLOOR_ARG_INFO init_info = FLOOR_ARG_INFO::NONE) {
+			// for now: just use the direct type size + no address space
+			uint64_t arg_info = (uint64_t)init_info;
+			// handle some llvm weirdness? why can this be a pointer still?
+			if(llvm_type->isPointerTy()) {
+				arg_info |= compute_type_size(llvm_type->getPointerElementType());
+			}
+			else {
+				arg_info |= compute_type_size(llvm_type);
+			}
+			arg_info |= (uint64_t)to_fas(clang_type.getAddressSpace());
+			info << arg_info << ",";
+		};
+		
+		// #2+: argument sizes + types
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			uint64_t arg_info = compute_type_size(pointee_type);
+			if(getLangOpts().OpenCL) {
+				arg_info |= (uint64_t)to_fas(clang_pointee_type.getAddressSpace());
+			}
+			else if(getLangOpts().CUDA) {
+				// always pretend this is global
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			if(getLangOpts().Vulkan) {
+				// NOTE: only using global& for const parameters (aka uniforms) right now,
+				//       if this should change, this must also be modified
+				//       -> global pointer must always be a SSBO
+				if(!clang_type->isReferenceType() &&
+				   clang_pointee_type.getAddressSpace() == LangAS::opencl_global) {
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::SSBO;
+				}
+			}
+			info << arg_info << ",";
+		}
+		// handle image types
+		else if(clang_type->isImageType()) {
+			add_image_arg(img_type_to_floor_type(clang_type.getTypePtr()),
+						  get_image_access(parm->getAttr<ImageAccessAttr>()));
+		}
+		// image array (std::array<*image_*<type>, extent>)
+		// NOTE: check before "isAggregateImageType()", because this is essentially a sub-type of it
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, getContext());
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(img_type_to_floor_type(array_image_info.first->getType().getTypePtr()),
+							  get_image_access(array_image_info.first->getAttr<ImageAccessAttr>()),
+							  array_image_info.second);
+			}
+			else {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image array!"));
+				return;
+			}
+		}
+		// image array (image*_t[N])
+		else if(!getLangOpts().CUDA && clang_type->isArrayImageType(false)) {
+			CGM.Error(parm->getSourceRange().getBegin(), StringRef("C array of images not supported yet"));
+			return;
+		}
+		// aggregate of image types (used with opencl/metal/vulkan)
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			// image count must either be 1 (for single read or write images) or 2 (one read, one write image)
+			const auto field_count = agg_images.size();
+			if(field_count == 0) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("no images in aggregate-image (min: 1)"));
+				return;
+			}
+			else if(field_count > 2) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("too many images in aggregate-image (max: 2)"));
+				return;
+			}
+			
+			// sanity check that all field types are actually images, have proper access attributes and image types match
+			// (should probably put this somewhere else, since it is sema-checking, but then I'd need to duplicate code)
+			FLOOR_ARG_INFO floor_img_type = FLOOR_ARG_INFO::NONE;
+			uint64_t floor_img_access = 0;
+			for(const auto& img : agg_images) {
+				const auto access_attr = img->getAttr<ImageAccessAttr>();
+				if(access_attr == nullptr) {
+					CGM.Error(img->getSourceRange().getBegin(),
+							  StringRef("image type in an aggregate-image must have an access qualifier"));
+					return;
+				}
+				floor_img_access |= uint64_t(get_image_access(access_attr));
+				
+				// first field initializes this
+				auto img_type = img->getType();
+				if(img_type->isArrayImageType(false)) {
+					// get element image type if this is an array
+					if(img_type->isPointerType()) {
+						img_type = img_type->getPointeeType();
+					}
+					img_type = img_type->getAsArrayTypeUnsafe()->getElementType();
+				}
+				if(floor_img_type == FLOOR_ARG_INFO::NONE) {
+					floor_img_type = img_type_to_floor_type(img_type.getTypePtr());
+				}
+				else {
+					// second field must have the same type!
+					if(floor_img_type != img_type_to_floor_type(img_type.getTypePtr())) {
+						CGM.Error(img->getSourceRange().getBegin(),
+								  StringRef("second image in aggregate-image does not have the same type as the first"));
+						return;
+					}
+				}
+			}
+			
+			// if the aggregate has two image objects, one must be read, one must be write -> read/write
+			if(field_count == 2 && floor_img_access != uint64_t(FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE)) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("aggregate-image has 2 image fields, but joint access is not read-write"));
+				return;
+			}
+			
+			// everything works out, add this as a single kernel argument (floor backends will handle r/w images as necessary)
+			// NOTE: for aggregate images that contain an array of images we still only count this as one image,
+			//       since this is behind-the-scenes stuff and not part of the user interface!
+			add_image_arg(floor_img_type, (FLOOR_ARG_INFO)floor_img_access);
+			
+			// 1 clang aggregate-image == 2 llvm image types -> inc index once more
+			if(field_count == 2) ++arg_idx;
+		}
+		// handle non-pointer parameters
+		else if(getLangOpts().CUDA) {
+			// is this an aggregate that is expanded into multiple llvm arguments?
+			if(cxx_rdecl &&
+			   (abi_arg_info_iter->info.isDirect() || abi_arg_info_iter->info.isIndirect()) &&
+			   TargetCodeGenInfo::isAggregateTypeForABI(abi_arg_info_iter->type)) {
+				// check if this is an aggregate image (must have image access qualifiers)
+				const ImageAccessAttr* access_attr = get_aggregate_access_attr(cxx_rdecl);
+				if(access_attr != nullptr) {
+					uint64_t arg_info = 0; // size is irrelevant for cuda images
+					arg_info |= uint64_t(get_image_access(access_attr));
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_IMAGE;
+					info << arg_info << ",";
+				}
+				else if(abi_arg_info_iter->info.isDirect()) {
+					// simple aggregate, all constant -> must handle each field individually
+					// note that we're only interested in the first expanded layer, not multiple expansion
+					// (i.e. fully scalarized), as this is identical to what cuda / nvptx / the abi do
+					uint64_t arg_info = 0; // sizes will be accumulated
+					const auto fields = get_aggregate_fields(cxx_rdecl);
+					for(size_t i = 0; i < fields.size(); ++i) {
+						const auto field_llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+						arg_info += compute_type_size(field_llvm_type);
+						++arg_idx;
+					}
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+					info << arg_info << ",";
+					--arg_idx; // fixup, b/c of inc later
+				}
+				else { // -> indirect
+					// simple aggregate, all constant -> single pointer on either side of clang/llvm
+					uint64_t arg_info = 0;
+					arg_info |= compute_type_size(llvm_type->getPointerElementType());
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+					info << arg_info << ",";
+				}
+			}
+			else {
+				// -> this is a simple constant (scalar or aggregate with scalar eval)
+				// store the parameter size
+				uint64_t arg_info = compute_type_size(llvm_type);
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+				info << arg_info << ",";
+			}
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(!is_vertex && !is_fragment) {
+				// TODO: should check this in sema
+				// TODO: should also make sure that only 1 exists
+				CGM.Error(FD->getSourceRange().getBegin(), "[[stage_input]] only allowed on vertex and fragment functions");
+			}
+			
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					// TODO: check if field type is int or float!
+					const auto field_llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+					add_normal_arg(field_llvm_type, field.type, FLOOR_ARG_INFO::STAGE_INPUT);
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// add as-is
+				// TODO: check if type is int or float!
+				add_normal_arg(llvm_type, clang_type, FLOOR_ARG_INFO::STAGE_INPUT);
+			}
+		}
+		else {
+			add_normal_arg(llvm_type, clang_type);
+		}
+		
+		// next arg
+		++arg_idx;
+		++abi_arg_info_iter;
+	}
+	
+	info << "\n";
+	file << info.str();
+	
+#if 0 // for debugging purposes
+	printf("floor function info: %s", info.str().c_str()); fflush(stdout);
+#endif
+	
+	// if this is wrong, the kernel will almost certainly not be usable
+	if(arg_idx != Fn->arg_size()) {
+		// signal that this is _very_ bad
+		auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "kernel function parameter count mismatch: %0 (clang), %1 (llvm)");
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), err_diagID) << std::to_string(arg_idx) << std::to_string(Fn->arg_size());
+		
+		auto llvm_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+		std::string llvm_fun_type = "";
+		llvm::raw_string_ostream llvm_fun_type_stream(llvm_fun_type);
+		Fn->getFunctionType()->print(llvm_fun_type_stream);
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), llvm_note_diagID) << llvm_fun_type_stream.str();
+		
+		auto clang_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "clang function type: %0");
+		std::string clang_fun_type = "";
+		llvm::raw_string_ostream clang_fun_type_stream(clang_fun_type);
+		FD->getType().print(clang_fun_type_stream, Policy);
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), clang_note_diagID) << clang_fun_type_stream.str();
+		return;
+	}
 }
 
 void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
-                                               llvm::Function *Fn)
+                                               llvm::Function *Fn,
+                                               const CGFunctionInfo &FnInfo)
 {
-  if (!FD->hasAttr<OpenCLKernelAttr>())
+  if (!FD->hasAttr<ComputeKernelAttr>() &&
+	  !FD->hasAttr<GraphicsVertexShaderAttr>() &&
+	  !FD->hasAttr<GraphicsFragmentShaderAttr>())
     return;
 
   llvm::LLVMContext &Context = getLLVMContext();
 
-  GenOpenCLArgMetadata(FD, Fn, CGM, Context, Builder, getContext());
+  SmallVector<llvm::Metadata *, 5> kernelMDArgs;
+  if (CGM.getLangOpts().Metal || CGM.getLangOpts().Vulkan) {
+	  // -> need to id/size handling args to the kernel function type
+	  // add original arg types
+	  SmallVector<llvm::Type*, 16> arg_types;
+	  for(const auto& arg : Fn->args()) {
+		  arg_types.push_back(arg.getType());
+	  }
+	  
+	  // NOTE: metal and vulkan handle these differently (metal: usually direct params, vulkan: usually pointers)
+	  if(CGM.getLangOpts().Metal) {
+		  if(FD->hasAttr<ComputeKernelAttr>()) {
+			  // add id types
+			  const auto id_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(Context), 3);
+			  for(int i = 0; i < 6; ++i) arg_types.push_back(id_vec_type);
+		  }
+		  else if(FD->hasAttr<GraphicsVertexShaderAttr>()) {
+			  // only vertex id for now
+			  arg_types.push_back(llvm::Type::getInt32Ty(Context));
+		  }
+		  else if(FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+			  // only point coord for now
+			  const auto pc_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(Context), 2);
+			  arg_types.push_back(pc_vec_type);
+		  }
+	  }
+	  else if(CGM.getLangOpts().Vulkan) {
+		  if(FD->hasAttr<ComputeKernelAttr>()) {
+			  // add id types
+			  const auto id_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(Context), 3)->getPointerTo();
+			  for(int i = 0; i < 4; ++i) arg_types.push_back(id_vec_type);
+		  }
+		  else if(FD->hasAttr<GraphicsVertexShaderAttr>()) {
+			  // only vertex id for now
+			  arg_types.push_back(llvm::Type::getInt32PtrTy(Context));
+		  }
+		  else if(FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+			  // only point + frag coord for now
+			  const auto pc_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(Context), 2)->getPointerTo();
+			  arg_types.push_back(pc_vec_type);
+			  const auto fc_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(Context), 4)->getPointerTo();
+			  arg_types.push_back(fc_vec_type);
+		  }
+	  }
+	  
+	  // create + add new function type
+	  const auto func_type_with_ids = llvm::FunctionType::get(Fn->getReturnType(), arg_types, false);
+	  Fn->mutateType(llvm::PointerType::get(func_type_with_ids, 0));
+	  Fn->mutateFunctionType(func_type_with_ids);
+  }
+  kernelMDArgs.push_back(llvm::ConstantAsMetadata::get(Fn));
+
+  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata)
+    GenOpenCLArgMetadata(FD, Fn, CGM, Context, kernelMDArgs, Builder,
+                         getContext());
+
+  if (CGM.getLangOpts().Metal)
+    GenAIRMetadata(FD, Fn, FnInfo, CGM, Context, kernelMDArgs, Builder, getContext());
+
+  if (CGM.getLangOpts().Vulkan)
+    GenVulkanMetadata(FD, Fn, CGM, Context, Builder, getContext());
 
   if (const VecTypeHintAttr *A = FD->getAttr<VecTypeHintAttr>()) {
     QualType hintQTy = A->getTypeHint();
     const ExtVectorType *hintEltQTy = hintQTy->getAs<ExtVectorType>();
-    bool isSignedInteger =
+    bool isSignedType =
         hintQTy->isSignedIntegerType() ||
-        (hintEltQTy && hintEltQTy->getElementType()->isSignedIntegerType());
+        (hintEltQTy && hintEltQTy->getElementType()->isSignedIntegerType()) ||
+        hintQTy->isFloatingType() ||
+        (hintEltQTy && hintEltQTy->getElementType()->isFloatingType());
     llvm::Metadata *attrMDArgs[] = {
         llvm::ConstantAsMetadata::get(llvm::UndefValue::get(
             CGM.getTypes().ConvertType(A->getTypeHint()))),
         llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
             llvm::IntegerType::get(Context, 32),
-            llvm::APInt(32, (uint64_t)(isSignedInteger ? 1 : 0))))};
-    Fn->setMetadata("vec_type_hint", llvm::MDNode::get(Context, attrMDArgs));
+            llvm::APInt(32, (uint64_t)(isSignedType ? 1 : 0))))};
+    kernelMDArgs.push_back(llvm::MDNode::get(Context, attrMDArgs));
   }
 
   if (const WorkGroupSizeHintAttr *A = FD->getAttr<WorkGroupSizeHintAttr>()) {
@@ -632,6 +2233,54 @@ void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
         llvm::ConstantAsMetadata::get(Builder.getInt32(A->getZDim()))};
     Fn->setMetadata("reqd_work_group_size", llvm::MDNode::get(Context, attrMDArgs));
   }
+
+  llvm::MDNode *kernelMDNode = llvm::MDNode::get(Context, kernelMDArgs);
+  llvm::NamedMDNode *MainMetadataNode;
+  if(!CGM.getLangOpts().Metal) {
+	  MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata("opencl.kernels");
+  }
+  else {
+    MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata(
+      (FD->hasAttr<GraphicsVertexShaderAttr>() ? "air.vertex" :
+       (FD->hasAttr<GraphicsFragmentShaderAttr>() ? "air.fragment" : "air.kernel")));
+  }
+  MainMetadataNode->addOperand(kernelMDNode);
+
+  // additional air info
+  if(CGM.getLangOpts().Metal) {
+	  // only do this once
+	  llvm::NamedMDNode *AIRVersion = CGM.getModule().getOrInsertNamedMetadata("air.version");
+	  if(AIRVersion->getNumOperands() > 0) return;
+	  
+	  // NOTE: this is fixed for now as only compiling in metal1.1 mode is possible
+	  const uint32_t metal_version[] = { 1, 8, 0 };
+	  const uint32_t metal_language_version[] = { 1, 1, 0 };
+	  
+	  SmallVector <llvm::Metadata*, 3> air_version;
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[0])));
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[1])));
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[2])));
+	  AIRVersion->addOperand(llvm::MDNode::get(Context, air_version));
+	  
+	  llvm::NamedMDNode *AIRLangVersion = CGM.getModule().getOrInsertNamedMetadata("air.language_version");
+	  SmallVector <llvm::Metadata*, 4> air_lang_version;
+	  air_lang_version.push_back(llvm::MDString::get(Context, "Metal"));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[0])));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[1])));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[2])));
+	  AIRLangVersion->addOperand(llvm::MDNode::get(Context, air_lang_version));
+	  
+	  llvm::NamedMDNode *AIRCompOpts = CGM.getModule().getOrInsertNamedMetadata("air.compile_options");
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.denorms_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.fast_math_enable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.framebuffer_fetch_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.native_double_disable")));
+  }
+  // NOTE: additional/global opencl metadata is handled in CGSPIRMetadataAdder
 }
 
 /// Determine whether the function F ends with a return stmt.
@@ -661,6 +2310,7 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
          "Do not use a CodeGenFunction object for more than one function");
 
   const Decl *D = GD.getDecl();
+  const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D);
 
   DidCallStackSave = false;
   CurCodeDecl = D;
@@ -711,7 +2361,7 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   // attribute to all functions that are not marked AlwaysInline, or
   // to all functions that are not marked inline or implicitly inline
   // in the case of -finline-hint-functions.
-  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D)) {
+  if (FD) {
     const CodeGenOptions& CodeGenOpts = CGM.getCodeGenOpts();
     if (!CodeGenOpts.NoInline) {
       for (auto RI : FD->redecls())
@@ -732,16 +2382,24 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   Fn->addFnAttr("no-jump-tables",
                 llvm::toStringRef(CGM.getCodeGenOpts().NoUseJumpTables));
 
-  if (getLangOpts().OpenCL) {
-    // Add metadata for a kernel function.
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
-      EmitOpenCLKernelMetadata(FD, Fn);
+  // emit compute metadata
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
+    if(FD) {
+      // add floor specific metadata for kernel functions
+      EmitFloorKernelMetadata(FD, Fn, Args, FnInfo);
+    }
+    
+    // opencl/spir, metal and vulkan specific metadata
+    if (getLangOpts().OpenCL) {
+      // Add metadata for a kernel function.
+      EmitOpenCLKernelMetadata(FD, Fn, FnInfo);
+    }
   }
 
   // If we are checking function types, emit a function type signature as
   // prologue data.
   if (getLangOpts().CPlusPlus && SanOpts.has(SanitizerKind::Function)) {
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D)) {
+    if (FD) {
       if (llvm::Constant *PrologueSig =
               CGM.getTargetCodeGenInfo().getUBSanFunctionSignature(CGM)) {
         llvm::Constant *FTRTTIConst =
@@ -758,7 +2416,7 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   // to be norecurse by the standard (3.6.1.3 "The function main shall not be
   // used within a program").
   if (getLangOpts().CPlusPlus)
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
+    if (FD)
       if (FD->isMain())
         Fn->addFnAttr(llvm::Attribute::NoRecurse);
   
@@ -822,7 +2480,16 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
     Addr = Builder.CreateAlignedLoad(Addr, getPointerAlign(), "agg.result");
     ReturnValue = Address(Addr, getNaturalTypeAlignment(RetTy));
   } else {
-    ReturnValue = CreateIRTemp(RetTy, "retval");
+    // fix retval allocation for vertex/fragment shader return values (use the computed coerce type)
+    if(FD &&
+       (FD->hasAttr<GraphicsVertexShaderAttr>() ||
+        FD->hasAttr<GraphicsFragmentShaderAttr>())) {
+      auto RetAlloc = CreateTempAlloca(FnInfo.getReturnInfo().getCoerceToType(), "retval");
+      CharUnits Align = getContext().getTypeAlignInChars(RetTy);
+      RetAlloc->setAlignment(Align.getQuantity());
+      ReturnValue = Address(RetAlloc, Align);
+    }
+    else ReturnValue = CreateIRTemp(RetTy, "retval");
 
     // Tell the epilog emitter to autorelease the result.  We do this
     // now so that various specialized functions can suppress it
@@ -864,11 +2531,11 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
               EmitLoadOfLValue(ThisFieldLValue, SourceLocation()).getScalarVal();
         }
       }
-      for (auto *FD : MD->getParent()->fields()) {
-        if (FD->hasCapturedVLAType()) {
-          auto *ExprArg = EmitLoadOfLValue(EmitLValueForLambdaField(FD),
+      for (auto *field : MD->getParent()->fields()) {
+        if (field->hasCapturedVLAType()) {
+          auto *ExprArg = EmitLoadOfLValue(EmitLValueForLambdaField(field),
                                            SourceLocation()).getScalarVal();
-          auto VAT = FD->getCapturedVLAType();
+          auto VAT = field->getCapturedVLAType();
           VLASizeMap[VAT->getSizeExpr()] = ExprArg;
         }
       }
@@ -1034,7 +2701,7 @@ void CodeGenFunction::GenerateCode(GlobalDecl GD, llvm::Function *Fn,
     EmitConstructorBody(Args);
   else if (getLangOpts().CUDA &&
            !getLangOpts().CUDAIsDevice &&
-           FD->hasAttr<CUDAGlobalAttr>())
+           FD->hasAttr<ComputeKernelAttr>())
     CGM.getCUDARuntime().emitDeviceStub(*this, Args);
   else if (isa<CXXConversionDecl>(FD) &&
            cast<CXXConversionDecl>(FD)->isLambdaToBlockPointerConversion()) {
diff --git a/lib/CodeGen/CodeGenFunction.h b/lib/CodeGen/CodeGenFunction.h
index bb04371..ed21d18 100644
--- a/lib/CodeGen/CodeGenFunction.h
+++ b/lib/CodeGen/CodeGenFunction.h
@@ -1186,8 +1186,14 @@ private:
   /// - A node for the reqd_work_group_size(X,Y,Z) qualifier contains string 
   ///   "reqd_work_group_size", and three 32-bit integers X, Y and Z.
   void EmitOpenCLKernelMetadata(const FunctionDecl *FD, 
-                                llvm::Function *Fn);
-
+                                llvm::Function *Fn,
+                                const CGFunctionInfo &FnInfo);
+
+  void EmitFloorKernelMetadata(const FunctionDecl *FD,
+                               llvm::Function *Fn,
+                               const FunctionArgList &Args,
+                               const CGFunctionInfo &FnInfo);
+	
 public:
   CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);
   ~CodeGenFunction();
@@ -1341,6 +1347,11 @@ public:
                                         const DeclMapTy &ldm,
                                         bool IsLambdaConversionToBlock);
 
+  llvm::Value *GenerateOCLBlockBind(llvm::Constant *blockFunc,
+                                    int ctxSize,
+                                    int ctxAlign,
+                                    llvm::Value *ctx);
+
   llvm::Constant *GenerateCopyHelperFunction(const CGBlockInfo &blockInfo);
   llvm::Constant *GenerateDestroyHelperFunction(const CGBlockInfo &blockInfo);
   llvm::Constant *GenerateObjCAtomicSetterCopyHelperFunction(
@@ -3263,14 +3274,16 @@ private:
   ///
   /// \param AI - The first function argument of the expansion.
   void ExpandTypeFromArgs(QualType Ty, LValue Dst,
-                          SmallVectorImpl<llvm::Value *>::iterator &AI);
+                          SmallVectorImpl<llvm::Value *>::iterator &AI,
+                          const CallingConv CC);
 
   /// ExpandTypeToArgs - Expand an RValue \arg RV, with the LLVM type for \arg
   /// Ty, into individual arguments on the provided vector \arg IRCallArgs,
   /// starting at index \arg IRCallArgPos. See ABIArgInfo::Expand.
   void ExpandTypeToArgs(QualType Ty, RValue RV, llvm::FunctionType *IRFuncTy,
                         SmallVectorImpl<llvm::Value *> &IRCallArgs,
-                        unsigned &IRCallArgPos);
+                        unsigned &IRCallArgPos,
+                        const CallingConv CC);
 
   llvm::Value* EmitAsmInput(const TargetInfo::ConstraintInfo &Info,
                             const Expr *InputExpr, std::string &ConstraintStr);
diff --git a/lib/CodeGen/CodeGenModule.cpp b/lib/CodeGen/CodeGenModule.cpp
index 1d74e4c..4b890c4 100644
--- a/lib/CodeGen/CodeGenModule.cpp
+++ b/lib/CodeGen/CodeGenModule.cpp
@@ -19,6 +19,7 @@
 #include "CGDebugInfo.h"
 #include "CGObjCRuntime.h"
 #include "CGOpenCLRuntime.h"
+#include "CGSPIRMetadataAdder.h"
 #include "CGOpenMPRuntime.h"
 #include "CGOpenMPRuntimeNVPTX.h"
 #include "CodeGenFunction.h"
@@ -447,7 +448,10 @@ void CodeGenModule::Release() {
     // parser will drop debug info with a different version number
     // (and warn about it, too).
     getModule().addModuleFlag(llvm::Module::Warning, "Debug Info Version",
-                              llvm::DEBUG_METADATA_VERSION);
+                              Context.getTargetInfo().getTriple().getOS() != llvm::Triple::IOS ?
+                              llvm::DEBUG_METADATA_VERSION :
+                              // metal/ios uses/requires a very specific metadata version number
+                              llvm::IOS_METAL_DEBUG_METADATA_VERSION);
 
   // We need to record the widths of enums and wchar_t, so that we can generate
   // the correct build attributes in the ARM backend.
@@ -488,6 +492,9 @@ void CodeGenModule::Release() {
 
   SimplifyPersonality();
 
+  if (getLangOpts().OpenCL && !getLangOpts().Metal)
+    EmitOCLAnnotations();
+
   if (getCodeGenOpts().EmitDeclMetadata)
     EmitDeclMetadata();
 
@@ -497,6 +504,33 @@ void CodeGenModule::Release() {
   if (DebugInfo)
     DebugInfo->finalize();
 
+  const llvm::Triple TT(TheModule.getTargetTriple());
+  if (TT.getArch() == llvm::Triple::ArchType::spir ||
+      TT.getArch() == llvm::Triple::ArchType::spir64) {
+    std::list<std::string> sBuildOptions;
+    std::string tmp = getCodeGenOpts().SPIRCompileOptions;
+    while (!tmp.empty()) {
+      auto first = tmp.find_first_not_of(' ');
+      auto last = tmp.find_first_of(' ', first);
+
+      std::string s;
+      if (last != std::string::npos)
+        s = tmp.substr(first, last-first);
+      else if (first != std::string::npos)
+        s = tmp.substr(first);
+      else
+        s = "";
+
+      if (!s.empty())
+        sBuildOptions.push_back(s);
+
+      if (last != std::string::npos)
+        tmp = tmp.substr(last);
+      else
+        tmp = "";
+    }
+    AddSPIRMetadata(TheModule, getLangOpts().OpenCLVersion, sBuildOptions, getContext().OpenCLFeatures);
+  }
   EmitVersionIdentMetadata();
 
   EmitTargetMetadata();
@@ -1340,6 +1374,108 @@ void CodeGenModule::EmitGlobalAnnotations() {
   gv->setSection(AnnotationSection);
 }
 
+void CodeGenModule::EmitOCLAnnotations() {
+  // For SPIR, we generate this metadata in a seperate pass
+  if (getTarget().getTriple().getArch() != llvm::Triple::spir &&
+      getTarget().getTriple().getArch() != llvm::Triple::spir64)
+    EmitOCLBuildOptions();
+
+  if (!Context.isFPContractDisabled() && (0 != getLangOpts().DefaultFPContract))
+  {
+    TheModule.getOrInsertNamedMetadata("opencl.enable.FP_CONTRACT");
+  }
+}
+
+llvm::SmallVector<llvm::Metadata *, 5> CodeGenModule::getBuildOptions() {
+  llvm::SmallVector<llvm::Metadata *, 5> BuildOption;
+
+  if(!getLangOpts().OpenCL)
+    return BuildOption;
+
+  // Math Intrinsics Options
+  if(getLangOpts().SinglePrecisionConstants)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-single-precision-constant")));
+
+  if(getCodeGenOpts().DenormsAreZero)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-denorms-are-zero")));
+
+  if(getCodeGenOpts().CorrectFPDivideSqrt)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-fp32-correctly-rounded-divide-sqrt")));
+
+  //Optimization Options
+  if(getCodeGenOpts().OptDisable)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-opt-disable")));
+
+  if(getCodeGenOpts().LessPreciseFPMAD)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-mad-enable")));
+
+  if(getCodeGenOpts().NoSignedZeros)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-no-signed-zeros")));
+
+  if(getCodeGenOpts().UnsafeFPMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-unsafe-math-optimizations")));
+
+  if(getCodeGenOpts().NoInfsFPMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-finite-math-only")));
+
+  if(getLangOpts().FastRelaxedMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-fast-relaxed-math")));
+
+  if(getCodeGenOpts().getDebugInfo() != codegenoptions::NoDebugInfo)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-g")));
+
+  //Options Controlling the OpenCL C version
+  if(110 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL1.1")));
+
+  if(120 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL1.2")));
+
+  if(200 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.0")));
+
+  if(210 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.1")));
+
+  if(220 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.2")));
+
+  // Options for Querying Kernel Argument Information
+  if(getCodeGenOpts().EmitOpenCLArgMetadata)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-kernel-arg-info")));
+
+  return BuildOption;
+}
+
+void CodeGenModule::EmitOCLBuildOptions()
+{
+  llvm::SmallVector<llvm::Metadata *, 5> BuildOptions = getBuildOptions();
+
+  if (BuildOptions.empty())
+    return;
+
+  llvm::NamedMDNode *OpenCLMetadata =
+    TheModule.getOrInsertNamedMetadata("opencl.compiler.options");
+
+  OpenCLMetadata->addOperand(llvm::MDNode::get(VMContext, BuildOptions));
+}
+
 llvm::Constant *CodeGenModule::EmitAnnotationString(StringRef Str) {
   llvm::Constant *&AStr = AnnotationStrings[Str];
   if (AStr)
@@ -1548,30 +1684,6 @@ void CodeGenModule::EmitGlobal(GlobalDecl GD) {
   if (Global->hasAttr<IFuncAttr>())
     return emitIFuncDefinition(GD);
 
-  // If this is CUDA, be selective about which declarations we emit.
-  if (LangOpts.CUDA) {
-    if (LangOpts.CUDAIsDevice) {
-      if (!Global->hasAttr<CUDADeviceAttr>() &&
-          !Global->hasAttr<CUDAGlobalAttr>() &&
-          !Global->hasAttr<CUDAConstantAttr>() &&
-          !Global->hasAttr<CUDASharedAttr>())
-        return;
-    } else {
-      // We need to emit host-side 'shadows' for all global
-      // device-side variables because the CUDA runtime needs their
-      // size and host-side address in order to provide access to
-      // their device-side incarnations.
-
-      // So device-only functions are the only things we skip.
-      if (isa<FunctionDecl>(Global) && !Global->hasAttr<CUDAHostAttr>() &&
-          Global->hasAttr<CUDADeviceAttr>())
-        return;
-
-      assert((isa<FunctionDecl>(Global) || isa<VarDecl>(Global)) &&
-             "Expected Variable or Function");
-    }
-  }
-
   if (LangOpts.OpenMP) {
     // If this is OpenMP device, check if it is legal to emit this global
     // normally.
@@ -2545,7 +2657,12 @@ void CodeGenModule::EmitGlobalVarDefinition(const VarDecl *D,
         Linkage = llvm::GlobalValue::InternalLinkage;
     }
   }
-  GV->setInitializer(Init);
+  if (LangOpts.OpenCL && D->getType()->isBlockPointerType()) {
+    GV->eraseFromParent();
+    OCLGlobalBlockFunctions[D] = Init;
+    return;
+  } else
+    GV->setInitializer(Init);
 
   // If it is safe to mark the global 'constant', do so now.
   GV->setConstant(!NeedsGlobalCtor && !NeedsGlobalDtor &&
@@ -2708,8 +2825,8 @@ llvm::GlobalValue::LinkageTypes CodeGenModule::getLLVMLinkageForDeclarator(
     if (Context.getLangOpts().AppleKext)
       return llvm::Function::ExternalLinkage;
     if (Context.getLangOpts().CUDA && Context.getLangOpts().CUDAIsDevice)
-      return D->hasAttr<CUDAGlobalAttr>() ? llvm::Function::ExternalLinkage
-                                          : llvm::Function::InternalLinkage;
+      return D->hasAttr<ComputeKernelAttr>() ? llvm::Function::ExternalLinkage
+                                             : llvm::Function::InternalLinkage;
     return llvm::Function::WeakODRLinkage;
   }
 
@@ -2881,6 +2998,34 @@ void CodeGenModule::HandleCXXStaticMemberVarInstantiation(VarDecl *VD) {
   EmitTopLevelDecl(VD);
 }
 
+static llvm::Type* GraphicsExpandReturnType(const CanQualType& type,
+                                            llvm::Type* llvm_type,
+                                            CodeGenTypes& CGT) {
+	const llvm::StructType* ST = dyn_cast<llvm::StructType>(llvm_type);
+	if(!ST) return llvm_type;
+	
+	const auto cxx_rdecl = type->getAsCXXRecordDecl();
+	
+	// if the top decl already is a compat vector, return it directly
+	if(cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+		return CGT.ConvertType(CGT.get_compat_vector_type(cxx_rdecl));
+	}
+	
+	// else: extract all fields and create a flat llvm struct from them
+	const auto fields = CGT.get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+	std::vector<llvm::Type*> llvm_fields;
+	for(const auto& field : fields) {
+		llvm_fields.push_back(CGT.ConvertType(field.type));
+	}
+	
+	// TODO: only create once?
+	const std::string name = "struct.floor.flat." + cxx_rdecl->getName().str() + ".packed";
+	auto ret = llvm::StructType::create(llvm_fields, name, true); // always make this packed
+	ret->setGraphicsReturnType(); // fix up alignment/sizes/offsets
+	CGT.create_flattened_cg_layout(cxx_rdecl, ret, fields); // create corresponding flattend CGRecordLayout
+	return ret;
+}
+
 void CodeGenModule::EmitGlobalFunctionDefinition(GlobalDecl GD,
                                                  llvm::GlobalValue *GV) {
   const auto *D = cast<FunctionDecl>(GD.getDecl());
@@ -2914,6 +3059,15 @@ void CodeGenModule::EmitGlobalFunctionDefinition(GlobalDecl GD,
 
   // Compute the function info and LLVM type.
   const CGFunctionInfo &FI = getTypes().arrangeGlobalDeclaration(GD);
+  if((getLangOpts().Metal || getLangOpts().Vulkan) && D &&
+     FI.getReturnType()->isStructureOrClassType() &&
+     (D->hasAttr<GraphicsVertexShaderAttr>() ||
+      D->hasAttr<GraphicsFragmentShaderAttr>())) {
+    // if this is a vertex/fragment shader function and the return type is a struct/aggregate,
+    // fully expand/flatten all types within (i.e. structs and arrays to scalars, keep existing scalars)
+    auto& retInfo = (ABIArgInfo&)FI.getReturnInfo();
+    retInfo.setCoerceToType(GraphicsExpandReturnType(FI.getReturnType(), retInfo.getCoerceToType(), getTypes()));
+  }
   llvm::FunctionType *Ty = getTypes().GetFunctionType(FI);
 
   // Get or create the prototype for the function.
@@ -3008,7 +3162,7 @@ void CodeGenModule::EmitAliasDefinition(GlobalDecl GD) {
     // Remove it and replace uses of it with the alias.
     GA->takeName(Entry);
 
-    Entry->replaceAllUsesWith(llvm::ConstantExpr::getBitCast(GA,
+    Entry->replaceAllUsesWith(llvm::ConstantExpr::getPointerBitCastOrAddrSpaceCast(GA,
                                                           Entry->getType()));
     Entry->eraseFromParent();
   } else {
@@ -4280,6 +4434,72 @@ void CodeGenModule::EmitOMPThreadPrivateDecl(const OMPThreadPrivateDecl *D) {
   }
 }
 
+llvm::Constant*
+CodeGenModule::createIntToSamplerConversion(const Expr *E,
+                                            CodeGenFunction *CGF,
+                                            llvm::GlobalVariable *InsertBefore,
+                                            StringRef Name) {
+  llvm::Constant *C = EmitConstantExpr(E, E->getType(), CGF);
+  assert(C && "Sampler must be initialized by constant");
+  assert(isa<llvm::ConstantInt>(C) && "Sampler must be initialized by integer");
+  if (!getLangOpts().CLSamplerOpaque)
+    return C;
+
+  llvm::StructType*
+    ConstSamplerTy = TheModule.getTypeByName("spirv.ConstantSampler");
+  if (!ConstSamplerTy ) {
+    llvm::Type* Elements[] = {Int32Ty, Int32Ty, Int32Ty};
+    ConstSamplerTy = llvm::StructType::create(VMContext, Elements,
+                                              "spirv.ConstantSampler");
+  }
+  const llvm::ConstantInt *CI = static_cast<llvm::ConstantInt*>(C);
+  const uint64_t SamplerValue = CI->getValue().getZExtValue();
+  // 32-bit value of sampler's initializer is interpreted as
+  // bit-field with the following structure:
+  // |unspecified|Filter|Addressing Mode| Normalized Coords|
+  // |31        6|5    4|3             1|                 0|
+  // This structure corresponds to values of sampler properties from opencl.h
+  // Mapping these bits to values defined by SPIR-V specification.
+  unsigned NormalizedCoords = 0x01 & SamplerValue;
+  unsigned AddressingMode  = (0x0E & SamplerValue) >> 1;
+  unsigned FilterMode      = (0x30 & SamplerValue) >> 4;
+  // In SPIR sampler's filter bits are defined as the following
+  // #define CLK_FILTER_NEAREST 0x10
+  // #define CLK_FILTER_LINEAR 0x20
+  // corresponding to 1 and 2 in bits 4-5.
+  // SPIR-V defines sampler filter mode enum as: nearest=0, linear=1,
+  // Therefore, to convert FilterMode from SPIR to SPIR-V,
+  // FilterMode value must be decremented
+  if (FilterMode == 1 || FilterMode == 2)
+    --FilterMode;
+   else
+    getDiags().Report(Context.getFullLoc(E->getLocStart()),
+      diag::warn_sampler_initializer_invalid_bits) << "Filter Mode";
+  if (AddressingMode > 4)
+    getDiags().Report(Context.getFullLoc(E->getLocStart()),
+      diag::warn_sampler_initializer_invalid_bits) << "Addressing Mode";
+
+  llvm::Constant *Initializer = llvm::ConstantStruct::get(ConstSamplerTy,
+    llvm::ConstantInt::get(Int32Ty, AddressingMode),
+    llvm::ConstantInt::get(Int32Ty, NormalizedCoords),
+    llvm::ConstantInt::get(Int32Ty, FilterMode),
+    nullptr);
+  llvm::StructType*
+    SamplerTy = TheModule.getTypeByName("spirv.Sampler");
+  if(!SamplerTy)
+    SamplerTy = llvm::StructType::create(VMContext, "spirv.Sampler");
+
+  unsigned AS = Context.getTargetAddressSpace(LangAS::opencl_constant);
+  llvm::GlobalVariable *GV =
+    new llvm::GlobalVariable(TheModule, ConstSamplerTy, true,
+                             llvm::GlobalVariable::InternalLinkage,
+                             Initializer, Name + ".sampler.init", InsertBefore,
+                             llvm::GlobalVariable::NotThreadLocal, AS);
+
+  return llvm::ConstantExpr::getBitCast(GV,
+                                        llvm::PointerType::get(SamplerTy, AS));
+}
+
 llvm::Metadata *CodeGenModule::CreateMetadataIdentifierForType(QualType T) {
   llvm::Metadata *&InternalId = MetadataIdMap[T.getCanonicalType()];
   if (InternalId)
@@ -4366,13 +4586,3 @@ llvm::SanitizerStatReport &CodeGenModule::getSanStats() {
 
   return *SanStats;
 }
-llvm::Value *
-CodeGenModule::createOpenCLIntToSamplerConversion(const Expr *E,
-                                                  CodeGenFunction &CGF) {
-  llvm::Constant *C = EmitConstantExpr(E, E->getType(), &CGF);
-  auto SamplerT = getOpenCLRuntime().getSamplerType();
-  auto FTy = llvm::FunctionType::get(SamplerT, {C->getType()}, false);
-  return CGF.Builder.CreateCall(CreateRuntimeFunction(FTy,
-                                "__translate_sampler_initializer"),
-                                {C});
-}
diff --git a/lib/CodeGen/CodeGenModule.h b/lib/CodeGen/CodeGenModule.h
index ed18156..246a936 100644
--- a/lib/CodeGen/CodeGenModule.h
+++ b/lib/CodeGen/CodeGenModule.h
@@ -465,6 +465,8 @@ private:
   llvm::Type *BlockDescriptorType = nullptr;
   llvm::Type *GenericBlockLiteralType = nullptr;
 
+  llvm::DenseMap<const VarDecl*, llvm::Constant *> OCLGlobalBlockFunctions;
+
   struct {
     int GlobalUniqueCount;
   } Block;
@@ -774,7 +776,11 @@ public:
 
   /// Gets the address of a block which requires no captures.
   llvm::Constant *GetAddrOfGlobalBlock(const BlockExpr *BE, const char *);
-  
+  /// 
+  llvm::Constant *GetOCLGlobalBlockFunction(const VarDecl *D) {
+    return OCLGlobalBlockFunctions[D];
+  }
+
   /// Return a pointer to a constant CFString object for the given string.
   ConstantAddress GetAddrOfConstantCFString(const StringLiteral *Literal);
 
@@ -1041,6 +1047,12 @@ public:
   /// Emit all the global annotations.
   void EmitGlobalAnnotations();
 
+  /// Emit OpenCL related annotations.
+  void EmitOCLAnnotations();
+
+  /// Emit OCL compiler options
+  void EmitOCLBuildOptions();
+
   /// Emit an annotation string.
   llvm::Constant *EmitAnnotationString(StringRef Str);
 
@@ -1149,8 +1161,11 @@ public:
 
   llvm::SanitizerStatReport &getSanStats();
 
-  llvm::Value *
-  createOpenCLIntToSamplerConversion(const Expr *E, CodeGenFunction &CGF);
+  llvm::Constant*
+  createIntToSamplerConversion(const Expr *E,
+                               CodeGenFunction *CGF,
+                               llvm::GlobalVariable *InsertBefore = nullptr,
+                               StringRef Name = "");
 
 private:
   llvm::Constant *
@@ -1266,6 +1281,9 @@ private:
   /// Check whether we can use a "simpler", more core exceptions personality
   /// function.
   void SimplifyPersonality();
+
+  // Get a metadata vector containing the build options
+  llvm::SmallVector<llvm::Metadata *, 5> getBuildOptions();
 };
 }  // end namespace CodeGen
 }  // end namespace clang
diff --git a/lib/CodeGen/CodeGenTypes.cpp b/lib/CodeGen/CodeGenTypes.cpp
index ebe55c7..ca626e0 100644
--- a/lib/CodeGen/CodeGenTypes.cpp
+++ b/lib/CodeGen/CodeGenTypes.cpp
@@ -381,6 +381,10 @@ llvm::Type *CodeGenTypes::ConvertType(QualType T) {
 
   const Type *Ty = T.getTypePtr();
 
+  // intercept image arrays before RT conversion
+  if (Ty->isArrayImageType(true))
+    return ConvertArrayImageType(Ty);
+
   // RecordTypes are cached and processed specially.
   if (const RecordType *RT = dyn_cast<RecordType>(Ty))
     return ConvertRecordDeclType(RT->getDecl());
@@ -598,6 +602,10 @@ llvm::Type *CodeGenTypes::ConvertType(QualType T) {
   }
 
   case Type::BlockPointer: {
+    if (Context.getLangOpts().OpenCL) {
+      ResultType = CGM.getOpenCLRuntime().getBlockType();
+      break;
+    }
     const QualType FTy = cast<BlockPointerType>(Ty)->getPointeeType();
     llvm::Type *PointeeType = ConvertTypeForMem(FTy);
     unsigned AS = Context.getTargetAddressSpace(FTy);
@@ -718,9 +726,71 @@ llvm::StructType *CodeGenTypes::ConvertRecordDeclType(const RecordDecl *RD) {
   return Ty;
 }
 
+llvm::Type *CodeGenTypes::ConvertArrayImageType(const Type* Ty) {
+  // ptr to array of images
+  if(Ty->isPointerType() &&
+     Ty->getPointeeType()->isArrayType() &&
+     Ty->getPointeeType()->getArrayElementTypeNoTypeQual()->isImageType()) {
+    return llvm::PointerType::get(ConvertArrayImageType(Ty->getPointeeType().getTypePtr()), 0);
+  }
+	
+  // simple C-style array that contains an image type
+  if(Ty->isArrayType() &&
+     Ty->getArrayElementTypeNoTypeQual()->isImageType()) {
+    const ConstantArrayType *CAT = Context.getAsConstantArrayType(QualType(Ty, 0));
+    const auto elem_type = CAT->getElementType();
+    if(elem_type->isImageType()) {
+      return llvm::ArrayType::get(ConvertType(elem_type), CAT->getSize().getZExtValue());
+    } else if(elem_type->isAggregateImageType()) {
+      // must be an aggregate image with exactly one image
+      const auto agg_img_type = elem_type->getAsCXXRecordDecl();
+      auto agg_img_fields = get_aggregate_scalar_fields(agg_img_type, agg_img_type, false, false,
+                                                        true /* TODO */);
+      if(agg_img_fields.size() != 1) return nullptr;
+      return llvm::ArrayType::get(ConvertType(agg_img_fields[0].type), CAT->getSize().getZExtValue());
+    }
+    assert(false && "invalid array of images type");
+  }
+
+  // must be struct or class, union is not allowed
+  if(!Ty->isStructureOrClassType()) return nullptr;
+
+  // must be a cxx rdecl
+  const auto decl = Ty->getAsCXXRecordDecl();
+  if(!decl) return nullptr;
+
+  // must have definition
+  if(!decl->hasDefinition()) return nullptr;
+
+  // must have exactly one field
+  const auto field_count = std::distance(decl->field_begin(), decl->field_end());
+  if(field_count != 1) return nullptr;
+
+  // field must be an array
+  const QualType arr_field_type = decl->field_begin()->getType();
+  const ConstantArrayType *CAT = Context.getAsConstantArrayType(arr_field_type);
+  if(!CAT) return nullptr;
+
+  // must be an aggregate image with exactly one image
+  const auto agg_img_type = CAT->getElementType()->getAsCXXRecordDecl();
+  auto agg_img_fields = get_aggregate_scalar_fields(agg_img_type, agg_img_type, false, false,
+                                                    true /* TODO */);
+  if(agg_img_fields.size() != 1) return nullptr;
+
+  // got everything we need
+  return llvm::ArrayType::get(ConvertType(agg_img_fields[0].type), CAT->getSize().getZExtValue());
+}
+
 /// getCGRecordLayout - Return record layout info for the given record decl.
 const CGRecordLayout &
-CodeGenTypes::getCGRecordLayout(const RecordDecl *RD) {
+CodeGenTypes::getCGRecordLayout(const RecordDecl *RD, llvm::Type* struct_type) {
+  // check if there is a flattened layout for this llvm struct type,
+  // return it if so, otherwise continue as usual
+  if (struct_type != nullptr) {
+    const auto flat_layout = FlattenedCGRecordLayouts.lookup(struct_type);
+    if(flat_layout) return *flat_layout;
+  }
+
   const Type *Key = Context.getTagDeclType(RD).getTypePtr();
 
   const CGRecordLayout *Layout = CGRecordLayouts.lookup(Key);
@@ -768,3 +838,230 @@ bool CodeGenTypes::isZeroInitializable(QualType T) {
 bool CodeGenTypes::isZeroInitializable(const RecordDecl *RD) {
   return getCGRecordLayout(RD).isZeroInitializable();
 }
+
+//
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  RecordDecl::field_iterator field_iter) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalFieldName(*field_iter, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  const std::string& name,
+												  const clang::QualType type) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalGeneric(name, type, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+
+clang::QualType CodeGenTypes::get_compat_vector_type(const CXXRecordDecl* decl) const {
+	const auto fields = get_aggregate_scalar_fields(decl, decl, true, false, true);
+	
+	const auto vec_size = fields.size();
+	if(vec_size < 1 || vec_size > 4) {
+		assert("invalid vector size (must be >= 1 && <= 4)");
+		return Context.VoidTy;
+	}
+	
+	const auto elem_type = fields[0].type.getUnqualifiedType();
+	for(size_t i = 1; i < vec_size; ++i) {
+		if(fields[i].type.getUnqualifiedType() != elem_type) {
+			assert("all vector-compat element types must be equal");
+			return Context.VoidTy;
+		}
+	}
+	
+	return Context.getExtVectorType(elem_type, vec_size);
+}
+
+void CodeGenTypes::aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+													 const CXXRecordDecl* parent_decl,
+													 const ConstantArrayType* CAT,
+													 const AttrVec* attrs,
+													 const FieldDecl* parent_field_decl,
+													 const std::string& name,
+													 const bool expand_array_image,
+													 std::vector<CodeGenTypes::aggregate_scalar_entry>& ret) const {
+	if(expand_array_image ||
+	   !(CAT->getElementType()->isAggregateImageType() ||
+		 CAT->getElementType()->isImageType())) {
+		const auto count = CAT->getSize().getZExtValue();
+		const auto ET = CAT->getElementType();
+		if(const auto arr_rdecl = ET->getAsCXXRecordDecl()) {
+			auto contained_ret = get_aggregate_scalar_fields(root_decl, arr_rdecl, false, false, expand_array_image);
+			for(auto& entry : contained_ret) {
+				entry.parents.push_back(parent_decl);
+			}
+			for(uint64_t i = 0; i < count; ++i) {
+				ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+			}
+		}
+		else if(ET->isArrayType()) {
+			const auto aoa_decl = dyn_cast<ConstantArrayType>(ET->getAsArrayTypeUnsafe());
+			if(aoa_decl) {
+				for(uint64_t i = 0; i < count; ++i) {
+					const auto idx_str = "_" + std::to_string(i);
+					aggregate_scalar_fields_add_array(root_decl, parent_decl, aoa_decl, attrs, parent_field_decl,
+													  name + idx_str, expand_array_image, ret);
+				}
+			}
+			else {
+				// TODO: error
+			}
+		}
+		else {
+			for(uint64_t i = 0; i < count; ++i) {
+				const auto idx_str = "_" + std::to_string(i);
+				ret.push_back(aggregate_scalar_entry {
+					ET,
+					name + idx_str,
+					aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), name + idx_str, ET),
+					attrs,
+					parent_field_decl,
+					{ parent_decl },
+					false,
+					false
+				});
+			}
+		}
+	}
+	else {
+		// directly add an array entry
+		ret.push_back(aggregate_scalar_entry {
+			clang::QualType(CAT, 0),
+			name,
+			aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), name, clang::QualType(CAT, 0)),
+			attrs,
+			parent_field_decl,
+			{ parent_decl },
+			false,
+			false
+		});
+	}
+}
+
+std::vector<CodeGenTypes::aggregate_scalar_entry>
+CodeGenTypes::get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+										  const CXXRecordDecl* decl,
+										  const bool ignore_root_vec_compat,
+										  const bool ignore_bases,
+										  const bool expand_array_image) const {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	// if the root decl is a direct compat vector, return it directly
+	if(!ignore_root_vec_compat &&
+	   decl->hasAttr<VectorCompatAttr>()) {
+		return {
+			aggregate_scalar_entry {
+				get_compat_vector_type(decl),
+				"",
+				"",
+				&decl->getAttrs(),
+				nullptr,
+				{},
+				true,
+				false
+			}
+		};
+	}
+	
+	//
+	std::vector<aggregate_scalar_entry> ret;
+	
+	// iterate over / recurse into all bases
+	if(!ignore_bases) {
+		for(const auto& base : decl->bases()) {
+			auto base_ret = get_aggregate_scalar_fields(root_decl, base.getType()->getAsCXXRecordDecl(),
+														false, false, expand_array_image);
+			for(auto& elem : base_ret) {
+				elem.is_in_base = true;
+			}
+			if(!base_ret.empty()) {
+				ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+			}
+		}
+	}
+	
+	// TODO/NOTE: make sure attrs are correctly forwarded/inherited/passed-through
+	const auto add_field = [this, &root_decl, &decl, &expand_array_image, &ret](RecordDecl::field_iterator field_iter) {
+		if(const auto rdecl = field_iter->getType()->getAsCXXRecordDecl()) {
+			if(rdecl->hasAttr<VectorCompatAttr>() ||
+			   field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+				const auto vec_type = get_compat_vector_type(rdecl);
+				
+				if(field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+					const auto as_vec_type = vec_type->getAs<ExtVectorType>();
+					if(as_vec_type->getNumElements() != 4 ||
+					   !as_vec_type->getElementType()->isFloatingType()) {
+						// TODO: error!
+					}
+				}
+				
+				ret.push_back(aggregate_scalar_entry {
+					vec_type,
+					field_iter->getName().str(),
+					aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(),
+												   field_iter->getName().str(), vec_type),
+					field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+					*field_iter,
+					{ decl },
+					true,
+					false
+				});
+			}
+			else {
+				auto contained_ret = get_aggregate_scalar_fields(root_decl, rdecl,
+																 false, false, expand_array_image);
+				for(auto& entry : contained_ret) {
+					entry.parents.push_back(decl);
+				}
+				if(!contained_ret.empty()) {
+					ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+				}
+			}
+		}
+		else if(field_iter->getType()->isArrayType()) {
+			const auto arr_decl = dyn_cast<ConstantArrayType>(field_iter->getType()->getAsArrayTypeUnsafe());
+			if(arr_decl) {
+				aggregate_scalar_fields_add_array(root_decl, decl, arr_decl,
+												  field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+												  *field_iter, field_iter->getName().str(), expand_array_image, ret);
+			}
+			else {
+				// TODO: error
+			}
+		}
+		else {
+			ret.push_back(aggregate_scalar_entry {
+				field_iter->getType(),
+				field_iter->getName().str(),
+				aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), field_iter),
+				field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+				*field_iter,
+				{ decl },
+				false,
+				false
+			});
+		}
+	};
+	
+	if(!decl->isUnion()) {
+		// iterate over all fields/members
+		for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+			add_field(iter);
+		}
+	}
+	else {
+		// for unions: only use the first field
+		add_field(decl->field_begin());
+	}
+	
+	return ret;
+}
diff --git a/lib/CodeGen/CodeGenTypes.h b/lib/CodeGen/CodeGenTypes.h
index 00df10d..4d591a2 100644
--- a/lib/CodeGen/CodeGenTypes.h
+++ b/lib/CodeGen/CodeGenTypes.h
@@ -138,6 +138,10 @@ class CodeGenTypes {
   /// Maps clang struct type with corresponding record layout info.
   llvm::DenseMap<const Type*, CGRecordLayout *> CGRecordLayouts;
 
+  /// This maps special flattened llvm struct types
+  /// with the corresponding record layout info.
+  llvm::DenseMap<const llvm::Type*, CGRecordLayout *> FlattenedCGRecordLayouts;
+
   /// Contains the LLVM IR type for any converted RecordDecl.
   llvm::DenseMap<const Type*, llvm::StructType *> RecordDeclTypes;
   
@@ -217,7 +221,8 @@ public:
   /// and/or incomplete argument types, this will return the opaque type.
   llvm::Type *GetFunctionTypeForVTable(GlobalDecl GD);
 
-  const CGRecordLayout &getCGRecordLayout(const RecordDecl*);
+  const CGRecordLayout &getCGRecordLayout(const RecordDecl*,
+										  llvm::Type* struct_type = nullptr);
 
   /// UpdateCompletedType - When we find the full definition for a TagDecl,
   /// replace the 'opaque' type we previously made for it if applicable.
@@ -337,16 +342,72 @@ public:
   /// optional suffix and name the given LLVM type using it.
   void addRecordTypeName(const RecordDecl *RD, llvm::StructType *Ty,
                          StringRef suffix);
-  
+
+  //
+  struct aggregate_scalar_entry {
+	clang::QualType type;
+	std::string name;
+	std::string mangled_name;
+    const AttrVec* attrs;
+	// NOTE: this is nullptr for non-fields!
+    const FieldDecl* field_decl;
+    std::vector<const CXXRecordDecl*> parents;
+    bool compat_vector;
+    bool is_in_base;
+	
+	template <typename SpecificAttr>
+	bool hasAttr() const {
+		if(attrs == nullptr) return false;
+		return hasSpecificAttr<SpecificAttr>(*attrs);
+	}
+	
+	template <typename SpecificAttr>
+	SpecificAttr* getAttr() const {
+		if(attrs == nullptr) return nullptr;
+		return getSpecificAttr<SpecificAttr>(*attrs);
+	}
+  };
+
+  // will recurse through the specified class/struct decl, its base classes,
+  // all its contained class/struct/union decls, all its contained arrays,
+  // returning a vector of all contained/scalarized fields + info
+  // NOTE: for unions, only the first field will be considered
+  // NOTE: this also transform/converts [[vector_compat]] types to clang vector types
+  std::vector<aggregate_scalar_entry> get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+                                                                  const CXXRecordDecl* decl,
+																  const bool ignore_root_vec_compat = false,
+																  const bool ignore_bases = false,
+																  const bool expand_array_image = true) const;
+
+  // returns the corresponding clang vector type for a [[vector_compat]] aggregate
+  clang::QualType get_compat_vector_type(const CXXRecordDecl* decl) const;
+
+  //
+  void create_flattened_cg_layout(const CXXRecordDecl* decl, llvm::StructType* type,
+								  const std::vector<aggregate_scalar_entry>& fields);
+
+private:
+  // helper function for get_aggregate_scalar_fields
+  void aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+										 const CXXRecordDecl* parent_decl,
+                                         const ConstantArrayType* CAT,
+										 const AttrVec* attrs,
+										 const FieldDecl* parent_field_decl,
+										 const std::string& name,
+										 const bool expand_array_image,
+                                         std::vector<CodeGenTypes::aggregate_scalar_entry>& ret) const;
 
 public:  // These are internal details of CGT that shouldn't be used externally.
   /// ConvertRecordDeclType - Lay out a tagged decl type like struct or union.
   llvm::StructType *ConvertRecordDeclType(const RecordDecl *TD);
 
+  llvm::Type *ConvertArrayImageType(const Type* Ty);
+
   /// getExpandedTypes - Expand the type \arg Ty into the LLVM
   /// argument types it would be passed as. See ABIArgInfo::Expand.
   void getExpandedTypes(QualType Ty,
-                        SmallVectorImpl<llvm::Type *>::iterator &TI);
+                        SmallVectorImpl<llvm::Type *>::iterator &TI,
+                        const CallingConv CC);
 
   /// IsZeroInitializable - Return whether a type can be
   /// zero-initialized (in the C++ sense) with an LLVM zeroinitializer.
diff --git a/lib/CodeGen/TargetInfo.cpp b/lib/CodeGen/TargetInfo.cpp
index 759e3d6..5209ced 100644
--- a/lib/CodeGen/TargetInfo.cpp
+++ b/lib/CodeGen/TargetInfo.cpp
@@ -69,11 +69,15 @@ static void AssignToArrayRange(CodeGen::CGBuilderTy &Builder,
   }
 }
 
-static bool isAggregateTypeForABI(QualType T) {
+bool TargetCodeGenInfo::isAggregateTypeForABI(QualType T) {
   return !CodeGenFunction::hasScalarEvaluationKind(T) ||
          T->isMemberFunctionPointerType();
 }
 
+static bool isAggregateImageType(QualType T) {
+  return CodeGenFunction::hasAggregateEvaluationKind(T) && T->isAggregateImageType();
+}
+
 ABIArgInfo
 ABIInfo::getNaturalAlignIndirect(QualType Ty, bool ByRef, bool Realign,
                                  llvm::Type *Padding) const {
@@ -92,6 +96,23 @@ Address ABIInfo::EmitMSVAArg(CodeGenFunction &CGF, Address VAListAddr,
   return Address::invalid();
 }
 
+static ABIArgInfo classifyOpenCL(QualType Ty) {
+
+  if (Ty->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  if (Ty->isRecordType())
+    return ABIArgInfo::getIndirect(CharUnits::Zero(), /*ByVal=*/false);
+
+  if (Ty->isPromotableIntegerType())
+    return ABIArgInfo::getExtend();
+
+  return ABIArgInfo::getDirect();
+}
+
 ABIInfo::~ABIInfo() {}
 
 /// Does the given lowering require more than the given number of
@@ -398,7 +419,7 @@ TargetCodeGenInfo::getDependentLibraryOption(llvm::StringRef Lib,
 }
 
 unsigned TargetCodeGenInfo::getOpenCLKernelCallingConv() const {
-  return llvm::CallingConv::C;
+  return llvm::CallingConv::FLOOR_KERNEL;
 }
 
 static bool isEmptyRecord(ASTContext &Context, QualType T, bool AllowArrays);
@@ -516,7 +537,7 @@ static const Type *isSingleElementStruct(QualType T, ASTContext &Context) {
       FT = AT->getElementType();
     }
 
-    if (!isAggregateTypeForABI(FT)) {
+    if (!TargetCodeGenInfo::isAggregateTypeForABI(FT)) {
       Found = FT.getTypePtr();
     } else {
       Found = isSingleElementStruct(FT, Context);
@@ -613,9 +634,12 @@ public:
 };
 
 ABIArgInfo DefaultABIInfo::classifyArgumentType(QualType Ty) const {
+  if (isAggregateImageType(Ty))
+    return ABIArgInfo::getExpand();
+
   Ty = useFirstFieldIfTransparentUnion(Ty);
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // passed by value.
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
@@ -636,7 +660,7 @@ ABIArgInfo DefaultABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVoidType())
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return getNaturalAlignIndirect(RetTy);
 
   // Treat an enum type as its underlying type.
@@ -686,7 +710,7 @@ public:
 ABIArgInfo WebAssemblyABIInfo::classifyArgumentType(QualType Ty) const {
   Ty = useFirstFieldIfTransparentUnion(Ty);
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // passed by value.
     if (auto RAA = getRecordArgABI(Ty, getCXXABI()))
@@ -706,7 +730,7 @@ ABIArgInfo WebAssemblyABIInfo::classifyArgumentType(QualType Ty) const {
 }
 
 ABIArgInfo WebAssemblyABIInfo::classifyReturnType(QualType RetTy) const {
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // returned by value.
     if (!getRecordArgABI(RetTy, getCXXABI())) {
@@ -779,7 +803,7 @@ Address PNaClABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
 
 /// \brief Classify argument of given type \p Ty.
 ABIArgInfo PNaClABIInfo::classifyArgumentType(QualType Ty) const {
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
     return getNaturalAlignIndirect(Ty);
@@ -800,7 +824,7 @@ ABIArgInfo PNaClABIInfo::classifyReturnType(QualType RetTy) const {
     return ABIArgInfo::getIgnore();
 
   // In the PNaCl ABI we always return records/structures on the stack.
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return getNaturalAlignIndirect(RetTy);
 
   // Treat an enum type as its underlying type.
@@ -1260,7 +1284,7 @@ ABIArgInfo X86_32ABIInfo::classifyReturnType(QualType RetTy,
     return ABIArgInfo::getDirect();
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     if (const RecordType *RT = RetTy->getAs<RecordType>()) {
       // Structures with flexible arrays are always indirect.
       if (RT->getDecl()->hasFlexibleArrayMember())
@@ -1430,7 +1454,7 @@ bool X86_32ABIInfo::shouldAggregateUseDirect(QualType Ty, CCState &State,
   // On Windows, aggregates other than HFAs are never passed in registers, and
   // they do not consume register slots. Homogenous floating-point aggregates
   // (HFAs) have already been dealt with at this point.
-  if (IsWin32StructABI && isAggregateTypeForABI(Ty))
+  if (IsWin32StructABI && TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return false;
 
   NeedsPadding = false;
@@ -1505,7 +1529,7 @@ ABIArgInfo X86_32ABIInfo::classifyArgumentType(QualType Ty,
     return getIndirectResult(Ty, /*ByVal=*/false, State);
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Structures with flexible arrays are always indirect.
     // FIXME: This should not be byval!
     if (RT && RT->getDecl()->hasFlexibleArrayMember())
@@ -1581,6 +1605,20 @@ ABIArgInfo X86_32ABIInfo::classifyArgumentType(QualType Ty,
 }
 
 void X86_32ABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  QualType RetTy = FI.getReturnType();
+
+  // TODO: why is this here?
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL clessify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(RetTy);
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
+
   CCState State(FI.getCallingConvention());
   if (IsMCUABI)
     State.FreeRegs = 3;
@@ -2655,7 +2693,7 @@ void X86_64ABIInfo::classify(QualType Ty, uint64_t OffsetBase,
 ABIArgInfo X86_64ABIInfo::getIndirectReturnResult(QualType Ty) const {
   // If this is a scalar LLVM value then assume LLVM will pass it in the right
   // place naturally.
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -2688,7 +2726,7 @@ ABIArgInfo X86_64ABIInfo::getIndirectResult(QualType Ty,
   // the argument in the free register. This does not seem to happen currently,
   // but this code would be much safer if we could mark the argument with
   // 'onstack'. See PR12193.
-  if (!isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -3278,6 +3316,19 @@ ABIArgInfo X86_64ABIInfo::classifyArgumentType(
 }
 
 void X86_64ABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  QualType RetTy = FI.getReturnType();
+
+  // TODO: again, why is this here?
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL clessify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(RetTy);
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
 
   if (!getCXXABI().classifyReturnType(FI))
     FI.getReturnInfo() = classifyReturnType(FI.getReturnType());
@@ -3643,6 +3694,18 @@ void WinX86_64ABIInfo::computeInfo(CGFunctionInfo &FI) const {
   if (!getCXXABI().classifyReturnType(FI))
     FI.getReturnInfo() = classify(FI.getReturnType(), FreeSSERegs, true);
 
+  // TODO: ... why is this here?
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL classify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(FI.getReturnType());
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
+
   // We can use up to 6 SSE register parameters with vectorcall.
   FreeSSERegs = IsVectorCall ? 6 : 0;
   for (auto &I : FI.arguments())
@@ -4055,7 +4118,7 @@ CharUnits PPC64_SVR4_ABIInfo::getParamTypeAlignment(QualType Ty) const {
   const Type *Base = nullptr;
   uint64_t Members = 0;
   if (!AlignAsType && Kind == ELFv2 &&
-      isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
+      TargetCodeGenInfo::isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
     AlignAsType = Base;
 
   // With special case aggregates, only vector base types need alignment.
@@ -4070,7 +4133,7 @@ CharUnits PPC64_SVR4_ABIInfo::getParamTypeAlignment(QualType Ty) const {
 
   // Otherwise, we only need alignment for any aggregate type that
   // has an alignment requirement of >= 16 bytes.
-  if (isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128) {
     if (HasQPX && getContext().getTypeAlign(Ty) >= 256)
       return CharUnits::fromQuantity(32);
     return CharUnits::fromQuantity(16);
@@ -4227,7 +4290,7 @@ PPC64_SVR4_ABIInfo::classifyArgumentType(QualType Ty) const {
     }
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
 
@@ -4299,7 +4362,7 @@ PPC64_SVR4_ABIInfo::classifyReturnType(QualType RetTy) const {
     }
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // ELFv2 homogeneous aggregates are returned as array types.
     const Type *Base = nullptr;
     uint64_t Members = 0;
@@ -4544,7 +4607,7 @@ ABIArgInfo AArch64ABIInfo::classifyArgumentType(QualType Ty) const {
     return getNaturalAlignIndirect(Ty, /*ByVal=*/false);
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -4609,7 +4672,7 @@ ABIArgInfo AArch64ABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 128)
     return getNaturalAlignIndirect(RetTy);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -4862,7 +4925,7 @@ Address AArch64ABIInfo::EmitAAPCSVAArg(Address VAListAddr,
     // It might be right-aligned in its slot.
     CharUnits SlotSize = BaseAddr.getAlignment();
     if (CGF.CGM.getDataLayout().isBigEndian() && !IsIndirect &&
-        (IsHFA || !isAggregateTypeForABI(Ty)) &&
+        (IsHFA || !TargetCodeGenInfo::isAggregateTypeForABI(Ty)) &&
         TyInfo.first < SlotSize) {
       CharUnits Offset = SlotSize - TyInfo.first;
       BaseAddr = CGF.Builder.CreateConstInBoundsByteGEP(BaseAddr, Offset);
@@ -4916,7 +4979,7 @@ Address AArch64ABIInfo::EmitAAPCSVAArg(Address VAListAddr,
   // Write the new value of __stack for the next call to va_arg
   CGF.Builder.CreateStore(NewStack, stack_p);
 
-  if (CGF.CGM.getDataLayout().isBigEndian() && !isAggregateTypeForABI(Ty) &&
+  if (CGF.CGM.getDataLayout().isBigEndian() && !TargetCodeGenInfo::isAggregateTypeForABI(Ty) &&
       TyInfo.first < StackSlotSize) {
     CharUnits Offset = StackSlotSize - TyInfo.first;
     OnStackAddr = CGF.Builder.CreateConstInBoundsByteGEP(OnStackAddr, Offset);
@@ -4946,7 +5009,7 @@ Address AArch64ABIInfo::EmitDarwinVAArg(Address VAListAddr, QualType Ty,
   // The backend's lowering doesn't support va_arg for aggregates or
   // illegal vector types.  Lower VAArg here for these cases and use
   // the LLVM va_arg instruction for everything else.
-  if (!isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
     return EmitVAArgInstr(CGF, VAListAddr, Ty, ABIArgInfo::getDirect());
 
   CharUnits SlotSize = CharUnits::fromQuantity(8);
@@ -5258,7 +5321,7 @@ ABIArgInfo ARMABIInfo::classifyArgumentType(QualType Ty,
     return ABIArgInfo::getDirect(ResType);
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>()) {
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -5456,7 +5519,7 @@ ABIArgInfo ARMABIInfo::classifyReturnType(QualType RetTy,
     return ABIArgInfo::getDirect(ResType);
   }
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -5688,7 +5751,7 @@ ABIArgInfo NVPTXABIInfo::classifyArgumentType(QualType Ty) const {
     Ty = EnumTy->getDecl()->getIntegerType();
 
   // Return aggregates type as indirect by value
-  if (isAggregateTypeForABI(Ty))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return getNaturalAlignIndirect(Ty, /* byval */ true);
 
   return (Ty->isPromotableIntegerType() ?
@@ -5725,7 +5788,7 @@ setTargetAttributes(const Decl *D, llvm::GlobalValue *GV,
   if (M.getLangOpts().OpenCL) {
     // Use OpenCL function attributes to check for kernel functions
     // By default, all functions are device functions
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL __kernel functions get kernel metadata
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
@@ -5739,7 +5802,7 @@ setTargetAttributes(const Decl *D, llvm::GlobalValue *GV,
     // CUDA __global__ functions get a kernel metadata entry.  Since
     // __global__ functions cannot be called from the device, we do not
     // need to set the noinline attribute.
-    if (FD->hasAttr<CUDAGlobalAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
     }
@@ -5782,6 +5845,198 @@ void NVPTXTargetCodeGenInfo::addNVVMMetadata(llvm::Function *F, StringRef Name,
 }
 
 //===----------------------------------------------------------------------===//
+// OpenCL/SPIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class SPIRABIInfo : public DefaultABIInfo {
+public:
+  SPIRABIInfo(CodeGenTypes &CGT) : DefaultABIInfo(CGT) {}
+};
+
+class SPIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  SPIRTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new SPIRABIInfo(CGT)) {}
+};
+
+}
+
+//===----------------------------------------------------------------------===//
+// Metal/AIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class AIRABIInfo : public ABIInfo {
+public:
+  AIRABIInfo(CodeGenTypes &CGT) : ABIInfo(CGT) {}
+
+  ABIArgInfo classifyReturnType(QualType RetTy) const;
+  ABIArgInfo classifyArgumentType(QualType Ty) const;
+
+  void computeInfo(CGFunctionInfo &FI) const override;
+  Address EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                    QualType Ty) const override;
+};
+
+class AIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  AIRTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new AIRABIInfo(CGT)) {}
+};
+
+ABIArgInfo AIRABIInfo::classifyReturnType(QualType RetTy) const {
+  if (RetTy->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  // note: this is different from default ABI
+  if (!RetTy->isScalarType())
+    return ABIArgInfo::getDirect();
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
+    RetTy = EnumTy->getDecl()->getIntegerType();
+
+  return (RetTy->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+ABIArgInfo AIRABIInfo::classifyArgumentType(QualType Ty) const {
+  // CGT.getTarget() // TODO: native array image test
+  // direct array of images (not writable)
+  if (Ty->isArrayImageType(true))
+    return getNaturalAlignIndirect(Ty);
+
+  if (CodeGenFunction::hasAggregateEvaluationKind(Ty) &&
+      Ty->isStructureOrClassType()) {
+    return ABIArgInfo::getExpand();
+  }
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  return (Ty->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+void AIRABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  // return type should never be indirect
+  // TODO: ... if the function is a kernel/vs/fs
+  FI.getReturnInfo() = classifyReturnType(FI.getReturnType());
+
+  for (auto &I : FI.arguments())
+    I.info = classifyArgumentType(I.type);
+
+  // Always honor user-specified calling convention.
+  if (FI.getCallingConvention() != llvm::CallingConv::C)
+    return;
+
+  FI.setEffectiveCallingConvention(getRuntimeCC());
+}
+
+Address AIRABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                              QualType Ty) const {
+  llvm_unreachable("AIR does not support varargs");
+}
+
+}
+
+//===----------------------------------------------------------------------===//
+// Vulkan/SPIR-V ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class VulkanABIInfo : public ABIInfo {
+public:
+  VulkanABIInfo(CodeGenTypes &CGT) : ABIInfo(CGT) {}
+
+  ABIArgInfo classifyReturnType(QualType RetTy, unsigned int CC) const;
+  ABIArgInfo classifyArgumentType(QualType Ty, unsigned int CC) const;
+
+  void computeInfo(CGFunctionInfo &FI) const override;
+  Address EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                    QualType Ty) const override;
+};
+
+class VulkanTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  VulkanTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new VulkanABIInfo(CGT)) {}
+};
+
+ABIArgInfo VulkanABIInfo::classifyReturnType(QualType RetTy, unsigned int CC) const {
+  if (RetTy->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  // note: this is different from default ABI
+  if (!RetTy->isScalarType())
+    return ABIArgInfo::getDirect();
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
+    RetTy = EnumTy->getDecl()->getIntegerType();
+
+  return (RetTy->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+ABIArgInfo VulkanABIInfo::classifyArgumentType(QualType Ty, unsigned int CC) const {
+  // direct array of images (not writable)
+  if (Ty->isArrayImageType(true))
+    return getNaturalAlignIndirect(Ty);
+
+  // all shader inputs must either be scalar or vector types, or arrays thereof
+  // -> expand all aggregates
+  if (CodeGenFunction::hasAggregateEvaluationKind(Ty) &&
+      Ty->isStructureOrClassType() &&
+      (CC == llvm::CallingConv::FLOOR_VERTEX ||
+       CC == llvm::CallingConv::FLOOR_FRAGMENT ||
+       CC == llvm::CallingConv::FLOOR_KERNEL)) {
+    return ABIArgInfo::getExpand();
+  }
+
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
+    // Records with non-trivial destructors/copy-constructors should not be
+    // passed by value.
+    if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
+      return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
+
+    return getNaturalAlignIndirect(Ty);
+  }
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  return (Ty->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+void VulkanABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  FI.getReturnInfo() = classifyReturnType(FI.getReturnType(), FI.getCallingConvention());
+
+  for (auto &I : FI.arguments())
+    I.info = classifyArgumentType(I.type, FI.getCallingConvention());
+
+  // Always honor user-specified calling convention.
+  if (FI.getCallingConvention() != llvm::CallingConv::C)
+    return;
+
+  FI.setEffectiveCallingConvention(getRuntimeCC());
+}
+
+Address VulkanABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                                 QualType Ty) const {
+  llvm_unreachable("Vulkan/SPIR-V does not support varargs");
+}
+
+}
+
+//===----------------------------------------------------------------------===//
 // SystemZ ABI Implementation
 //===----------------------------------------------------------------------===//
 
@@ -5852,7 +6107,7 @@ bool SystemZABIInfo::isPromotableIntegerType(QualType Ty) const {
 bool SystemZABIInfo::isCompoundType(QualType Ty) const {
   return (Ty->isAnyComplexType() ||
           Ty->isVectorType() ||
-          isAggregateTypeForABI(Ty));
+          TargetCodeGenInfo::isAggregateTypeForABI(Ty));
 }
 
 bool SystemZABIInfo::isVectorArgumentType(QualType Ty) const {
@@ -6350,7 +6605,7 @@ MipsABIInfo::classifyArgumentType(QualType Ty, uint64_t &Offset) const {
   unsigned CurrOffset = llvm::alignTo(Offset, Align);
   Offset = CurrOffset + llvm::alignTo(TySize, Align * 8) / 8;
 
-  if (isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
     // Ignore empty aggregates.
     if (TySize == 0)
       return ABIArgInfo::getIgnore();
@@ -6435,7 +6690,7 @@ ABIArgInfo MipsABIInfo::classifyReturnType(QualType RetTy) const {
   if (!IsO32 && Size == 0)
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
     if (Size <= 128) {
       if (RetTy->isAnyComplexType())
         return ABIArgInfo::getDirect();
@@ -6588,7 +6843,7 @@ void TCETargetCodeGenInfo::setTargetAttributes(
   llvm::Function *F = cast<llvm::Function>(GV);
 
   if (M.getLangOpts().OpenCL) {
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL C Kernel functions are not subject to inlining
       F->addFnAttr(llvm::Attribute::NoInline);
       const ReqdWorkGroupSizeAttr *Attr = FD->getAttr<ReqdWorkGroupSizeAttr>();
@@ -6668,7 +6923,7 @@ void HexagonABIInfo::computeInfo(CGFunctionInfo &FI) const {
 }
 
 ABIArgInfo HexagonABIInfo::classifyArgumentType(QualType Ty) const {
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -6706,7 +6961,7 @@ ABIArgInfo HexagonABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 64)
     return getNaturalAlignIndirect(RetTy);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -6824,7 +7079,7 @@ ABIArgInfo LanaiABIInfo::classifyArgumentType(QualType Ty,
     }
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Structures with flexible arrays are always indirect.
     if (RT && RT->getDecl()->hasFlexibleArrayMember())
       return getIndirectResult(Ty, /*ByVal=*/true, State);
@@ -6927,7 +7182,21 @@ public:
 
 }
 
-static void appendOpenCLVersionMD (CodeGen::CodeGenModule &CGM);
+static void appendOpenCLVersionMD (CodeGen::CodeGenModule &CGM) {
+  llvm::LLVMContext &Ctx = CGM.getModule().getContext();
+  llvm::Type *Int32Ty = llvm::Type::getInt32Ty(Ctx);
+  llvm::Module &M = CGM.getModule();
+  // SPIR v2.0 s2.13 - The OpenCL version used by the module is stored in the
+  // opencl.ocl.version named metadata node.
+  llvm::Metadata *OCLVerElts[] = {
+      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
+          Int32Ty, CGM.getLangOpts().OpenCLVersion / 100)),
+      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
+          Int32Ty, (CGM.getLangOpts().OpenCLVersion % 100) / 10))};
+  llvm::NamedMDNode *OCLVerMD =
+      M.getOrInsertNamedMetadata("opencl.ocl.version");
+  OCLVerMD->addOperand(llvm::MDNode::get(Ctx, OCLVerElts));
+}
 
 void AMDGPUTargetCodeGenInfo::setTargetAttributes(
   const Decl *D,
@@ -6953,7 +7222,7 @@ void AMDGPUTargetCodeGenInfo::setTargetAttributes(
 
   appendOpenCLVersionMD(M);
 }
-
+
 
 unsigned AMDGPUTargetCodeGenInfo::getOpenCLKernelCallingConv() const {
   return llvm::CallingConv::AMDGPU_KERNEL;
@@ -7168,7 +7437,7 @@ SparcV9ABIInfo::classifyType(QualType Ty, unsigned SizeLimit) const {
     return ABIArgInfo::getExtend();
 
   // Other non-aggregates go in registers.
-  if (!isAggregateTypeForABI(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return ABIArgInfo::getDirect();
 
   // If a C++ object has either a non-trivial copy constructor or a non-trivial
@@ -7596,58 +7865,6 @@ void XCoreTargetCodeGenInfo::emitTargetMD(const Decl *D, llvm::GlobalValue *GV,
   }
 }
 
-//===----------------------------------------------------------------------===//
-// SPIR ABI Implementation
-//===----------------------------------------------------------------------===//
-
-namespace {
-class SPIRTargetCodeGenInfo : public TargetCodeGenInfo {
-public:
-  SPIRTargetCodeGenInfo(CodeGen::CodeGenTypes &CGT)
-    : TargetCodeGenInfo(new DefaultABIInfo(CGT)) {}
-  void emitTargetMD(const Decl *D, llvm::GlobalValue *GV,
-                    CodeGen::CodeGenModule &M) const override;
-  unsigned getOpenCLKernelCallingConv() const override;
-};
-} // End anonymous namespace.
-
-/// Emit SPIR specific metadata: OpenCL and SPIR version.
-void SPIRTargetCodeGenInfo::emitTargetMD(const Decl *D, llvm::GlobalValue *GV,
-                                         CodeGen::CodeGenModule &CGM) const {
-  llvm::LLVMContext &Ctx = CGM.getModule().getContext();
-  llvm::Type *Int32Ty = llvm::Type::getInt32Ty(Ctx);
-  llvm::Module &M = CGM.getModule();
-  // SPIR v2.0 s2.12 - The SPIR version used by the module is stored in the
-  // opencl.spir.version named metadata.
-  llvm::Metadata *SPIRVerElts[] = {
-      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Int32Ty, 2)),
-      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Int32Ty, 0))};
-  llvm::NamedMDNode *SPIRVerMD =
-      M.getOrInsertNamedMetadata("opencl.spir.version");
-  SPIRVerMD->addOperand(llvm::MDNode::get(Ctx, SPIRVerElts));
-  appendOpenCLVersionMD(CGM);
-}
-
-static void appendOpenCLVersionMD (CodeGen::CodeGenModule &CGM) {
-  llvm::LLVMContext &Ctx = CGM.getModule().getContext();
-  llvm::Type *Int32Ty = llvm::Type::getInt32Ty(Ctx);
-  llvm::Module &M = CGM.getModule();
-  // SPIR v2.0 s2.13 - The OpenCL version used by the module is stored in the
-  // opencl.ocl.version named metadata node.
-  llvm::Metadata *OCLVerElts[] = {
-      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
-          Int32Ty, CGM.getLangOpts().OpenCLVersion / 100)),
-      llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
-          Int32Ty, (CGM.getLangOpts().OpenCLVersion % 100) / 10))};
-  llvm::NamedMDNode *OCLVerMD =
-      M.getOrInsertNamedMetadata("opencl.ocl.version");
-  OCLVerMD->addOperand(llvm::MDNode::get(Ctx, OCLVerElts));
-}
-
-unsigned SPIRTargetCodeGenInfo::getOpenCLKernelCallingConv() const {
-  return llvm::CallingConv::SPIR_KERNEL;
-}
-
 static bool appendType(SmallStringEnc &Enc, QualType QType,
                        const CodeGen::CodeGenModule &CGM,
                        TypeStringCache &TSC);
@@ -8145,6 +8362,11 @@ const TargetCodeGenInfo &CodeGenModule::getTargetCodeGenInfo() {
     return SetCGInfo(new XCoreTargetCodeGenInfo(Types));
   case llvm::Triple::spir:
   case llvm::Triple::spir64:
+    if(Triple.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan) {
+      return SetCGInfo(new VulkanTargetCodeGenInfo(Types));
+    }
     return SetCGInfo(new SPIRTargetCodeGenInfo(Types));
+  case llvm::Triple::air64:
+    return SetCGInfo(new AIRTargetCodeGenInfo(Types));
   }
 }
diff --git a/lib/CodeGen/TargetInfo.h b/lib/CodeGen/TargetInfo.h
index e463825..5700c24 100644
--- a/lib/CodeGen/TargetInfo.h
+++ b/lib/CodeGen/TargetInfo.h
@@ -220,6 +220,9 @@ public:
 
   /// Get LLVM calling convention for OpenCL kernel.
   virtual unsigned getOpenCLKernelCallingConv() const;
+
+  static bool isAggregateTypeForABI(QualType T);
+
 };
 
 } // namespace CodeGen
diff --git a/lib/Driver/Driver.cpp b/lib/Driver/Driver.cpp
index 9871f29..c895374 100644
--- a/lib/Driver/Driver.cpp
+++ b/lib/Driver/Driver.cpp
@@ -1837,6 +1837,14 @@ Action *Driver::ConstructPhaseAction(Compilation &C, const ArgList &Args,
       return C.MakeAction<CompileJobAction>(Input, types::TY_ModuleFile);
     if (Args.hasArg(options::OPT_verify_pch))
       return C.MakeAction<VerifyPCHJobAction>(Input, types::TY_Nothing);
+    if (Args.hasArg(options::OPT_llvm_bc_32))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC_32);
+    if (Args.hasArg(options::OPT_llvm_bc_35))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC_35);
+    if (Args.hasArg(options::OPT_llvm_spirv))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_SPIRV);
+    if (Args.hasArg(options::OPT_llvm_spirv_container))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_SPIRVC);
     return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC);
   }
   case phases::Backend: {
@@ -1846,8 +1854,16 @@ Action *Driver::ConstructPhaseAction(Compilation &C, const ArgList &Args,
       return C.MakeAction<BackendJobAction>(Input, Output);
     }
     if (Args.hasArg(options::OPT_emit_llvm)) {
-      types::ID Output =
-          Args.hasArg(options::OPT_S) ? types::TY_LLVM_IR : types::TY_LLVM_BC;
+      types::ID Output = types::TY_LLVM_BC;
+      if (Args.hasArg(options::OPT_S)) {
+        Output = types::TY_LLVM_IR;
+      }
+      else {
+        if (Args.hasArg(options::OPT_llvm_bc_32)) Output = types::TY_LLVM_BC_32;
+        if (Args.hasArg(options::OPT_llvm_bc_35)) Output = types::TY_LLVM_BC_35;
+        if (Args.hasArg(options::OPT_llvm_spirv)) Output = types::TY_SPIRV;
+        if (Args.hasArg(options::OPT_llvm_spirv_container)) Output = types::TY_SPIRVC;
+      }
       return C.MakeAction<BackendJobAction>(Input, Output);
     }
     return C.MakeAction<BackendJobAction>(Input, types::TY_PP_Asm);
@@ -2455,8 +2471,13 @@ const char *Driver::GetNamedOutputPath(Compilation &C, const JobAction &JA,
     // the unoptimized bitcode so that it does not get overwritten by the ".bc"
     // optimized bitcode output.
     if (!AtTopLevel && C.getArgs().hasArg(options::OPT_emit_llvm) &&
-        JA.getType() == types::TY_LLVM_BC)
+        (JA.getType() == types::TY_LLVM_BC ||
+         JA.getType() == types::TY_LLVM_BC_32 ||
+         JA.getType() == types::TY_LLVM_BC_35 ||
+         JA.getType() == types::TY_SPIRV ||
+         JA.getType() == types::TY_SPIRVC)) {
       Suffixed += ".tmp";
+    }
     Suffixed += '.';
     Suffixed += Suffix;
     NamedOutput = C.getArgs().MakeArgString(Suffixed.c_str());
diff --git a/lib/Driver/ToolChains.cpp b/lib/Driver/ToolChains.cpp
index 4b8182e..b99b571 100644
--- a/lib/Driver/ToolChains.cpp
+++ b/lib/Driver/ToolChains.cpp
@@ -78,6 +78,8 @@ ToolChain::CXXStdlibType Darwin::GetDefaultCXXStdlibType() const {
 
 /// Darwin provides an ARC runtime starting in MacOS X 10.7 and iOS 5.0.
 ObjCRuntime Darwin::getDefaultObjCRuntime(bool isNonFragile) const {
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return ObjCRuntime(ObjCRuntime::FragileMacOSX, TargetVersion);
   if (isTargetWatchOSBased())
     return ObjCRuntime(ObjCRuntime::WatchOS, TargetVersion);
   if (isTargetIOSBased())
@@ -89,6 +91,8 @@ ObjCRuntime Darwin::getDefaultObjCRuntime(bool isNonFragile) const {
 
 /// Darwin provides a blocks runtime starting in MacOS X 10.6 and iOS 3.2.
 bool Darwin::hasBlocksRuntime() const {
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return false;
   if (isTargetWatchOSBased())
     return true;
   else if (isTargetIOSBased())
@@ -232,6 +236,10 @@ DarwinClang::DarwinClang(const Driver &D, const llvm::Triple &Triple,
     : Darwin(D, Triple, Args) {}
 
 void DarwinClang::addClangWarningOptions(ArgStringList &CC1Args) const {
+  // nothing of interest in here for air/metal
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return;
+
   // For modern targets, promote certain warnings to errors.
   if (isTargetWatchOSBased() || getTriple().isArch64Bit()) {
     // Always enable -Wdeprecated-objc-isa-usage and promote it
@@ -1271,6 +1279,11 @@ void Darwin::CheckObjCARC() const {
 SanitizerMask Darwin::getSupportedSanitizers() const {
   const bool IsX86_64 = getTriple().getArch() == llvm::Triple::x86_64;
   SanitizerMask Res = ToolChain::getSupportedSanitizers();
+
+  // no additional ones
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return Res;
+
   Res |= SanitizerKind::Address;
   if (isTargetMacOS()) {
     if (!isMacosxVersionLT(10, 9))
@@ -1760,6 +1773,8 @@ static CudaVersion ParseCudaVersionFile(llvm::StringRef V) {
     return CudaVersion::CUDA_75;
   if (Major == 8 && Minor == 0)
     return CudaVersion::CUDA_80;
+  if (Major == 9 && Minor == 0)
+    return CudaVersion::CUDA_90;
   return CudaVersion::UNKNOWN;
 }
 
@@ -1774,8 +1789,9 @@ void Generic_GCC::CudaInstallationDetector::init(
         Args.getLastArgValue(options::OPT_cuda_path_EQ));
   else {
     CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda");
-    // FIXME: Uncomment this once we can compile the cuda 8 headers.
-    // CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda-8.0");
+    // FIXME: Uncomment this once we can compile the cuda 9 headers.
+    // CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda-9.0");
+    CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda-8.0");
     CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda-7.5");
     CudaPathCandidates.push_back(D.SysRoot + "/usr/local/cuda-7.0");
   }
@@ -1828,6 +1844,8 @@ void Generic_GCC::CudaInstallationDetector::init(
         LibDeviceMap["sm_60"] = FilePath;
         LibDeviceMap["sm_61"] = FilePath;
         LibDeviceMap["sm_62"] = FilePath;
+        LibDeviceMap["sm_70"] = FilePath;
+        LibDeviceMap["sm_72"] = FilePath;
       } else if (GpuArch == "compute_35") {
         LibDeviceMap["sm_35"] = FilePath;
         LibDeviceMap["sm_37"] = FilePath;
@@ -4820,11 +4838,11 @@ CudaToolChain::addClangTargetOptions(const llvm::opt::ArgList &DriverArgs,
   CC1Args.push_back("-mlink-cuda-bitcode");
   CC1Args.push_back(DriverArgs.MakeArgString(LibDeviceFile));
 
-  // Libdevice in CUDA-7.0 requires PTX version that's more recent
-  // than LLVM defaults to. Use PTX4.2 which is the PTX version that
-  // came with CUDA-7.0.
+  // Libdevice in CUDA-7.5 requires PTX version that's more recent
+  // than LLVM defaults to. Use PTX4.3 which is the PTX version that
+  // came with CUDA-7.5.
   CC1Args.push_back("-target-feature");
-  CC1Args.push_back("+ptx42");
+  CC1Args.push_back("+ptx43");
 }
 
 void CudaToolChain::AddCudaIncludeArgs(const ArgList &DriverArgs,
diff --git a/lib/Driver/ToolChains.h b/lib/Driver/ToolChains.h
index 61c559c..6bec807 100644
--- a/lib/Driver/ToolChains.h
+++ b/lib/Driver/ToolChains.h
@@ -537,6 +537,10 @@ public:
   }
 
   unsigned GetDefaultStackProtectorLevel(bool KernelOrKext) const override {
+    // not supported on air/metal
+    if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+      return 0;
+
     // Stack protectors default to on for user code on 10.5,
     // and for everything in 10.6 and beyond
     if (isTargetIOSBased() || isTargetWatchOSBased())
diff --git a/lib/Driver/Tools.cpp b/lib/Driver/Tools.cpp
index c1d68bc..b492d66 100644
--- a/lib/Driver/Tools.cpp
+++ b/lib/Driver/Tools.cpp
@@ -3993,6 +3993,16 @@ void Clang::ConstructJob(Compilation &C, const JobAction &JA,
     } else if (JA.getType() == types::TY_LLVM_BC ||
                JA.getType() == types::TY_LTO_BC) {
       CmdArgs.push_back("-emit-llvm-bc");
+    } else if (JA.getType() == types::TY_LLVM_BC_32) {
+      CmdArgs.push_back("-emit-llvm-bc"); // order matters
+      CmdArgs.push_back("-llvm-bc-32");
+    } else if (JA.getType() == types::TY_LLVM_BC_35) {
+      CmdArgs.push_back("-emit-llvm-bc"); // order matters
+      CmdArgs.push_back("-llvm-bc-35");
+    } else if (JA.getType() == types::TY_SPIRV) {
+      CmdArgs.push_back("-emit-spirv");
+    } else if (JA.getType() == types::TY_SPIRVC) {
+      CmdArgs.push_back("-emit-spirv-container");
     } else if (JA.getType() == types::TY_PP_Asm) {
       CmdArgs.push_back("-S");
     } else if (JA.getType() == types::TY_AST) {
@@ -4013,7 +4023,7 @@ void Clang::ConstructJob(Compilation &C, const JobAction &JA,
     // loading the bitcode up in 'opt' or 'llc' and running passes gives the
     // same result as running passes here.  For LTO, we don't need to preserve
     // the use-list order, since serialization to bitcode is part of the flow.
-    if (JA.getType() == types::TY_LLVM_BC)
+    if (JA.getType() == types::TY_LLVM_BC) // NOTE: don't do this for 3.2/3.5
       CmdArgs.push_back("-emit-llvm-uselists");
 
     if (D.isUsingLTO())
@@ -6879,6 +6889,8 @@ void gcc::Compiler::RenderExtraToolArgs(const JobAction &JA,
   case types::TY_LLVM_IR:
   case types::TY_LTO_IR:
   case types::TY_LLVM_BC:
+  case types::TY_LLVM_BC_32:
+  case types::TY_LLVM_BC_35:
   case types::TY_LTO_BC:
     CmdArgs.push_back("-c");
     break;
@@ -7487,6 +7499,8 @@ llvm::Triple::ArchType darwin::getArchTypeForMachOArchName(StringRef Str) {
       .Case("nvptx64", llvm::Triple::nvptx64)
       .Case("amdil", llvm::Triple::amdil)
       .Case("spir", llvm::Triple::spir)
+      .Case("spir64", llvm::Triple::spir64)
+      .Case("air64", llvm::Triple::air64)
       .Default(llvm::Triple::UnknownArch);
 }
 
diff --git a/lib/Driver/Types.cpp b/lib/Driver/Types.cpp
index f8e1e40..fff00d4 100644
--- a/lib/Driver/Types.cpp
+++ b/lib/Driver/Types.cpp
@@ -97,6 +97,8 @@ bool types::isAcceptedByClang(ID Id) {
   case TY_ObjCXXHeader: case TY_PP_ObjCXXHeader:
   case TY_AST: case TY_ModuleFile:
   case TY_LLVM_IR: case TY_LLVM_BC:
+  case TY_LLVM_BC_32: case TY_LLVM_BC_35:
+  case TY_SPIRV: case TY_SPIRVC:
     return true;
   }
 }
@@ -135,6 +137,8 @@ bool types::isLLVMIR(ID Id) {
 
   case TY_LLVM_IR:
   case TY_LLVM_BC:
+  case TY_LLVM_BC_32:
+  case TY_LLVM_BC_35:
   case TY_LTO_IR:
   case TY_LTO_BC:
     return true;
@@ -174,6 +178,10 @@ types::ID types::lookupTypeForExtension(const char *Ext) {
            .Case("mi", TY_PP_ObjC)
            .Case("mm", TY_ObjCXX)
            .Case("bc", TY_LLVM_BC)
+           .Case("bc32", TY_LLVM_BC_32) // not ideal
+           .Case("bc35", TY_LLVM_BC_35) // not ideal
+           .Case("spv", TY_SPIRV)
+           .Case("spvc", TY_SPIRVC)
            .Case("cc", TY_CXX)
            .Case("CC", TY_CXX)
            .Case("cl", TY_CL)
diff --git a/lib/Edit/RewriteObjCFoundationAPI.cpp b/lib/Edit/RewriteObjCFoundationAPI.cpp
index 0ae1ec7..2148316 100644
--- a/lib/Edit/RewriteObjCFoundationAPI.cpp
+++ b/lib/Edit/RewriteObjCFoundationAPI.cpp
@@ -1076,6 +1076,7 @@ static bool rewriteToNumericBoxedExpression(const ObjCMessageExpr *Msg,
     case CK_CopyAndAutoreleaseBlockObject:
     case CK_BuiltinFnToFnPtr:
     case CK_ZeroToOCLEvent:
+    case CK_ZeroToOCLQueue:
     case CK_IntToOCLSampler:
       return false;
 
diff --git a/lib/Frontend/CompilerInstance.cpp b/lib/Frontend/CompilerInstance.cpp
index 89907f1..e6281f1 100644
--- a/lib/Frontend/CompilerInstance.cpp
+++ b/lib/Frontend/CompilerInstance.cpp
@@ -903,6 +903,10 @@ bool CompilerInstance::ExecuteAction(FrontendAction &Act) {
 /// \brief Determine the appropriate source input kind based on language
 /// options.
 static InputKind getSourceInputKindFromOptions(const LangOptions &LangOpts) {
+  if (LangOpts.Metal)
+    return IK_Metal;
+  if (LangOpts.Vulkan)
+    return IK_Vulkan;
   if (LangOpts.OpenCL)
     return IK_OpenCL;
   if (LangOpts.CUDA)
diff --git a/lib/Frontend/CompilerInvocation.cpp b/lib/Frontend/CompilerInvocation.cpp
index 97c37de..e678fb3 100644
--- a/lib/Frontend/CompilerInvocation.cpp
+++ b/lib/Frontend/CompilerInvocation.cpp
@@ -45,6 +45,7 @@
 #include "llvm/Support/ScopedPrinter.h"
 #include <atomic>
 #include <memory>
+#include <fstream>
 #include <sys/stat.h>
 #include <system_error>
 using namespace clang;
@@ -82,7 +83,8 @@ using namespace llvm::opt;
 static unsigned getOptimizationLevel(ArgList &Args, InputKind IK,
                                      DiagnosticsEngine &Diags) {
   unsigned DefaultOpt = 0;
-  if (IK == IK_OpenCL && !Args.hasArg(OPT_cl_opt_disable))
+  if ((IK == IK_OpenCL || IK == IK_Metal || IK == IK_Vulkan) &&
+      !Args.hasArg(OPT_cl_opt_disable))
     DefaultOpt = 2;
 
   if (Arg *A = Args.getLastArg(options::OPT_O_Group)) {
@@ -561,7 +563,9 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
   Opts.DiscardValueNames = Args.hasArg(OPT_discard_value_names);
   Opts.DisableTailCalls = Args.hasArg(OPT_mdisable_tail_calls);
   Opts.FloatABI = Args.getLastArgValue(OPT_mfloat_abi);
-  Opts.LessPreciseFPMAD = Args.hasArg(OPT_cl_mad_enable);
+  Opts.LessPreciseFPMAD = Args.hasArg(OPT_cl_mad_enable) ||
+                          Args.hasArg(OPT_cl_unsafe_math_optimizations) ||
+                          Args.hasArg(OPT_cl_fast_relaxed_math);
   Opts.LimitFloatPrecision = Args.getLastArgValue(OPT_mlimit_float_precision);
   Opts.NoInfsFPMath = (Args.hasArg(OPT_menable_no_infinities) ||
                        Args.hasArg(OPT_cl_finite_math_only) ||
@@ -634,6 +638,13 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
   Opts.MainFileName = Args.getLastArgValue(OPT_main_file_name);
   Opts.VerifyModule = !Args.hasArg(OPT_disable_llvm_verifier);
 
+  Opts.DenormsAreZero = Args.hasArg(OPT_cl_denorms_are_zero);
+  Opts.CorrectFPDivideSqrt = Args.hasArg(OPT_cl_fp32_correctly_rounded_divide_sqrt);
+  Opts.OptDisable = Args.hasArg(OPT_cl_opt_disable);
+  Opts.NoSignedZeros = Args.hasArg(OPT_fno_signed_zeros) ||
+                       Args.hasArg(OPT_cl_unsafe_math_optimizations) ||
+                       Args.hasArg(OPT_cl_fast_relaxed_math);
+
   Opts.DisableGCov = Args.hasArg(OPT_test_coverage);
   Opts.EmitGcovArcs = Args.hasArg(OPT_femit_coverage_data);
   Opts.EmitGcovNotes = Args.hasArg(OPT_femit_coverage_notes);
@@ -700,7 +711,17 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
   Opts.XRayInstructionThreshold =
       getLastArgIntValue(Args, OPT_fxray_instruction_threshold_, 200, Diags);
   Opts.InstrumentForProfiling = Args.hasArg(OPT_pg);
-  Opts.EmitOpenCLArgMetadata = Args.hasArg(OPT_cl_kernel_arg_info);
+  Opts.EmitOpenCLArgMetadata = (Args.hasArg(OPT_cl_kernel_arg_info) ||
+                                Args.hasArg(OPT_emit_spirv) ||
+                                Args.hasArg(OPT_emit_spirv_container));
+  if (IK == IK_Metal) {
+    // dwarf version must always be 2 for metal/air
+    Opts.DwarfVersion = 2;
+  }
+  Opts.MetalIntelWorkarounds = Args.hasArg(OPT_metal_intel_workarounds);
+  Opts.MetalNvidiaWorkarounds = Args.hasArg(OPT_metal_nvidia_workarounds);
+  Opts.MetalNoArrayImage = Args.hasArg(OPT_metal_no_array_image);
+  Opts.SPIRIntelWorkarounds = Args.hasArg(OPT_cl_spir_intel_workarounds);
   Opts.CompressDebugSections = Args.hasArg(OPT_compress_debug_sections);
   Opts.RelaxELFRelocations = Args.hasArg(OPT_mrelax_relocations);
   Opts.DebugCompilationDir = Args.getLastArgValue(OPT_fdebug_compilation_dir);
@@ -780,6 +801,7 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
     }
   }
 
+  Opts.SPIRCompileOptions = Args.getLastArgValue(OPT_cl_spir_compile_options).trim("\t\n\v\f\r\" ");
   if (Arg *A = Args.getLastArg(OPT_ffp_contract)) {
     StringRef Val = A->getValue();
     if (Val == "fast")
@@ -1099,6 +1121,14 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
       Opts.ProgramAction = frontend::EmitAssembly; break;
     case OPT_emit_llvm_bc:
       Opts.ProgramAction = frontend::EmitBC; break;
+    case OPT_llvm_bc_32:
+      Opts.ProgramAction = frontend::EmitBC32; break;
+    case OPT_llvm_bc_35:
+      Opts.ProgramAction = frontend::EmitBC35; break;
+    case OPT_emit_spirv:
+      Opts.ProgramAction = frontend::EmitSPIRV; break;
+    case OPT_emit_spirv_container:
+      Opts.ProgramAction = frontend::EmitSPIRVContainer; break;
     case OPT_emit_html:
       Opts.ProgramAction = frontend::EmitHTML; break;
     case OPT_emit_llvm:
@@ -1293,6 +1323,8 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
     DashX = llvm::StringSwitch<InputKind>(A->getValue())
       .Case("c", IK_C)
       .Case("cl", IK_OpenCL)
+      .Case("metal", IK_Metal)
+      .Case("vulkan", IK_Vulkan)
       .Case("cuda", IK_CUDA)
       .Case("c++", IK_CXX)
       .Case("objective-c", IK_ObjC)
@@ -1307,6 +1339,8 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
       .Case("objc++-cpp-output", IK_PreprocessedObjCXX)
       .Case("c-header", IK_C)
       .Case("cl-header", IK_OpenCL)
+      .Case("metal-header", IK_Metal)
+      .Case("vulkan-header", IK_Vulkan)
       .Case("objective-c-header", IK_ObjC)
       .Case("c++-header", IK_CXX)
       .Case("objective-c++-header", IK_ObjCXX)
@@ -1507,6 +1541,12 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     case IK_OpenCL:
       LangStd = LangStandard::lang_opencl;
       break;
+    case IK_Metal:
+      LangStd = LangStandard::lang_metal11;
+      break;
+    case IK_Vulkan:
+      LangStd = LangStandard::lang_vulkan10;
+      break;
     case IK_CUDA:
     case IK_PreprocessedCuda:
       LangStd = LangStandard::lang_cuda;
@@ -1558,6 +1598,24 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     Opts.OpenCLVersion = 120;
   else if (LangStd == LangStandard::lang_opencl20)
     Opts.OpenCLVersion = 200;
+  else if (LangStd == LangStandard::lang_opencl21)
+    Opts.OpenCLVersion = 210;
+  else if (LangStd == LangStandard::lang_opencl22)
+    Opts.OpenCLVersion = 220;
+
+  // as Metal is largely compiled as OpenCL, also enable + init opencl
+  if (LangStd == LangStandard::lang_metal11 || IK == IK_Metal) {
+    Opts.Metal = 1;
+    Opts.OpenCL = 1;
+    Opts.OpenCLVersion = 120;
+  }
+
+  // as Vulkan is largely compiled as OpenCL, also enable + init opencl
+  if (LangStd == LangStandard::lang_vulkan10 || IK == IK_Vulkan) {
+    Opts.Vulkan = 1;
+    Opts.OpenCL = 1;
+    Opts.OpenCLVersion = 200;
+  }
 
   // OpenCL has some additional defaults.
   if (Opts.OpenCL) {
@@ -1655,10 +1713,20 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
             << A->getAsString(Args) << "C++/ObjC++";
         break;
       case IK_OpenCL:
-        if (!isOpenCL(LangStd))
+        if (!Std.isC99() && !Std.isCPlusPlus())
           Diags.Report(diag::err_drv_argument_not_allowed_with)
             << A->getAsString(Args) << "OpenCL";
         break;
+      case IK_Metal:
+        if (!Std.isCPlusPlus())
+          Diags.Report(diag::err_drv_argument_not_allowed_with)
+            << A->getAsString(Args) << "Metal";
+        break;
+      case IK_Vulkan:
+        if (!Std.isCPlusPlus())
+          Diags.Report(diag::err_drv_argument_not_allowed_with)
+            << A->getAsString(Args) << "Vulkan";
+        break;
       case IK_CUDA:
       case IK_PreprocessedCuda:
         if (!Std.isCPlusPlus())
@@ -1676,10 +1744,12 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   if (const Arg *A = Args.getLastArg(OPT_cl_std_EQ)) {
     LangStandard::Kind OpenCLLangStd
     = llvm::StringSwitch<LangStandard::Kind>(A->getValue())
-    .Cases("cl", "CL", LangStandard::lang_opencl)
-    .Cases("cl1.1", "CL1.1", LangStandard::lang_opencl11)
-    .Cases("cl1.2", "CL1.2", LangStandard::lang_opencl12)
-    .Cases("cl2.0", "CL2.0", LangStandard::lang_opencl20)
+    .Case("CL", LangStandard::lang_opencl)
+    .Case("CL1.1", LangStandard::lang_opencl11)
+    .Case("CL1.2", LangStandard::lang_opencl12)
+    .Case("CL2.0", LangStandard::lang_opencl20)
+    .Case("CL2.1", LangStandard::lang_opencl21)
+    .Case("CL2.2", LangStandard::lang_opencl22)
     .Default(LangStandard::lang_unspecified);
 
     if (OpenCLLangStd == LangStandard::lang_unspecified) {
@@ -1707,6 +1777,28 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
       << VerSpec << Args.getLastArg(OPT_cl_strict_aliasing)->getAsString(Args);
   }
 
+  // open libfloor function info file
+  if (const Arg *A = Args.getLastArg(OPT_floor_function_info)) {
+    if (A->getValue() != nullptr && strlen(A->getValue()) > 0) {
+      Opts.floor_function_info = new std::fstream(A->getValue(), std::ios::out | std::ios::binary);
+      if (Opts.floor_function_info == nullptr ||
+          !Opts.floor_function_info->is_open()) {
+        Diags.Report(diag::err_drv_floor_function_info);
+      }
+    }
+  }
+
+  // extract libfloor image capabilities
+  if (const Arg *A = Args.getLastArg(OPT_floor_image_capabilities)) {
+    StringRef image_caps = A->getValue();
+    Opts.floor_image_capabilities = (unsigned int)std::stoul(image_caps);
+  }
+
+  // metal lang options
+  if (Args.hasArg(OPT_metal_no_array_image)) {
+    Opts.metal_no_array_image = true;
+  }
+
   // We abuse '-f[no-]gnu-keywords' to force overriding all GNU-extension
   // keywords. This behavior is provided by GCC's poorly named '-fasm' flag,
   // while a subset (the non-C++ GNU keywords) is provided by GCC's
@@ -2143,6 +2235,20 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   Opts.RetainCommentsFromSystemHeaders =
       Args.hasArg(OPT_fretain_comments_from_system_headers);
 
+  Opts.CLEnableHalf = Args.hasArg(OPT_cl_enable_half);
+  Opts.CLVerifySPIR = Args.hasArg(OPT_cl_verify_spir);
+
+  if(const Arg* A = Args.getLastArg(OPT_cl_sampler_type)) {
+      Opts.CLSamplerOpaque  = llvm::StringSwitch<unsigned int>(A->getValue())
+        .Case("i32", 0u)
+        .Case("opaque", 1u)
+        .Default(~0u);
+      if(Opts.CLSamplerOpaque == ~0u)
+        Diags.Report(diag::err_drv_invalid_value) << A->getAsString(Args)
+                                                  << A->getValue();
+  } else
+    Opts.CLSamplerOpaque = 1;
+
   unsigned SSP = getLastArgIntValue(Args, OPT_stack_protector, 0, Diags);
   switch (SSP) {
   default:
@@ -2252,6 +2358,10 @@ static void ParsePreprocessorOutputArgs(PreprocessorOutputOptions &Opts,
   case frontend::ASTView:
   case frontend::EmitAssembly:
   case frontend::EmitBC:
+  case frontend::EmitBC32:
+  case frontend::EmitBC35:
+  case frontend::EmitSPIRV:
+  case frontend::EmitSPIRVContainer:
   case frontend::EmitHTML:
   case frontend::EmitLLVM:
   case frontend::EmitLLVMOnly:
diff --git a/lib/Frontend/FrontendActions.cpp b/lib/Frontend/FrontendActions.cpp
index 706ccea..0e1fb00 100644
--- a/lib/Frontend/FrontendActions.cpp
+++ b/lib/Frontend/FrontendActions.cpp
@@ -750,6 +750,8 @@ void PrintPreambleAction::ExecuteAction() {
   case IK_ObjC:
   case IK_ObjCXX:
   case IK_OpenCL:
+  case IK_Metal:
+  case IK_Vulkan:
   case IK_CUDA:
     break;
       
diff --git a/lib/Frontend/InitPreprocessor.cpp b/lib/Frontend/InitPreprocessor.cpp
index f8b912e..2598023 100644
--- a/lib/Frontend/InitPreprocessor.cpp
+++ b/lib/Frontend/InitPreprocessor.cpp
@@ -109,11 +109,14 @@ static void AddImplicitIncludePCH(MacroBuilder &Builder, Preprocessor &PP,
 /// PickFP - This is used to pick a value based on the FP semantics of the
 /// specified FP model.
 template <typename T>
-static T PickFP(const llvm::fltSemantics *Sem, T IEEESingleVal,
+static T PickFP(const llvm::fltSemantics *Sem,
+				T IEEEHalfVal, T IEEESingleVal,
                 T IEEEDoubleVal, T X87DoubleExtendedVal, T PPCDoubleDoubleVal,
                 T IEEEQuadVal) {
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEsingle)
     return IEEESingleVal;
+  if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEhalf)
+    return IEEEHalfVal;
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEdouble)
     return IEEEDoubleVal;
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::x87DoubleExtended)
@@ -127,26 +130,26 @@ static T PickFP(const llvm::fltSemantics *Sem, T IEEESingleVal,
 static void DefineFloatMacros(MacroBuilder &Builder, StringRef Prefix,
                               const llvm::fltSemantics *Sem, StringRef Ext) {
   const char *DenormMin, *Epsilon, *Max, *Min;
-  DenormMin = PickFP(Sem, "1.40129846e-45", "4.9406564584124654e-324",
+  DenormMin = PickFP(Sem, "6.10352e-5", "1.40129846e-45", "4.9406564584124654e-324",
                      "3.64519953188247460253e-4951",
                      "4.94065645841246544176568792868221e-324",
                      "6.47517511943802511092443895822764655e-4966");
-  int Digits = PickFP(Sem, 6, 15, 18, 31, 33);
-  int DecimalDigits = PickFP(Sem, 9, 17, 21, 33, 36);
-  Epsilon = PickFP(Sem, "1.19209290e-7", "2.2204460492503131e-16",
+  int Digits = PickFP(Sem, 3, 6, 15, 18, 31, 33);
+  int DecimalDigits = PickFP(Sem, 6, 9, 17, 21, 33, 36);
+  Epsilon = PickFP(Sem, "0x1.0p-10", "1.19209290e-7", "2.2204460492503131e-16",
                    "1.08420217248550443401e-19",
                    "4.94065645841246544176568792868221e-324",
                    "1.92592994438723585305597794258492732e-34");
-  int MantissaDigits = PickFP(Sem, 24, 53, 64, 106, 113);
-  int Min10Exp = PickFP(Sem, -37, -307, -4931, -291, -4931);
-  int Max10Exp = PickFP(Sem, 38, 308, 4932, 308, 4932);
-  int MinExp = PickFP(Sem, -125, -1021, -16381, -968, -16381);
-  int MaxExp = PickFP(Sem, 128, 1024, 16384, 1024, 16384);
-  Min = PickFP(Sem, "1.17549435e-38", "2.2250738585072014e-308",
+  int MantissaDigits = PickFP(Sem, 11, 24, 53, 64, 106, 113);
+  int Min10Exp = PickFP(Sem, -4, -37, -307, -4931, -291, -4931);
+  int Max10Exp = PickFP(Sem, 4, 38, 308, 4932, 308, 4932);
+  int MinExp = PickFP(Sem, -13, -125, -1021, -16381, -968, -16381);
+  int MaxExp = PickFP(Sem, 16, 128, 1024, 16384, 1024, 16384);
+  Min = PickFP(Sem, "0x1.0p-14", "1.17549435e-38", "2.2250738585072014e-308",
                "3.36210314311209350626e-4932",
                "2.00416836000897277799610805135016e-292",
                "3.36210314311209350626267781732175260e-4932");
-  Max = PickFP(Sem, "3.40282347e+38", "1.7976931348623157e+308",
+  Max = PickFP(Sem, "0x1.ffcp15", "3.40282347e+38", "1.7976931348623157e+308",
                "1.18973149535723176502e+4932",
                "1.79769313486231580793728971405301e+308",
                "1.18973149535723176508575932662800702e+4932");
@@ -425,6 +428,8 @@ static void InitializeStandardPredefinedMacros(const TargetInfo &TI,
       Builder.defineMacro("__OPENCL_C_VERSION__", "120");
       break;
     case 200:
+    case 210:
+    case 220:
       Builder.defineMacro("__OPENCL_C_VERSION__", "200");
       break;
     default:
@@ -741,6 +746,7 @@ static void InitializePredefinedMacros(const TargetInfo &TI,
   DefineFmt("__UINTPTR", TI.getUIntPtrType(), TI, Builder);
   DefineTypeWidth("__UINTPTR_WIDTH__", TI.getUIntPtrType(), TI, Builder);
 
+  DefineFloatMacros(Builder, "HALF", &TI.getHalfFormat(), "H");
   DefineFloatMacros(Builder, "FLT", &TI.getFloatFormat(), "F");
   DefineFloatMacros(Builder, "DBL", &TI.getDoubleFormat(), "");
   DefineFloatMacros(Builder, "LDBL", &TI.getLongDoubleFormat(), "L");
@@ -983,6 +989,9 @@ void clang::InitializePreprocessor(
   llvm::raw_string_ostream Predefines(PredefineBuffer);
   MacroBuilder Builder(Predefines);
 
+  // Setup pragma support
+  PP.setSupportedPragmas(InitOpts.SupportedPragmas);
+
   // Emit line markers for various builtin sections of the file.  We don't do
   // this in asm preprocessor mode, because "# 4" is not a line marker directive
   // in this mode.
diff --git a/lib/FrontendTool/ExecuteCompilerInvocation.cpp b/lib/FrontendTool/ExecuteCompilerInvocation.cpp
index 13cb52a..9c6cbc9 100644
--- a/lib/FrontendTool/ExecuteCompilerInvocation.cpp
+++ b/lib/FrontendTool/ExecuteCompilerInvocation.cpp
@@ -46,6 +46,10 @@ CreateFrontendBaseAction(CompilerInstance &CI) {
   case DumpTokens:             return llvm::make_unique<DumpTokensAction>();
   case EmitAssembly:           return llvm::make_unique<EmitAssemblyAction>();
   case EmitBC:                 return llvm::make_unique<EmitBCAction>();
+  case EmitBC32:               return llvm::make_unique<EmitBC32Action>();
+  case EmitBC35:               return llvm::make_unique<EmitBC35Action>();
+  case EmitSPIRV:              return llvm::make_unique<EmitSPIRVAction>();
+  case EmitSPIRVContainer:     return llvm::make_unique<EmitSPIRVContainerAction>();
   case EmitHTML:               return llvm::make_unique<HTMLPrintAction>();
   case EmitLLVM:               return llvm::make_unique<EmitLLVMAction>();
   case EmitLLVMOnly:           return llvm::make_unique<EmitLLVMOnlyAction>();
diff --git a/lib/Headers/CMakeLists.txt b/lib/Headers/CMakeLists.txt
index 600fece..a89b378 100644
--- a/lib/Headers/CMakeLists.txt
+++ b/lib/Headers/CMakeLists.txt
@@ -22,12 +22,7 @@ set(files
   avxintrin.h
   bmi2intrin.h
   bmiintrin.h
-  __clang_cuda_cmath.h
-  __clang_cuda_intrinsics.h
-  __clang_cuda_math_forward_declares.h
-  __clang_cuda_runtime_wrapper.h
   cpuid.h
-  cuda_builtin_vars.h
   clflushoptintrin.h
   emmintrin.h
   f16cintrin.h
@@ -50,7 +45,6 @@ set(files
   module.modulemap
   mwaitxintrin.h
   nmmintrin.h
-  opencl-c.h
   pkuintrin.h
   pmmintrin.h
   popcntintrin.h
diff --git a/lib/Lex/LiteralSupport.cpp b/lib/Lex/LiteralSupport.cpp
index 23bbace..b05ac39 100644
--- a/lib/Lex/LiteralSupport.cpp
+++ b/lib/Lex/LiteralSupport.cpp
@@ -560,8 +560,6 @@ NumericLiteralParser::NumericLiteralParser(StringRef TokSpelling,
     switch (*s) {
     case 'h':      // FP Suffix for "half".
     case 'H':
-      // OpenCL Extension v1.2 s9.5 - h or H suffix for half type.
-      if (!PP.getLangOpts().Half) break;
       if (!isFPConstant) break;  // Error for integer constant.
       if (isHalf || isFloat || isLong) break; // HH, FH, LH invalid.
       isHalf = true;
@@ -579,7 +577,6 @@ NumericLiteralParser::NumericLiteralParser(StringRef TokSpelling,
       if (isHalf || isFloat || isLong || isFloat128)
         break; // HQ, FQ, LQ, QQ invalid.
       isFloat128 = true;
-      continue;  // Success.
     case 'u':
     case 'U':
       if (isFPConstant) break;  // Error for floating constant.
diff --git a/lib/Lex/PPDirectives.cpp b/lib/Lex/PPDirectives.cpp
index 3f94d21..e8d2751 100644
--- a/lib/Lex/PPDirectives.cpp
+++ b/lib/Lex/PPDirectives.cpp
@@ -2143,7 +2143,7 @@ bool Preprocessor::ReadMacroDefinitionArgList(MacroInfo *MI, Token &Tok) {
              diag::ext_variadic_macro);
 
       // OpenCL v1.2 s6.9.e: variadic macros are not supported.
-      if (LangOpts.OpenCL) {
+      if (LangOpts.OpenCL && !LangOpts.CPlusPlus) {
         Diag(Tok, diag::err_pp_opencl_variadic_macros);
         return true;
       }
diff --git a/lib/Parse/ParseDecl.cpp b/lib/Parse/ParseDecl.cpp
index 0459cb7..dbbfa30 100644
--- a/lib/Parse/ParseDecl.cpp
+++ b/lib/Parse/ParseDecl.cpp
@@ -670,23 +670,6 @@ void Parser::ParseBorlandTypeAttributes(ParsedAttributes &attrs) {
   }
 }
 
-void Parser::ParseOpenCLKernelAttributes(ParsedAttributes &attrs) {
-  // Treat these like attributes
-  while (Tok.is(tok::kw___kernel)) {
-    IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-    SourceLocation AttrNameLoc = ConsumeToken();
-    attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-                 AttributeList::AS_Keyword);
-  }
-}
-
-void Parser::ParseOpenCLQualifiers(ParsedAttributes &Attrs) {
-  IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-  SourceLocation AttrNameLoc = Tok.getLocation();
-  Attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-               AttributeList::AS_Keyword);
-}
-
 void Parser::ParseNullabilityTypeSpecifiers(ParsedAttributes &attrs) {
   // Treat these like attributes, even though they're type specifiers.
   while (true) {
@@ -2671,7 +2654,6 @@ Parser::DiagnoseMissingSemiAfterTagDefinition(DeclSpec &DS, AccessSpecifier AS,
 /// [C99]   'inline'
 /// [C++]   'virtual'
 /// [C++]   'explicit'
-/// [OpenCL] '__kernel'
 ///       'friend': [C++ dcl.friend]
 ///       'constexpr': [C++0x dcl.constexpr]
 void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
@@ -3130,11 +3112,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
       ParseBorlandTypeAttributes(DS.getAttributes());
       continue;
 
-    // OpenCL single token adornments.
-    case tok::kw___kernel:
-      ParseOpenCLKernelAttributes(DS.getAttributes());
-      continue;
-
     // Nullability type specifiers.
     case tok::kw__Nonnull:
     case tok::kw__Nullable:
@@ -3391,12 +3368,26 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
       }
       isInvalid = DS.SetTypePipe(true, Loc, PrevSpec, DiagID, Policy);
       break;
-#define GENERIC_IMAGE_TYPE(ImgType, Id) \
-  case tok::kw_##ImgType##_t: \
-    isInvalid = DS.SetTypeSpecType(DeclSpec::TST_##ImgType##_t, Loc, PrevSpec, \
-                                   DiagID, Policy); \
-    break;
-#include "clang/Basic/OpenCLImageTypes.def"
+    case tok::kw_sampler_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_sampler_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_event_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_event_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_queue_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_queue_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_clk_event_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_clk_event_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_reserve_id_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_reserve_id_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
     case tok::kw___unknown_anytype:
       isInvalid = DS.SetTypeSpecType(TST_unknown_anytype, Loc,
                                      PrevSpec, DiagID, Policy);
@@ -3498,26 +3489,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
                                  getLangOpts());
       break;
 
-    // OpenCL qualifiers:
-    case tok::kw___generic:
-      // generic address space is introduced only in OpenCL v2.0
-      // see OpenCL C Spec v2.0 s6.5.5
-      if (Actions.getLangOpts().OpenCLVersion < 200) {
-        DiagID = diag::err_opencl_unknown_type_specifier;
-        PrevSpec = Tok.getIdentifierInfo()->getNameStart();
-        isInvalid = true;
-        break;
-      };
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
     case tok::less:
       // GCC ObjC supports types like "<SomeProtocol>" as a synonym for
       // "id<SomeProtocol>".  This is hopelessly old fashioned and dangerous,
@@ -3751,10 +3722,10 @@ void Parser::ParseStructUnionBody(SourceLocation RecordLoc,
       ExpectAndConsume(tok::r_paren);
     }
 
-    if (TryConsumeToken(tok::semi))
+    if (TryConsumeToken(tok::semi)) {
       continue;
 
-    if (Tok.is(tok::r_brace)) {
+    } else if (Tok.is(tok::r_brace) && !getLangOpts().OpenCL) {
       ExpectAndConsume(tok::semi, diag::ext_expected_semi_decl_list);
       break;
     }
@@ -4332,8 +4303,12 @@ bool Parser::isKnownToBeTypeSpecifier(const Token &Tok) const {
   case tok::kw__Decimal64:
   case tok::kw__Decimal128:
   case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
 
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
@@ -4407,8 +4382,12 @@ bool Parser::isTypeSpecifierQualifier() {
   case tok::kw__Decimal64:
   case tok::kw__Decimal128:
   case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
 
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
@@ -4451,17 +4430,11 @@ bool Parser::isTypeSpecifierQualifier() {
 
   case tok::kw___kindof:
 
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-
     return true;
 
+  case tok::kw_reserve_id_t:
+    return getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200;
+
   // C11 _Atomic
   case tok::kw__Atomic:
     return true;
@@ -4563,6 +4536,13 @@ bool Parser::isDeclarationSpecifier(bool DisambiguatingWithExpression) {
   case tok::kw__Decimal128:
   case tok::kw___vector:
 
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
+  case tok::kw_reserve_id_t:
+
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
   case tok::kw_struct:
@@ -4637,18 +4617,6 @@ bool Parser::isDeclarationSpecifier(bool DisambiguatingWithExpression) {
   case tok::kw__Null_unspecified:
 
   case tok::kw___kindof:
-
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
-
     return true;
   }
 }
@@ -4828,22 +4796,6 @@ void Parser::ParseTypeQualifierListOpt(DeclSpec &DS, unsigned AttrReqs,
                                  getLangOpts());
       break;
 
-    // OpenCL qualifiers:
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-    case tok::kw___generic:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
-    case tok::kw___unaligned:
-      isInvalid = DS.SetTypeQual(DeclSpec::TQ_unaligned, Loc, PrevSpec, DiagID,
-                                 getLangOpts());
-      break;
     case tok::kw___uptr:
       // GNU libc headers in C mode use '__uptr' as an identifer which conflicts
       // with the MS modifier keyword.
@@ -5041,6 +4993,8 @@ void Parser::ParseDeclaratorInternal(Declarator &D,
 
   tok::TokenKind Kind = Tok.getKind();
 
+  // Add pipe type info, only if it is not already there. (It may already been
+  // added by the recursive call).
   if (D.getDeclSpec().isTypeSpecPipe() && !isPipeDeclerator(D)) {
     DeclSpec DS(AttrFactory);
     ParseTypeQualifierListOpt(DS);
diff --git a/lib/Parse/ParseExpr.cpp b/lib/Parse/ParseExpr.cpp
index 3788b18..36dc577 100644
--- a/lib/Parse/ParseExpr.cpp
+++ b/lib/Parse/ParseExpr.cpp
@@ -473,12 +473,14 @@ Parser::ParseRHSOfBinaryExpression(ExprResult LHS, prec::Level MinPrec) {
 ///
 ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
                                        bool isAddressOfOperand,
-                                       TypeCastState isTypeCast) {
+                                       TypeCastState isTypeCast,
+                                       bool isVectorLiteral) {
   bool NotCastExpr;
   ExprResult Res = ParseCastExpression(isUnaryExpression,
                                        isAddressOfOperand,
                                        NotCastExpr,
-                                       isTypeCast);
+                                       isTypeCast,
+                                       isVectorLiteral);
   if (NotCastExpr)
     Diag(Tok, diag::err_expected_expression);
   return Res;
@@ -694,7 +696,8 @@ class CastExpressionIdValidator : public CorrectionCandidateCallback {
 ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
                                        bool isAddressOfOperand,
                                        bool &NotCastExpr,
-                                       TypeCastState isTypeCast) {
+                                       TypeCastState isTypeCast,
+                                       bool isVectorLiteral) {
   ExprResult Res;
   tok::TokenKind SavedKind = Tok.getKind();
   NotCastExpr = false;
@@ -722,6 +725,11 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
     Res = ParseParenExpression(ParenExprType, false/*stopIfCastExr*/,
                                isTypeCast == IsTypeCast, CastTy, RParenLoc);
 
+    if (isVectorLiteral)
+    {
+        return Res;
+    }
+
     switch (ParenExprType) {
     case SimpleExpr:   break;    // Nothing else to do.
     case CompoundStmt: break;  // Nothing else to do.
@@ -1049,7 +1057,7 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
   case tok::amp: {         // unary-expression: '&' cast-expression
     // Special treatment because of member pointers
     SourceLocation SavedLoc = ConsumeToken();
-    Res = ParseCastExpression(false, true);
+    Res = ParseCastExpression(false, true, NotTypeCast, false);
     if (!Res.isInvalid())
       Res = Actions.ActOnUnaryOp(getCurScope(), SavedLoc, SavedKind, Res.get());
     return Res;
@@ -1104,6 +1112,9 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
     if (Tok.isNot(tok::identifier))
       return ExprError(Diag(Tok, diag::err_expected) << tok::identifier);
 
+    if (getLangOpts().OpenCL)
+      return ExprError(Diag(Tok, diag::err_opencl_address_of_label));
+
     if (getCurScope()->getFnParent() == nullptr)
       return ExprError(Diag(Tok, diag::err_address_of_label_outside_fn));
     
@@ -1177,10 +1188,11 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
   case tok::kw_void:
   case tok::kw_typename:
   case tok::kw_typeof:
-  case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
-  {
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
+  case tok::kw___vector: {
     if (!getLangOpts().CPlusPlus) {
       Diag(Tok, diag::err_expected_expression);
       return ExprError();
@@ -1369,7 +1381,7 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
 
   // These can be followed by postfix-expr pieces.
   Res = ParsePostfixExpressionSuffix(Res);
-  if (getLangOpts().OpenCL)
+  if (getLangOpts().OpenCL && !getLangOpts().CPlusPlus)
     if (Expr *PostfixExpr = Res.get()) {
       QualType Ty = PostfixExpr->getType();
       if (!Ty.isNull() && Ty->isFunctionType()) {
@@ -2341,6 +2353,48 @@ Parser::ParseParenExpression(ParenParseOption &ExprType, bool stopIfCastExpr,
         return ParseCompoundLiteralExpression(Ty.get(), OpenLoc, RParenLoc);
       }
 
+      if (Tok.is(tok::l_paren)) {
+        // This could be OpenCL vector Literals
+        if (getLangOpts().OpenCL)
+        {
+          TypeResult Ty;
+          {
+            InMessageExpressionRAIIObject InMessage(*this, false);
+            Ty = Actions.ActOnTypeName(getCurScope(), DeclaratorInfo);
+          }
+          if(Ty.isInvalid())
+          {
+             return ExprError();
+          }
+          QualType QT = Ty.get().get().getCanonicalType();
+          if (QT->isVectorType())
+          {
+            // We parsed '(' vector-type-name ')' followed by '('
+
+            // Parse the cast-expression that follows it next.
+            // isVectorLiteral = true will make sure we don't parse any
+            // Postfix expression yet
+            Result = ParseCastExpression(/*isUnaryExpression=*/false,
+                                         /*isAddressOfOperand=*/false,
+                                         /*isTypeCast=*/IsTypeCast,
+                                         /*isVectorLiteral=*/true);
+
+            if (!Result.isInvalid()) {
+              Result = Actions.ActOnCastExpr(getCurScope(), OpenLoc,
+                                             DeclaratorInfo, CastTy,
+                                             RParenLoc, Result.get());
+            }
+
+            // After we performed the cast we can check for postfix-expr pieces.
+            if (!Result.isInvalid()) {
+              Result = ParsePostfixExpressionSuffix(Result);
+            }
+
+            return Result;
+          }
+        }
+      }
+
       if (ExprType == CastExpr) {
         // We parsed '(' type-name ')' and the thing after it wasn't a '{'.
 
diff --git a/lib/Parse/ParsePragma.cpp b/lib/Parse/ParsePragma.cpp
index bff5d11..72b3468 100644
--- a/lib/Parse/ParsePragma.cpp
+++ b/lib/Parse/ParsePragma.cpp
@@ -467,6 +467,7 @@ void Parser::HandlePragmaOpenCLExtension() {
   SourceLocation NameLoc = Tok.getLocation();
   ConsumeToken(); // The annotation token.
 
+  OpenCLOptions &af = Actions.getASTContext().OpenCLFeatures;
   OpenCLOptions &f = Actions.getOpenCLOptions();
   auto CLVer = getLangOpts().OpenCLVersion;
   auto &Supp = getTargetInfo().getSupportedOpenCLOpts();
@@ -476,12 +477,12 @@ void Parser::HandlePragmaOpenCLExtension() {
   if (state == 0 && ename->isStr("all")) {
 #define OPENCLEXT(nm) \
     if (Supp.is_##nm##_supported_extension(CLVer)) \
-      f.nm = 0;
+      { f.nm = 0; af.nm = 0; }
 #include "clang/Basic/OpenCLExtensions.def"
   }
 #define OPENCLEXT(nm) else if (ename->isStr(#nm)) \
    if (Supp.is_##nm##_supported_extension(CLVer)) \
-     f.nm = state; \
+     { f.nm = state; af.nm = state; } \
    else if (Supp.is_##nm##_supported_core(CLVer)) \
      PP.Diag(NameLoc, diag::warn_pragma_extension_is_core) << ename; \
    else \
@@ -2104,12 +2105,6 @@ void PragmaUnrollHintHandler::HandlePragma(Preprocessor &PP,
     if (ParseLoopHintValue(PP, Tok, PragmaName, Option, ValueInParens, *Info))
       return;
 
-    // In CUDA, the argument to '#pragma unroll' should not be contained in
-    // parentheses.
-    if (PP.getLangOpts().CUDA && ValueInParens)
-      PP.Diag(Info->Toks[0].getLocation(),
-              diag::warn_pragma_unroll_cuda_value_in_parens);
-
     if (Tok.isNot(tok::eod)) {
       PP.Diag(Tok.getLocation(), diag::warn_pragma_extra_tokens_at_eol)
           << "unroll";
diff --git a/lib/Parse/ParseStmtAsm.cpp b/lib/Parse/ParseStmtAsm.cpp
index 1f63dc2..033435d 100644
--- a/lib/Parse/ParseStmtAsm.cpp
+++ b/lib/Parse/ParseStmtAsm.cpp
@@ -344,14 +344,6 @@ static bool isTypeQualifier(const Token &Tok) {
   case tok::kw_const:
   case tok::kw_volatile:
   case tok::kw_restrict:
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
     return true;
   }
 }
diff --git a/lib/Parse/ParseTentative.cpp b/lib/Parse/ParseTentative.cpp
index 556fbf3..0a25654 100644
--- a/lib/Parse/ParseTentative.cpp
+++ b/lib/Parse/ParseTentative.cpp
@@ -1064,8 +1064,10 @@ Parser::isExpressionOrTypeSpecifierSimple(tok::TokenKind Kind) {
   case tok::kw___pixel:
   case tok::kw___bool:
   case tok::kw__Atomic:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
   case tok::kw___unknown_anytype:
     return TPResult::False;
 
diff --git a/lib/Sema/DeclSpec.cpp b/lib/Sema/DeclSpec.cpp
index 42d4633..aff42f7 100644
--- a/lib/Sema/DeclSpec.cpp
+++ b/lib/Sema/DeclSpec.cpp
@@ -337,6 +337,11 @@ bool Declarator::isDeclarationOfFunction() const {
     case TST_wchar:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) case TST_##ImgType##_t:
 #include "clang/Basic/OpenCLImageTypes.def"
+    case TST_sampler_t:
+    case TST_event_t:
+    case TST_queue_t:
+    case TST_clk_event_t:
+    case TST_reserve_id_t:
       return false;
 
     case TST_decltype_auto:
@@ -514,6 +519,11 @@ const char *DeclSpec::getSpecifierName(DeclSpec::TST T,
   case DeclSpec::TST_##ImgType##_t: \
     return #ImgType "_t";
 #include "clang/Basic/OpenCLImageTypes.def"
+  case DeclSpec::TST_sampler_t:   return "sampler_t";
+  case DeclSpec::TST_event_t:     return "event_t";
+  case DeclSpec::TST_queue_t:     return "queue_t";
+  case DeclSpec::TST_clk_event_t: return "clk_event_t";
+  case DeclSpec::TST_reserve_id_t: return "reserve_id_t";
   case DeclSpec::TST_error:       return "(error)";
   }
   llvm_unreachable("Unknown typespec!");
diff --git a/lib/Sema/Sema.cpp b/lib/Sema/Sema.cpp
index 081d45b..e94e2d1 100644
--- a/lib/Sema/Sema.cpp
+++ b/lib/Sema/Sema.cpp
@@ -74,7 +74,9 @@ Sema::Sema(Preprocessor &pp, ASTContext &ctxt, ASTConsumer &consumer,
            TranslationUnitKind TUKind,
            CodeCompleteConsumer *CodeCompleter)
   : ExternalSource(nullptr),
-    isMultiplexExternalSource(false), FPFeatures(pp.getLangOpts()),
+    isMultiplexExternalSource(false),
+    OpenCLFeatures(),
+    FPFeatures(pp.getLangOpts()),
     LangOpts(pp.getLangOpts()), PP(pp), Context(ctxt), Consumer(consumer),
     Diags(PP.getDiagnostics()), SourceMgr(PP.getSourceManager()),
     CollectStats(false), CodeCompleter(CodeCompleter),
@@ -216,6 +218,10 @@ void Sema::Initialize() {
        getOpenCLOptions().Ext = 1;
 #include "clang/Basic/OpenCLExtensions.def"
 
+#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
+    addImplicitTypedef(#ImgType #Suffix "_t", Context. SingletonId);
+#include "clang/Basic/OpenCLImageTypes.def"
+
     addImplicitTypedef("sampler_t", Context.OCLSamplerTy);
     addImplicitTypedef("event_t", Context.OCLEventTy);
     if (getLangOpts().OpenCLVersion >= 200) {
diff --git a/lib/Sema/SemaAttr.cpp b/lib/Sema/SemaAttr.cpp
index bad9e70..0aa61f4 100644
--- a/lib/Sema/SemaAttr.cpp
+++ b/lib/Sema/SemaAttr.cpp
@@ -454,9 +454,12 @@ void Sema::ActOnPragmaFPContract(tok::OnOffSwitch OOS) {
     break;
   case tok::OOS_OFF:
     FPFeatures.fp_contract = 0; 
+    Context.disableFPContract();
     break;
   case tok::OOS_DEFAULT:
     FPFeatures.fp_contract = getLangOpts().DefaultFPContract;
+    if (0 == getLangOpts().DefaultFPContract)
+      Context.disableFPContract();
     break;
   }
 }
diff --git a/lib/Sema/SemaCUDA.cpp b/lib/Sema/SemaCUDA.cpp
index 6f94e54..b77bb97 100644
--- a/lib/Sema/SemaCUDA.cpp
+++ b/lib/Sema/SemaCUDA.cpp
@@ -45,22 +45,13 @@ Sema::CUDAFunctionTarget Sema::IdentifyCUDATarget(const FunctionDecl *D) {
   if (D->hasAttr<CUDAInvalidTargetAttr>())
     return CFT_InvalidTarget;
 
-  if (D->hasAttr<CUDAGlobalAttr>())
+  if (D->hasAttr<ComputeKernelAttr>())
     return CFT_Global;
 
-  if (D->hasAttr<CUDADeviceAttr>()) {
-    if (D->hasAttr<CUDAHostAttr>())
-      return CFT_HostDevice;
-    return CFT_Device;
-  } else if (D->hasAttr<CUDAHostAttr>()) {
-    return CFT_Host;
-  } else if (D->isImplicit()) {
-    // Some implicit declarations (like intrinsic functions) are not marked.
-    // Set the most lenient target on them for maximal flexibility.
-    return CFT_HostDevice;
-  }
-
-  return CFT_Host;
+  // if not a kernel, always default to device
+  // this is IMO a much saner approach and doesn't require to add the __device__
+  // attribute to _all_ functions
+  return CFT_Device;
 }
 
 // * CUDA Call preference table
@@ -446,7 +437,7 @@ void Sema::maybeAddCUDAHostDeviceAttrs(Scope *S, FunctionDecl *NewD,
   assert(getLangOpts().CUDA && "May be called only for CUDA compilations.");
   if (!getLangOpts().CUDAHostDeviceConstexpr || !NewD->isConstexpr() ||
       NewD->isVariadic() || NewD->hasAttr<CUDAHostAttr>() ||
-      NewD->hasAttr<CUDADeviceAttr>() || NewD->hasAttr<CUDAGlobalAttr>())
+      NewD->hasAttr<CUDADeviceAttr>() || NewD->hasAttr<ComputeKernelAttr>())
     return;
 
   // Is D a __device__ function with the same signature as NewD, ignoring CUDA
diff --git a/lib/Sema/SemaCast.cpp b/lib/Sema/SemaCast.cpp
index e19020c..c7862ba 100644
--- a/lib/Sema/SemaCast.cpp
+++ b/lib/Sema/SemaCast.cpp
@@ -2526,6 +2526,12 @@ void CastOperation::CheckCStyleCast() {
       SrcExpr = ExprError();
       return;
     }
+    if (SrcExpr.get()->getType()->isHalfType()) {
+      Self.Diag(SrcExpr.get()->getLocStart(), diag::err_opencl_cast_from_half)
+        << SrcType << SrcExpr.get()->getSourceRange();
+      SrcExpr = ExprError();
+      return;
+    }
   }
 
   // ARC imposes extra restrictions on casts.
diff --git a/lib/Sema/SemaChecking.cpp b/lib/Sema/SemaChecking.cpp
index 6edb251..ebb6860 100644
--- a/lib/Sema/SemaChecking.cpp
+++ b/lib/Sema/SemaChecking.cpp
@@ -480,9 +480,11 @@ static bool SemaOpenCLBuiltinEnqueueKernel(Sema &S, CallExpr *TheCall) {
   return true;
 }
 
-/// Returns OpenCL access qual.
-static OpenCLAccessAttr *getOpenCLArgAccess(const Decl *D) {
-    return D->getAttr<OpenCLAccessAttr>();
+/// Returns libfloor (OpenCL/Metal/Vulkan) access qual.
+static ImageAccessAttr *getImageArgAccess(const Decl *D) {
+  if (D->hasAttr<ImageAccessAttr>())
+    return D->getAttr<ImageAccessAttr>();
+  return nullptr;
 }
 
 /// Returns true if pipe element type is different from the pointer.
@@ -494,8 +496,8 @@ static bool checkOpenCLPipeArg(Sema &S, CallExpr *Call) {
         << Call->getDirectCallee() << Arg0->getSourceRange();
     return true;
   }
-  OpenCLAccessAttr *AccessQual =
-      getOpenCLArgAccess(cast<DeclRefExpr>(Arg0)->getDecl());
+  ImageAccessAttr *AccessQual =
+      getImageArgAccess(cast<DeclRefExpr>(Arg0)->getDecl());
   // Validates the access qualifier is compatible with the call.
   // OpenCL v2.0 s6.13.16 - The access qualifiers for pipe should only be
   // read_only and write_only, and assumed to be read_only if no qualifier is
@@ -1181,6 +1183,42 @@ static QualType getNeonEltType(NeonTypeFlags Flags, ASTContext &Context,
   llvm_unreachable("Invalid NeonTypeFlag!");
 }
 
+static void checkAccessModifier(Sema &S, ImageAccessAttr* Actual,
+                                ImageAccessAttr* Expected, QualType Ty,
+                                SourceLocation Loc, SourceRange Range) {
+  // We allow two types of conversions:
+  // a) anything -> unkown
+  // b) unkown -> read_only
+  if (!Expected || (!Actual && Expected->isReadOnly()))
+    return;
+
+  if (Actual->getSemanticSpelling() == Expected->getSemanticSpelling())
+    return;
+
+  if (Ty->isImageType()) {
+    if (Actual->isReadWrite() || Expected->isReadWrite())
+      return;
+
+    // We assume that the type declaration has some access qualifier, since it
+    // is mandatory. Not doing so should result a syntax error.
+    S.Diag(Loc, diag::err_mismatch_access_qualifiers) <<
+          Actual << Expected << Range;
+    return;
+  }
+
+  if (Ty->isPipeType()) {
+    // Pipe qualifier defaults to read_only.
+    if((!Actual && Expected->isReadOnly()))
+      return;
+
+    // Since read_write is illegal for pipes, we need strict equality.
+    S.Diag(Loc, diag::err_mismatch_access_qualifiers) <<
+          Actual << Expected << Range;
+    return;
+  }
+}
+
+
 bool Sema::CheckNeonBuiltinFunctionCall(unsigned BuiltinID, CallExpr *TheCall) {
   llvm::APSInt Result;
   uint64_t mask = 0;
@@ -2178,6 +2216,47 @@ void Sema::checkCall(NamedDecl *FDecl, const FunctionProtoType *Proto,
         CheckArgumentWithTypeTag(I, Args.data());
     }
   }
+
+  // We don't treat variadic functions, since we can't match the access modifier
+  // in the function declaration.
+  if (!getLangOpts().OpenCL || VariadicDoesNotApply != CallType)
+    return;
+
+  if (!FDecl || !isa<FunctionDecl>(FDecl))
+    return;
+
+  const FunctionDecl *FnDecl = cast<FunctionDecl>(FDecl);
+
+  // Check if overloadble built-in function with floating point arguments takes
+  // integer values.
+  if (FnDecl->hasAttr<OverloadableAttr>()) {
+    for (unsigned Idx = 0; Idx < Args.size(); Idx++) {
+      const Expr *Arg = Args[Idx];
+      const ImplicitCastExpr *ICE = dyn_cast<ImplicitCastExpr>(Arg);
+      if (!ICE || ICE->getCastKind() != CK_IntegralToFloating)
+        continue;
+      Diag(Loc, diag::warn_ocl_bultin_potential_ambiguity) << Range;
+    }
+  }
+
+  // This may indicate that this is a builtin function call, which will be
+  // treated by another part of Sema. (e.g., PipeBiCallSema).
+  if (FnDecl->getNumParams() != Args.size())
+    return;
+
+  // Check whether access attribute are respected.
+  for (unsigned Idx = 0; Idx < Args.size(); Idx++) {
+    const Expr *Arg = Args[Idx];
+    ImageAccessAttr* Expected = getImageArgAccess(FnDecl->getParamDecl(Idx));
+    ImageAccessAttr* Actual = nullptr;
+
+    if (const DeclRefExpr *RefArg = dyn_cast<DeclRefExpr>(Arg->IgnoreImpCasts()))
+      Actual = getImageArgAccess(RefArg->getDecl());
+
+    // Checking that the expected access modifier and the actual one match.
+    checkAccessModifier(*this, Actual, Expected, Arg->getType(),
+                        Arg->getExprLoc(), Range);
+  }
 }
 
 /// CheckConstructorCall - Check a constructor call for correctness and safety
@@ -2225,6 +2304,18 @@ bool Sema::CheckFunctionCall(FunctionDecl *FDecl, CallExpr *TheCall,
   if (getLangOpts().ObjC1)
     DiagnoseCStringFormatDirectiveInCFAPI(*this, FDecl, Args, NumArgs);
 
+  // OpenCL 2.0 Sec. 6.6 prohibits images with 'read_write' qualifier to read
+  // using a sampler.
+  // FIXME: this code is buggy - there should be additional check that TheCall
+  // is OpenCL built-in function call.
+  //if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+  //  if (checkOpenCLRead(TheCall)) {
+  //    Diag(TheCall->getLocStart(), diag::err_read_write_with_samplers) <<
+  //    TheCall->getSourceRange();
+  //    return true;
+  //  }
+  //}
+
   unsigned CMId = FDecl->getMemoryFunctionKind();
   if (CMId == 0)
     return false;
diff --git a/lib/Sema/SemaDecl.cpp b/lib/Sema/SemaDecl.cpp
index 9122030..1dca7ff 100644
--- a/lib/Sema/SemaDecl.cpp
+++ b/lib/Sema/SemaDecl.cpp
@@ -4015,6 +4015,10 @@ Sema::ParsedFreeStandingDeclSpec(Scope *S, AccessSpecifier AS, DeclSpec &DS,
   //   names into the program, or shall redeclare a name introduced by a
   //   previous declaration.
   if (!DeclaresAnything) {
+    if (getLangOpts().OpenCL) {
+      Diag(DS.getLocStart(), diag::err_no_declarators) << DS.getSourceRange();
+      return 0;
+    }
     // In C, we allow this as a (popular) extension / bug. Don't bother
     // producing further diagnostics for redundant qualifiers after this.
     Diag(DS.getLocStart(), diag::ext_no_declarators) << DS.getSourceRange();
@@ -5882,6 +5886,28 @@ NamedDecl *Sema::ActOnVariableDeclarator(
     return nullptr;
   }
 
+  // OpenCL v1.2 s6.5 p5
+  // There is no generic address space name for program scope variables.
+  // All program scope variables must be declared in the __constant address space.
+  if (getLangOpts().OpenCL && !S->getParent() &&
+      LangAS::opencl_constant != R.getAddressSpace()) {
+    // One exception is the sampler_t which can be declared as "const" instead
+    // of "__constant" address space.
+    if (R->isSamplerT() && R.isConstant(Context));
+    else if (R->isOpenCLSpecificType()) {
+      Diag(D.getIdentifierLoc(), diag::err_invalid_type_for_program_scope_var)
+          << R;
+      D.setInvalidType();
+    } else if (getLangOpts().OpenCLVersion < 200) {
+        Diag(D.getIdentifierLoc(), diag::err_program_scope_variable_non_constant);
+        D.setInvalidType();
+    } else if (LangAS::opencl_global != R.getAddressSpace()) {
+      Diag(D.getIdentifierLoc(),
+             diag::err_program_scope_variable_non_constant_or_global);
+      D.setInvalidType();
+    }
+  }
+
   DeclSpec::SCS SCSpec = D.getDeclSpec().getStorageClassSpec();
   StorageClass SC = StorageClassSpecToVarDeclStorageClass(D.getDeclSpec());
 
@@ -5958,17 +5984,17 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       R.getAddressSpace() == LangAS::opencl_global)) {
       Diag(D.getIdentifierLoc(), diag::err_wrong_sampler_addressspace);
     }
+    if (R.getAddressSpace() == LangAS::opencl_constant) {
+      if (SC == SC_Extern)
+        SC = SC_OpenCLConstantExtern;
+      else
+        SC = SC_OpenCLConstant;
+    }
 
     // OpenCL 1.2 spec, p6.9 r:
-    // The event type cannot be used to declare a program scope variable.
     // The event type cannot be used with the __local, __constant and __global
     // address space qualifiers.
     if (R->isEventT()) {
-      if (S->getParent() == nullptr) {
-        Diag(D.getLocStart(), diag::err_event_t_global_var);
-        D.setInvalidType();
-      }
-
       if (R.getAddressSpace()) {
         Diag(D.getLocStart(), diag::err_event_t_addr_space_qual);
         D.setInvalidType();
@@ -6000,6 +6026,8 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       // This is an out-of-line definition of a static data member.
       switch (SC) {
       case SC_None:
+      case SC_OpenCLConstant:
+      case SC_OpenCLConstantExtern:
         break;
       case SC_Static:
         Diag(D.getDeclSpec().getStorageClassSpecLoc(),
@@ -6346,6 +6374,8 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       case SC_Static:
       case SC_Extern:
       case SC_PrivateExtern:
+      case SC_OpenCLConstant:
+      case SC_OpenCLConstantExtern:
         break;
       }
     } else if (SC == SC_Register) {
@@ -6814,11 +6844,27 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
 
   // OpenCL v1.2 s6.8 - The static qualifier is valid only in program
   // scope.
-  if (getLangOpts().OpenCLVersion == 120 &&
-      !getOpenCLOptions().cl_clang_storage_class_specifiers &&
-      NewVD->isStaticLocal()) {
-    Diag(NewVD->getLocation(), diag::err_static_function_scope);
-    NewVD->setInvalidDecl();
+  // (same for Metal, enabled for CUDA as well for compatibility)
+  if (NewVD->isStaticLocal() &&
+      ((getLangOpts().OpenCL &&
+        getLangOpts().OpenCLVersion >= 120 &&
+        !getOpenCLOptions().cl_clang_storage_class_specifiers) ||
+       getLangOpts().CUDA)) {
+    // however, if it is constexpr, this can be safely put into the constant address space
+    if (NewVD->isConstexpr()) {
+      // CUDA (backend) can handle this on its own
+      if (getLangOpts().OpenCL) {
+        QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+        TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+        NewVD->setType(constant_Tinfo->getType());
+        NewVD->setTypeSourceInfo(constant_Tinfo);
+      }
+    }
+    // CUDA shared/local decls are allowed to be static, so ignore them
+    else if(!(getLangOpts().CUDA && NewVD->hasAttr<CUDASharedAttr>())) {
+      Diag(NewVD->getLocation(), diag::err_static_function_scope);
+      NewVD->setInvalidDecl();
+    }
     return;
   }
 
@@ -6855,40 +6901,59 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
         return;
       }
     }
-    // OpenCL v1.2 s6.5 - All program scope variables must be declared in the
-    // __constant address space.
-    // OpenCL v2.0 s6.5.1 - Variables defined at program scope and static
-    // variables inside a function can also be declared in the global
-    // address space.
-    if (NewVD->isFileVarDecl() || NewVD->isStaticLocal() ||
-        NewVD->hasExternalStorage()) {
-      if (!T->isSamplerT() &&
+    if (NewVD->isFileVarDecl()) {
+      if (!T->isSamplerT()) {
+        // if the variable doesn't have an address space, but is a global static const variable,
+        // automatically add the constant address space
+        if (T.getAddressSpace() == 0 &&
+            (NewVD->isStaticDataMember() || NewVD->hasGlobalStorage()) &&
+            T.isConstQualified()) {
+          QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+          TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+          NewVD->setType(constant_Tinfo->getType());
+          NewVD->setTypeSourceInfo(constant_Tinfo);
+        }
+        else {
+          if (!(T.getAddressSpace() == LangAS::opencl_constant ||
+                (T.getAddressSpace() == LangAS::opencl_global &&
+                 getLangOpts().OpenCLVersion >= 200))) {
+            if (getLangOpts().OpenCLVersion >= 200)
+              Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
+                  << "global or constant";
+            else
+              Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
+                  << "constant";
+            NewVD->setInvalidDecl();
+            return;
+          }
+        }
+      }
+    } else {
+      // TODO: does this need automatic "constant" handling?
+
+      // OpenCL v2.0 s6.5.1 - Variables defined at program scope and static
+      // variables inside a function can also be declared in the global
+      // address space.
+      if (NewVD->isStaticLocal() &&
           !(T.getAddressSpace() == LangAS::opencl_constant ||
             (T.getAddressSpace() == LangAS::opencl_global &&
-             getLangOpts().OpenCLVersion == 200))) {
-        int Scope = NewVD->isStaticLocal() | NewVD->hasExternalStorage() << 1;
-        if (getLangOpts().OpenCLVersion == 200)
+             getLangOpts().OpenCLVersion >= 200))) {
+        if (getLangOpts().OpenCLVersion >= 200)
           Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
-              << Scope << "global or constant";
+              << "global or constant";
         else
           Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
-              << Scope << "constant";
-        NewVD->setInvalidDecl();
-        return;
-      }
-    } else {
-      if (T.getAddressSpace() == LangAS::opencl_global) {
-        Diag(NewVD->getLocation(), diag::err_opencl_function_variable)
-            << 1 /*is any function*/ << "global";
+              << "constant";
         NewVD->setInvalidDecl();
         return;
       }
       // OpenCL v1.1 s6.5.2 and s6.5.3 no local or constant variables
       // in functions.
+#if 0 // everything gets inlined, so there is no need for this
       if (T.getAddressSpace() == LangAS::opencl_constant ||
           T.getAddressSpace() == LangAS::opencl_local) {
         FunctionDecl *FD = getCurFunctionDecl();
-        if (FD && !FD->hasAttr<OpenCLKernelAttr>()) {
+        if (FD && !FD->hasAttr<ComputeKernelAttr>()) {
           if (T.getAddressSpace() == LangAS::opencl_constant)
             Diag(NewVD->getLocation(), diag::err_opencl_function_variable)
                 << 0 /*non-kernel only*/ << "constant";
@@ -6899,6 +6964,7 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
           return;
         }
       }
+#endif
     }
   }
 
@@ -6986,6 +7052,24 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
     NewVD->setInvalidDecl();
     return;
   }
+
+  // OpenCL 2.0: Enforce block 6.12.5: block's prototype cannot be variadic.
+  if (getLangOpts().OpenCL && LangOpts.OpenCLVersion >= 200 && T->isBlockPointerType()) {
+    const BlockPointerType *BlkTy = T->getAs<BlockPointerType>();
+    assert(BlkTy && "Not a block pointer.");
+
+    const FunctionProtoType *FTy =
+      BlkTy->getPointeeType()->getAs<FunctionProtoType>();
+    assert(FTy && "Not a function prototype.");
+
+    if (FTy->isVariadic()) {
+      Diag(NewVD->getLocation(), diag::err_block_proto_variadic) << T
+      << NewVD->getSourceRange();
+      NewVD->setInvalidDecl();
+      return;
+    }
+
+  }
 }
 
 /// \brief Perform semantic checking on a newly-created variable
@@ -7508,12 +7592,16 @@ enum OpenCLParamType {
   RecordKernelParam
 };
 
-static OpenCLParamType getOpenCLKernelParameterType(QualType PT) {
+static OpenCLParamType getOpenCLKernelParameterType(QualType PT, const bool is_metal) {
   if (PT->isPointerType()) {
     QualType PointeeType = PT->getPointeeType();
     if (PointeeType->isPointerType())
       return PtrPtrKernelParam;
-    return PointeeType.getAddressSpace() == 0 ? PrivatePtrKernelParam
+
+    unsigned addrSpace = PointeeType.getAddressSpace();
+    return (addrSpace != LangAS::opencl_global &&
+            addrSpace != LangAS::opencl_constant &&
+            addrSpace != LangAS::opencl_local) ? PrivatePtrKernelParam
                                               : PtrKernelParam;
   }
 
@@ -7529,7 +7617,10 @@ static OpenCLParamType getOpenCLKernelParameterType(QualType PT) {
   if (PT->isEventT())
     return InvalidKernelParam;
 
-  if (PT->isHalfType())
+  if (PT->isReserveIDT())
+    return InvalidKernelParam;
+
+  if (PT->isHalfType() && !is_metal)
     return InvalidKernelParam;
 
   if (PT->isRecordType())
@@ -7542,7 +7633,8 @@ static void checkIsValidOpenCLKernelParameter(
   Sema &S,
   Declarator &D,
   ParmVarDecl *Param,
-  llvm::SmallPtrSetImpl<const Type *> &ValidTypes) {
+  llvm::SmallPtrSetImpl<const Type *> &ValidTypes,
+  const bool is_metal) {
   QualType PT = Param->getType();
 
   // Cache the valid types we encounter to avoid rechecking structs that are
@@ -7550,7 +7642,7 @@ static void checkIsValidOpenCLKernelParameter(
   if (ValidTypes.count(PT.getTypePtr()))
     return;
 
-  switch (getOpenCLKernelParameterType(PT)) {
+  switch (getOpenCLKernelParameterType(PT, is_metal)) {
   case PtrPtrKernelParam:
     // OpenCL v1.2 s6.9.a:
     // A kernel function argument cannot be declared as a
@@ -7614,6 +7706,8 @@ static void checkIsValidOpenCLKernelParameter(
       continue;
     }
 
+    // TODO: this should also check base classes
+
     // Adds everything except the original parameter declaration (which is not a
     // field itself) to the history stack.
     const RecordDecl *RD;
@@ -7627,13 +7721,17 @@ static void checkIsValidOpenCLKernelParameter(
     // Add a null marker so we know when we've gone back up a level
     VisitStack.push_back(nullptr);
 
+    // if this is an aggregate of images, all is well
+    if (RD->getTypeForDecl()->isAggregateImageType())
+      continue;
+
     for (const auto *FD : RD->fields()) {
       QualType QT = FD->getType();
 
       if (ValidTypes.count(QT.getTypePtr()))
         continue;
 
-      OpenCLParamType ParamType = getOpenCLKernelParameterType(QT);
+      OpenCLParamType ParamType = getOpenCLKernelParameterType(QT, is_metal);
       if (ParamType == ValidKernelParam)
         continue;
 
@@ -8570,7 +8668,7 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
     // -fcuda-allow-variadic-functions.
     if (!getLangOpts().CUDAAllowVariadicFunctions && NewFD->isVariadic() &&
         (NewFD->hasAttr<CUDADeviceAttr>() ||
-         NewFD->hasAttr<CUDAGlobalAttr>()) &&
+         NewFD->hasAttr<ComputeKernelAttr>()) &&
         !(II && II->isStr("printf") && NewFD->isExternC() &&
           !D.isFunctionDefinition())) {
       Diag(NewFD->getLocation(), diag::err_variadic_device_fn);
@@ -8585,15 +8683,8 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
     }
   }
 
-  if (NewFD->hasAttr<OpenCLKernelAttr>()) {
-    // OpenCL v1.2 s6.8 static is invalid for kernel functions.
-    if ((getLangOpts().OpenCLVersion >= 120)
-        && (SC == SC_Static)) {
-      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
-      D.setInvalidType();
-    }
-
-    // OpenCL v1.2, s6.9 -- Kernels can only have return type void.
+  if (NewFD->hasAttr<ComputeKernelAttr>()) {
+    // Kernels can only have return type void.
     if (!NewFD->getReturnType()->isVoidType()) {
       SourceRange RTRange = NewFD->getReturnTypeSourceRange();
       Diag(D.getIdentifierLoc(), diag::err_expected_kernel_void_return_type)
@@ -8601,10 +8692,23 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
                                 : FixItHint());
       D.setInvalidType();
     }
+  }
 
-    llvm::SmallPtrSet<const Type *, 16> ValidTypes;
-    for (auto Param : NewFD->parameters())
-      checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes);
+  if(NewFD->hasAttr<ComputeKernelAttr>() ||
+     NewFD->hasAttr<GraphicsVertexShaderAttr>() ||
+     NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    // static is invalid for kernel/vertex/fragment functions.
+    if (SC == SC_Static) {
+      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
+      D.setInvalidType();
+    }
+
+    // only check this for opencl/metal/vulkan
+    if (getLangOpts().OpenCL) {
+      llvm::SmallPtrSet<const Type *, 16> ValidTypes;
+      for (auto Param : NewFD->parameters())
+        checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes, getLangOpts().Metal);
+    }
   }
   for (const ParmVarDecl *Param : NewFD->parameters()) {
     QualType PT = Param->getType();
@@ -8913,7 +9017,10 @@ bool Sema::CheckFunctionDeclaration(Scope *S, FunctionDecl *NewFD,
     // the function returns a UDT (class, struct, or union type) that is not C
     // compatible, and if it does, warn the user.
     // But, issue any diagnostic on the first declaration only.
-    if (Previous.empty() && NewFD->isExternC()) {
+    if (Previous.empty() && NewFD->isExternC() &&
+        // ignore this for vertex/fragment shaders
+        !NewFD->hasAttr<GraphicsVertexShaderAttr>() &&
+        !NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
       QualType R = NewFD->getReturnType();
       if (R->isIncompleteType() && !R->isVoidType())
         Diag(NewFD->getLocation(), diag::warn_return_value_udt_incomplete)
@@ -8954,9 +9061,10 @@ void Sema::CheckMain(FunctionDecl* FD, const DeclSpec& DS) {
     FD->setConstexpr(false);
   }
 
-  if (getLangOpts().OpenCL) {
+  // TODO: this doesn't seem necessary?
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
     Diag(FD->getLocation(), diag::err_opencl_no_main)
-        << FD->hasAttr<OpenCLKernelAttr>();
+        << FD->hasAttr<ComputeKernelAttr>();
     FD->setInvalidDecl();
     return;
   }
@@ -9828,7 +9936,8 @@ void Sema::AddInitializerToDecl(Decl *RealDecl, Expr *Init,
     // C++ does not have this restriction.
     if (!getLangOpts().CPlusPlus && !VDecl->isInvalidDecl()) {
       const Expr *Culprit;
-      if (VDecl->getStorageClass() == SC_Static)
+      if (VDecl->getStorageClass() == SC_Static ||
+          VDecl->getStorageClass() == SC_OpenCLConstant)
         CheckForConstantInitializer(Init, DclT);
       // C89 is stricter than C99 for non-static aggregate types.
       // C89 6.5.7p3: All the expressions [...] in an initializer list
@@ -10090,7 +10199,7 @@ void Sema::ActOnUninitializedDecl(Decl *RealDecl,
     // be initialized.
     if (!Var->isInvalidDecl() &&
         Var->getType().getAddressSpace() == LangAS::opencl_constant &&
-        Var->getStorageClass() != SC_Extern && !Var->getInit()) {
+        Var->getStorageClass() != SC_OpenCLConstantExtern && !Var->getInit()) {
       Diag(Var->getLocation(), diag::err_opencl_constant_no_init);
       Var->setInvalidDecl();
       return;
@@ -10302,6 +10411,9 @@ void Sema::ActOnCXXForRangeDecl(Decl *D) {
   case SC_Register:
     Error = 4;
     break;
+  case SC_OpenCLConstant:
+  case SC_OpenCLConstantExtern:
+    llvm_unreachable("Unexpected storage class");
   }
   if (Error != -1) {
     Diag(VD->getOuterLocStart(), diag::err_for_range_storage_class)
@@ -10588,18 +10700,21 @@ Sema::FinalizeDeclaration(Decl *ThisDecl) {
         NewAttr->setInherited(true);
         VD->addAttr(NewAttr);
       }
+#if 0 // nope
       // CUDA E.2.9.4: Within the body of a __device__ or __global__
       // function, only __shared__ variables may be declared with
       // static storage class.
       if (getLangOpts().CUDA && getLangOpts().CUDAIsDevice &&
-          (FD->hasAttr<CUDADeviceAttr>() || FD->hasAttr<CUDAGlobalAttr>()) &&
+          (FD->hasAttr<CUDADeviceAttr>() || FD->hasAttr<ComputeKernelAttr>()) &&
           !VD->hasAttr<CUDASharedAttr>()) {
         Diag(VD->getLocation(), diag::err_device_static_local_var);
         VD->setInvalidDecl();
       }
+#endif
     }
   }
 
+#if 0 // again: nope, also incomplete
   // Perform check for initializers of device-side global variables.
   // CUDA allows empty constructors as initializers (see E.2.3.1, CUDA
   // 7.5). We must also apply the same checks to all __shared__
@@ -10657,6 +10772,7 @@ Sema::FinalizeDeclaration(Decl *ThisDecl) {
       }
     }
   }
+#endif
 
   // Grab the dllimport or dllexport attribute off of the VarDecl.
   const InheritableAttr *DLLAttr = getDLLAttr(VD);
@@ -11133,10 +11249,16 @@ ParmVarDecl *Sema::CheckParameter(DeclContext *DC, SourceLocation StartLoc,
   if (T.getAddressSpace() != 0) {
     // OpenCL allows function arguments declared to be an array of a type
     // to be qualified with an address space.
-    if (!(getLangOpts().OpenCL && T->isArrayType())) {
+    if (!((getLangOpts().OpenCL || getLangOpts().CUDA) && T->isArrayType())) {
       Diag(NameLoc, diag::err_arg_with_address_space);
       New->setInvalidDecl();
     }
+  }   
+  // Passing pointer to image is invalid in OpenCL.
+  if (getLangOpts().OpenCL && T->isPointerType() &&
+      T->getPointeeType()->isImageType()) {
+    Diag(NameLoc, diag::err_opencl_pointer_to_image);
+    New->setInvalidDecl();
   }
 
   return New;
@@ -11178,6 +11300,28 @@ void Sema::ActOnFinishKNRParamDeclarations(Scope *S, Declarator &D,
   }
 }
 
+static void AggregateTypeCompleter(Sema& S, const CXXRecordDecl* decl) {
+	if(decl == nullptr) return;
+	
+	// make sure decl is complete
+	S.RequireCompleteType(decl->getLocStart(), QualType(decl->getTypeForDecl(), 0),
+						  diag::err_typecheck_decl_incomplete_type);
+	
+	// must have definition
+	if(!decl->hasDefinition()) return;
+	
+	// iterate over / recurse into all bases, and complete all their fields
+	for(const auto& base : decl->bases()) {
+		AggregateTypeCompleter(S, base.getType()->getAsCXXRecordDecl());
+	}
+	
+	// iterate over and complete all fields
+	for(const auto& field : decl->fields()) {
+		S.RequireCompleteType(field->getLocStart(), field->getType(),
+							  diag::err_typecheck_decl_incomplete_type);
+	}
+}
+
 Decl *
 Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Declarator &D,
                               MultiTemplateParamsArg TemplateParameterLists,
@@ -11225,8 +11369,10 @@ static bool ShouldWarnAboutMissingPrototype(const FunctionDecl *FD,
   if (FD->isFunctionTemplateSpecialization())
     return false;
 
-  // Don't warn for OpenCL kernels.
-  if (FD->hasAttr<OpenCLKernelAttr>())
+  // Don't warn for compute kernels, or vertex/fragment shaders.
+  if (FD->hasAttr<ComputeKernelAttr>() ||
+      FD->hasAttr<GraphicsVertexShaderAttr>() ||
+      FD->hasAttr<GraphicsFragmentShaderAttr>())
     return false;
 
   // Don't warn on explicitly deleted functions.
@@ -11405,6 +11551,32 @@ Decl *Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Decl *D,
   CheckParmsForFunctionDef(FD->parameters(),
                            /*CheckParameterNames=*/true);
 
+  // for kernel and shader functions: make sure that function parameter types are complete,
+  // including pointer/pointee types that must always be complete as well, since their sizes
+  // and (possibly) structure need to be known later on
+  if(FD->hasAttr<ComputeKernelAttr>() ||
+     FD->hasAttr<GraphicsVertexShaderAttr>() ||
+     FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    for (const auto& Param : FD->parameters()) {
+      const auto param_type = Param->getType();
+      const CXXRecordDecl* cxx_rdecl = nullptr;
+      if(param_type->isPointerType()) {
+        const auto pointee_type = param_type->getPointeeType();
+        RequireCompleteType(Param->getLocation(), pointee_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = pointee_type->getAsCXXRecordDecl();
+      }
+      else {
+        RequireCompleteType(Param->getLocation(), param_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = param_type->getAsCXXRecordDecl();
+      }
+
+      // if this is an aggregate, ensure that all contained types are also complete
+      AggregateTypeCompleter(*this, cxx_rdecl);
+    }
+  }
+
   // Introduce our parameters into the function scope
   for (auto Param : FD->parameters()) {
     Param->setOwningFunction(FD);
@@ -11854,6 +12026,9 @@ NamedDecl *Sema::ImplicitlyDefineFunction(SourceLocation Loc,
   unsigned diag_id;
   if (II.getName().startswith("__builtin_"))
     diag_id = diag::warn_builtin_unknown;
+  else if (getLangOpts().OpenCL)
+    // Don't allow imlicit function declarations in OpenCL
+    diag_id = diag::err_opencl_implicit_function_decl;
   else if (getLangOpts().C99)
     diag_id = diag::ext_implicit_function_decl;
   else
@@ -13604,7 +13779,7 @@ FieldDecl *Sema::CheckFieldDecl(DeclarationName Name, QualType T,
   }
 
   // OpenCL v1.2 s6.9.c: bitfields are not supported.
-  if (BitWidth && getLangOpts().OpenCL) {
+  if (BitWidth && getLangOpts().OpenCL && !getLangOpts().CPlusPlus) {
     Diag(Loc, diag::err_opencl_bitfields);
     InvalidDecl = true;
   }
diff --git a/lib/Sema/SemaDeclAttr.cpp b/lib/Sema/SemaDeclAttr.cpp
index 0471f65..bc59622 100644
--- a/lib/Sema/SemaDeclAttr.cpp
+++ b/lib/Sema/SemaDeclAttr.cpp
@@ -84,9 +84,12 @@ static bool hasFunctionProto(const Decl *D) {
 /// parameters. It is an error to call this on a K&R function (use
 /// hasFunctionProto first).
 static unsigned getFunctionOrMethodNumParams(const Decl *D) {
-  if (const FunctionType *FnTy = D->getFunctionType())
-    return cast<FunctionProtoType>(FnTy)->getNumParams();
-  if (const BlockDecl *BD = dyn_cast<BlockDecl>(D))
+  if (const FunctionType *FnTy = D->getFunctionType()) {
+    if (hasFunctionProto(D))
+      return cast<FunctionProtoType>(FnTy)->getNumParams();
+    else return 0;
+  }
+  if (const auto *BD = dyn_cast<BlockDecl>(D))
     return BD->getNumParams();
   return cast<ObjCMethodDecl>(D)->param_size();
 }
@@ -2323,6 +2326,116 @@ static void handleVisibilityAttr(Sema &S, Decl *D, const AttributeList &Attr,
     D->addAttr(newAttr);
 }
 
+static void handleFloorImageDataTypeAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!Attr.hasParsedType()) {
+    S.Diag(Attr.getLoc(), diag::err_attribute_wrong_number_arguments)
+      << Attr.getName() << 1;
+    return;
+  }
+
+  TypeSourceInfo *ParmTSI = nullptr;
+  S.GetTypeFromParser(Attr.getTypeArg(), &ParmTSI);
+  D->addAttr(::new (S.Context) FloorImageDataTypeAttr(Attr.getLoc(), S.Context, ParmTSI,
+                                                      Attr.getAttributeSpellingListIndex()));
+}
+
+static void handleGraphicsFBOColorLocationAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+  S.AddGraphicsFBOColorLocationAttr(Attr.getRange(), D, Attr.getArgAsExpr(0),
+                                    Attr.getAttributeSpellingListIndex());
+}
+
+void Sema::AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E, unsigned SpellingListIndex) {
+  GraphicsFBOColorLocationAttr TmpAttr(AttrRange, Context, E, SpellingListIndex);
+  SourceLocation AttrLoc = AttrRange.getBegin();
+
+  QualType T;
+  if (ValueDecl *VD = dyn_cast<ValueDecl>(D))
+    T = VD->getType();
+  else {
+    Diag(AttrLoc, diag::err_attribute_argument_type) <<
+      &TmpAttr << AANT_ArgumentIntegerConstant;
+    return;
+  }
+
+  // TODO: check usage
+
+  if (!E->isValueDependent()) {
+    // TODO: might want to use/check isPotentialConstantExprUnevaluated
+
+    llvm::APSInt ColorLoc(32);
+    ExprResult ICE
+      = VerifyIntegerConstantExpression(E, &ColorLoc,
+          diag::err_expr_not_ice, /*AllowFold*/ true);
+    if (ICE.isInvalid())
+      return;
+
+    // check for < 0 location
+    if (ColorLoc.isNegative()) {
+      unsigned diagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "%0");
+      Diags.Report(AttrRange.getBegin(), diagID) << "location must not be negative!";
+      return;
+    }
+
+    auto loc_attr = ::new (Context) GraphicsFBOColorLocationAttr(AttrRange, Context, ICE.get(), SpellingListIndex);
+    loc_attr->setEvalLocation((unsigned int)ColorLoc.getZExtValue());
+    D->addAttr(loc_attr);
+    return;
+  }
+
+  // Save dependent expressions in the AST to be instantiated.
+  D->addAttr(::new (Context) GraphicsFBOColorLocationAttr(TmpAttr));
+  return;
+}
+
+static void handleGraphicsFBODepthTypeAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+
+  GraphicsFBODepthTypeAttr::DepthQualifierType type;
+  if (Attr.isArgIdent(0)) {
+    IdentifierLoc *Ident = Attr.getArgAsIdent(0);
+    StringRef TypeString = Ident->Ident->getName();
+
+    if (!GraphicsFBODepthTypeAttr::ConvertStrToDepthQualifierType(TypeString, type)) {
+      S.Diag(Ident->Loc, diag::warn_attribute_type_not_supported)
+        << Attr.getName() << TypeString;
+      return;
+    }
+  }
+  else {
+    S.Diag(Attr.getLoc(), diag::err_attribute_argument_type) <<
+      Attr.getName() << AANT_ArgumentIdentifier;
+    return;
+  }
+
+  D->addAttr(::new (S.Context)
+             GraphicsFBODepthTypeAttr(Attr.getRange(), S.Context, type,
+                                      Attr.getAttributeSpellingListIndex()));
+}
+
+static void handleRangeAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 2)) return;
+
+  llvm::APSInt lower_bound(64), upper_bound(64);
+  ExprResult lower_res
+    = S.VerifyIntegerConstantExpression(Attr.getArgAsExpr(0), &lower_bound,
+        diag::err_expr_not_ice, /*AllowFold*/ true);
+  ExprResult upper_res
+    = S.VerifyIntegerConstantExpression(Attr.getArgAsExpr(1), &upper_bound,
+        diag::err_expr_not_ice, /*AllowFold*/ true);
+  if (lower_res.isInvalid() || upper_res.isInvalid()) return;
+
+  if ((lower_bound.isUnsigned() && lower_bound.getZExtValue() > upper_bound.getZExtValue()) ||
+	  (!lower_bound.isUnsigned() && lower_bound.getExtValue() > upper_bound.getExtValue())) {
+    unsigned diagID = S.getDiagnostics().getCustomDiagID(DiagnosticsEngine::Error, "%0");
+    S.Diag(Attr.getRange().getBegin(), diagID) << "lower bound must be lower than the upper bound";
+    return;
+  }
+
+  D->addAttr(::new (S.Context) RetRangeAttr(Attr.getRange(), S.Context, lower_res.get(), upper_res.get(),
+                                            Attr.getAttributeSpellingListIndex()));
+}
+
 static void handleObjCMethodFamilyAttr(Sema &S, Decl *decl,
                                        const AttributeList &Attr) {
   ObjCMethodDecl *method = cast<ObjCMethodDecl>(decl);
@@ -3696,39 +3809,6 @@ static void handleOptimizeNoneAttr(Sema &S, Decl *D,
     D->addAttr(Optnone);
 }
 
-static void handleGlobalAttr(Sema &S, Decl *D, const AttributeList &Attr) {
-  if (checkAttrMutualExclusion<CUDADeviceAttr>(S, D, Attr.getRange(),
-                                               Attr.getName()) ||
-      checkAttrMutualExclusion<CUDAHostAttr>(S, D, Attr.getRange(),
-                                             Attr.getName())) {
-    return;
-  }
-  FunctionDecl *FD = cast<FunctionDecl>(D);
-  if (!FD->getReturnType()->isVoidType()) {
-    SourceRange RTRange = FD->getReturnTypeSourceRange();
-    S.Diag(FD->getTypeSpecStartLoc(), diag::err_kern_type_not_void_return)
-        << FD->getType()
-        << (RTRange.isValid() ? FixItHint::CreateReplacement(RTRange, "void")
-                              : FixItHint());
-    return;
-  }
-  if (const auto *Method = dyn_cast<CXXMethodDecl>(FD)) {
-    if (Method->isInstance()) {
-      S.Diag(Method->getLocStart(), diag::err_kern_is_nonstatic_method)
-          << Method;
-      return;
-    }
-    S.Diag(Method->getLocStart(), diag::warn_kern_is_method) << Method;
-  }
-  // Only warn for "inline" when compiling for host, to cut down on noise.
-  if (FD->isInlineSpecified() && !S.getLangOpts().CUDAIsDevice)
-    S.Diag(FD->getLocStart(), diag::warn_kern_is_inline) << FD;
-
-  D->addAttr(::new (S.Context)
-              CUDAGlobalAttr(Attr.getRange(), S.Context,
-                             Attr.getAttributeSpellingListIndex()));
-}
-
 static void handleGNUInlineAttr(Sema &S, Decl *D, const AttributeList &Attr) {
   FunctionDecl *Fn = cast<FunctionDecl>(D);
   if (!Fn->isInlineSpecified()) {
@@ -3892,6 +3972,9 @@ bool Sema::CheckCallingConvAttr(const AttributeList &attr, CallingConv &CC,
   case AttributeList::AT_IntelOclBicc: CC = CC_IntelOclBicc; break;
   case AttributeList::AT_PreserveMost: CC = CC_PreserveMost; break;
   case AttributeList::AT_PreserveAll: CC = CC_PreserveAll; break;
+  case AttributeList::AT_GraphicsVertexShader: CC = CC_FloorVertex; break;
+  case AttributeList::AT_GraphicsFragmentShader: CC = CC_FloorFragment; break;
+  case AttributeList::AT_ComputeKernel: CC = CC_FloorKernel; break;
   default: llvm_unreachable("unexpected attribute kind");
   }
 
@@ -5308,40 +5391,6 @@ static bool handleCommonAttributeFeatures(Sema &S, Scope *scope, Decl *D,
   return false;
 }
 
-static void handleOpenCLAccessAttr(Sema &S, Decl *D,
-                                   const AttributeList &Attr) {
-  if (D->isInvalidDecl())
-    return;
-
-  // Check if there is only one access qualifier.
-  if (D->hasAttr<OpenCLAccessAttr>()) {
-    S.Diag(Attr.getLoc(), diag::err_opencl_multiple_access_qualifiers)
-        << D->getSourceRange();
-    D->setInvalidDecl(true);
-    return;
-  }
-
-  // OpenCL v2.0 s6.6 - read_write can be used for image types to specify that an
-  // image object can be read and written.
-  // OpenCL v2.0 s6.13.6 - A kernel cannot read from and write to the same pipe
-  // object. Using the read_write (or __read_write) qualifier with the pipe
-  // qualifier is a compilation error.
-  if (const ParmVarDecl *PDecl = dyn_cast<ParmVarDecl>(D)) {
-    const Type *DeclTy = PDecl->getType().getCanonicalType().getTypePtr();
-    if (Attr.getName()->getName().find("read_write") != StringRef::npos) {
-      if (S.getLangOpts().OpenCLVersion < 200 || DeclTy->isPipeType()) {
-        S.Diag(Attr.getLoc(), diag::err_opencl_invalid_read_write)
-            << Attr.getName() << PDecl->getType() << DeclTy->isImageType();
-        D->setInvalidDecl(true);
-        return;
-      }
-    }
-  }
-
-  D->addAttr(::new (S.Context) OpenCLAccessAttr(
-      Attr.getRange(), S.Context, Attr.getAttributeSpellingListIndex()));
-}
-
 //===----------------------------------------------------------------------===//
 // Top Level Sema Entry Points
 //===----------------------------------------------------------------------===//
@@ -5493,16 +5542,13 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case AttributeList::AT_FormatArg:
     handleFormatArgAttr(S, D, Attr);
     break;
-  case AttributeList::AT_CUDAGlobal:
-    handleGlobalAttr(S, D, Attr);
-    break;
   case AttributeList::AT_CUDADevice:
-    handleSimpleAttributeWithExclusions<CUDADeviceAttr, CUDAGlobalAttr>(S, D,
-                                                                        Attr);
+    handleSimpleAttributeWithExclusions<CUDADeviceAttr, ComputeKernelAttr>(S, D,
+                                                                           Attr);
     break;
   case AttributeList::AT_CUDAHost:
-    handleSimpleAttributeWithExclusions<CUDAHostAttr, CUDAGlobalAttr>(S, D,
-                                                                      Attr);
+    handleSimpleAttributeWithExclusions<CUDAHostAttr, ComputeKernelAttr>(S, D,
+                                                                         Attr);
     break;
   case AttributeList::AT_GNUInline:
     handleGNUInlineAttr(S, D, Attr);
@@ -5750,11 +5796,41 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case AttributeList::AT_PreserveAll:
     handleCallConvAttr(S, D, Attr);
     break;
-  case AttributeList::AT_OpenCLKernel:
-    handleSimpleAttribute<OpenCLKernelAttr>(S, D, Attr);
+  case AttributeList::AT_ComputeKernel:
+    handleSimpleAttribute<ComputeKernelAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsVertexShader:
+    handleSimpleAttribute<GraphicsVertexShaderAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFragmentShader:
+    handleSimpleAttribute<GraphicsFragmentShaderAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_RetRange:
+    handleRangeAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_ImageAccess:
+    handleSimpleAttribute<ImageAccessAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_FloorImageDataType:
+    handleFloorImageDataTypeAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_VectorCompat:
+    handleSimpleAttribute<VectorCompatAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFBOColorLocation:
+    handleGraphicsFBOColorLocationAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFBODepthType:
+    handleGraphicsFBODepthTypeAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsVertexPosition:
+    handleSimpleAttribute<GraphicsVertexPositionAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsPointSize:
+    handleSimpleAttribute<GraphicsPointSizeAttr>(S, D, Attr);
     break;
-  case AttributeList::AT_OpenCLAccess:
-    handleOpenCLAccessAttr(S, D, Attr);
+  case AttributeList::AT_GraphicsStageInput:
+    handleSimpleAttribute<GraphicsStageInputAttr>(S, D, Attr);
     break;
   case AttributeList::AT_OpenCLNoSVM:
     handleOpenCLNoSVMAttr(S, D, Attr);
@@ -5943,7 +6019,7 @@ void Sema::ProcessDeclAttributeList(Scope *S, Decl *D,
   // good to have a way to specify "these attributes must appear as a group",
   // for these. Additionally, it would be good to have a way to specify "these
   // attribute must never appear as a group" for attributes like cold and hot.
-  if (!D->hasAttr<OpenCLKernelAttr>()) {
+  if (!D->hasAttr<ComputeKernelAttr>()) {
     // These attributes cannot be applied to a non-kernel function.
     if (Attr *A = D->getAttr<ReqdWorkGroupSizeAttr>()) {
       // FIXME: This emits a different error message than
diff --git a/lib/Sema/SemaExpr.cpp b/lib/Sema/SemaExpr.cpp
index 4bf17a6..6f14f15 100644
--- a/lib/Sema/SemaExpr.cpp
+++ b/lib/Sema/SemaExpr.cpp
@@ -44,6 +44,7 @@
 #include "clang/Sema/SemaInternal.h"
 #include "clang/Sema/Template.h"
 #include "llvm/Support/ConvertUTF.h"
+#include <sstream>
 using namespace clang;
 using namespace sema;
 
@@ -204,6 +205,96 @@ DiagnoseAvailabilityOfDecl(Sema &S, NamedDecl *D, SourceLocation Loc,
   }
 }
 
+// \brief Preform dynamic type checking on the actual arguments passed to the
+// call.
+static bool CheckEnqueueKernel(const CallExpr *TheCall, ArrayRef<Expr*> Args,
+                               Sema &S) {
+  // The index of the block paramater in overload I.
+  #define BLOCK_INDEX_I   3U
+  // The index of the block paramater in overload II.
+  #define BLOCK_INDEX_II  6U
+
+  // Minimum number of arguments in overload I.
+  #define MIN_NUM_ARGS_I  5U
+  // Minimum number of arguments in overload II.
+  #define MIN_NUM_ARGS_II 8U
+
+  QualType BlkTy;
+
+  // There are two overloads of the function which receives blocks, we need
+  // to figure if the call is one of them.
+  const unsigned NumArgs = Args.size();
+  unsigned BlkIdx = 0;
+
+  if (NumArgs >= MIN_NUM_ARGS_I) {
+    QualType ArgTy = Args[BLOCK_INDEX_I]->getType();
+
+    if (ArgTy->isBlockPointerType()) {
+      BlkTy = ArgTy->getPointeeType();
+      BlkIdx = BLOCK_INDEX_I;
+    }
+    else if (NumArgs >= MIN_NUM_ARGS_II) {
+      ArgTy = Args[BLOCK_INDEX_II]->getType();
+      if (ArgTy->isBlockPointerType()) {
+        BlkTy = ArgTy->getPointeeType();
+        BlkIdx = BLOCK_INDEX_II;
+      }
+    }
+  }
+
+  if (BlkTy.isNull())
+    return false;
+
+  bool Invalid = false;
+
+  // Making sure that if the type is a pointer, it is in local AS.
+  const FunctionProtoType *BlkProto = BlkTy->getAs<FunctionProtoType>();
+  for (unsigned i = 0; i<BlkProto->getNumParams(); i++) {
+    QualType ParmTy = BlkProto->getParamType(i);
+    if (!ParmTy->isPointerType() ||
+        ParmTy->getPointeeType().getAddressSpace() != LangAS::opencl_local) {
+      S.Diag(Args[BlkIdx]->getLocStart(), diag::err_invalid_block_as_parameter)
+             << BlkTy << TheCall->getSourceRange();
+      Invalid = true;
+    }
+  }
+
+  // Making sure that all variadic arguments are of type unsigned int.
+  unsigned VariadicIdx = ((FunctionDecl*)TheCall->getCalleeDecl())->
+           getMinRequiredArguments();
+
+  // Making sure that the number of local arg sizes corresponds the number of
+  // pointers in the block.
+  unsigned NumLocalSizes = NumArgs - VariadicIdx +1;
+  if (BlkProto->getNumParams() != NumLocalSizes) {
+    S.Diag(Args[BlkIdx]->getLocStart(),
+           diag::err_enqueue_kernel_num_args_mismatch) <<
+    TheCall->getSourceRange();
+    Invalid = true;
+  }
+
+ for (unsigned i=(VariadicIdx-1); i<NumArgs; i++) {
+    const Expr *Arg = Args[i];
+    const BuiltinType *BITy = Arg->getType().getCanonicalType()->
+                              getAs<BuiltinType>();
+    if (BITy && (BITy->getKind() == BuiltinType::UInt ||
+                 BITy->getKind() == BuiltinType::ULong ||
+                 BITy->getKind() == BuiltinType::UInt128 ||
+                 BITy->getKind() == BuiltinType::ULongLong)){
+         //at va positions natively accept UInt type
+          //and accept U types to be interpreted as 32bit sizes of local mem
+          continue;
+      }
+      else {
+          S.Diag(Arg->getLocStart(), diag::err_variadic_enqueue_kernel) <<
+          TheCall->getSourceRange();
+          Invalid = true;
+      }
+  }
+
+  return Invalid;
+}
+
 /// \brief Emit a note explaining that this function is deleted.
 void Sema::NoteDeletedFunction(FunctionDecl *Decl) {
   assert(Decl->isDeleted());
@@ -528,7 +619,7 @@ ExprResult Sema::DefaultFunctionArrayConversion(Expr *E, bool Diagnose) {
   if (Ty->isFunctionType()) {
     // If we are here, we are not calling a function but taking
     // its address (which is not allowed in OpenCL v1.0 s6.8.a.3).
-    if (getLangOpts().OpenCL) {
+    if (getLangOpts().OpenCL && !LangOpts.CPlusPlus) {
       if (Diagnose)
         Diag(E->getExprLoc(), diag::err_opencl_taking_function_address);
       return ExprError();
@@ -811,6 +902,35 @@ ExprResult Sema::UsualUnaryConversions(Expr *E) {
   return E;
 }
 
+// Find out which conversion function to call for a vector with the given
+// element type.
+//
+// TODO: unused?
+/*static std::string vec_conversion_function_for_type(BuiltinType::Kind elem_type)
+{
+    switch (elem_type)
+    {
+        case BuiltinType::Float:
+            return "convert_double";
+        case BuiltinType::Char_S:
+        case BuiltinType::SChar:
+        case BuiltinType::Short:
+            return "convert_int";
+        case BuiltinType::Char_U:
+        case BuiltinType::UChar:
+        case BuiltinType::UShort:
+            return "convert_uint";
+        default:
+            // We won't get here because the call to this function will happen
+            // only if elem_type->isPromotableIntegerType(), which apart
+            // from the above types includes bool, and vectors of bools don't
+            // currently exist in OpenCL
+            //
+            assert(0 && "Invalid vector type in conversion");
+            return "";
+    }
+}*/
+
 /// DefaultArgumentPromotion (C99 6.5.2.2p6). Used for function calls that
 /// do not have a prototype. Arguments that have type float or __fp16
 /// are promoted to double. All other argument types are converted by
@@ -824,12 +944,15 @@ ExprResult Sema::DefaultArgumentPromotion(Expr *E) {
     return ExprError();
   E = Res.get();
 
-  // If this is a 'float' or '__fp16' (CVR qualified or typedef) promote to
-  // double.
-  const BuiltinType *BTy = Ty->getAs<BuiltinType>();
-  if (BTy && (BTy->getKind() == BuiltinType::Half ||
-              BTy->getKind() == BuiltinType::Float))
-    E = ImpCastExprToType(E, Context.DoubleTy, CK_FloatingCast).get();
+  if (!getLangOpts().OpenCL || ((getLangOpts().OpenCLVersion >= 120) ||
+                                getOpenCLOptions().cl_khr_fp64)) {
+    // If this is a 'float' or '__fp16' (CVR qualified or typedef) promote to
+    // double.
+    const BuiltinType *BTy = Ty->getAs<BuiltinType>();
+    if (BTy && (BTy->getKind() == BuiltinType::Half ||
+      BTy->getKind() == BuiltinType::Float))
+      E = ImpCastExprToType(E, Context.DoubleTy, CK_FloatingCast).get();
+  }
 
   // C++ performs lvalue-to-rvalue conversion as a default argument
   // promotion, even on class types, but note:
@@ -3384,14 +3507,9 @@ ExprResult Sema::ActOnNumericConstant(const Token &Tok, Scope *UDLScope) {
 
   if (Literal.isFloatingLiteral()) {
     QualType Ty;
-    if (Literal.isHalf){
-      if (getOpenCLOptions().cl_khr_fp16)
-        Ty = Context.HalfTy;
-      else {
-        Diag(Tok.getLocation(), diag::err_half_const_requires_fp16);
-        return ExprError();
-      }
-    } else if (Literal.isFloat)
+    if (Literal.isHalf)
+      Ty = Context.HalfTy;
+    else if (Literal.isFloat)
       Ty = Context.FloatTy;
     else if (Literal.isLong)
       Ty = Context.LongDoubleTy;
@@ -4381,6 +4499,7 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
                                       Expr *Idx, SourceLocation RLoc) {
   Expr *LHSExp = Base;
   Expr *RHSExp = Idx;
+  bool LHSIsPointerType = false;
 
   // Perform default conversions.
   if (!LHSExp->getType()->getAs<VectorType>()) {
@@ -4412,6 +4531,7 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
     BaseExpr = LHSExp;
     IndexExpr = RHSExp;
     ResultType = PTy->getPointeeType();
+    LHSIsPointerType = true;
   } else if (const ObjCObjectPointerType *PTy =
                LHSTy->getAs<ObjCObjectPointerType>()) {
     BaseExpr = LHSExp;
@@ -4512,6 +4632,13 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
                           diag::err_subscript_incomplete_type, BaseExpr))
     return ExprError();
 
+  if (getLangOpts().OpenCL && ResultType->isHalfType() && !LHSIsPointerType &&
+      !getOpenCLOptions().cl_khr_fp16) {
+    Diag(BaseExpr->getLocStart(), diag::err_opencl_subscript) << ResultType <<
+    BaseExpr->getType() << BaseExpr->getSourceRange();
+    return ExprError();
+  }
+
   assert(VK == VK_RValue || LangOpts.CPlusPlus ||
          !ResultType.isCForbiddenLValueType());
 
@@ -5436,7 +5563,7 @@ Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
   if (getLangOpts().CUDA) {
     if (Config) {
       // CUDA: Kernel calls must be to global functions
-      if (FDecl && !FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && !FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc,diag::err_kern_call_not_global_function)
             << FDecl->getName() << Fn->getSourceRange());
 
@@ -5446,12 +5573,17 @@ Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
             << Fn->getType() << Fn->getSourceRange());
     } else {
       // CUDA: Calls to global functions must be configured
-      if (FDecl && FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc, diag::err_global_call_not_config)
             << FDecl->getName() << Fn->getSourceRange());
     }
   }
 
+  if (LangOpts.OpenCL && LangOpts.OpenCLVersion >= 200)
+    if (FDecl && FDecl->getName() == "enqueue_kernel")
+      if(CheckEnqueueKernel(TheCall, Args, *this))
+        return ExprError();
+
   // Check for a valid return type
   if (CheckCallReturnType(FuncT->getReturnType(), Fn->getLocStart(), TheCall,
                           FDecl))
@@ -7939,7 +8071,8 @@ QualType Sema::InvalidOperands(SourceLocation Loc, ExprResult &LHS,
 static bool tryVectorConvertAndSplat(Sema &S, ExprResult *scalar,
                                      QualType scalarTy,
                                      QualType vectorEltTy,
-                                     QualType vectorTy) {
+                                     QualType vectorTy,
+                                     SourceLocation Loc) {
   // The conversion to apply to the scalar before splatting it,
   // if necessary.
   CastKind scalarCast = CK_Invalid;
@@ -7954,8 +8087,14 @@ static bool tryVectorConvertAndSplat(Sema &S, ExprResult *scalar,
   } else if (vectorEltTy->isRealFloatingType()) {
     if (scalarTy->isRealFloatingType()) {
       if (S.getLangOpts().OpenCL &&
-          S.Context.getFloatingTypeOrder(vectorEltTy, scalarTy) < 0)
-        return true;
+          S.Context.getFloatingTypeOrder(vectorEltTy, scalarTy) < 0) {
+          // OpenCL V2.0 6.2.6.p2:
+          // An error shall occur if any scalar operand type has greater rank
+          // than the type of the vector element.
+          S.Diag(Loc, diag::err_scalar_type_rank_greater_than_vector_type)
+            << scalarTy << vectorTy;
+          return true;
+      }
       scalarCast = CK_FloatingCast;
     }
     else if (scalarTy->isIntegralType(S.Context))
@@ -8047,13 +8186,13 @@ QualType Sema::CheckVectorOperands(ExprResult &LHS, ExprResult &RHS,
   // the vector element type and splat.
   if (!RHSVecType && isa<ExtVectorType>(LHSVecType)) {
     if (!tryVectorConvertAndSplat(*this, &RHS, RHSType,
-                                  LHSVecType->getElementType(), LHSType))
+                                  LHSVecType->getElementType(), LHSType, Loc))
       return LHSType;
   }
   if (!LHSVecType && isa<ExtVectorType>(RHSVecType)) {
     if (!tryVectorConvertAndSplat(*this, (IsCompAssign ? nullptr : &LHS),
                                   LHSType, RHSVecType->getElementType(),
-                                  RHSType))
+                                  RHSType, Loc))
       return RHSType;
   }
 
@@ -9534,6 +9673,18 @@ QualType Sema::CheckCompareOperands(ExprResult &LHS, ExprResult &RHS,
     return ResultTy;
   }
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    if (LHSIsNull && RHSType->isQueueT()) {
+      LHS = ImpCastExprToType(LHS.get(), RHSType, CK_NullToPointer);
+      return ResultTy;
+    }
+
+    if (LHSType->isQueueT() && RHSIsNull) {
+      RHS = ImpCastExprToType(RHS.get(), LHSType, CK_NullToPointer);
+      return ResultTy;
+    }
+  }
+
   return InvalidOperands(Loc, LHS, RHS);
 }
 
@@ -10477,7 +10628,7 @@ QualType Sema::CheckAddressOfOperand(ExprResult &OrigOp, SourceLocation OpLoc) {
   Expr *op = OrigOp.get()->IgnoreParens();
 
   // OpenCL v1.0 s6.8.a.3: Pointers to functions are not allowed.
-  if (LangOpts.OpenCL && op->getType()->isFunctionType()) {
+  if (LangOpts.OpenCL && !LangOpts.CPlusPlus && op->getType()->isFunctionType()) {
     Diag(op->getExprLoc(), diag::err_opencl_taking_function_address);
     return QualType();
   }
@@ -10639,6 +10790,14 @@ QualType Sema::CheckAddressOfOperand(ExprResult &OrigOp, SourceLocation OpLoc) {
 
   CheckAddressOfPackedMember(op);
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    const QualType Ty = OrigOp.get()->getType();
+    if (Ty->isBlockPointerType()) {
+      Diag(OpLoc, diag::err_typecheck_unary_expr) << Ty << op->getSourceRange();
+      return QualType();
+    }
+  }
+
   return Context.getPointerType(op->getType());
 }
 
@@ -10679,9 +10838,17 @@ static QualType CheckIndirectionOperand(Sema &S, Expr *Op, ExprValueKind &VK,
                                      Op->getSourceRange());
   }
 
-  if (const PointerType *PT = OpTy->getAs<PointerType>())
-  {
+  if (const PointerType *PT = OpTy->getAs<PointerType>()) {
     Result = PT->getPointeeType();
+    // OpenCL v1.2 s6.1.1.1 p2:
+    // The half data type can only be used to declare a pointer to a buffer that
+    // contains half values
+    if (S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200 &&
+        Result->isBlockPointerType()) {
+      S.Diag(OpLoc, diag::err_opencl_dereferencing) << OpTy
+                                                    << Op->getSourceRange();
+      return QualType();
+    }
   }
   else if (const ObjCObjectPointerType *OPT =
              OpTy->getAs<ObjCObjectPointerType>())
@@ -10895,6 +11062,22 @@ ExprResult Sema::CreateBuiltinBinOp(SourceLocation OpLoc,
     RHSExpr = Init.get();
   }
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    QualType LHSTy = LHSExpr->getType(), RHSTy = RHSExpr->getType();
+    // OpenCL 2.0 Section 6.13.11.1 allows atomic varibles to be initialized by
+    // the ATOMIC_VAR_INIT macro.
+    if (LHSTy->isAtomicType() || RHSTy->isAtomicType()) {
+      SourceRange SR(LHSExpr->getLocStart(), RHSExpr->getLocEnd());
+      if (BO_Assign == Opc)
+        Diag(OpLoc, diag::err_atomic_init_constant) << SR;
+      else {
+        Diag(OpLoc, diag::err_typecheck_invalid_operands) << LHSTy.getAsString()
+        << RHSTy.getAsString() << SR;
+      }
+      return ExprError();
+    }
+  }
+
   ExprResult LHS = LHSExpr, RHS = RHSExpr;
   QualType ResultTy;     // Result type of the binary operator.
   // The following two variables are used for compound assignment operators
@@ -11407,6 +11590,18 @@ ExprResult Sema::BuildBinOp(Scope *S, SourceLocation OpLoc,
 ExprResult Sema::CreateBuiltinUnaryOp(SourceLocation OpLoc,
                                       UnaryOperatorKind Opc,
                                       Expr *InputExpr) {
+
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    QualType Ty = InputExpr->getType();
+
+    // The only legal unary operation for atomics is '&'.
+    if (Opc != UO_AddrOf && Ty->isAtomicType()) {
+        Diag(OpLoc, diag::err_typecheck_unary_expr) << Ty.getAsString() <<
+        InputExpr->getSourceRange();
+        return ExprError();
+    }
+  }
+
   ExprResult Input = InputExpr;
   ExprValueKind VK = VK_RValue;
   ExprObjectKind OK = OK_Ordinary;
@@ -13400,13 +13595,16 @@ static bool captureInBlock(BlockScopeInfo *BSI, VarDecl *Var,
   bool ByRef = false;
       
   // Blocks are not allowed to capture arrays.
-  if (CaptureType->isArrayType()) {
-    if (BuildAndDiagnose) {
-      S.Diag(Loc, diag::err_ref_array_type);
-      S.Diag(Var->getLocation(), diag::note_previous_decl) 
-      << Var->getDeclName();
+  // Only if it's not OpenCL 2.0.
+  if (!(S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200)) {
+    if (CaptureType->isArrayType()) {
+      if (BuildAndDiagnose) {
+        S.Diag(Loc, diag::err_ref_array_type);
+        S.Diag(Var->getLocation(), diag::note_previous_decl)
+          << Var->getDeclName();
+      }
+      return false;
     }
-    return false;
   }
 
   // Forbid the block-capture of autoreleasing variables.
@@ -13421,7 +13619,11 @@ static bool captureInBlock(BlockScopeInfo *BSI, VarDecl *Var,
   }
   const bool HasBlocksAttr = Var->hasAttr<BlocksAttr>();
   if (HasBlocksAttr || CaptureType->isReferenceType() ||
-      (S.getLangOpts().OpenMP && S.IsOpenMPCapturedDecl(Var))) {
+      (S.getLangOpts().OpenMP && S.IsOpenMPCapturedDecl(Var)) ||
+      // This is a unique behavior for OpenCL 2.0, since array capturing is
+      // allowed.
+      (S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200 &&
+       CaptureType->isArrayType())) {
     // Block capture by reference does not change the capture or
     // declaration reference types.
     ByRef = true;
diff --git a/lib/Sema/SemaExprCXX.cpp b/lib/Sema/SemaExprCXX.cpp
index b7a968e..e190cde 100644
--- a/lib/Sema/SemaExprCXX.cpp
+++ b/lib/Sema/SemaExprCXX.cpp
@@ -3699,6 +3699,18 @@ Sema::PerformImplicitConversion(Expr *From, QualType ToType,
                              From->getValueKind()).get();
     break;
 
+  case ICK_Zero_Queue_Conversion:
+    From = ImpCastExprToType(From, ToType,
+                             CK_ZeroToOCLQueue,
+                             From->getValueKind()).get();
+    break;
+
+  case ICK_Int_Sampler_Conversion:
+    From = ImpCastExprToType(From, ToType,
+                             CK_IntToOCLSampler,
+                             From->getValueKind()).get();
+    break;
+
   case ICK_Lvalue_To_Rvalue:
   case ICK_Array_To_Pointer:
   case ICK_Function_To_Pointer:
diff --git a/lib/Sema/SemaExprMember.cpp b/lib/Sema/SemaExprMember.cpp
index 26f52bc..becb1aa 100644
--- a/lib/Sema/SemaExprMember.cpp
+++ b/lib/Sema/SemaExprMember.cpp
@@ -366,6 +366,7 @@ CheckExtVectorComponent(Sema &S, QualType baseType, ExprValueKind &VK,
     if (HexSwizzle)
       compStr++;
 
+    // TODO: add SPIR pass to scalarize all non-{1,2,3,4,8,16} vector uses
     while (*compStr) {
       if (!vecType->isAccessorWithinNumElements(*compStr++, HexSwizzle)) {
         S.Diag(OpLoc, diag::err_ext_vector_component_exceeds_length)
@@ -1793,7 +1794,8 @@ Sema::BuildFieldReferenceExpr(Expr *BaseExpr, bool IsArrow,
     Qualifiers MemberQuals =
         Context.getCanonicalType(MemberType).getQualifiers();
 
-    assert(!MemberQuals.hasAddressSpace());
+    // this should very well be possible
+    //assert(!MemberQuals.hasAddressSpace());
 
     Qualifiers Combined = BaseQuals + MemberQuals;
     if (Combined != MemberQuals)
diff --git a/lib/Sema/SemaInit.cpp b/lib/Sema/SemaInit.cpp
index 386c7ab..8365fbb 100644
--- a/lib/Sema/SemaInit.cpp
+++ b/lib/Sema/SemaInit.cpp
@@ -1171,7 +1171,8 @@ void InitListChecker::CheckSubElementType(const InitializedEntity &Entity,
     }
 
     // Fall through for subaggregate initialization
-  } else if (ElemType->isScalarType() || ElemType->isAtomicType()) {
+  } else if (ElemType->isScalarType() || ElemType->isAtomicType() ||
+             (SemaRef.getLangOpts().OpenCLVersion >= 200 && ElemType->isExecType())) {
     // FIXME: Need to handle atomic aggregate types with implicit init lists.
     return CheckScalarType(Entity, IList, ElemType, Index,
                            StructuredList, StructuredIndex);
@@ -1229,7 +1230,7 @@ void InitListChecker::CheckSubElementType(const InitializedEntity &Entity,
   //   subaggregate, brace elision is assumed and the initializer is
   //   considered for the initialization of the first member of
   //   the subaggregate.
-  if (!SemaRef.getLangOpts().OpenCL && 
+  if (!SemaRef.getLangOpts().OpenCL &&
       (ElemType->isAggregateType() || ElemType->isVectorType())) {
     CheckImplicitInitList(Entity, IList, ElemType, Index, StructuredList,
                           StructuredIndex);
@@ -3060,6 +3061,7 @@ void InitializationSequence::Step::Destroy() {
   case SK_StdInitializerListConstructorCall:
   case SK_OCLSamplerInit:
   case SK_OCLZeroEvent:
+  case SK_OCLZeroQueue:
     break;
 
   case SK_ConversionSequence:
@@ -3321,6 +3323,13 @@ void InitializationSequence::AddOCLZeroEventStep(QualType T) {
   Steps.push_back(S);
 }
 
+void InitializationSequence::AddOCLZeroQueueStep(QualType T) {
+  Step S;
+  S.Kind = SK_OCLZeroQueue;
+  S.Type = T;
+  Steps.push_back(S);
+}
+
 void InitializationSequence::RewrapReferenceInitList(QualType T,
                                                      InitListExpr *Syntactic) {
   assert(Syntactic->getNumInits() == 1 &&
@@ -4354,6 +4363,7 @@ static void TryReferenceInitializationCore(Sema &S,
   //         where "cv1 T1" is reference-compatible with "cv3 T3",
   //
   // DR1287 removes the "implicitly" here.
+  bool isOpenCLASRef = false;
   if (T2->isRecordType()) {
     if (RefRelationship == Sema::Ref_Incompatible) {
       ConvOvlResult = TryRefInitWithConversionFunction(
@@ -4374,8 +4384,15 @@ static void TryReferenceInitializationCore(Sema &S,
       return;
     }
 
-    Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
-    return;
+    if(S.getLangOpts().OpenCL &&
+       ((cv1T1.getAddressSpace() == 0 && cv2T2.getAddressSpace() != 0) ||
+        (cv1T1.getAddressSpace() != 0 && cv2T2.getAddressSpace() == 0))) {
+      isOpenCLASRef = true;
+    }
+    if(!isOpenCLASRef) {
+      Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
+      return;
+    }
   }
 
   //      - Otherwise, a temporary of type "cv1 T1" is created and initialized
@@ -4919,6 +4936,20 @@ static bool TryOCLZeroEventInitialization(Sema &S,
   return true;
 }
 
+static bool TryOCLZeroQueueInitialization(Sema &S,
+                                          InitializationSequence &Sequence,
+                                          QualType DestType,
+                                          Expr *Initializer) {
+  if (!S.getLangOpts().OpenCL || S.getLangOpts().OpenCLVersion < 200 ||
+      !DestType->isQueueT() ||
+      !Initializer->isIntegerConstantExpr(S.getASTContext()) ||
+      (Initializer->EvaluateKnownConstInt(S.getASTContext()) != 0))
+    return false;
+
+  Sequence.AddOCLZeroQueueStep(DestType);
+  return true;
+}
+
 InitializationSequence::InitializationSequence(Sema &S,
                                                const InitializedEntity &Entity,
                                                const InitializationKind &Kind,
@@ -5110,13 +5141,21 @@ void InitializationSequence::InitializeFrom(Sema &S,
         tryObjCWritebackConversion(S, *this, Entity, Initializer)) {
       return;
     }
+  }
 
+  // need to try these when using C++ with OpenCL
+  if (!S.getLangOpts().CPlusPlus || S.getLangOpts().OpenCL) {
     if (TryOCLSamplerInitialization(S, *this, DestType, Initializer))
       return;
 
     if (TryOCLZeroEventInitialization(S, *this, DestType, Initializer))
       return;
 
+    if (TryOCLZeroQueueInitialization(S, *this, DestType, Initializer))
+      return;
+  }
+
+  if (!S.getLangOpts().CPlusPlus) {
     // Handle initialization in C
     AddCAssignmentStep(DestType);
     MaybeProduceObjCObject(S, *this, Entity);
@@ -6312,6 +6351,20 @@ InitializationSequence::Perform(Sema &S,
       << Init->getSourceRange();
   }
 
+  QualType ETy = Entity.getType();
+  Qualifiers TyQualifiers = ETy.getQualifiers();
+  bool HasGlobalAS = TyQualifiers.hasAddressSpace() &&
+                     TyQualifiers.getAddressSpace() == LangAS::opencl_global;
+
+  if (S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200 &&
+      ETy->isAtomicType() && !HasGlobalAS &&
+      Entity.getKind() == InitializedEntity::EK_Variable && Args.size() > 0) {
+    const Expr *Init = Args[0];
+    S.Diag(Init->getLocStart(), diag::err_atomic_init_addressspace) <<
+    SourceRange(Entity.getDecl()->getLocStart(), Init->getLocEnd());
+    return ExprError();
+  }
+
   // Diagnose cases where we initialize a pointer to an array temporary, and the
   // pointer obviously outlives the temporary.
   if (Args.size() == 1 && Args[0]->getType()->isArrayType() &&
@@ -6366,7 +6419,8 @@ InitializationSequence::Perform(Sema &S,
   case SK_ProduceObjCObject:
   case SK_StdInitializerList:
   case SK_OCLSamplerInit:
-  case SK_OCLZeroEvent: {
+  case SK_OCLZeroEvent:
+  case SK_OCLZeroQueue: {
     assert(Args.size() == 1);
     CurInit = Args[0];
     if (!CurInit.get()) return ExprError();
@@ -6476,7 +6530,10 @@ InitializationSequence::Perform(Sema &S,
 
     case SK_BindReferenceToTemporary: {
       // Make sure the "temporary" is actually an rvalue.
-      assert(CurInit.get()->isRValue() && "not a temporary");
+      // TODO: fix this!
+      //if(CurInit.get()->getType()) {
+      //assert(CurInit.get()->isRValue() && "not a temporary");
+      //}
 
       // Check exception specifications
       if (S.CheckExceptionSpecCompatibility(CurInit.get(), DestType))
@@ -7021,6 +7078,15 @@ InitializationSequence::Perform(Sema &S,
                                     CurInit.get()->getValueKind());
       break;
     }
+    case SK_OCLZeroQueue: {
+      assert(Step->Type->isQueueT() &&
+             "Event initialization on non queue type.");
+
+      CurInit = S.ImpCastExprToType(CurInit.get(), Step->Type,
+                                    CK_ZeroToOCLQueue,
+                                    CurInit.get()->getValueKind());
+      break;
+    }
     }
   }
 
@@ -7806,6 +7872,10 @@ void InitializationSequence::dump(raw_ostream &OS) const {
     case SK_OCLZeroEvent:
       OS << "OpenCL event_t from zero";
       break;
+
+    case SK_OCLZeroQueue:
+      OS << "OpenCL queue_t from zero";
+      break;
     }
 
     OS << " [" << S->Type.getAsString() << ']';
diff --git a/lib/Sema/SemaLookup.cpp b/lib/Sema/SemaLookup.cpp
index 19df1e3..b46e7f8 100644
--- a/lib/Sema/SemaLookup.cpp
+++ b/lib/Sema/SemaLookup.cpp
@@ -693,6 +693,16 @@ static bool LookupBuiltin(Sema &S, LookupResult &R) {
             S.Context.BuiltinInfo.isPredefinedLibFunction(BuiltinID))
           return false;
 
+        // OpenCL v1.2 s6.9.f:
+        // The library functions defined in the C99 standard headers assert.h,
+        // ctype.h, complex.h, errno.h, fenv.h, float.h, inttypes.h, limits.h,
+        // locale.h, setjmp.h, signal.h, stdarg.h, stdio.h, stdlib.h, string.h,
+        // tgmath.h, time.h, wchar.h and wctype.h are not available and cannot
+        // be included by a program.
+        if (S.getLangOpts().OpenCL &&
+            S.Context.BuiltinInfo.isPredefinedLibFunction(BuiltinID))
+          return false;
+
         if (NamedDecl *D = S.LazilyCreateBuiltin((IdentifierInfo *)II,
                                                  BuiltinID, S.TUScope,
                                                  R.isForRedeclaration(),
diff --git a/lib/Sema/SemaOverload.cpp b/lib/Sema/SemaOverload.cpp
index 72ad9a4..e085eee 100644
--- a/lib/Sema/SemaOverload.cpp
+++ b/lib/Sema/SemaOverload.cpp
@@ -23,6 +23,7 @@
 #include "clang/Basic/DiagnosticOptions.h"
 #include "clang/Basic/PartialDiagnostic.h"
 #include "clang/Basic/TargetInfo.h"
+#include "clang/Lex/Preprocessor.h"
 #include "clang/Sema/Initialization.h"
 #include "clang/Sema/Lookup.h"
 #include "clang/Sema/SemaInternal.h"
@@ -128,14 +129,14 @@ ImplicitConversionRank clang::GetConversionRank(ImplicitConversionKind Kind) {
     ICR_Conversion,
     ICR_Conversion,
     ICR_Conversion,
-    ICR_Conversion,
+    ICR_OCL_Scalar_Widening,
     ICR_Complex_Real_Conversion,
     ICR_Conversion,
     ICR_Conversion,
     ICR_Writeback_Conversion,
-    ICR_Exact_Match, // NOTE(gbiv): This may not be completely right --
-                     // it was omitted by the patch that added
-                     // ICK_Zero_Event_Conversion
+    ICR_Conversion,
+    ICR_Conversion,
+    ICR_Conversion,
     ICR_C_Conversion
   };
   return Rank[(int)Kind];
@@ -169,7 +170,9 @@ static const char* GetImplicitConversionName(ImplicitConversionKind Kind) {
     "Block Pointer conversion",
     "Transparent Union Conversion",
     "Writeback conversion",
-    "OpenCL Zero Event Conversion",
+    "Zero Event conversion",
+    "Zero Queue Conversion",
+    "Integer-to-Sampler conversion",
     "C specific type conversion"
   };
   return Name[Kind];
@@ -1738,6 +1741,15 @@ static bool IsStandardConversion(Sema &S, Expr* From, QualType ToType,
              From->EvaluateKnownConstInt(S.getASTContext()) == 0) {
     SCS.Second = ICK_Zero_Event_Conversion;
     FromType = ToType;
+  } else if (ToType->isQueueT() &&
+             From->isIntegerConstantExpr(S.getASTContext()) &&
+             (From->EvaluateKnownConstInt(S.getASTContext()) == 0)) {
+    SCS.Second = ICK_Zero_Queue_Conversion;
+    FromType = ToType;
+  } else if (ToType->isSamplerT() &&
+             From->isIntegerConstantExpr(S.getASTContext())) {
+    SCS.Second = ICK_Int_Sampler_Conversion;
+    FromType = ToType;
   } else {
     // No second conversion required.
     SCS.Second = ICK_Identity;
@@ -4148,7 +4160,7 @@ Sema::CompareReferenceRelationship(SourceLocation Loc,
 
   if (T1Quals == T2Quals)
     return Ref_Compatible;
-  else if (T1Quals.compatiblyIncludes(T2Quals))
+  else if (T1Quals.compatiblyIncludes(T2Quals, !getASTContext().getLangOpts().OpenCL))
     return Ref_Compatible_With_Added_Qualification;
   else
     return Ref_Related;
@@ -4477,7 +4489,7 @@ TryReferenceInit(Sema &S, Expr *Init, QualType DeclType,
     // MS compiler ignores __unaligned qualifier for references; do the same.
     T1Quals.removeUnaligned();
     T2Quals.removeUnaligned();
-    if (!T1Quals.compatiblyIncludes(T2Quals))
+    if (!T1Quals.compatiblyIncludes(T2Quals, !S.getLangOpts().OpenCL))
       return ICS;
   }
 
@@ -5071,6 +5083,8 @@ static bool CheckConvertedConstantConversions(Sema &S,
   case ICK_NoReturn_Adjustment:
   case ICK_Integral_Promotion:
   case ICK_Integral_Conversion: // Narrowing conversions are checked elsewhere.
+  case ICK_Zero_Queue_Conversion:
+  case ICK_Int_Sampler_Conversion:
     return true;
 
   case ICK_Boolean_Conversion:
@@ -5809,6 +5823,41 @@ Sema::AddOverloadCandidate(FunctionDecl *Function,
     return;
   }
 
+  // OpenCL
+  // A candidate function that uses extentions that are not enabled or
+  // supported is not viable.
+  bool hasHalf = getOpenCLOptions().cl_khr_fp16 &&
+                 PP.getSupportedPragmas().cl_khr_fp16;
+  bool hasDouble = PP.getSupportedPragmas().cl_khr_fp64;
+
+  if (getLangOpts().OpenCL) {
+    if (!hasHalf && Function->getReturnType()->isHalfType()) {
+      Candidate.Viable = false;
+      Candidate.FailureKind = ovl_fail_bad_target;
+      return;
+    }
+    if (!hasDouble && Function->getReturnType()->isDoubleType()) {
+      Candidate.Viable = false;
+      Candidate.FailureKind = ovl_fail_bad_target;
+      return;
+    }
+    for (FunctionDecl::param_iterator PI = Function->param_begin(),
+         PE = Function->param_end(); PI != PE; ++PI) {
+      ParmVarDecl *Param = *PI;
+      QualType PT = Param->getType();
+      if (!hasHalf && PT->isHalfType()) {
+        Candidate.Viable = false;
+        Candidate.FailureKind = ovl_fail_bad_target;
+        return;
+      }
+      if (!hasDouble && PT->isDoubleType()) {
+        Candidate.Viable = false;
+        Candidate.FailureKind = ovl_fail_bad_target;
+        return;
+      }
+    }
+  }
+
   // (CUDA B.1): Check for invalid calls between targets.
   if (getLangOpts().CUDA)
     if (const FunctionDecl *Caller = dyn_cast<FunctionDecl>(CurContext))
diff --git a/lib/Sema/SemaStmtAttr.cpp b/lib/Sema/SemaStmtAttr.cpp
index 87fd889..36fef5c 100644
--- a/lib/Sema/SemaStmtAttr.cpp
+++ b/lib/Sema/SemaStmtAttr.cpp
@@ -92,7 +92,7 @@ static Attr *handleLoopHintAttr(Sema &S, Stmt *St, const AttributeList &A,
     } else {
       // #pragma unroll
       Option = LoopHintAttr::Unroll;
-      State = LoopHintAttr::Enable;
+      State = LoopHintAttr::Full;
     }
   } else {
     // #pragma clang loop ...
diff --git a/lib/Sema/SemaTemplateDeduction.cpp b/lib/Sema/SemaTemplateDeduction.cpp
index f8e825f..4d7ebe7 100644
--- a/lib/Sema/SemaTemplateDeduction.cpp
+++ b/lib/Sema/SemaTemplateDeduction.cpp
@@ -2683,7 +2683,7 @@ CheckOriginalCallArgDeduction(Sema &S, Sema::OriginalCallArg OriginalArg,
 
     if (AQuals == DeducedAQuals) {
       // Qualifiers match; there's nothing to do.
-    } else if (!DeducedAQuals.compatiblyIncludes(AQuals)) {
+    } else if (!DeducedAQuals.compatiblyIncludes(AQuals, !S.getLangOpts().OpenCL)) {
       return true;
     } else {
       // Qualifiers are compatible, so have the argument type adopt the
diff --git a/lib/Sema/SemaTemplateInstantiateDecl.cpp b/lib/Sema/SemaTemplateInstantiateDecl.cpp
index f7d9787..014c71f 100644
--- a/lib/Sema/SemaTemplateInstantiateDecl.cpp
+++ b/lib/Sema/SemaTemplateInstantiateDecl.cpp
@@ -308,6 +308,30 @@ static void instantiateOMPDeclareSimdDeclAttr(
       Attr.getRange());
 }
 
+static void instantiateDependentFloorImageDataTypeAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const FloorImageDataTypeAttr *A, const Decl *Tmpl, Decl *New) {
+  TypeSourceInfo *Result = S.SubstType(A->getImageDataTypeLoc(), TemplateArgs,
+                                       A->getLocation(), DeclarationName());
+  if (Result) {
+    FloorImageDataTypeAttr *new_attr = new (S.getASTContext())
+        FloorImageDataTypeAttr(A->getLocation(), S.getASTContext(), Result,
+                               A->getSpellingListIndex());
+    New->addAttr(new_attr);
+  }
+}
+
+static void instantiateDependentGraphicsFBOColorLocationAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const GraphicsFBOColorLocationAttr *A, const Decl *Tmpl, Decl *New) {
+  // TODO: check Tmpl with isPotentialConstantExprUnevaluated?
+  EnterExpressionEvaluationContext Unevaluated(S, Sema::ConstantEvaluated);
+  ExprResult Result = S.SubstExpr(A->getColorLocation(), TemplateArgs);
+  if (!Result.isInvalid())
+    S.AddGraphicsFBOColorLocationAttr(A->getLocation(), New, Result.getAs<Expr>(),
+                                      A->getSpellingListIndex());
+}
+
 void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
                             const Decl *Tmpl, Decl *New,
                             LateInstantiatedAttrVec *LateAttrs,
@@ -378,6 +402,18 @@ void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
       continue;
     }
 
+    const FloorImageDataTypeAttr *ImgType = dyn_cast<FloorImageDataTypeAttr>(TmplAttr);
+    if (ImgType && ImgType->getImageDataType()->isDependentType()) {
+      instantiateDependentFloorImageDataTypeAttr(*this, TemplateArgs, ImgType, Tmpl, New);
+      continue;
+    }
+
+    const GraphicsFBOColorLocationAttr *ColorLoc = dyn_cast<GraphicsFBOColorLocationAttr>(TmplAttr);
+    if (ColorLoc) {
+      instantiateDependentGraphicsFBOColorLocationAttr(*this, TemplateArgs, ColorLoc, Tmpl, New);
+      continue;
+    }
+
     assert(!TmplAttr->isPackExpansion());
     if (TmplAttr->isLateParsed() && LateAttrs) {
       // Late parsed attributes must be instantiated and attached after the
diff --git a/lib/Sema/SemaTemplateVariadic.cpp b/lib/Sema/SemaTemplateVariadic.cpp
index 06afe87..ade60df 100644
--- a/lib/Sema/SemaTemplateVariadic.cpp
+++ b/lib/Sema/SemaTemplateVariadic.cpp
@@ -740,9 +740,14 @@ bool Sema::containsUnexpandedParameterPacks(Declarator &D) {
   case TST_auto:
   case TST_auto_type:
   case TST_decltype_auto:
+  case TST_unknown_anytype:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) case TST_##ImgType##_t:
 #include "clang/Basic/OpenCLImageTypes.def"
-  case TST_unknown_anytype:
+  case TST_sampler_t:
+  case TST_event_t:
+  case TST_queue_t:
+  case TST_clk_event_t:
+  case TST_reserve_id_t:
   case TST_error:
     break;
   }
diff --git a/lib/Sema/SemaType.cpp b/lib/Sema/SemaType.cpp
index 8a49f61..1647008 100644
--- a/lib/Sema/SemaType.cpp
+++ b/lib/Sema/SemaType.cpp
@@ -19,6 +19,7 @@
 #include "clang/AST/DeclObjC.h"
 #include "clang/AST/DeclTemplate.h"
 #include "clang/AST/Expr.h"
+#include "clang/AST/Type.h"
 #include "clang/AST/TypeLoc.h"
 #include "clang/AST/TypeLocVisitor.h"
 #include "clang/Basic/PartialDiagnostic.h"
@@ -114,12 +115,16 @@ static void diagnoseBadTypeAttribute(Sema &S, const AttributeList &attr,
     case AttributeList::AT_Pcs: \
     case AttributeList::AT_IntelOclBicc: \
     case AttributeList::AT_PreserveMost: \
-    case AttributeList::AT_PreserveAll
+    case AttributeList::AT_PreserveAll: \
+    case AttributeList::AT_ComputeKernel: \
+    case AttributeList::AT_GraphicsVertexShader: \
+    case AttributeList::AT_GraphicsFragmentShader
 
 // Function type attributes.
 #define FUNCTION_TYPE_ATTRS_CASELIST \
     case AttributeList::AT_NoReturn: \
     case AttributeList::AT_Regparm: \
+    case AttributeList::AT_RetRange: \
     CALLING_CONV_ATTRS_CASELIST
 
 // Microsoft-specific type qualifiers.
@@ -289,7 +294,8 @@ enum TypeAttrLocation {
 
 static void processTypeAttrs(TypeProcessingState &state,
                              QualType &type, TypeAttrLocation TAL,
-                             AttributeList *attrs);
+                             AttributeList *attrs, Declarator &D,
+                             unsigned int OpenCLVersion);
 
 static bool handleFunctionTypeAttr(TypeProcessingState &state,
                                    AttributeList &attr,
@@ -1227,7 +1233,7 @@ static StringRef getImageAccessAttrStr(AttributeList *attrs) {
     do {
       AttributeList &Attr = *attrs;
       Next = Attr.getNext();
-      if (Attr.getKind() == AttributeList::AT_OpenCLAccess) {
+      if (Attr.getKind() == AttributeList::AT_ImageAccess) {
         return Attr.getName()->getName();
       }
     } while (Next);
@@ -1346,6 +1352,9 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
         S.Diag(DeclLoc, diag::err_missing_actual_pipe_type)
           << DS.getSourceRange();
         declarator.setInvalidType(true);
+      } else if (S.getLangOpts().OpenCL) {
+        S.Diag(DeclLoc, diag::err_opencl_missing_type_specifier)
+          << DS.getSourceRange();
       } else {
         S.Diag(DeclLoc, diag::ext_missing_type_specifier)
           << DS.getSourceRange();
@@ -1495,22 +1504,6 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
               << Result << "cl_khr_fp64";
           declarator.setInvalidType(true);
         }
-      } else if (!S.getOpenCLOptions().cl_khr_gl_msaa_sharing &&
-                 (Result->isOCLImage2dArrayMSAADepthROType() ||
-                  Result->isOCLImage2dArrayMSAADepthWOType() ||
-                  Result->isOCLImage2dArrayMSAADepthRWType() ||
-                  Result->isOCLImage2dArrayMSAAROType() ||
-                  Result->isOCLImage2dArrayMSAARWType() ||
-                  Result->isOCLImage2dArrayMSAAWOType() ||
-                  Result->isOCLImage2dMSAADepthROType() ||
-                  Result->isOCLImage2dMSAADepthRWType() ||
-                  Result->isOCLImage2dMSAADepthWOType() ||
-                  Result->isOCLImage2dMSAAROType() ||
-                  Result->isOCLImage2dMSAARWType() ||
-                  Result->isOCLImage2dMSAAWOType())) {
-        S.Diag(DS.getTypeSpecTypeLoc(), diag::err_type_requires_extension)
-            << Result << "cl_khr_gl_msaa_sharing";
-        declarator.setInvalidType(true);
       }
     }
 
@@ -1621,6 +1614,24 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
     }
     break;
 
+  case DeclSpec::TST_sampler_t:
+    Result = Context.OCLSamplerTy;
+    break;
+
+  case DeclSpec::TST_event_t:
+    Result = Context.OCLEventTy;
+    break;
+  case DeclSpec::TST_queue_t:
+    Result = Context.OCLQueueTy;
+    break;
+  case DeclSpec::TST_clk_event_t:
+    Result = Context.OCLClkEventTy;
+    break;
+  case DeclSpec::TST_reserve_id_t:
+    Result = Context.OCLReserveIDTy;
+    break;
+
+#if 0 // TODO: enable this when using ro/wo/rw image types
 #define GENERIC_IMAGE_TYPE(ImgType, Id) \
   case DeclSpec::TST_##ImgType##_t: \
     Result = llvm::StringSwitch<QualType>( \
@@ -1630,6 +1641,17 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
                  .Default(Context.Id##ROTy); \
     break;
 #include "clang/Basic/OpenCLImageTypes.def"
+#else
+#define GENERIC_IMAGE_TYPE(ImgType, Id) \
+  case DeclSpec::TST_##ImgType##_t: \
+    Result = llvm::StringSwitch<QualType>( \
+                 getImageAccessAttrStr(DS.getAttributes().getList())) \
+                 .Cases("write_only", "__write_only", Context.Id##Ty) \
+                 .Cases("read_write", "__read_write", Context.Id##Ty) \
+                 .Default(Context.Id##Ty); \
+    break;
+#include "clang/Basic/OpenCLImageTypes.def"
+#endif
 
   case DeclSpec::TST_error:
     Result = Context.IntTy;
@@ -1667,7 +1689,8 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
   // attributes are pushed around.
   // pipe attributes will be handled later ( at GetFullTypeForDeclarator )
   if (!DS.isTypeSpecPipe())
-      processTypeAttrs(state, Result, TAL_DeclSpec, DS.getAttributes().getList());
+      processTypeAttrs(state, Result, TAL_DeclSpec, DS.getAttributes().getList(),
+                       declarator, S.getLangOpts().OpenCLVersion);
 
   // Apply const/volatile/restrict qualifiers to T.
   if (unsigned TypeQuals = DS.getTypeQualifiers()) {
@@ -2045,7 +2068,9 @@ QualType Sema::BuildReferenceType(QualType T, bool SpelledAsLValue,
 ///
 /// \param T The type to which we'll be building a Pipe.
 ///
-/// \param Loc We do not use it for now.
+/// \param Loc The location of the entity whose type involves this
+/// pointer type or, if there is no such entity, the location of the
+/// type that will have pointer type.
 ///
 /// \returns A suitable pipe type, if there are no errors. Otherwise, returns a
 /// NULL type.
@@ -2282,11 +2307,21 @@ QualType Sema::BuildArrayType(QualType T, ArrayType::ArraySizeModifier ASM,
     const QualType ArrType = Context.getBaseElementType(T);
     if (ArrType->isBlockPointerType() || ArrType->isPipeType() ||
         ArrType->isSamplerT() || ArrType->isImageType()) {
-      Diag(Loc, diag::err_opencl_invalid_type_array) << ArrType;
-      return QualType();
+      // allow C array of images for Vulkan and Metal
+      if (!((getLangOpts().Vulkan || getLangOpts().Metal) && ArrType->isImageType())) {
+        Diag(Loc, diag::err_opencl_invalid_type_array) << ArrType;
+        return QualType();
+      }
     }
   }
 
+  QualType ElemTy = Context.getBaseElementType(T);
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200 &&
+      ElemTy->isBlockPointerType()) {
+    Diag(Loc, diag::err_invalid_block_array);
+    return QualType();
+  }
+
   return T;
 }
 
@@ -2348,7 +2383,7 @@ bool Sema::CheckFunctionReturnType(QualType T, SourceLocation Loc) {
   }
 
   // Functions cannot return half FP.
-  if (T->isHalfType() && !getLangOpts().HalfArgsAndReturns) {
+  if (T->isHalfType() && !getLangOpts().HalfArgsAndReturns && !LangOpts.OpenCL && !LangOpts.CUDA) {
     Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 1 <<
       FixItHint::CreateInsertion(Loc, "*");
     return true;
@@ -2446,7 +2481,7 @@ QualType Sema::BuildFunctionType(QualType T,
     if (ParamType->isVoidType()) {
       Diag(Loc, diag::err_param_with_void_type);
       Invalid = true;
-    } else if (ParamType->isHalfType() && !getLangOpts().HalfArgsAndReturns) {
+    } else if (ParamType->isHalfType() && !getLangOpts().HalfArgsAndReturns && !LangOpts.OpenCL && !LangOpts.CUDA) {
       // Disallow half FP arguments.
       Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 0 <<
         FixItHint::CreateInsertion(Loc, "*");
@@ -2815,7 +2850,8 @@ static QualType GetDeclSpecTypeForDeclarator(TypeProcessingState &state,
     // "void" instead.
     T = SemaRef.Context.VoidTy;
     processTypeAttrs(state, T, TAL_DeclSpec,
-                     D.getDeclSpec().getAttributes().getList());
+                     D.getDeclSpec().getAttributes().getList(),
+                     D, SemaRef.getLangOpts().OpenCLVersion);
     break;
 
   case UnqualifiedId::IK_ConversionFunctionId:
@@ -3195,19 +3231,23 @@ getCCForDeclaratorChunk(Sema &S, Declarator &D,
   CallingConv CC = S.Context.getDefaultCallingConvention(FTI.isVariadic,
                                                          IsCXXInstanceMethod);
 
-  // Attribute AT_OpenCLKernel affects the calling convention for SPIR
-  // and AMDGPU targets, hence it cannot be treated as a calling
-  // convention attribute. This is the simplest place to infer
-  // calling convention for OpenCL kernels.
-  if (S.getLangOpts().OpenCL) {
+  // Attributes AT_ComputeKernel, AT_GraphicsVertexShader, AT_GraphicsFragmentShader
+  // affect the calling convention only on SPIR, AIR and CUDA targets, hence they cannot
+  // be treated as calling convention attributes. This is the simplest place to infer
+  // "floor_kernel"/"floor_vertex"/"floor_fragment".
+  if (CC == CC_FloorFunction) {
     for (const AttributeList *Attr = D.getDeclSpec().getAttributes().getList();
          Attr; Attr = Attr->getNext()) {
-      if (Attr->getKind() == AttributeList::AT_OpenCLKernel) {
-        llvm::Triple::ArchType arch = S.Context.getTargetInfo().getTriple().getArch();
-        if (arch == llvm::Triple::spir || arch == llvm::Triple::spir64 ||
-            arch == llvm::Triple::amdgcn) {
-          CC = CC_OpenCLKernel;
-        }
+      if (Attr->getKind() == AttributeList::AT_ComputeKernel) {
+        CC = CC_FloorKernel;
+        break;
+      }
+      if (Attr->getKind() == AttributeList::AT_GraphicsVertexShader) {
+        CC = CC_FloorVertex;
+        break;
+      }
+      if (Attr->getKind() == AttributeList::AT_GraphicsFragmentShader) {
+        CC = CC_FloorFragment;
         break;
       }
     }
@@ -4048,7 +4088,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
                 << T << 0 /*pointer hint*/;
             D.setInvalidType(true);
           } 
-        } else if (!S.getLangOpts().HalfArgsAndReturns) {
+        } else if (!S.getLangOpts().HalfArgsAndReturns && !S.getLangOpts().CUDA) {
           S.Diag(D.getIdentifierLoc(),
             diag::err_parameters_retval_cannot_have_fp16_type) << 1;
           D.setInvalidType(true);
@@ -4167,7 +4207,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
 
       FunctionType::ExtInfo EI(getCCForDeclaratorChunk(S, D, FTI, chunkIndex));
 
-      if (!FTI.NumParams && !FTI.isVariadic && !LangOpts.CPlusPlus) {
+      if (!FTI.NumParams && !FTI.isVariadic && !LangOpts.CPlusPlus  && !LangOpts.OpenCL) {
         // Simple void foo(), where the incoming T is the result type.
         T = Context.getFunctionNoProtoType(T, EI);
       } else {
@@ -4256,7 +4296,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
                 D.setInvalidType();
                 Param->setInvalidDecl();
               }
-            } else if (!S.getLangOpts().HalfArgsAndReturns) {
+            } else if (!S.getLangOpts().HalfArgsAndReturns || S.getLangOpts().CUDA) {
               S.Diag(Param->getLocation(),
                 diag::err_parameters_retval_cannot_have_fp16_type) << 0;
               D.setInvalidType();
@@ -4385,7 +4425,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
     }
 
     case DeclaratorChunk::Pipe: {
-      T = S.BuildPipeType(T, DeclType.Loc );
+      T = S.BuildPipeType(T, DeclType.Loc);
       break;
     }
     }
@@ -4397,7 +4437,8 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
 
     // See if there are any attributes on this declarator chunk.
     processTypeAttrs(state, T, TAL_DeclChunk,
-                     const_cast<AttributeList *>(DeclType.getAttrs()));
+                     const_cast<AttributeList *>(DeclType.getAttrs()),
+                     D, S.getLangOpts().OpenCLVersion);
   }
 
   assert(!T.isNull() && "T must not be null after this point");
@@ -4490,7 +4531,8 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
   }
 
   // Apply any undistributed attributes from the declarator.
-  processTypeAttrs(state, T, TAL_DeclName, D.getAttributes());
+  processTypeAttrs(state, T, TAL_DeclName, D.getAttributes(),
+                   D, S.getLangOpts().OpenCLVersion);
 
   // Diagnose any ignored type attributes.
   state.diagnoseIgnoredTypeAttrs(T);
@@ -4768,6 +4810,12 @@ static AttributeList::Kind getAttrListKind(AttributedType::Kind kind) {
     return AttributeList::AT_PreserveMost;
   case AttributedType::attr_preserve_all:
     return AttributeList::AT_PreserveAll;
+  case AttributedType::attr_floor_vertex:
+    return AttributeList::AT_GraphicsVertexShader;
+  case AttributedType::attr_floor_fragment:
+    return AttributeList::AT_GraphicsFragmentShader;
+  case AttributedType::attr_floor_kernel:
+    return AttributeList::AT_ComputeKernel;
   case AttributedType::attr_ptr32:
     return AttributeList::AT_Ptr32;
   case AttributedType::attr_ptr64:
@@ -5324,16 +5372,16 @@ static void HandleAddressSpaceTypeAttribute(QualType &Type,
   } else {
     // The keyword-based type attributes imply which address space to use.
     switch (Attr.getKind()) {
-    case AttributeList::AT_OpenCLGlobalAddressSpace:
+    case AttributeList::AT_GlobalAddressSpace:
       ASIdx = LangAS::opencl_global; break;
-    case AttributeList::AT_OpenCLLocalAddressSpace:
+    case AttributeList::AT_LocalAddressSpace:
       ASIdx = LangAS::opencl_local; break;
-    case AttributeList::AT_OpenCLConstantAddressSpace:
+    case AttributeList::AT_ConstantAddressSpace:
       ASIdx = LangAS::opencl_constant; break;
-    case AttributeList::AT_OpenCLGenericAddressSpace:
+    case AttributeList::AT_GenericAddressSpace:
       ASIdx = LangAS::opencl_generic; break;
     default:
-      assert(Attr.getKind() == AttributeList::AT_OpenCLPrivateAddressSpace);
+      assert(Attr.getKind() == AttributeList::AT_PrivateAddressSpace);
       ASIdx = 0; break;
     }
   }
@@ -6110,6 +6158,12 @@ static AttributedType::Kind getCCTypeAttrKind(AttributeList &Attr) {
     return AttributedType::attr_preserve_most;
   case AttributeList::AT_PreserveAll:
     return AttributedType::attr_preserve_all;
+  case AttributeList::AT_GraphicsVertexShader:
+    return AttributedType::attr_floor_vertex;
+  case AttributeList::AT_GraphicsFragmentShader:
+    return AttributedType::attr_floor_fragment;
+  case AttributeList::AT_ComputeKernel:
+    return AttributedType::attr_floor_kernel;
   }
   llvm_unreachable("unexpected attribute kind!");
 }
@@ -6507,38 +6561,9 @@ static void HandleNeonVectorTypeAttr(QualType& CurType,
   CurType = S.Context.getVectorType(CurType, numElts, VecKind);
 }
 
-/// Handle OpenCL Access Qualifier Attribute.
-static void HandleOpenCLAccessAttr(QualType &CurType, const AttributeList &Attr,
-                                   Sema &S) {
-  // OpenCL v2.0 s6.6 - Access qualifier can be used only for image and pipe type.
-  if (!(CurType->isImageType() || CurType->isPipeType())) {
-    S.Diag(Attr.getLoc(), diag::err_opencl_invalid_access_qualifier);
-    Attr.setInvalid();
-    return;
-  }
-
-  if (const TypedefType* TypedefTy = CurType->getAs<TypedefType>()) {
-    QualType PointeeTy = TypedefTy->desugar();
-    S.Diag(Attr.getLoc(), diag::err_opencl_multiple_access_qualifiers);
-
-    std::string PrevAccessQual;
-    switch (cast<BuiltinType>(PointeeTy.getTypePtr())->getKind()) {
-      #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-    case BuiltinType::Id:                                          \
-      PrevAccessQual = #Access;                                    \
-      break;
-      #include "clang/Basic/OpenCLImageTypes.def"
-    default:
-      assert(0 && "Unable to find corresponding image type.");
-    }
-
-    S.Diag(TypedefTy->getDecl()->getLocStart(),
-       diag::note_opencl_typedef_access_qualifier) << PrevAccessQual;
-  }
-}
-
 static void processTypeAttrs(TypeProcessingState &state, QualType &type,
-                             TypeAttrLocation TAL, AttributeList *attrs) {
+                             TypeAttrLocation TAL, AttributeList *attrs,
+                             Declarator &D, unsigned int OpenCLVersion) {
   // Scan through and apply attributes to this type where it makes sense.  Some
   // attributes (such as __address_space__, __vector_size__, etc) apply to the
   // type, but others can be present in the type specifiers even though they
@@ -6599,11 +6624,11 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
       // it it breaks large amounts of Linux software.
       attr.setUsedAsTypeAttr();
       break;
-    case AttributeList::AT_OpenCLPrivateAddressSpace:
-    case AttributeList::AT_OpenCLGlobalAddressSpace:
-    case AttributeList::AT_OpenCLLocalAddressSpace:
-    case AttributeList::AT_OpenCLConstantAddressSpace:
-    case AttributeList::AT_OpenCLGenericAddressSpace:
+    case AttributeList::AT_PrivateAddressSpace:
+    case AttributeList::AT_GlobalAddressSpace:
+    case AttributeList::AT_LocalAddressSpace:
+    case AttributeList::AT_ConstantAddressSpace:
+    case AttributeList::AT_GenericAddressSpace:
     case AttributeList::AT_AddressSpace:
       HandleAddressSpaceTypeAttribute(type, attr, state.getSema());
       attr.setUsedAsTypeAttr();
@@ -6632,8 +6657,28 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
                                VectorType::NeonPolyVector);
       attr.setUsedAsTypeAttr();
       break;
-    case AttributeList::AT_OpenCLAccess:
-      HandleOpenCLAccessAttr(type, attr, state.getSema());
+    case AttributeList::AT_ImageAccess:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_FloorImageDataType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_VectorCompat:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsFBOColorLocation:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsFBODepthType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsVertexPosition:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsPointSize:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsStageInput:
       attr.setUsedAsTypeAttr();
       break;
 
@@ -6712,7 +6757,8 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
   // (...)
   // Pointers that are declared without pointing to a named address space point
   // to the generic address space.
-  if (state.getSema().getLangOpts().OpenCLVersion >= 200 &&
+  // NOTE: disabled due to it being _very_ incompatible to other backends right now
+  /*if (state.getSema().getLangOpts().OpenCLVersion >= 200 &&
       !hasOpenCLAddressSpace && type.getAddressSpace() == 0 &&
       (TAL == TAL_DeclSpec || TAL == TAL_DeclChunk)) {
     Declarator &D = state.getDeclarator();
@@ -6733,7 +6779,7 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
              D.getDeclSpec().getStorageClassSpec() == DeclSpec::SCS_static)
       type = state.getSema().Context.getAddrSpaceQualType(
           type, LangAS::opencl_global);
-  }
+  }*/
 }
 
 void Sema::completeExprArrayBound(Expr *E) {
diff --git a/lib/StaticAnalyzer/Core/ExprEngineC.cpp b/lib/StaticAnalyzer/Core/ExprEngineC.cpp
index 0f40739..5244e70 100644
--- a/lib/StaticAnalyzer/Core/ExprEngineC.cpp
+++ b/lib/StaticAnalyzer/Core/ExprEngineC.cpp
@@ -341,6 +341,7 @@ void ExprEngine::VisitCast(const CastExpr *CastE, const Expr *Ex,
       case CK_AnyPointerToBlockPointerCast:
       case CK_ObjCObjectLValueCast:
       case CK_ZeroToOCLEvent:
+      case CK_ZeroToOCLQueue:
       case CK_IntToOCLSampler:
       case CK_LValueBitCast: {
         // Delegate to SValBuilder to process.
diff --git a/tools/driver/cc1_main.cpp b/tools/driver/cc1_main.cpp
index 45d44a0..163513e 100644
--- a/tools/driver/cc1_main.cpp
+++ b/tools/driver/cc1_main.cpp
@@ -18,6 +18,7 @@
 #include "clang/Config/config.h"
 #include "clang/Driver/DriverDiagnostic.h"
 #include "clang/Driver/Options.h"
+#include "clang/Lex/PreprocessorOptions.h"
 #include "clang/Frontend/CompilerInstance.h"
 #include "clang/Frontend/CompilerInvocation.h"
 #include "clang/Frontend/FrontendDiagnostic.h"
@@ -140,6 +141,30 @@ int cc1_main(ArrayRef<const char *> Argv, const char *Argv0, void *MainAddr) {
   PCHOps->registerWriter(llvm::make_unique<ObjectFilePCHContainerWriter>());
   PCHOps->registerReader(llvm::make_unique<ObjectFilePCHContainerReader>());
 
+  // Enable OpenCL supported pragmas by default.
+  OpenCLOptions &SP = Clang->getPreprocessorOpts().SupportedPragmas;
+  SP.cl_khr_3d_image_writes = 1;
+  SP.cl_khr_byte_addressable_store = 1;
+  SP.cl_khr_depth_images = 1;
+  SP.cl_khr_d3d10_sharing = 1;
+  SP.cl_khr_fp16 = 1;
+  SP.cl_khr_fp64 = 1;
+  SP.cl_khr_gl_event = 1;
+  SP.cl_khr_gl_msaa_sharing = 1;
+  SP.cl_khr_gl_sharing = 1;
+  SP.cl_khr_int64_base_atomics = 1;
+  SP.cl_khr_int64_extended_atomics = 1;
+  SP.cl_khr_global_int32_base_atomics = 1;
+  SP.cl_khr_global_int32_extended_atomics = 1;
+  SP.cl_khr_local_int32_base_atomics = 1;
+  SP.cl_khr_local_int32_extended_atomics = 1;
+  SP.cl_khr_subgroups = 1;
+  SP.cl_khr_mipmap_image = 1;
+  SP.cl_khr_mipmap_image_writes = 1;
+  SP.cl_intel_subgroups = 1;
+
+  SP.cl_clang_storage_class_specifiers = 1;
+
   // Initialize targets first, so that --version shows registered targets.
   llvm::InitializeAllTargets();
   llvm::InitializeAllTargetMCs();
diff --git a/tools/libclang/CIndex.cpp b/tools/libclang/CIndex.cpp
index 22a17ad..d895bb7 100644
--- a/tools/libclang/CIndex.cpp
+++ b/tools/libclang/CIndex.cpp
@@ -4754,11 +4754,11 @@ CXString clang_getCursorKindSpelling(enum CXCursorKind Kind) {
   case CXCursor_NoDuplicateAttr:
     return cxstring::createRef("attribute(noduplicate)");
   case CXCursor_CUDAConstantAttr:
-    return cxstring::createRef("attribute(constant)");
+    return cxstring::createRef("attribute(constant_cuda)");
   case CXCursor_CUDADeviceAttr:
     return cxstring::createRef("attribute(device)");
-  case CXCursor_CUDAGlobalAttr:
-    return cxstring::createRef("attribute(global)");
+  case CXCursor_ComputeKernelAttr:
+    return cxstring::createRef("attribute(compute_kernel)");
   case CXCursor_CUDAHostAttr:
     return cxstring::createRef("attribute(host)");
   case CXCursor_CUDASharedAttr:
@@ -7166,6 +7166,8 @@ enum CX_StorageClass clang_Cursor_getStorageClass(CXCursor C) {
   }
   switch (sc) {
   case SC_None:
+  case SC_OpenCLConstant: // unsupported in here
+  case SC_OpenCLConstantExtern: // unsupported in here
     return CX_SC_None;
   case SC_Extern:
     return CX_SC_Extern;
diff --git a/tools/libclang/CXCursor.cpp b/tools/libclang/CXCursor.cpp
index 047f822..d185a84 100644
--- a/tools/libclang/CXCursor.cpp
+++ b/tools/libclang/CXCursor.cpp
@@ -55,7 +55,7 @@ static CXCursorKind GetCursorKind(const Attr *A) {
     case attr::NoDuplicate: return CXCursor_NoDuplicateAttr;
     case attr::CUDAConstant: return CXCursor_CUDAConstantAttr;
     case attr::CUDADevice: return CXCursor_CUDADeviceAttr;
-    case attr::CUDAGlobal: return CXCursor_CUDAGlobalAttr;
+    case attr::ComputeKernel: return CXCursor_ComputeKernelAttr;
     case attr::CUDAHost: return CXCursor_CUDAHostAttr;
     case attr::CUDAShared: return CXCursor_CUDASharedAttr;
     case attr::Visibility: return CXCursor_VisibilityAttr;
diff --git a/tools/libclang/CXType.cpp b/tools/libclang/CXType.cpp
index 4fcd886..b176756 100644
--- a/tools/libclang/CXType.cpp
+++ b/tools/libclang/CXType.cpp
@@ -537,11 +537,13 @@ CXCallingConv clang_getFunctionTypeCallingConv(CXType X) {
       TCALLINGCONV(AAPCS);
       TCALLINGCONV(AAPCS_VFP);
       TCALLINGCONV(IntelOclBicc);
+      TCALLINGCONV(FloorFunction);
+      TCALLINGCONV(FloorKernel);
+      TCALLINGCONV(FloorVertex);
+      TCALLINGCONV(FloorFragment);
       TCALLINGCONV(Swift);
       TCALLINGCONV(PreserveMost);
       TCALLINGCONV(PreserveAll);
-    case CC_SpirFunction: return CXCallingConv_Unexposed;
-    case CC_OpenCLKernel: return CXCallingConv_Unexposed;
       break;
     }
 #undef TCALLINGCONV
