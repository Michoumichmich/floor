diff --git a/.gitignore b/.gitignore
index 3ea38b6e00..1db8ab78e3 100644
--- a/.gitignore
+++ b/.gitignore
@@ -18,6 +18,7 @@
 # vim swap files
 .*.sw?
 .sw?
+.DS_Store
 
 #==============================================================================#
 # Explicit files to ignore (only matches one).
diff --git a/include/clang-c/Index.h b/include/clang-c/Index.h
index c51dfb1598..cc29d5db2f 100644
--- a/include/clang-c/Index.h
+++ b/include/clang-c/Index.h
@@ -2562,7 +2562,7 @@ enum CXCursorKind {
   CXCursor_NoDuplicateAttr               = 411,
   CXCursor_CUDAConstantAttr              = 412,
   CXCursor_CUDADeviceAttr                = 413,
-  CXCursor_CUDAGlobalAttr                = 414,
+  CXCursor_ComputeKernelAttr             = 414,
   CXCursor_CUDAHostAttr                  = 415,
   CXCursor_CUDASharedAttr                = 416,
   CXCursor_VisibilityAttr                = 417,
@@ -3254,6 +3254,7 @@ enum CXTypeKind {
   CXType_Pipe = 120,
 
   /* OpenCL builtin types. */
+#if 0 // OpenCL image types with access qualifiers
   CXType_OCLImage1dRO = 121,
   CXType_OCLImage1dArrayRO = 122,
   CXType_OCLImage1dBufferRO = 123,
@@ -3290,6 +3291,24 @@ enum CXTypeKind {
   CXType_OCLImage2dMSAADepthRW = 154,
   CXType_OCLImage2dArrayMSAADepthRW = 155,
   CXType_OCLImage3dRW = 156,
+#else // OpenCL image types without access qualifiers
+  CXType_OCLImage1d = 121,
+  CXType_OCLImage1dArray = 122,
+  CXType_OCLImage1dBuffer = 123,
+  CXType_OCLImage2d = 124,
+  CXType_OCLImage2dArray = 125,
+  CXType_OCLImage2dDepth = 126,
+  CXType_OCLImage2dArrayDepth = 127,
+  CXType_OCLImage2dMSAA = 128,
+  CXType_OCLImage2dArrayMSAA = 129,
+  CXType_OCLImage2dMSAADepth = 130,
+  CXType_OCLImage2dArrayMSAADepth = 131,
+  CXType_OCLImage3d = 132,
+  CXType_OCLImageCube = 133,
+  CXType_OCLImageCubeArray = 134,
+  CXType_OCLImageCubeDepth = 135,
+  CXType_OCLImageCubeArrayDepth = 136,
+#endif
   CXType_OCLSampler = 157,
   CXType_OCLEvent = 158,
   CXType_OCLQueue = 159,
@@ -3333,10 +3352,14 @@ enum CXCallingConv {
   CXCallingConv_X86_64Win64 = CXCallingConv_Win64,
   CXCallingConv_X86_64SysV = 11,
   CXCallingConv_X86VectorCall = 12,
-  CXCallingConv_Swift = 13,
-  CXCallingConv_PreserveMost = 14,
-  CXCallingConv_PreserveAll = 15,
-  CXCallingConv_AArch64VectorCall = 16,
+  CXCallingConv_FloorFunction = 13,
+  CXCallingConv_FloorKernel = 14,
+  CXCallingConv_FloorVertex = 15,
+  CXCallingConv_FloorFragment = 16,
+  CXCallingConv_Swift = 17,
+  CXCallingConv_PreserveMost = 18,
+  CXCallingConv_PreserveAll = 19,
+  CXCallingConv_AArch64VectorCall = 20,
 
   CXCallingConv_Invalid = 100,
   CXCallingConv_Unexposed = 200
diff --git a/include/clang/AST/ASTContext.h b/include/clang/AST/ASTContext.h
index 7edf3b3fed..fe09cf1824 100644
--- a/include/clang/AST/ASTContext.h
+++ b/include/clang/AST/ASTContext.h
@@ -529,6 +529,10 @@ private:
   ///  this ASTContext object.
   LangOptions &LangOpts;
 
+  OpenCLOptions OpenCLFeatures;
+
+  bool disabledFPContract = false;
+
   /// Blacklist object that is used by sanitizers to decide which
   /// entities should not be instrumented.
   std::unique_ptr<SanitizerBlacklist> SanitizerBL;
@@ -705,6 +709,9 @@ public:
 
   const LangOptions& getLangOpts() const { return LangOpts; }
 
+  OpenCLOptions& getOpenCLFeatures() { return OpenCLFeatures; }
+  const OpenCLOptions& getOpenCLFeatures() const { return OpenCLFeatures; }
+
   const SanitizerBlacklist &getSanitizerBlacklist() const {
     return *SanitizerBL;
   }
@@ -713,6 +720,10 @@ public:
     return *XRayFilter;
   }
 
+  void disableFPContract() { disabledFPContract = true; }
+
+  bool isFPContractDisabled() const { return disabledFPContract; }
+
   DiagnosticsEngine &getDiagnostics() const;
 
   FullSourceLoc getFullLoc(SourceLocation Loc) const {
diff --git a/include/clang/AST/Decl.h b/include/clang/AST/Decl.h
index 3145f35ead..319380fa4b 100644
--- a/include/clang/AST/Decl.h
+++ b/include/clang/AST/Decl.h
@@ -863,11 +863,11 @@ private:
     friend class ASTDeclReader;
     friend class VarDecl;
 
-    unsigned SClass : 3;
+    unsigned SClass : 4;
     unsigned TSCSpec : 2;
     unsigned InitStyle : 2;
   };
-  enum { NumVarDeclBits = 7 };
+  enum { NumVarDeclBits = 8 };
 
 protected:
   enum { NumParameterIndexBits = 8 };
@@ -1067,6 +1067,7 @@ public:
   /// storage.
   bool hasExternalStorage() const {
     return getStorageClass() == SC_Extern ||
+           getStorageClass() == SC_OpenCLConstantExtern ||
            getStorageClass() == SC_PrivateExtern;
   }
 
diff --git a/include/clang/AST/Expr.h b/include/clang/AST/Expr.h
index d57c45eec0..041710df91 100644
--- a/include/clang/AST/Expr.h
+++ b/include/clang/AST/Expr.h
@@ -5401,6 +5401,16 @@ public:
     BI_First = 0
   };
 
+  // The ABI values for various atomic memory orderings.
+  enum AtomicOrderingKind {
+    AO_ABI_memory_order_relaxed = 0,
+    AO_ABI_memory_order_consume = 1,
+    AO_ABI_memory_order_acquire = 2,
+    AO_ABI_memory_order_release = 3,
+    AO_ABI_memory_order_acq_rel = 4,
+    AO_ABI_memory_order_seq_cst = 5
+  };
+
 private:
   /// Location of sub-expressions.
   /// The location of Scope sub-expression is NumSubExprs - 1, which is
diff --git a/include/clang/AST/Mangle.h b/include/clang/AST/Mangle.h
index c42fe91b32..8d91f209a9 100644
--- a/include/clang/AST/Mangle.h
+++ b/include/clang/AST/Mangle.h
@@ -37,6 +37,7 @@ namespace clang {
   struct ThisAdjustment;
   struct ThunkInfo;
   class VarDecl;
+  class FieldDecl;
 
 /// MangleContext - Context for tracking state which persists across multiple
 /// calls to the C++ name mangler.
@@ -147,6 +148,9 @@ public:
   /// across translation units so it can be used with LTO.
   virtual void mangleTypeName(QualType T, raw_ostream &) = 0;
 
+  virtual void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) {}
+  virtual void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) {}
+
   /// @}
 };
 
diff --git a/include/clang/AST/OperationKinds.def b/include/clang/AST/OperationKinds.def
index cd19091e31..8ff745a81a 100644
--- a/include/clang/AST/OperationKinds.def
+++ b/include/clang/AST/OperationKinds.def
@@ -330,6 +330,12 @@ CAST_OPERATION(BuiltinFnToFnPtr)
 // queue_t, etc.)
 CAST_OPERATION(ZeroToOCLOpaqueType)
 
+// Convert a zero value for OpenCL event_t initialization.
+CAST_OPERATION(ZeroToOCLEvent)
+
+// Convert a zero value for OpenCL queue_t initialization.
+CAST_OPERATION(ZeroToOCLQueue)
+
 // Convert a pointer to a different address space.
 CAST_OPERATION(AddressSpaceConversion)
 
diff --git a/include/clang/AST/Type.h b/include/clang/AST/Type.h
index 5b69570aab..40335b6f07 100644
--- a/include/clang/AST/Type.h
+++ b/include/clang/AST/Type.h
@@ -450,8 +450,33 @@ public:
   /// Add the qualifiers from the given set to this set, given that
   /// they don't conflict.
   void addConsistentQualifiers(Qualifiers qs) {
-    assert(getAddressSpace() == qs.getAddressSpace() ||
-           !hasAddressSpace() || !qs.hasAddressSpace());
+    // fix address space, otherwise assert
+    if ((!hasAddressSpace() && qs.hasAddressSpace()) ||
+        (hasAddressSpace() && !qs.hasAddressSpace())) {
+      // -> adding an address space or keeping an existing address space, let it pass
+    } else if (getAddressSpace() == qs.getAddressSpace()) {
+      // -> both have the same address space, all okay
+    } else {
+      // -> different address spaces
+      if (getAddressSpace() == LangAS::Default ||
+          getAddressSpace() == LangAS::opencl_private ||
+          getAddressSpace() == LangAS::opencl_generic) {
+        // allow adjustment to new address space for private/generic,
+        // this usually happens when going to a more specific one
+        removeAddressSpace();
+      } else if (qs.getAddressSpace() == LangAS::Default ||
+                 qs.getAddressSpace() == LangAS::opencl_private ||
+                 qs.getAddressSpace() == LangAS::opencl_generic) {
+        // ignore less specific address space
+        qs.removeAddressSpace();
+      } else {
+        // really mismatching address space
+        // -> assert and keep original
+        assert(false && "address space mismatch");
+        qs.removeAddressSpace();
+      }
+    }
+
     assert(getObjCGCAttr() == qs.getObjCGCAttr() ||
            !hasObjCGCAttr() || !qs.hasObjCGCAttr());
     assert(getObjCLifetime() == qs.getObjCLifetime() ||
@@ -466,21 +491,31 @@ public:
   ///   every address space is a superset of itself.
   /// CL2.0 adds:
   ///   __generic is a superset of any address space except for __constant.
-  bool isAddressSpaceSupersetOf(Qualifiers other) const {
-    return
-        // Address spaces must match exactly.
+  bool isAddressSpaceSupersetOf(Qualifiers other, bool check_as = true, bool allow_default_as_cast = false) const {
+    if (allow_default_as_cast) {
+      if (getAddressSpace() == LangAS::Default ||
+          other.getAddressSpace() == LangAS::Default) {
+        return true;
+      }
+    }
+
+    if (check_as) {
+      return // Address spaces must match exactly.
         getAddressSpace() == other.getAddressSpace() ||
         // Otherwise in OpenCLC v2.0 s6.5.5: every address space except
         // for __constant can be used as __generic.
         (getAddressSpace() == LangAS::opencl_generic &&
          other.getAddressSpace() != LangAS::opencl_constant);
+    }
+
+    return true; // !check_as -> always pass
   }
 
   /// Determines if these qualifiers compatibly include another set.
   /// Generally this answers the question of whether an object with the other
   /// qualifiers can be safely used as an object with these qualifiers.
-  bool compatiblyIncludes(Qualifiers other) const {
-    return isAddressSpaceSupersetOf(other) &&
+  bool compatiblyIncludes(Qualifiers other, bool check_as = true, bool allow_default_as_cast = false) const {
+    return isAddressSpaceSupersetOf(other, check_as, allow_default_as_cast) &&
            // ObjC GC qualifiers can match, be added, or be removed, but can't
            // be changed.
            (getObjCGCAttr() == other.getObjCGCAttr() || !hasObjCGCAttr() ||
@@ -1933,6 +1968,7 @@ public:
   bool isComplexType() const;      // C99 6.2.5p11 (complex)
   bool isAnyComplexType() const;   // C99 6.2.5p11 (complex) + Complex Int.
   bool isFloatingType() const;     // C99 6.2.5p11 (real floating + complex)
+  bool isDoubleType() const;       // (double + long double)
   bool isHalfType() const;         // OpenCL 6.1.1.1, NEON (IEEE 754-2008 half)
   bool isFloat16Type() const;      // C11 extension ISO/IEC TS 18661
   bool isFloat128Type() const;
@@ -1944,6 +1980,12 @@ public:
   bool isFundamentalType() const;
   bool isCompoundType() const;
 
+  // Vector categories
+  bool isFloatingVecType() const;
+  bool isDoubleVecType() const;
+  bool isIntegerVecType() const;
+  bool isRealVecType() const;
+
   // Type Predicates: Check to see if this type is structurally the specified
   // type, ignoring typedefs and qualifiers.
   bool isFunctionType() const;
@@ -2038,11 +2080,15 @@ public:
 
   bool isImageType() const;                     // Any OpenCL image type
 
+  bool isAggregateImageType() const;            // struct/class containing only image*_t members
+  bool isArrayImageType(bool single_field_arr) const; // array of aggregate images
+
   bool isSamplerT() const;                      // OpenCL sampler_t
   bool isEventT() const;                        // OpenCL event_t
   bool isClkEventT() const;                     // OpenCL clk_event_t
   bool isQueueT() const;                        // OpenCL queue_t
   bool isReserveIDT() const;                    // OpenCL reserve_id_t
+  bool isExecType() const;                      // OpenCL 2.0 execution model types
 
 #define EXT_OPAQUE_TYPE(ExtType, Id, Ext) \
   bool is##Id##Type() const;
@@ -6220,7 +6266,7 @@ inline FunctionType::ExtInfo getFunctionExtInfo(QualType t) {
 inline bool QualType::isMoreQualifiedThan(QualType other) const {
   Qualifiers MyQuals = getQualifiers();
   Qualifiers OtherQuals = other.getQualifiers();
-  return (MyQuals != OtherQuals && MyQuals.compatiblyIncludes(OtherQuals));
+  return (MyQuals != OtherQuals && MyQuals.compatiblyIncludes(OtherQuals, false));
 }
 
 /// Determine whether this type is at last
@@ -6234,7 +6280,7 @@ inline bool QualType::isAtLeastAsQualifiedAs(QualType other) const {
   if (getUnqualifiedType()->isVoidType())
     OtherQuals.removeUnaligned();
 
-  return getQualifiers().compatiblyIncludes(OtherQuals);
+  return getQualifiers().compatiblyIncludes(OtherQuals, false);
 }
 
 /// If Type is a reference type (e.g., const
@@ -6471,6 +6517,11 @@ inline bool Type::isReserveIDT() const {
   return isSpecificBuiltinType(BuiltinType::OCLReserveID);
 }
 
+inline bool Type::isExecType() const {
+ return isSpecificBuiltinType(BuiltinType::OCLQueue) ||
+        isSpecificBuiltinType(BuiltinType::OCLClkEvent);
+}
+
 inline bool Type::isImageType() const {
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) is##Id##Type() ||
   return
@@ -6505,7 +6556,8 @@ inline bool Type::isOCLExtOpaqueType() const {
 
 inline bool Type::isOpenCLSpecificType() const {
   return isSamplerT() || isEventT() || isImageType() || isClkEventT() ||
-         isQueueT() || isReserveIDT() || isPipeType() || isOCLExtOpaqueType();
+         isQueueT() || isReserveIDT() || isPipeType() || isOCLExtOpaqueType() ||
+         isAggregateImageType();
 }
 
 inline bool Type::isTemplateTypeParmType() const {
diff --git a/include/clang/Basic/AddressSpaces.h b/include/clang/Basic/AddressSpaces.h
index 217fbd763f..3ea117d5b6 100644
--- a/include/clang/Basic/AddressSpaces.h
+++ b/include/clang/Basic/AddressSpaces.h
@@ -38,6 +38,9 @@ enum class LangAS : unsigned {
   opencl_private,
   opencl_generic,
 
+  // Vulkan specific address spaces.
+  vulkan_input,
+
   // CUDA specific address spaces.
   cuda_device,
   cuda_constant,
diff --git a/include/clang/Basic/Attr.td b/include/clang/Basic/Attr.td
index 04125e67b2..858f4c3129 100644
--- a/include/clang/Basic/Attr.td
+++ b/include/clang/Basic/Attr.td
@@ -137,7 +137,7 @@ def FunctionLike : SubsetSubject<DeclBase,
                                  "functions, function pointers">;
 
 def OpenCLKernelFunction
-    : SubsetSubject<Function, [{S->hasAttr<OpenCLKernelAttr>()}],
+    : SubsetSubject<Function, [{S->hasAttr<ComputeKernelAttr>()}],
                     "kernel functions">;
 
 // HasFunctionProto is a more strict version of FunctionLike, so it should
@@ -908,13 +908,6 @@ def CPUDispatch : InheritableAttr {
 
 // CUDA attributes are spelled __attribute__((attr)) or __declspec(__attr__),
 // and they do not receive a [[]] spelling.
-def CUDAConstant : InheritableAttr {
-  let Spellings = [GNU<"constant">, Declspec<"__constant__">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDACudartBuiltin : IgnoredAttr {
   let Spellings = [GNU<"cudart_builtin">, Declspec<"__cudart_builtin__">];
   let LangOpts = [CUDA];
@@ -944,13 +937,6 @@ def CUDADeviceBuiltinTextureType : IgnoredAttr {
   let LangOpts = [CUDA];
 }
 
-def CUDAGlobal : InheritableAttr {
-  let Spellings = [GNU<"global">, Declspec<"__global__">];
-  let Subjects = SubjectList<[Function]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDAHost : InheritableAttr {
   let Spellings = [GNU<"host">, Declspec<"__host__">];
   let Subjects = SubjectList<[Function]>;
@@ -976,13 +962,6 @@ def CUDALaunchBounds : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAShared : InheritableAttr {
-  let Spellings = [GNU<"shared">, Declspec<"__shared__">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def C11NoReturn : InheritableAttr {
   let Spellings = [Keyword<"_Noreturn">];
   let Subjects = SubjectList<[Function], ErrorDiag>;
@@ -996,11 +975,27 @@ def CXX11NoReturn : InheritableAttr {
   let Documentation = [CXX11NoReturnDocs];
 }
 
-// Similar to CUDA, OpenCL attributes do not receive a [[]] spelling because
-// the specification does not expose them with one currently.
-def OpenCLKernel : InheritableAttr {
-  let Spellings = [Keyword<"__kernel">, Keyword<"kernel">];
-  let Subjects = SubjectList<[Function], ErrorDiag>;
+def ComputeKernel : DeclOrTypeAttr {
+  let Spellings = [GNU<"compute_kernel">, CXX11<"","compute_kernel", 200809>];
+//  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def GraphicsVertexShader : DeclOrTypeAttr {
+  let Spellings = [GNU<"vertex_shader">, CXX11<"","vertex_shader", 200809>];
+//  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def GraphicsFragmentShader : DeclOrTypeAttr {
+  let Spellings = [GNU<"fragment_shader">, CXX11<"","fragment_shader", 200809>];
+ // let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def RetRange : InheritableAttr {
+  let Spellings = [GNU<"range">, CXX11<"","range", 200809>];
+  let Args = [ExprArgument<"LowerBound">, ExprArgument<"UpperBound">];
   let Documentation = [Undocumented];
 }
 
@@ -1019,42 +1014,41 @@ def OpenCLIntelReqdSubGroupSize: InheritableAttr {
 
 // This attribute is both a type attribute, and a declaration attribute (for
 // parameter variables).
-def OpenCLAccess : Attr {
-  let Spellings = [Keyword<"__read_only">, Keyword<"read_only">,
-                   Keyword<"__write_only">, Keyword<"write_only">,
-                   Keyword<"__read_write">, Keyword<"read_write">];
-  let Subjects = SubjectList<[ParmVar, TypedefName], ErrorDiag>;
-  let Accessors = [Accessor<"isReadOnly", [Keyword<"__read_only">,
-                                           Keyword<"read_only">]>,
-                   Accessor<"isReadWrite", [Keyword<"__read_write">,
-                                            Keyword<"read_write">]>,
-                   Accessor<"isWriteOnly", [Keyword<"__write_only">,
-                                            Keyword<"write_only">]>];
+def ImageAccess : Attr {
+  let Spellings = [GNU<"image_read_only">, CXX11<"","image_read_only", 200809>,
+                   GNU<"image_write_only">, CXX11<"","image_write_only", 200809>,
+                   GNU<"image_read_write">, CXX11<"","image_read_write", 200809>];
+  let Accessors = [Accessor<"isReadOnly", [GNU<"image_read_only">,
+										   CXX11<"","image_read_only", 200809>]>,
+                   Accessor<"isReadWrite", [GNU<"image_read_write">,
+											CXX11<"","image_read_write", 200809>]>,
+                   Accessor<"isWriteOnly", [GNU<"image_write_only">,
+											CXX11<"","image_write_only", 200809>]>];
   let Documentation = [OpenCLAccessDocs];
 }
 
-def OpenCLPrivateAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__private">, Keyword<"private">];
+def PrivateAddressSpace : TypeAttr {
+  let Spellings = [GNU<"private_as">, CXX11<"","private_as", 200809>];
   let Documentation = [OpenCLAddressSpacePrivateDocs];
 }
 
-def OpenCLGlobalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__global">, Keyword<"global">];
+def GlobalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"global_as">, CXX11<"","global_as", 200809>];
   let Documentation = [OpenCLAddressSpaceGlobalDocs];
 }
 
-def OpenCLLocalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__local">, Keyword<"local">];
+def LocalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"local_as">, CXX11<"","local_as", 200809>];
   let Documentation = [OpenCLAddressSpaceLocalDocs];
 }
 
-def OpenCLConstantAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__constant">, Keyword<"constant">];
+def ConstantAddressSpace : TypeAttr {
+  let Spellings = [GNU<"constant_as">, CXX11<"","constant_as", 200809>];
   let Documentation = [OpenCLAddressSpaceConstantDocs];
 }
 
-def OpenCLGenericAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__generic">, Keyword<"generic">];
+def GenericAddressSpace : TypeAttr {
+  let Spellings = [GNU<"generic_as">, CXX11<"","generic_as", 200809>];
   let Documentation = [OpenCLAddressSpaceGenericDocs];
 }
 
@@ -1073,6 +1067,79 @@ def RenderScriptKernel : Attr {
   let LangOpts = [RenderScript];
 }
 
+// CUDA address space attrs are not type attrs, so they need to be handled specially
+def CUDAShared : InheritableAttr {
+  let Spellings = [GNU<"local_cuda">, CXX11<"","local_cuda", 200809>];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def CUDAConstant : InheritableAttr {
+  let Spellings = [GNU<"constant_cuda">, CXX11<"","constant_cuda", 200809>];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def FloorImageDataType : InheritableAttr {
+  let Spellings = [GNU<"floor_image">, CXX11<"","floor_image", 200809>];
+  let Args = [TypeArgument<"ImageDataType">];
+  let TemplateDependent = 1;
+  let Documentation = [Undocumented];
+}
+
+// on aggregate types this signals that they can be converted/coerced to the corresponding clang/llvm vector type
+def VectorCompat : InheritableAttr {
+  let Spellings = [GNU<"vector_compat">, CXX11<"","vector_compat", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// fbo color output location
+def GraphicsFBOColorLocation : InheritableAttr {
+  let Spellings = [GNU<"color">, CXX11<"","color", 200809>];
+  let Args = [ExprArgument<"ColorLocation">];
+  let TemplateDependent = 1;
+  let AdditionalMembers = [{
+  unsigned int eval_location = 0;
+  unsigned int getEvalLocation() const {
+    return eval_location;
+  }
+  void setEvalLocation(unsigned int loc) {
+    eval_location = loc;
+  }
+  }];
+  let Documentation = [Undocumented];
+}
+
+// fbo explicit writable depth with depth type
+def GraphicsFBODepthType : InheritableAttr {
+  let Spellings = [GNU<"depth">, CXX11<"","depth", 200809>];
+  let Args = [EnumArgument<"DepthQualifier", "DepthQualifierType",
+                           ["any", "greater", "less"],
+                           ["FBODepthTypeAny", "FBODepthTypeGreater", "FBODepthTypeLess"]>];
+  let Documentation = [Undocumented];
+}
+
+// vertex output position (used in vertex output structs)
+def GraphicsVertexPosition : InheritableAttr {
+  let Spellings = [GNU<"position">, CXX11<"","position", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// vertex/point output size (used in vertex output structs)
+def GraphicsPointSize : InheritableAttr {
+  let Spellings = [GNU<"point_size">, CXX11<"","point_size", 200809>];
+  let Documentation = [Undocumented];
+}
+
+// stage input (just fragment shader input right now)
+def GraphicsStageInput : Attr {
+  let Spellings = [GNU<"stage_input">, CXX11<"","stage_input", 200809>];
+  let Subjects = SubjectList<[ParmVar], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
 def Deprecated : InheritableAttr {
   let Spellings = [GCC<"deprecated">, Declspec<"deprecated">,
                    CXX11<"","deprecated", 201309>, C2x<"", "deprecated">];
diff --git a/include/clang/Basic/Builtins.def b/include/clang/Basic/Builtins.def
index fa031ce09f..c3a9fb5df7 100644
--- a/include/clang/Basic/Builtins.def
+++ b/include/clang/Basic/Builtins.def
@@ -126,10 +126,12 @@ BUILTIN(__builtin_huge_val, "d", "nc")
 BUILTIN(__builtin_huge_valf, "f", "nc")
 BUILTIN(__builtin_huge_vall, "Ld", "nc")
 BUILTIN(__builtin_huge_valf128, "LLd", "nc")
+BUILTIN(__builtin_huge_valh, "h", "nc")
 BUILTIN(__builtin_inf  , "d"   , "nc")
 BUILTIN(__builtin_inff , "f"   , "nc")
 BUILTIN(__builtin_infl , "Ld"  , "nc")
 BUILTIN(__builtin_inff128 , "LLd"  , "nc")
+BUILTIN(__builtin_infh , "h"   , "nc")
 BUILTIN(__builtin_labs , "LiLi"  , "Fnc")
 BUILTIN(__builtin_llabs, "LLiLLi", "Fnc")
 BUILTIN(__builtin_ldexp , "ddi"  , "Fne")
@@ -142,10 +144,12 @@ BUILTIN(__builtin_nan,  "dcC*" , "FnU")
 BUILTIN(__builtin_nanf, "fcC*" , "FnU")
 BUILTIN(__builtin_nanl, "LdcC*", "FnU")
 BUILTIN(__builtin_nanf128, "LLdcC*", "FnU")
+BUILTIN(__builtin_nanh, "hcC*" , "ncF")
 BUILTIN(__builtin_nans,  "dcC*" , "FnU")
 BUILTIN(__builtin_nansf, "fcC*" , "FnU")
 BUILTIN(__builtin_nansl, "LdcC*", "FnU")
 BUILTIN(__builtin_nansf128, "LLdcC*", "FnU")
+BUILTIN(__builtin_nansh, "hcC*" , "ncF")
 BUILTIN(__builtin_powi , "ddi"  , "Fnc")
 BUILTIN(__builtin_powif, "ffi"  , "Fnc")
 BUILTIN(__builtin_powil, "LdLdi", "Fnc")
diff --git a/include/clang/Basic/CodeGenOptions.def b/include/clang/Basic/CodeGenOptions.def
index 952aa588b6..f457b9b1bc 100644
--- a/include/clang/Basic/CodeGenOptions.def
+++ b/include/clang/Basic/CodeGenOptions.def
@@ -75,6 +75,14 @@ CODEGENOPT(EmitVersionIdentMetadata , 1, 1) ///< Emit compiler version metadata.
 CODEGENOPT(EmitGcovArcs      , 1, 0) ///< Emit coverage data files, aka. GCDA.
 CODEGENOPT(EmitGcovNotes     , 1, 0) ///< Emit coverage "notes" files, aka GCNO.
 CODEGENOPT(EmitOpenCLArgMetadata , 1, 0) ///< Emit OpenCL kernel arg metadata.
+CODEGENOPT(MetalIntelWorkarounds , 1, 0) ///< Enable Intel GPU specific fixes and workarounds.
+CODEGENOPT(MetalNvidiaWorkarounds , 1, 0) ///< Enable Nvidia GPU specific fixes and workarounds.
+CODEGENOPT(MetalNoArrayImage , 1, 0) ///< Disable native array of images support.
+CODEGENOPT(MetalSoftPrintf , 1, 0) ///< Enables support of software printf emulation.
+CODEGENOPT(SPIRIntelWorkarounds , 1, 0) ///< Enable Intel SPIR specific fixes and workarounds.
+VALUE_CODEGENOPT(VulkanIUBSize, 32, 256) ///< max supported size of Vulkan inline uniform blocks
+VALUE_CODEGENOPT(VulkanIUBCount, 32, 4) ///< max supported count of Vulkan inline uniform blocks
+CODEGENOPT(VulkanSoftPrintf , 1, 0) ///< Enables support of software printf emulation.
 CODEGENOPT(EmulatedTLS       , 1, 0) ///< Set by default or -f[no-]emulated-tls.
 CODEGENOPT(ExplicitEmulatedTLS , 1, 0) ///< Set if -f[no-]emulated-tls is used.
 /// Embed Bitcode mode (off/all/bitcode/marker).
@@ -230,6 +238,11 @@ CODEGENOPT(VectorizeLoop     , 1, 0) ///< Run loop vectorizer.
 CODEGENOPT(VectorizeSLP      , 1, 0) ///< Run SLP vectorizer.
 CODEGENOPT(ProfileSampleAccurate, 1, 0) ///< Sample profile is accurate.
 
+CODEGENOPT(DenormsAreZero    , 1, 0) ///< Allow flushing of denorms to zero.
+CODEGENOPT(CorrectFPDivideSqrt , 1, 0) ///< Single precision divide and sqrt are
+                                       ///< correctly rounded.
+CODEGENOPT(OptDisable        , 1, 0) ///< Disables all optimizations.
+
   /// Attempt to use register sized accesses to bit-fields in structures, when
   /// possible.
 CODEGENOPT(UseRegisterSizedBitfieldAccess , 1, 0)
diff --git a/include/clang/Basic/CodeGenOptions.h b/include/clang/Basic/CodeGenOptions.h
index a12744ee3d..0d164d37a8 100644
--- a/include/clang/Basic/CodeGenOptions.h
+++ b/include/clang/Basic/CodeGenOptions.h
@@ -198,6 +198,9 @@ public:
   /// function instead of to trap instructions.
   std::string TrapFuncName;
 
+  /// OpenCL compile options to embed in the SPIR metadata
+  std::string SPIRCompileOptions;
+
   /// A list of dependent libraries.
   std::vector<std::string> DependentLibraries;
 
diff --git a/include/clang/Basic/Cuda.h b/include/clang/Basic/Cuda.h
index 0575e70333..18f95897bb 100644
--- a/include/clang/Basic/Cuda.h
+++ b/include/clang/Basic/Cuda.h
@@ -25,7 +25,8 @@ enum class CudaVersion {
   CUDA_91,
   CUDA_92,
   CUDA_100,
-  LATEST = CUDA_100,
+  CUDA_101,
+  LATEST = CUDA_101,
 };
 const char *CudaVersionToString(CudaVersion V);
 
@@ -48,7 +49,9 @@ enum class CudaArch {
   SM_62,
   SM_70,
   SM_72,
+  SM_73,
   SM_75,
+  SM_82,
   GFX600,
   GFX601,
   GFX700,
@@ -87,7 +90,9 @@ enum class CudaVirtualArch {
   COMPUTE_62,
   COMPUTE_70,
   COMPUTE_72,
+  COMPUTE_73,
   COMPUTE_75,
+  COMPUTE_82,
   COMPUTE_AMDGCN,
 };
 const char *CudaVirtualArchToString(CudaVirtualArch A);
diff --git a/include/clang/Basic/DiagnosticDriverKinds.td b/include/clang/Basic/DiagnosticDriverKinds.td
index af528e1718..7f08370ccf 100644
--- a/include/clang/Basic/DiagnosticDriverKinds.td
+++ b/include/clang/Basic/DiagnosticDriverKinds.td
@@ -131,6 +131,8 @@ def err_drv_cannot_read_config_file : Error<
   "cannot read configuration file '%0'">;
 def err_drv_nested_config_file: Error<
   "option '--config' is not allowed inside configuration file">;
+def err_drv_floor_function_info : Error<
+  "unable to open floor function info file">, DefaultFatal;
 
 def err_target_unsupported_arch
   : Error<"the target architecture '%0' is not supported by the target '%1'">;
diff --git a/include/clang/Basic/DiagnosticGroups.td b/include/clang/Basic/DiagnosticGroups.td
index 6ba6c19a28..cb7ad5aed5 100644
--- a/include/clang/Basic/DiagnosticGroups.td
+++ b/include/clang/Basic/DiagnosticGroups.td
@@ -1023,16 +1023,16 @@ def CudaCompat : DiagGroup<"cuda-compat">;
 // A warning group for things that will change semantics in the future.
 def FutureCompat : DiagGroup<"future-compat">;
 
+// A warning group for warnings about code that clang accepts when
+// compiling OpenCL C/C++ but which is not compatible with the SPIR spec.
+def SpirCompat : DiagGroup<"spir-compat">;
+
 def InvalidOrNonExistentDirectory : DiagGroup<"invalid-or-nonexistent-directory">;
 
 def OptionIgnored : DiagGroup<"option-ignored">;
 
 def UnknownArgument : DiagGroup<"unknown-argument">;
 
-// A warning group for warnings about code that clang accepts when
-// compiling OpenCL C/C++ but which is not compatible with the SPIR spec.
-def SpirCompat : DiagGroup<"spir-compat">;
-
 // Warning for the experimental-isel options.
 def ExperimentalISel : DiagGroup<"experimental-isel">;
 
diff --git a/include/clang/Basic/DiagnosticIDs.h b/include/clang/Basic/DiagnosticIDs.h
index 876629f373..2d7141c259 100644
--- a/include/clang/Basic/DiagnosticIDs.h
+++ b/include/clang/Basic/DiagnosticIDs.h
@@ -37,7 +37,7 @@ namespace clang {
       DIAG_SIZE_AST           =  150,
       DIAG_SIZE_COMMENT       =  100,
       DIAG_SIZE_CROSSTU       =  100,
-      DIAG_SIZE_SEMA          = 3500,
+      DIAG_SIZE_SEMA          = 4000,
       DIAG_SIZE_ANALYSIS      =  100,
       DIAG_SIZE_REFACTORING   = 1000,
     };
diff --git a/include/clang/Basic/DiagnosticParseKinds.td b/include/clang/Basic/DiagnosticParseKinds.td
index ec07bb5c4f..5f4317817c 100644
--- a/include/clang/Basic/DiagnosticParseKinds.td
+++ b/include/clang/Basic/DiagnosticParseKinds.td
@@ -1117,8 +1117,12 @@ def warn_pragma_unsupported_extension : Warning<
   "unsupported OpenCL extension %0 - ignoring">, InGroup<IgnoredPragmas>;
 def warn_pragma_extension_is_core : Warning<
   "OpenCL extension %0 is core feature or supported optional core feature - ignoring">, InGroup<DiagGroup<"pedantic-core-features">>, DefaultIgnore;
+def err_pragma_enabled_unsupported : Error<
+  "OpenCL extension %0 is unsupported">;
 
 // OpenCL errors.
+def err_opencl_address_of_label : Error<
+  "OpenCL does not support address of label ('&&') GNU extension">;
 def err_opencl_taking_function_address_parser : Error<
   "taking address of function is not allowed">;
 def err_opencl_logical_exclusive_or : Error<
diff --git a/include/clang/Basic/DiagnosticSemaKinds.td b/include/clang/Basic/DiagnosticSemaKinds.td
index 2e84f5fedf..31cbd97ba5 100644
--- a/include/clang/Basic/DiagnosticSemaKinds.td
+++ b/include/clang/Basic/DiagnosticSemaKinds.td
@@ -718,6 +718,7 @@ def ext_main_used : Extension<
 /// parser diagnostics
 def ext_no_declarators : ExtWarn<"declaration does not declare anything">,
   InGroup<MissingDeclarations>;
+def err_no_declarators : Error<"declaration does not declare anything">;
 def ext_typedef_without_a_name : ExtWarn<"typedef requires a name">,
   InGroup<MissingDeclarations>;
 def err_typedef_not_identifier : Error<"typedef name must be an identifier">;
@@ -732,10 +733,15 @@ def err_object_cannot_be_passed_returned_by_value : Error<
   "; did you forget * in %1?">;
 def err_parameters_retval_cannot_have_fp16_type : Error<
   "%select{parameters|function return value}0 cannot have __fp16 type; did you forget * ?">;
+def err_opencl_dereferencing : Error<
+  "dereferencing pointer of type %0 is not allowed">;
 def err_opencl_half_load_store : Error<
   "%select{loading directly from|assigning directly to}0 pointer to type %1 requires "
   "cl_khr_fp16. Use vector data %select{load|store}0 builtin functions instead">;
+def err_opencl_subscript : Error<
+  "subscript to array of type %0 is not allowed">;
 def err_opencl_cast_to_half : Error<"casting to type %0 is not allowed">;
+def err_opencl_cast_from_half : Error<"casting from type %0 is not allowed">;
 def err_opencl_half_declaration : Error<
   "declaring variable of type %0 is not allowed">;
 def err_opencl_half_param : Error<
@@ -7420,6 +7426,9 @@ def err_opencl_function_pointer : Error<
 def err_opencl_taking_address_capture : Error<
   "taking address of a capture is not allowed">;
 
+def err_opencl_taking_function_address : Error<
+  "taking address of function is not allowed">;
+
 def err_invalid_conversion_between_vector_and_scalar : Error<
   "invalid conversion between vector type %0 and scalar type %1">;
 
@@ -8045,6 +8054,18 @@ def err_builtin_annotation_second_arg : Error<
 def err_msvc_annotation_wide_str : Error<
   "arguments to __annotation must be wide string constants">;
 
+// Builtin pipe
+def err_builtin_pipe_first_arg : Error<
+  "first argument to %0 must be a pipe type">;
+def err_builtin_pipe_argument_type_mismatch : Error<
+  "argument type doesn't match pipe type">;
+def err_builtin_pipe_args_num_mismatch : Error<
+  "invalid number of arguments to function: %0">;
+def err_builtin_pipe_invalid_arg : Error<
+  "invalid argument type to function %0 (expecting: %1)">;
+def err_builtin_pipe_invalid_access_modifier : Error<"invalid pipe access modifier (expecting %0)">;
+
+
 // CFString checking
 def err_cfstring_literal_not_string_constant : Error<
   "CFString literal is not a string constant">;
@@ -8575,6 +8596,47 @@ def err_sampler_initializer_not_integer : Error<
   "sampler_t initialization requires 32-bit integer, not %0">;
 def warn_sampler_initializer_invalid_bits : Warning<
   "sampler initializer has invalid %0 bits">, InGroup<SpirCompat>, DefaultIgnore;
+def err_event_initialization : Error<
+  "cannot initialize event_t">;
+def err_event_argument_not_null : Error<
+  "event_t variable or NULL required - got %0">;
+def err_opencl_missing_type_specifier : Error<
+  "type specifier missing">;
+def err_program_scope_variable_non_constant : Error<
+  "program scope variables are required to be declared in constant address space">;
+def err_program_scope_variable_non_constant_or_global : Error<
+  "program scope variables are required to be declared either in constant or global address space">;
+def err_half_variables : Error<
+  "half type variables are not allowed in OpenCL">;
+def err_invalid_vector_promotion : Error<
+  "cannot apply default argument promotion on a vector">;
+def err_implicit_pointer_address_space_cast : Error<
+  "illegal implicit conversion between two pointers with different address "
+  "spaces">;
+def err_static_variables : Error<
+  "static storage class can be specified only for global and constant variables">;
+def err_enqueue_kernel_num_args_mismatch : Error<
+  "number of local_size argument doesn't match the block's prototype">;
+def err_variadic_enqueue_kernel : Error<
+  "variadic arguments passed to 'enqueue_kernel' has to be of type 'unsigned int'">;
+def err_opencl_pointer_to_image : Error<
+  "pointer to image is invalid in OpenCL">;
+def err_scalar_type_rank_greater_than_vector_type : Error<
+  "scalar operand type has greater rank than the type of the vector element. (%0 and %1)">;
+// Images.
+def err_sampler_initializer_not_constant : Error<
+  "sampler_t initialization requires compile time constant">;
+def err_opencl_image3d_writes : Error<
+  "image3d_t access qualifier write_only requires"
+  " cl_khr_3d_image_writes extension to be enabled">;
+def warn_opencl_image_access_non_image : Warning<
+  "using image access qualifier with non-image type">;
+def err_opencl_image_access_read_write : Error<
+  "image access qualifier read_write is reserved for future use">;
+def err_depth_image_requires_ext : Error<
+  "use of depth image type requires extension cl_khr_depth_images">;
+def err_msaa_image_requires_ext : Error<
+  "use of multi-sample image type requires extension cl_khr_gl_msaa_sharing">;
 def err_sampler_argument_required : Error<
   "sampler_t variable required - got %0">;
 def err_wrong_sampler_addressspace: Error<
@@ -8585,10 +8647,44 @@ def err_opencl_cast_non_zero_to_event_t : Error<
   "cannot cast non-zero value '%0' to 'event_t'">;
 def err_opencl_global_invalid_addr_space : Error<
   "%select{program scope|static local|extern}0 variable must reside in %1 address space">;
+def err_read_write_with_samplers : Error <
+  "reading from an image declared with 'read_write' qualifier using a sampler is prohibited">;
+def err_image_type_can_be_used_only_as_parameter : Error <
+  "An image type can only be used as a type of a function parameter">;
+// Atomics.
+def err_atomic_init_addressspace : Error<
+  "initialization of atomic variables is restricted to variables in global address space">;
+def err_atomic_init_constant : Error<
+  "atomic variable can only be assigned to a compile time constant"
+  " in the declaration statement in the program scope">;
+// Blocks.
+def err_invalid_block_as_parameter : Error<
+  "block parameter given must take pointers to local memory as parameters (prototype is %0)">;
+def err_block_proto_variadic : Error<
+  "Invalid block prototype, variadic arguments are not allowed">;
+def err_invalid_block_array : Error<
+  "Array of block is invalid in OpenCL">;
+def err_ternary_with_block : Error<
+  "blocks cannot be used as expressions in ternary expressions">;
+// Pipes.
+def err_pipe_can_be_used_only_as_parameter : Error<
+  "pipes can be used only as function parameters">;
+def err_read_write_not_allowed_for_pipes : Error<
+  "read_write access qualifier can't be specified for pipes">;
+def err_mismatch_access_qualifiers : Error<
+  "passing '%0' to '%1' mismatch access qualifiers">;
 def err_missing_actual_pipe_type : Error<
   "missing actual type specifier for pipe">;
+def err_multiple_access_qualifiers : Error<
+  "multiple access qualifiers">;
 def err_reference_pipe_type : Error <
   "pipes packet types cannot be of reference type">;
+def err_nosvm_attr_not_pointer : Error<
+  "nosvm attribute should be used with pointer variables only">;
+def err_nosvm_opencl_version : Error<
+  "nosvm attribute supported in OpenCL 2.0 and above">;
+def warn_ocl_bultin_potential_ambiguity : Warning<
+  "implicit conversion from integral type to floating point type for overloadable function might lead to ambiguity">;
 def err_opencl_no_main : Error<"%select{function|kernel}0 cannot be called 'main'">;
 def err_opencl_kernel_attr :
   Error<"attribute %0 can only be applied to an OpenCL kernel function">;
diff --git a/include/clang/Basic/LangOptions.def b/include/clang/Basic/LangOptions.def
index be4491d512..171c88e60c 100644
--- a/include/clang/Basic/LangOptions.def
+++ b/include/clang/Basic/LangOptions.def
@@ -189,8 +189,12 @@ ENUM_LANGOPT(DefaultCallingConv, DefaultCallingConvention, 3, DCC_None, "default
 
 LANGOPT(ShortEnums        , 1, 0, "short enum types")
 
+LANGOPT(Metal             , 1, 0, "Metal")
+LANGOPT(MetalVersion      , 32, 110, "Metal version")
+LANGOPT(Vulkan            , 1, 0, "Vulkan")
+LANGOPT(VulkanVersion     , 32, 100, "Vulkan version")
 LANGOPT(OpenCL            , 1, 0, "OpenCL")
-LANGOPT(OpenCLVersion     , 32, 0, "OpenCL C version")
+LANGOPT(OpenCLVersion     , 32, 120, "OpenCL C version")
 LANGOPT(OpenCLCPlusPlus   , 1, 0, "OpenCL C++")
 LANGOPT(OpenCLCPlusPlusVersion     , 32, 0, "OpenCL C++ version")
 LANGOPT(NativeHalfType    , 1, 0, "Native half type support")
@@ -314,6 +318,10 @@ LANGOPT(PaddingOnUnsignedFixedPoint, 1, 0,
 
 LANGOPT(RegisterStaticDestructors, 1, 1, "Register C++ static destructors")
 
+LANGOPT(CLEnableHalf            , 1, 0, "cl-enable-half flag used")
+LANGOPT(CLSamplerOpaque, 1, 0, "Emit sampler as a pointer to opaque structure")
+LANGOPT(CLVerifySPIR            , 1, 0, "cl-verify-spir flag used")
+
 #undef LANGOPT
 #undef COMPATIBLE_LANGOPT
 #undef BENIGN_LANGOPT
diff --git a/include/clang/Basic/LangOptions.h b/include/clang/Basic/LangOptions.h
index 34f510f5ca..464eb24223 100644
--- a/include/clang/Basic/LangOptions.h
+++ b/include/clang/Basic/LangOptions.h
@@ -22,6 +22,7 @@
 #include "clang/Basic/Visibility.h"
 #include "llvm/ADT/StringRef.h"
 #include "llvm/ADT/Triple.h"
+#include "clang/Basic/OpenCLOptions.h"
 #include <string>
 #include <vector>
 
@@ -170,6 +171,11 @@ public:
     FEA_On
   };
 
+  std::fstream* floor_function_info { nullptr };
+  unsigned int floor_image_capabilities { 0 };
+  bool metal_no_array_image { false };
+  bool metal_soft_printf { false };
+  bool vulkan_soft_printf { false };
 
 public:
   /// Set of enabled sanitizers.
diff --git a/include/clang/Basic/OpenCLExtensions.def b/include/clang/Basic/OpenCLExtensions.def
index 5e7d2cb473..9cb524c944 100644
--- a/include/clang/Basic/OpenCLExtensions.def
+++ b/include/clang/Basic/OpenCLExtensions.def
@@ -70,10 +70,12 @@ OPENCLEXT_INTERNAL(cl_khr_spir, 120, ~0U)
 // OpenCL 2.0.
 OPENCLEXT_INTERNAL(cl_khr_egl_event, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_egl_image, 200, ~0U)
-OPENCLEXT_INTERNAL(cl_khr_mipmap_image, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_srgb_image_writes, 200, ~0U)
-OPENCLEXT_INTERNAL(cl_khr_subgroups, 200, ~0U)
 OPENCLEXT_INTERNAL(cl_khr_terminate_context, 200, ~0U)
+// technically OpenCL 2.0, but Intel supports these with OpenCL/SPIR 1.2
+OPENCLEXT_INTERNAL(cl_khr_mipmap_image, 120, ~0U)
+OPENCLEXT_INTERNAL(cl_khr_mipmap_image_writes, 120, ~0U)
+OPENCLEXT_INTERNAL(cl_khr_subgroups, 120, ~0U)
 
 // Clang Extensions.
 OPENCLEXT_INTERNAL(cl_clang_storage_class_specifiers, 100, ~0U)
@@ -87,6 +89,12 @@ OPENCLEXT_INTERNAL(cl_intel_subgroups, 120, ~0U)
 OPENCLEXT_INTERNAL(cl_intel_subgroups_short, 120, ~0U)
 OPENCLEXT_INTERNAL(cl_intel_device_side_avc_motion_estimation, 120, ~0U)
 
+// Vulkan capabilities and extensions
+OPENCLEXT_INTERNAL(vk_capability_int16, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_int64, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_float16, 100, ~0U)
+OPENCLEXT_INTERNAL(vk_capability_float64, 100, ~0U)
+
 #undef OPENCLEXT_INTERNAL
 
 #ifdef OPENCLEXT
diff --git a/include/clang/Basic/OpenCLImageTypes.def b/include/clang/Basic/OpenCLImageTypes.def
index 0efed996ab..9ce4976976 100644
--- a/include/clang/Basic/OpenCLImageTypes.def
+++ b/include/clang/Basic/OpenCLImageTypes.def
@@ -22,22 +22,42 @@
 #define IMAGE_READ_WRITE_TYPE(Type, Id, Ext)
 
 #elif defined(GENERIC_IMAGE_TYPE_EXT)
+#if 1 // NOTE: same as below
+#define IMAGE_READ_TYPE(Type, Id, Ext) GENERIC_IMAGE_TYPE_EXT(Type, Id##Ty, Ext)
+#define IMAGE_WRITE_TYPE(Type, Id, Ext)
+#define IMAGE_READ_WRITE_TYPE(Type, Id, Ext)
+#else
 #define IMAGE_READ_TYPE(Type, Id, Ext) GENERIC_IMAGE_TYPE_EXT(Type, Id##ROTy, Ext)
 #define IMAGE_WRITE_TYPE(Type, Id, Ext) GENERIC_IMAGE_TYPE_EXT(Type, Id##WOTy, Ext)
 #define IMAGE_READ_WRITE_TYPE(Type, Id, Ext) GENERIC_IMAGE_TYPE_EXT(Type, Id##RWTy, Ext)
+#endif
+
+#else
+
+// NOTE/TODO:
+// this new method of using ro/wo/rw specific image types does not yet
+// work everywhere and is generally incompatible to SPIR 1.2 itself
+// -> use the new facilities, but keep using the old/standard type names
+#if 1
+
+#define IMAGE_READ_TYPE(Type, Id, Ext) IMAGE_TYPE(Type, Id, Id##Ty, , )
+#define IMAGE_WRITE_TYPE(Type, Id, Ext)
+#define IMAGE_READ_WRITE_TYPE(Type, Id, Ext)
 
 #else
 #ifndef IMAGE_READ_TYPE
 #define IMAGE_READ_TYPE(Type, Id, Ext) \
-          IMAGE_TYPE(Type, Id##RO, Id##ROTy,  read_only, ro)
+          IMAGE_TYPE(Type, Id##RO, Id##ROTy,  read_only, _ro)
 #endif
 #ifndef IMAGE_WRITE_TYPE
 #define IMAGE_WRITE_TYPE(Type, Id, Ext) \
-          IMAGE_TYPE(Type, Id##WO, Id##WOTy, write_only, wo)
+          IMAGE_TYPE(Type, Id##WO, Id##WOTy, write_only, _wo)
 #endif
 #ifndef IMAGE_READ_WRITE_TYPE
 #define IMAGE_READ_WRITE_TYPE(Type, Id, Ext) \
-          IMAGE_TYPE(Type, Id##RW, Id##RWTy, read_write, rw)
+          IMAGE_TYPE(Type, Id##RW, Id##RWTy, read_write, _rw)
+#endif
+
 #endif
 
 #endif
@@ -54,6 +74,10 @@ IMAGE_READ_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA, "cl_khr_gl_msaa_sharing
 IMAGE_READ_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_READ_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_READ_TYPE(image3d, OCLImage3d, "")
+IMAGE_READ_TYPE(imagecube, OCLImageCube, "")
+IMAGE_READ_TYPE(imagecube_array, OCLImageCubeArray, "")
+IMAGE_READ_TYPE(imagecube_depth, OCLImageCubeDepth, "")
+IMAGE_READ_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth, "")
 
 IMAGE_WRITE_TYPE(image1d, OCLImage1d, "")
 IMAGE_WRITE_TYPE(image1d_array, OCLImage1dArray, "")
@@ -67,6 +91,10 @@ IMAGE_WRITE_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA, "cl_khr_gl_msaa_sharin
 IMAGE_WRITE_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_WRITE_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_WRITE_TYPE(image3d, OCLImage3d, "cl_khr_3d_image_writes")
+IMAGE_WRITE_TYPE(imagecube, OCLImageCube, "")
+IMAGE_WRITE_TYPE(imagecube_array, OCLImageCubeArray, "")
+IMAGE_WRITE_TYPE(imagecube_depth, OCLImageCubeDepth, "")
+IMAGE_WRITE_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth, "")
 
 IMAGE_READ_WRITE_TYPE(image1d, OCLImage1d, "")
 IMAGE_READ_WRITE_TYPE(image1d_array, OCLImage1dArray, "")
@@ -80,6 +108,10 @@ IMAGE_READ_WRITE_TYPE(image2d_array_msaa, OCLImage2dArrayMSAA, "cl_khr_gl_msaa_s
 IMAGE_READ_WRITE_TYPE(image2d_msaa_depth, OCLImage2dMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_READ_WRITE_TYPE(image2d_array_msaa_depth, OCLImage2dArrayMSAADepth, "cl_khr_gl_msaa_sharing")
 IMAGE_READ_WRITE_TYPE(image3d, OCLImage3d, "")
+IMAGE_READ_WRITE_TYPE(imagecube, OCLImageCube, "")
+IMAGE_READ_WRITE_TYPE(imagecube_array, OCLImageCubeArray, "")
+IMAGE_READ_WRITE_TYPE(imagecube_depth, OCLImageCubeDepth, "")
+IMAGE_READ_WRITE_TYPE(imagecube_array_depth, OCLImageCubeArrayDepth, "")
 
 #undef IMAGE_TYPE
 #undef GENERIC_IMAGE_TYPE
diff --git a/include/clang/Basic/Specifiers.h b/include/clang/Basic/Specifiers.h
index 0af01e4543..3321e72619 100644
--- a/include/clang/Basic/Specifiers.h
+++ b/include/clang/Basic/Specifiers.h
@@ -80,6 +80,11 @@ namespace clang {
     TST_atomic,           // C11 _Atomic
 #define GENERIC_IMAGE_TYPE(ImgType, Id) TST_##ImgType##_t, // OpenCL image types
 #include "clang/Basic/OpenCLImageTypes.def"
+    TST_sampler_t,        // OpenCL sampler_t
+    TST_event_t,          // OpenCL event_t
+    TST_queue_t,          // OpenCL queue_t
+    TST_clk_event_t,      // OpenCL clk_event_t
+    TST_reserve_id_t,     // OpenCL reserve_id_t
     TST_error // erroneous type
   };
 
@@ -211,6 +216,9 @@ namespace clang {
     SC_PrivateExtern,
 
     // These are only legal on variables.
+    // TODO: are these wanted/unproblematic? (SC_OpenCLWorkGroupLocal was removed due to issues)
+    SC_OpenCLConstant,
+    SC_OpenCLConstantExtern,
     SC_Auto,
     SC_Register
   };
@@ -246,8 +254,12 @@ namespace clang {
     CC_AAPCS,       // __attribute__((pcs("aapcs")))
     CC_AAPCS_VFP,   // __attribute__((pcs("aapcs-vfp")))
     CC_IntelOclBicc, // __attribute__((intel_ocl_bicc))
-    CC_SpirFunction, // default for OpenCL functions on SPIR target
-    CC_OpenCLKernel, // inferred for OpenCL kernels
+	// NOTE: don't go above 15 for anything that is actually used by clang
+    CC_FloorFunction, // default for OpenCL/SPIR, Metal/AIR, CUDA and Vulkan/SPIR-V functions (non entry points)
+    CC_FloorKernel,   // inferred for OpenCL/SPIR, Metal/AIR, CUDA and Vulkan/SPIR-V kernels
+    CC_FloorVertex,   // inferred for Metal/AIR and Vulkan/SPIR-V vertex shaders
+    CC_FloorFragment, // inferred for Metal/AIR and Vulkan/SPIR-V fragment shaders
+    // ^^^ 14
     CC_Swift,        // __attribute__((swiftcall))
     CC_PreserveMost, // __attribute__((preserve_most))
     CC_PreserveAll,  // __attribute__((preserve_all))
@@ -264,8 +276,10 @@ namespace clang {
     case CC_X86RegCall:
     case CC_X86Pascal:
     case CC_X86VectorCall:
-    case CC_SpirFunction:
-    case CC_OpenCLKernel:
+    case CC_FloorFunction:
+    case CC_FloorKernel:
+    case CC_FloorVertex:
+    case CC_FloorFragment:
     case CC_Swift:
       return false;
     default:
diff --git a/include/clang/Basic/TokenKinds.def b/include/clang/Basic/TokenKinds.def
index e4616c9a6a..5bfe178506 100644
--- a/include/clang/Basic/TokenKinds.def
+++ b/include/clang/Basic/TokenKinds.def
@@ -529,38 +529,21 @@ KEYWORD(__forceinline               , KEYMS)
 KEYWORD(__unaligned                 , KEYMS)
 KEYWORD(__super                     , KEYMS)
 
-// OpenCL address space qualifiers
-KEYWORD(__global                    , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__local                     , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__constant                  , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__private                   , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__generic                   , KEYOPENCLC | KEYOPENCLCXX)
-ALIAS("global", __global            , KEYOPENCLC)
-ALIAS("local", __local              , KEYOPENCLC)
-ALIAS("constant", __constant        , KEYOPENCLC)
-ALIAS("private", __private          , KEYOPENCLC)
-ALIAS("generic", __generic          , KEYOPENCLC)
-// OpenCL function qualifiers
-KEYWORD(__kernel                    , KEYOPENCLC | KEYOPENCLCXX)
-ALIAS("kernel", __kernel            , KEYOPENCLC | KEYOPENCLCXX)
-// OpenCL access qualifiers
-KEYWORD(__read_only                 , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__write_only                , KEYOPENCLC | KEYOPENCLCXX)
-KEYWORD(__read_write                , KEYOPENCLC | KEYOPENCLCXX)
-ALIAS("read_only", __read_only      , KEYOPENCLC | KEYOPENCLCXX)
-ALIAS("write_only", __write_only    , KEYOPENCLC | KEYOPENCLCXX)
-ALIAS("read_write", __read_write    , KEYOPENCLC | KEYOPENCLCXX)
 // OpenCL builtins
-KEYWORD(__builtin_astype            , KEYOPENCLC)
-KEYWORD(vec_step                    , KEYOPENCLC | KEYALTIVEC | KEYZVECTOR)
-#define GENERIC_IMAGE_TYPE(ImgType, Id) KEYWORD(ImgType##_t, KEYOPENCLC)
-#include "clang/Basic/OpenCLImageTypes.def"
+KEYWORD(__builtin_astype            , KEYCXX|KEYOPENCLC)
+KEYWORD(sampler_t                   , KEYCXX|KEYOPENCLC)
+KEYWORD(event_t                     , KEYCXX|KEYOPENCLC)
+KEYWORD(vec_step                    , KEYCXX|KEYOPENCLC|KEYALTIVEC|KEYZVECTOR)
+
+// OpenCL 2.0
+KEYWORD(queue_t                     , KEYCXX|KEYOPENCLC)
+KEYWORD(clk_event_t                 , KEYCXX|KEYOPENCLC)
+KEYWORD(reserve_id_t                , KEYCXX|KEYOPENCLC)
+KEYWORD(pipe                        , KEYCXX|KEYOPENCLC)
 
 // OpenMP Type Traits
 KEYWORD(__builtin_omp_required_simd_align, KEYALL)
 
-KEYWORD(pipe                        , KEYOPENCLC)
-
 // Borland Extensions.
 KEYWORD(__pascal                    , KEYALL)
 
diff --git a/include/clang/CodeGen/BackendUtil.h b/include/clang/CodeGen/BackendUtil.h
index 3d1221a43b..78c7ba41fc 100644
--- a/include/clang/CodeGen/BackendUtil.h
+++ b/include/clang/CodeGen/BackendUtil.h
@@ -31,6 +31,11 @@ namespace clang {
   enum BackendAction {
     Backend_EmitAssembly,  ///< Emit native assembly files
     Backend_EmitBC,        ///< Emit LLVM bitcode files
+    Backend_EmitBC32,      ///< Emit LLVM 3.2 bitcode files
+    Backend_EmitBC35,      ///< Emit LLVM 3.5 bitcode files
+    Backend_EmitSPIRV,     ///< Emit SPIR-V bitcode files
+    Backend_EmitSPIRVContainer,    ///< Emit container with SPIR-V bitcode files
+    Backend_EmitMetalLib,          ///< Emit Metal Library
     Backend_EmitLL,        ///< Emit human-readable LLVM assembly
     Backend_EmitNothing,   ///< Don't emit anything (benchmarking mode)
     Backend_EmitMCNull,    ///< Run CodeGen, but don't emit anything
diff --git a/include/clang/CodeGen/CodeGenAction.h b/include/clang/CodeGen/CodeGenAction.h
index 5a18a9de03..790235c4cc 100644
--- a/include/clang/CodeGen/CodeGenAction.h
+++ b/include/clang/CodeGen/CodeGenAction.h
@@ -93,6 +93,36 @@ public:
   EmitBCAction(llvm::LLVMContext *_VMContext = nullptr);
 };
 
+class EmitBC32Action : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitBC32Action(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitBC35Action : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitBC35Action(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitSPIRVAction : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitSPIRVAction(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitSPIRVContainerAction : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitSPIRVContainerAction(llvm::LLVMContext *_VMContext = nullptr);
+};
+
+class EmitMetalLibAction : public CodeGenAction {
+  virtual void anchor();
+public:
+  EmitMetalLibAction(llvm::LLVMContext *_VMContext = nullptr);
+};
+
 class EmitLLVMAction : public CodeGenAction {
   virtual void anchor();
 public:
diff --git a/include/clang/Driver/CC1Options.td b/include/clang/Driver/CC1Options.td
index 9d2d2df7d2..f691274f62 100644
--- a/include/clang/Driver/CC1Options.td
+++ b/include/clang/Driver/CC1Options.td
@@ -568,6 +568,12 @@ def emit_pch : Flag<["-"], "emit-pch">,
   HelpText<"Generate pre-compiled header file">;
 def emit_llvm_bc : Flag<["-"], "emit-llvm-bc">,
   HelpText<"Build ASTs then convert to LLVM, emit .bc file">;
+def emit_spirv : Flag<["-"], "emit-spirv">,
+  HelpText<"Build ASTs then convert to LLVM, then convert to SPIR-V, emit .spv file">;
+def emit_spirv_container : Flag<["-"], "emit-spirv-container">,
+  HelpText<"Build ASTs then convert to LLVM, then convert to multiple SPIR-V modules, emit .spvc file">;
+def emit_metallib : Flag<["-"], "emit-metallib">,
+  HelpText<"Builds Metal/AIR bitcode and puts it in a .metallib file">;
 def emit_llvm_only : Flag<["-"], "emit-llvm-only">,
   HelpText<"Build ASTs and convert to LLVM, discarding output">;
 def emit_codegen_only : Flag<["-"], "emit-codegen-only">,
@@ -806,9 +812,34 @@ def detailed_preprocessing_record : Flag<["-"], "detailed-preprocessing-record">
 // OpenCL Options
 //===----------------------------------------------------------------------===//
 
+def cl_enable_half : Flag<["-"], "cl-enable-half">,
+HelpText<"OpenCL only. This option enables the dereferencing of half pointers">;
+
+// SPIR generator options
+def cl_spir_compile_options : Separate<["-"], "cl-spir-compile-options">,
+HelpText<"SPIR compilation options to record in metadata">;
+def cl_sampler_type : Separate<["-"], "cl-sampler-type">,
+HelpText<"OpenCL only. Specify type of sampler to emit. Valid values: \"opaque\"(default), \"i32\"">;
+
+def cl_verify_spir : Flag<["-"], "cl-verify-spir">,
+HelpText<"OpenCL/SPIR only. Runs the Khronos SPIR verifier on the final LLVM IR.">;
+
+def cl_spir_intel_workarounds : Flag<["-"], "cl-spir-intel-workarounds">,
+HelpText<"Enable Intel SPIR specific fixes and workarounds">;
+
 def cl_ext_EQ : CommaJoined<["-"], "cl-ext=">,
   HelpText<"OpenCL only. Enable or disable OpenCL extensions. The argument is a comma-separated sequence of one or more extension names, each prefixed by '+' or '-'.">;
 
+//===----------------------------------------------------------------------===//
+// libfloor Options (applying to OpenCL, CUDA, Metal and Vulkan)
+//===----------------------------------------------------------------------===//
+
+// TODO: move all of this stuff to Options.td?
+def floor_function_info : Joined<["-"], "floor-function-info=">,
+  HelpText<"floor function info output file">;
+def floor_image_capabilities : Joined<["-"], "floor-image-capabilities=">,
+  HelpText<"image read and write capabilities">;
+
 //===----------------------------------------------------------------------===//
 // CUDA Options
 //===----------------------------------------------------------------------===//
@@ -822,6 +853,30 @@ def fcuda_allow_variadic_functions : Flag<["-"], "fcuda-allow-variadic-functions
 def fno_cuda_host_device_constexpr : Flag<["-"], "fno-cuda-host-device-constexpr">,
   HelpText<"Don't treat unattributed constexpr functions as __host__ __device__.">;
 
+//===----------------------------------------------------------------------===//
+// AIR/Metal Options
+//===----------------------------------------------------------------------===//
+
+def metal_intel_workarounds : Flag<["-"], "metal-intel-workarounds">,
+  HelpText<"Enable Intel GPU specific fixes and workarounds">;
+def metal_nvidia_workarounds : Flag<["-"], "metal-nvidia-workarounds">,
+  HelpText<"Enable Nvidia GPU specific fixes and workarounds">;
+def metal_no_array_image : Flag<["-"], "metal-no-array-image">,
+  HelpText<"Disables native support for array of images">;
+def metal_soft_printf : Flag<["-"], "metal-soft-printf">,
+  HelpText<"Enables support of software printf emulation">;
+
+//===----------------------------------------------------------------------===//
+// Vulkan Options
+//===----------------------------------------------------------------------===//
+
+def vulkan_iub_size_EQ : Joined<["-"], "vulkan-iub-size=">,
+  HelpText<"Sets the Vulkan inline uniform block size">;
+def vulkan_iub_count_EQ : Joined<["-"], "vulkan-iub-count=">,
+  HelpText<"Sets the Vulkan inline uniform block count">;
+def vulkan_soft_printf : Flag<["-"], "vulkan-soft-printf">,
+  HelpText<"Enables support of software printf emulation">;
+
 //===----------------------------------------------------------------------===//
 // OpenMP Options
 //===----------------------------------------------------------------------===//
diff --git a/include/clang/Driver/Options.td b/include/clang/Driver/Options.td
index acf82c5ab2..a75694699b 100644
--- a/include/clang/Driver/Options.td
+++ b/include/clang/Driver/Options.td
@@ -624,6 +624,16 @@ def emit_ast : Flag<["-"], "emit-ast">,
   HelpText<"Emit Clang AST files for source inputs">;
 def emit_llvm : Flag<["-"], "emit-llvm">, Flags<[CC1Option]>, Group<Action_Group>,
   HelpText<"Use the LLVM representation for assembler and object files">;
+def llvm_bc_32 : Flag<["-"], "llvm-bc-32">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output LLVM 3.2 compatible bitcode">;
+def llvm_bc_35 : Flag<["-"], "llvm-bc-35">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output LLVM 3.5 compatible bitcode">;
+def llvm_spirv : Flag<["-"], "llvm-spirv">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output SPIR-V compatible bitcode">;
+def llvm_spirv_container : Flag<["-"], "llvm-spirv-container">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output a container with SPIR-V compatible bitcode modules">;
+def llvm_metallib : Flag<["-"], "llvm-metallib">, Flags<[CC1Option]>, Group<Action_Group>,
+  HelpText<"Output a Metal Library container">;
 def exported__symbols__list : Separate<["-"], "exported_symbols_list">;
 def e : JoinedOrSeparate<["-"], "e">, Group<Link_Group>;
 def fPIC : Flag<["-"], "fPIC">, Group<f_Group>;
diff --git a/include/clang/Driver/Types.def b/include/clang/Driver/Types.def
index c25bc4b080..a665ca94a9 100644
--- a/include/clang/Driver/Types.def
+++ b/include/clang/Driver/Types.def
@@ -43,6 +43,8 @@
 TYPE("cpp-output",               PP_C,         INVALID,         "i",     "u")
 TYPE("c",                        C,            PP_C,            "c",     "u")
 TYPE("cl",                       CL,           PP_C,            "cl",    "u")
+TYPE("metal",                    METAL,        PP_CXX,          "cpp",   "u")
+TYPE("vulkan",                   VULKAN,       PP_CXX,          "cpp",   "u")
 TYPE("cuda-cpp-output",          PP_CUDA,      INVALID,         "cui",   "u")
 TYPE("cuda",                     CUDA,         PP_CUDA,         "cu",    "u")
 TYPE("cuda",                     CUDA_DEVICE,  PP_CUDA,         "cu",    "")
@@ -63,6 +65,8 @@ TYPE("renderscript",             RenderScript, PP_C,            "rs",    "u")
 TYPE("c-header-cpp-output",      PP_CHeader,   INVALID,         "i",     "p")
 TYPE("c-header",                 CHeader,      PP_CHeader,      "h",     "pu")
 TYPE("cl-header",                CLHeader,     PP_CHeader,      "h",     "pu")
+TYPE("metal-header",             MetalHeader,  PP_CXXHeader,    "h",     "pu")
+TYPE("vulkan-header",            VulkanHeader, PP_CXXHeader,    "h",     "pu")
 TYPE("objective-c-header-cpp-output", PP_ObjCHeader, INVALID,   "mi",    "p")
 TYPE("objective-c-header",       ObjCHeader,   PP_ObjCHeader,   "h",     "pu")
 TYPE("c++-header-cpp-output",    PP_CXXHeader, INVALID,         "ii",    "p")
@@ -84,6 +88,8 @@ TYPE("java",                     Java,         INVALID,         nullptr, "u")
 // outputs should use the standard suffixes.
 TYPE("ir",                       LLVM_IR,      INVALID,         "ll",    "u")
 TYPE("ir",                       LLVM_BC,      INVALID,         "bc",    "u")
+TYPE("ir",                       LLVM_BC_32,   INVALID,         "bc",    "u")
+TYPE("ir",                       LLVM_BC_35,   INVALID,         "bc",    "u")
 TYPE("lto-ir",                   LTO_IR,       INVALID,         "s",     "")
 TYPE("lto-bc",                   LTO_BC,       INVALID,         "o",     "")
 
@@ -102,4 +108,7 @@ TYPE("dSYM",                     dSYM,         INVALID,         "dSYM",  "A")
 TYPE("dependencies",             Dependencies, INVALID,         "d",     "")
 TYPE("cuda-fatbin",              CUDA_FATBIN,  INVALID,         "fatbin","A")
 TYPE("hip-fatbin",               HIP_FATBIN,   INVALID,         "hipfb", "A")
+TYPE("spirv",                    SPIRV,        INVALID,         "spv",   "u")
+TYPE("spirvc",                   SPIRVC,       INVALID,         "spvc",  "u")
+TYPE("metallib",                 METALLIB,     INVALID,         "metallib", "u")
 TYPE("none",                     Nothing,      INVALID,         nullptr, "u")
diff --git a/include/clang/Frontend/FrontendOptions.h b/include/clang/Frontend/FrontendOptions.h
index 92191ebd12..2ac5e23ce4 100644
--- a/include/clang/Frontend/FrontendOptions.h
+++ b/include/clang/Frontend/FrontendOptions.h
@@ -58,6 +58,21 @@ enum ActionKind {
   /// Emit a .bc file.
   EmitBC,
 
+  /// Emit a LLVM 3.2 .bc file.
+  EmitBC32,
+
+  /// Emit a LLVM 3.5 .bc file.
+  EmitBC35,
+
+  /// Emit a .spv file.
+  EmitSPIRV,
+
+  /// Emit a .spvc container file.
+  EmitSPIRVContainer,
+
+  /// Emit a .metallib file.
+  EmitMetalLib,
+
   /// Translate input source into HTML.
   EmitHTML,
 
@@ -159,6 +174,8 @@ public:
     ObjC,
     ObjCXX,
     OpenCL,
+    Metal,
+    Vulkan,
     CUDA,
     RenderScript,
     HIP,
diff --git a/include/clang/Frontend/LangStandards.def b/include/clang/Frontend/LangStandards.def
index 0fdd35f320..1e83e645e7 100644
--- a/include/clang/Frontend/LangStandards.def
+++ b/include/clang/Frontend/LangStandards.def
@@ -144,36 +144,57 @@ LANGSTANDARD(gnucxx2a, "gnu++2a",
              CPlusPlus2a | Digraphs | HexFloat | GNUMode)
 
 // OpenCL
-LANGSTANDARD(opencl10, "cl1.0",
+LANGSTANDARD(opencl10, "CL",
              OpenCL, "OpenCL 1.0",
-             LineComment | C99 | Digraphs | HexFloat | OpenCL)
-LANGSTANDARD_ALIAS_DEPR(opencl10, "cl")
-
-LANGSTANDARD(opencl11, "cl1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(opencl11, "CL1.1",
              OpenCL, "OpenCL 1.1",
-             LineComment | C99 | Digraphs | HexFloat | OpenCL)
-LANGSTANDARD(opencl12, "cl1.2",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(opencl12, "CL1.2",
              OpenCL, "OpenCL 1.2",
-             LineComment | C99 | Digraphs | HexFloat | OpenCL)
-LANGSTANDARD(opencl20, "cl2.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(opencl20, "CL2.0",
              OpenCL, "OpenCL 2.0",
-             LineComment | C99 | Digraphs | HexFloat | OpenCL)
-LANGSTANDARD(openclcpp, "c++",
-             OpenCL, "OpenCL C++ 1.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(opencl21, "CL2.1",
+             OpenCL, "OpenCL 2.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(opencl22, "CL2.2",
+             OpenCL, "OpenCL 2.2",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(openclcpp, "clc++",
+             OpenCL, "OpenCL C++ 1.0 (unsupported)",
              LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | Digraphs | OpenCL)
 
-LANGSTANDARD_ALIAS_DEPR(opencl10, "CL")
-LANGSTANDARD_ALIAS_DEPR(opencl11, "CL1.1")
-LANGSTANDARD_ALIAS_DEPR(opencl12, "CL1.2")
-LANGSTANDARD_ALIAS_DEPR(opencl20, "CL2.0")
+// Metal
+LANGSTANDARD(metal11, "metal1.1",
+             Metal, "Metal 1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(metal12, "metal1.2",
+             Metal, "Metal 1.2",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(metal20, "metal2.0",
+             Metal, "Metal 2.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(metal21, "metal2.1",
+             Metal, "Metal 2.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+
+// Vulkan C++
+LANGSTANDARD(vulkan10, "vulkan1.0",
+             Vulkan, "Vulkan C++ 1.0",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
+LANGSTANDARD(vulkan11, "vulkan1.1",
+             Vulkan, "Vulkan C++ 1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode | OpenCL)
 
 // CUDA
 LANGSTANDARD(cuda, "cuda", CUDA, "NVIDIA CUDA(tm)",
-             LineComment | CPlusPlus | Digraphs)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode)
 
 // HIP
 LANGSTANDARD(hip, "hip", HIP, "HIP",
-             LineComment | CPlusPlus | Digraphs)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus14 | CPlusPlus17 | Digraphs | HexFloat | GNUMode)
 
 #undef LANGSTANDARD
 #undef LANGSTANDARD_ALIAS
diff --git a/include/clang/Lex/Preprocessor.h b/include/clang/Lex/Preprocessor.h
index 64ddb5307f..35a6b00912 100644
--- a/include/clang/Lex/Preprocessor.h
+++ b/include/clang/Lex/Preprocessor.h
@@ -137,6 +137,7 @@ class Preprocessor {
   std::unique_ptr<ScratchBuffer> ScratchBuf;
   HeaderSearch      &HeaderInfo;
   ModuleLoader      &TheModuleLoader;
+  OpenCLOptions     SupportedPragmas;
 
   /// External source of macros.
   ExternalPreprocessorSource *ExternalSource;
@@ -812,6 +813,12 @@ public:
   DiagnosticsEngine &getDiagnostics() const { return *Diags; }
   void setDiagnostics(DiagnosticsEngine &D) { Diags = &D; }
 
+  const OpenCLOptions &getSupportedPragmas() const { return SupportedPragmas; }
+  void setSupportedPragmas(const OpenCLOptions &opts)
+  {
+    SupportedPragmas = opts;
+  }
+
   const LangOptions &getLangOpts() const { return LangOpts; }
   const TargetInfo &getTargetInfo() const { return *Target; }
   const TargetInfo *getAuxTargetInfo() const { return AuxTarget; }
diff --git a/include/clang/Lex/PreprocessorOptions.h b/include/clang/Lex/PreprocessorOptions.h
index f1ac72c474..4544996a5c 100644
--- a/include/clang/Lex/PreprocessorOptions.h
+++ b/include/clang/Lex/PreprocessorOptions.h
@@ -18,6 +18,7 @@
 #include <string>
 #include <utility>
 #include <vector>
+#include "clang/Basic/LangOptions.h"
 
 namespace llvm {
 
@@ -71,6 +72,9 @@ public:
   /// skipped until after an #include of this header is seen.
   std::string PCHThroughHeader;
 
+  /// Initialize the preprocessor list of supported pragmas
+  OpenCLOptions SupportedPragmas;
+
   /// The implicit PCH included at the start of the translation unit, or empty.
   std::string ImplicitPCHInclude;
 
diff --git a/include/clang/Parse/Parser.h b/include/clang/Parse/Parser.h
index 09e81d22ae..4c249de19f 100644
--- a/include/clang/Parse/Parser.h
+++ b/include/clang/Parse/Parser.h
@@ -2480,8 +2480,6 @@ private:
   SourceLocation SkipExtendedMicrosoftTypeAttributes();
   void ParseMicrosoftInheritanceClassAttributes(ParsedAttributes &attrs);
   void ParseBorlandTypeAttributes(ParsedAttributes &attrs);
-  void ParseOpenCLKernelAttributes(ParsedAttributes &attrs);
-  void ParseOpenCLQualifiers(ParsedAttributes &Attrs);
   /// Parses opencl_unroll_hint attribute if language is OpenCL v2.0
   /// or higher.
   /// \return false if error happens.
diff --git a/include/clang/Sema/DeclSpec.h b/include/clang/Sema/DeclSpec.h
index b667e077f5..e322674587 100644
--- a/include/clang/Sema/DeclSpec.h
+++ b/include/clang/Sema/DeclSpec.h
@@ -307,6 +307,11 @@ public:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) \
   static const TST TST_##ImgType##_t = clang::TST_##ImgType##_t;
 #include "clang/Basic/OpenCLImageTypes.def"
+  static const TST TST_sampler_t = clang::TST_sampler_t;
+  static const TST TST_event_t = clang::TST_event_t;
+  static const TST TST_queue_t = clang::TST_queue_t;
+  static const TST TST_clk_event_t = clang::TST_clk_event_t;
+  static const TST TST_reserve_id_t = clang::TST_reserve_id_t;
   static const TST TST_error = clang::TST_error;
 
   // type-qualifiers
diff --git a/include/clang/Sema/Initialization.h b/include/clang/Sema/Initialization.h
index 3a2d627565..997ec20c9a 100644
--- a/include/clang/Sema/Initialization.h
+++ b/include/clang/Sema/Initialization.h
@@ -894,7 +894,13 @@ public:
     SK_OCLSamplerInit,
 
     /// Initialize an opaque OpenCL type (event_t, queue_t, etc.) with zero
-    SK_OCLZeroOpaqueType
+    SK_OCLZeroOpaqueType,
+
+    /// Initialize queue_t from 0.
+    SK_OCLZeroQueue,
+
+    /// Passing zero to a function where OpenCL event_t is expected.
+    SK_OCLZeroEvent
   };
 
   /// A single step in the initialization sequence.
@@ -1335,6 +1341,9 @@ public:
   /// from a zero constant.
   void AddOCLZeroOpaqueTypeStep(QualType T);
 
+  /// Add a step to initialize an OpenCL queue_t from 0.
+  void AddOCLZeroQueueStep(QualType T);
+
   /// Add a step to initialize by zero types defined in the
   /// cl_intel_device_side_avc_motion_estimation OpenCL extension
   void AddOCLIntelSubgroupAVCZeroInitStep(QualType T);
diff --git a/include/clang/Sema/Overload.h b/include/clang/Sema/Overload.h
index 96fd5892da..7348d7e783 100644
--- a/include/clang/Sema/Overload.h
+++ b/include/clang/Sema/Overload.h
@@ -155,6 +155,9 @@ class Sema;
     /// Zero constant to queue
     ICK_Zero_Queue_Conversion,
 
+    /// Integer constant to OpenCL sampler
+    ICK_Int_Sampler_Conversion,
+
     /// Conversions allowed in C, but not C++
     ICK_C_Only_Conversion,
 
@@ -700,6 +703,8 @@ class Sema;
     /// (CUDA) This candidate was not viable because the callee
     /// was not accessible from the caller's target (i.e. host->device,
     /// global->host, device->host).
+    /// (OpenCL) This candidate was not viable because the callee
+    /// uses extensions that are not enabled or supported.
     ovl_fail_bad_target,
 
     /// This candidate function was not viable because an enable_if
diff --git a/include/clang/Sema/Sema.h b/include/clang/Sema/Sema.h
index 4ddbf6caec..6720b8bf61 100644
--- a/include/clang/Sema/Sema.h
+++ b/include/clang/Sema/Sema.h
@@ -312,7 +312,7 @@ public:
   typedef OpaquePtr<TemplateName> TemplateTy;
   typedef OpaquePtr<QualType> TypeTy;
 
-  OpenCLOptions OpenCLFeatures;
+  OpenCLOptions& OpenCLFeatures;
   FPOptions FPFeatures;
 
   const LangOptions &LangOpts;
@@ -8746,6 +8746,10 @@ public:
   /// \param Init First part of the for loop.
   void ActOnOpenMPLoopInitialization(SourceLocation ForLoc, Stmt *Init);
 
+  /// Adds a color(location) attribute to a particular declaration.
+  void AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E,
+                                       unsigned SpellingListIndex);
+
   // OpenMP directives and clauses.
   /// Called on correct id-expression from the '#pragma omp
   /// threadprivate'.
diff --git a/include/clang/Sema/SemaInternal.h b/include/clang/Sema/SemaInternal.h
index c55e16a27c..d9788b68e4 100644
--- a/include/clang/Sema/SemaInternal.h
+++ b/include/clang/Sema/SemaInternal.h
@@ -56,7 +56,7 @@ inline bool DeclAttrsMatchCUDAMode(const LangOptions &LangOpts, Decl *D) {
     return true;
   bool isDeviceSideDecl = D->hasAttr<CUDADeviceAttr>() ||
                           D->hasAttr<CUDASharedAttr>() ||
-                          D->hasAttr<CUDAGlobalAttr>();
+                          D->hasAttr<ComputeKernelAttr>();
   return isDeviceSideDecl == LangOpts.CUDAIsDevice;
 }
 
diff --git a/lib/AST/ASTContext.cpp b/lib/AST/ASTContext.cpp
index fae1cf863c..f90a1d0ea5 100644
--- a/lib/AST/ASTContext.cpp
+++ b/lib/AST/ASTContext.cpp
@@ -758,6 +758,7 @@ static const LangASMap *getAddressSpaceMap(const TargetInfo &T,
       2, // opencl_constant
       0, // opencl_private
       4, // opencl_generic
+      0, // vulkan_input
       5, // cuda_device
       6, // cuda_constant
       7  // cuda_shared
@@ -1945,7 +1946,17 @@ TypeInfo ASTContext::getTypeInfoImpl(const Type *T) const {
       Width = Target->getPointerWidth(0);
       Align = Target->getPointerAlign(0);
       break;
-    case BuiltinType::OCLSampler:
+    case BuiltinType::OCLSampler: {
+      // TODO/NOTE: Samplers are modeled as integers for now.
+      Width = Target->getIntWidth();
+      Align = Target->getIntAlign();
+#if 0 // -> use this when treating samplers as pointers
+      auto AS = getTargetAddressSpace(LangAS::opencl_constant);
+      Width = Target->getPointerWidth(AS);
+      Align = Target->getPointerAlign(AS);
+#endif
+      break;
+    }
     case BuiltinType::OCLEvent:
     case BuiltinType::OCLClkEvent:
     case BuiltinType::OCLQueue:
@@ -2662,8 +2673,14 @@ QualType ASTContext::getAddrSpaceQualType(QualType T,
 
   // If this type already has an address space specified, it cannot get
   // another one.
+  if (Quals.hasAddressSpace()) {
+    if (Quals.getAddressSpace() == LangAS::opencl_private) {
+      Quals.removeAddressSpace(); // private can be replaced
+	} else {
   assert(!Quals.hasAddressSpace() &&
          "Type cannot be in multiple addr spaces!");
+    }
+  }
   Quals.addAddressSpace(AddressSpace);
 
   return getExtQualType(TypeNode, Quals);
@@ -8573,14 +8590,36 @@ QualType ASTContext::mergeFunctionTypes(QualType lhs, QualType rhs,
   if (lproto && rproto) { // two C99 style function prototypes
     assert(!lproto->hasExceptionSpec() && !rproto->hasExceptionSpec() &&
            "C++ shouldn't be here");
+
+    unsigned lproto_nargs = lproto->getNumParams();
+    unsigned rproto_nargs = rproto->getNumParams();
+
+    if ( LangOpts.OpenCLVersion < 200 || !lproto->isVariadic() ) {
     // Compatible functions must have the same number of parameters
-    if (lproto->getNumParams() != rproto->getNumParams())
-      return {};
+      if (lproto_nargs != rproto_nargs)
+        return QualType();
 
     // Variadic and non-variadic functions aren't compatible
     if (lproto->isVariadic() != rproto->isVariadic())
       return {};
 
+    } else {
+
+      if ( !lproto->isVariadic() && !lproto->isVariadic() ) {
+        if (lproto_nargs != rproto_nargs)
+          return QualType();
+
+      } else if ( lproto->isVariadic() ) {
+        if (lproto_nargs > rproto_nargs)
+          return QualType();
+
+      } else if ( rproto->isVariadic() ) {
+        if (lproto_nargs < rproto_nargs)
+          return QualType();
+
+      }
+    }
+
     if (lproto->getTypeQuals() != rproto->getTypeQuals())
       return {};
 
@@ -9610,7 +9649,7 @@ static GVALinkage basicGVALinkageForFunction(const ASTContext &Context,
   if (!FD->isInlined())
     return External;
 
-  if ((!Context.getLangOpts().CPlusPlus &&
+  if ((!Context.getLangOpts().CPlusPlus && !Context.getLangOpts().OpenCL &&
        !Context.getTargetInfo().getCXXABI().isMicrosoft() &&
        !FD->hasAttr<DLLExportAttr>()) ||
       FD->hasAttr<GNUInlineAttr>()) {
@@ -9645,7 +9684,7 @@ static GVALinkage adjustGVALinkageForAttributes(const ASTContext &Context,
     if (L == GVA_DiscardableODR)
       return GVA_StrongODR;
   } else if (Context.getLangOpts().CUDA && Context.getLangOpts().CUDAIsDevice &&
-             D->hasAttr<CUDAGlobalAttr>()) {
+             D->hasAttr<ComputeKernelAttr>()) {
     // Device-side functions with __global__ attribute must always be
     // visible externally so they can be launched from host.
     if (L == GVA_DiscardableODR || L == GVA_Internal)
diff --git a/lib/AST/Decl.cpp b/lib/AST/Decl.cpp
index b32e5d9aa0..becba2040c 100644
--- a/lib/AST/Decl.cpp
+++ b/lib/AST/Decl.cpp
@@ -643,6 +643,7 @@ LinkageComputer::getLVForNamespaceScopeDecl(const NamedDecl *D,
 
       if (Var->getStorageClass() != SC_Extern &&
           Var->getStorageClass() != SC_PrivateExtern &&
+          Var->getStorageClass() != SC_OpenCLConstantExtern &&
           !isSingleLineLanguageLinkage(*Var))
         return getInternalLinkageFor(Var);
     }
@@ -1890,6 +1891,8 @@ const char *VarDecl::getStorageClassSpecifierString(StorageClass SC) {
   case SC_None:                 break;
   case SC_Auto:                 return "auto";
   case SC_Extern:               return "extern";
+  case SC_OpenCLConstantExtern: return "<<opencl-constant-extern>>";
+  case SC_OpenCLConstant:       return "<<opencl-constant>>";
   case SC_PrivateExtern:        return "__private_extern__";
   case SC_Register:             return "register";
   case SC_Static:               return "static";
@@ -3000,7 +3003,10 @@ unsigned FunctionDecl::getBuiltinID() const {
     return 0;
 
   ASTContext &Context = getASTContext();
-  if (Context.getLangOpts().CPlusPlus) {
+  if (Context.getLangOpts().CPlusPlus &&
+      // unsure why this is even checked, but don't do it for OpenCL-based languages,
+      // b/c decls might be FunctionDecls due to address space casts
+      !Context.getLangOpts().OpenCL) {
     const auto *LinkageDecl =
         dyn_cast<LinkageSpecDecl>(getFirstDecl()->getDeclContext());
     // In C++, the first declaration of a builtin is always inside an implicit
diff --git a/lib/AST/DeclPrinter.cpp b/lib/AST/DeclPrinter.cpp
index 517851f9ee..274b148ba4 100644
--- a/lib/AST/DeclPrinter.cpp
+++ b/lib/AST/DeclPrinter.cpp
@@ -573,6 +573,7 @@ void DeclPrinter::VisitFunctionDecl(FunctionDecl *D) {
     case SC_Static: Out << "static "; break;
     case SC_PrivateExtern: Out << "__private_extern__ "; break;
     case SC_Auto: case SC_Register:
+    case SC_OpenCLConstant: case SC_OpenCLConstantExtern:
       llvm_unreachable("invalid for functions");
     }
 
diff --git a/lib/AST/Expr.cpp b/lib/AST/Expr.cpp
index 5a80016850..1f08e46703 100644
--- a/lib/AST/Expr.cpp
+++ b/lib/AST/Expr.cpp
@@ -1653,6 +1653,8 @@ bool CastExpr::CastConsistency() const {
   case CK_ARCReclaimReturnedObject:
   case CK_ARCExtendBlockObject:
   case CK_ZeroToOCLOpaqueType:
+  case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_IntToOCLSampler:
   case CK_FixedPointCast:
     assert(!getType()->isBooleanType() && "unheralded conversion to bool");
diff --git a/lib/AST/ExprConstant.cpp b/lib/AST/ExprConstant.cpp
index 837dc9c2a8..b42bf11cb7 100644
--- a/lib/AST/ExprConstant.cpp
+++ b/lib/AST/ExprConstant.cpp
@@ -1243,7 +1243,8 @@ APValue &CallStackFrame::createTemporary(const void *Key,
                                          bool IsLifetimeExtended) {
   unsigned Version = Info.CurrentCall->getTempVersion();
   APValue &Result = Temporaries[MapKeyTy(Key, Version)];
-  assert(Result.isUninit() && "temporary created multiple times");
+  // TODO: fix this!
+  //assert(Result.isUninit() && "temporary created multiple times");
   Info.CleanupStack.push_back(Cleanup(&Result, IsLifetimeExtended));
   return Result;
 }
@@ -7337,7 +7338,8 @@ public:
       : ExprEvaluatorBaseTy(info), Result(result) {}
 
   bool Success(const llvm::APSInt &SI, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() &&
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     assert(SI.isSigned() == E->getType()->isSignedIntegerOrEnumerationType() &&
            "Invalid evaluation result.");
@@ -7351,7 +7353,8 @@ public:
   }
 
   bool Success(const llvm::APInt &I, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() &&
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     assert(I.getBitWidth() == Info.Ctx.getIntWidth(E->getType()) &&
            "Invalid evaluation result.");
@@ -7365,7 +7368,8 @@ public:
   }
 
   bool Success(uint64_t Value, const Expr *E, APValue &Result) {
-    assert(E->getType()->isIntegralOrEnumerationType() &&
+    assert((E->getType()->isIntegralOrEnumerationType() ||
+            E->getType()->isSamplerT()) &&
            "Invalid evaluation result.");
     Result = APValue(Info.Ctx.MakeIntValue(Value, E->getType()));
     return true;
@@ -9722,13 +9726,22 @@ bool IntExprEvaluator::VisitCastExpr(const CastExpr *E) {
   case CK_IntegralComplexCast:
   case CK_IntegralComplexToFloatingComplex:
   case CK_BuiltinFnToFnPtr:
+  case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_ZeroToOCLOpaqueType:
   case CK_NonAtomicToAtomic:
   case CK_AddressSpaceConversion:
-  case CK_IntToOCLSampler:
   case CK_FixedPointCast:
     llvm_unreachable("invalid cast kind for integral value");
 
+  case CK_IntToOCLSampler: {
+    Expr::EvalResult ExprResult;
+    if(!SubExpr->EvaluateAsInt(ExprResult, Info.Ctx)) {
+      return false;
+    }
+    return Success(ExprResult.Val.getInt(), E);
+  }
+
   case CK_BitCast:
   case CK_Dependent:
   case CK_LValueBitCast:
@@ -9994,10 +10007,12 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_huge_valf:
   case Builtin::BI__builtin_huge_vall:
   case Builtin::BI__builtin_huge_valf128:
+  case Builtin::BI__builtin_huge_valh:
   case Builtin::BI__builtin_inf:
   case Builtin::BI__builtin_inff:
   case Builtin::BI__builtin_infl:
-  case Builtin::BI__builtin_inff128: {
+  case Builtin::BI__builtin_inff128:
+  case Builtin::BI__builtin_infh: {
     const llvm::fltSemantics &Sem =
       Info.Ctx.getFloatTypeSemantics(E->getType());
     Result = llvm::APFloat::getInf(Sem);
@@ -10008,6 +10023,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nansf:
   case Builtin::BI__builtin_nansl:
   case Builtin::BI__builtin_nansf128:
+  case Builtin::BI__builtin_nansh:
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
                                true, Result))
       return Error(E);
@@ -10017,6 +10033,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nanf:
   case Builtin::BI__builtin_nanl:
   case Builtin::BI__builtin_nanf128:
+  case Builtin::BI__builtin_nanh:
     // If this is __builtin_nan() turn this into a nan, otherwise we
     // can't constant fold it.
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
@@ -10265,6 +10282,8 @@ bool ComplexExprEvaluator::VisitCastExpr(const CastExpr *E) {
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLOpaqueType:
+  case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_NonAtomicToAtomic:
   case CK_AddressSpaceConversion:
   case CK_IntToOCLSampler:
@@ -10795,6 +10814,9 @@ static bool Evaluate(APValue &Result, EvalInfo &Info, const Expr *E) {
       if (!EvaluateAtomic(E, nullptr, Result, Info))
         return false;
     }
+  } else if (T->isSamplerT()) {
+    if (!IntExprEvaluator(Info, Result).Visit(E))
+      return false;
   } else if (Info.getLangOpts().CPlusPlus11) {
     Info.FFDiag(E, diag::note_constexpr_nonliteral) << E->getType();
     return false;
diff --git a/lib/AST/ItaniumMangle.cpp b/lib/AST/ItaniumMangle.cpp
index 8231ebe88b..dba68fe2c3 100644
--- a/lib/AST/ItaniumMangle.cpp
+++ b/lib/AST/ItaniumMangle.cpp
@@ -170,6 +170,9 @@ public:
 
   void mangleStringLiteral(const StringLiteral *, raw_ostream &) override;
 
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) override;
+  void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) override;
+
   bool getNextDiscriminator(const NamedDecl *ND, unsigned &disc) {
     // Lambda closure types are already numbered.
     if (isLambda(ND))
@@ -424,6 +427,7 @@ public:
   void mangleName(const NamedDecl *ND);
   void mangleType(QualType T);
   void mangleNameOrStandardSubstitution(const NamedDecl *ND);
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD);
 
 private:
 
@@ -2331,7 +2335,7 @@ static bool isTypeSubstitutable(Qualifiers Quals, const Type *Ty,
   if (Ty->isSpecificBuiltinType(BuiltinType::ObjCSel))
     return true;
   if (Ty->isOpenCLSpecificType())
-    return true;
+    return false;
   if (Ty->isBuiltinType())
     return false;
   // Through to Clang 6.0, we accidentally treated undeduced auto types as
@@ -2400,7 +2404,8 @@ void CXXNameMangler::mangleType(QualType T) {
   const Type *ty = split.Ty;
 
   bool isSubstitutable =
-    isTypeSubstitutable(quals, ty, Context.getASTContext());
+    isTypeSubstitutable(quals, ty, Context.getASTContext()) &&
+    !(Context.getASTContext().getLangOpts().OpenCL && isa<ExtVectorType>(T));
   if (isSubstitutable && mangleSubstitution(T))
     return;
 
@@ -2452,6 +2457,30 @@ void CXXNameMangler::mangleNameOrStandardSubstitution(const NamedDecl *ND) {
     mangleName(ND);
 }
 
+void CXXNameMangler::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD) {
+	const DeclContext *DC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(D));
+	const DeclContext *PDC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(RD));
+	
+	if(const auto II = D->getIdentifier()) {
+		// TODO: need actual parent field entry for all nested types
+		if(DC->getParent()->Equals(PDC)) {
+			mangleSourceName(II);
+		}
+	}
+	
+	// top level: mangle directly (without enclosing record decl / PDC)
+	// all else: mangle nested type as well
+	if(!DC->getParent()->Equals(PDC)) {
+		if (GetLocalClassDecl(D)) {
+			mangleLocalName(D, nullptr);
+		}
+		else {
+			mangleNestedName(D, DC, nullptr);
+		}
+	}
+	mangleType(D->getType());
+}
+
 void CXXNameMangler::mangleType(const BuiltinType *T) {
   //  <type>         ::= <builtin-type>
   //  <builtin-type> ::= v  # void
@@ -2614,10 +2643,11 @@ void CXXNameMangler::mangleType(const BuiltinType *T) {
     Out << "13objc_selector";
     break;
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-  case BuiltinType::Id: \
-    type_name = "ocl_" #ImgType "_" #Suffix; \
+  case BuiltinType::Id: { \
+    const std::string type_name = "ocl_" #ImgType; \
     Out << type_name.size() << type_name; \
-    break;
+    break; \
+  }
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
     Out << "11ocl_sampler";
@@ -2655,8 +2685,10 @@ StringRef CXXNameMangler::getCallingConvQualifierName(CallingConv CC) {
   case CC_AAPCS_VFP:
   case CC_AArch64VectorCall:
   case CC_IntelOclBicc:
-  case CC_SpirFunction:
-  case CC_OpenCLKernel:
+  case CC_FloorFunction:
+  case CC_FloorKernel:
+  case CC_FloorVertex:
+  case CC_FloorFragment:
   case CC_PreserveMost:
   case CC_PreserveAll:
     // FIXME: we should be mangling all of the above.
@@ -5030,6 +5062,26 @@ void ItaniumMangleContextImpl::mangleStringLiteral(const StringLiteral *, raw_os
   llvm_unreachable("Can't mangle string literals");
 }
 
+void ItaniumMangleContextImpl::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &Out) {
+	assert(isa<FieldDecl>(D) &&
+		   "Invalid mangleName() call, argument is not a field decl!");
+	
+	PrettyStackTraceDecl CrashInfo(D, SourceLocation(),
+								   getASTContext().getSourceManager(),
+								   "Mangling declaration");
+	
+	CXXNameMangler Mangler(*this, Out, D);
+	Mangler.mangleMetalFieldName(D, RD);
+}
+
+void ItaniumMangleContextImpl::mangleMetalGeneric(const std::string& name, QualType Ty,
+												  const CXXRecordDecl* RD, raw_ostream &Out) {
+	CXXNameMangler Mangler(*this, Out, nullptr);
+	Out << name.size();
+	Out << name;
+	Mangler.mangleType(Ty);
+}
+
 ItaniumMangleContext *
 ItaniumMangleContext::create(ASTContext &Context, DiagnosticsEngine &Diags) {
   return new ItaniumMangleContextImpl(Context, Diags);
diff --git a/lib/AST/MicrosoftMangle.cpp b/lib/AST/MicrosoftMangle.cpp
index db0d770d9a..ba28e9316c 100644
--- a/lib/AST/MicrosoftMangle.cpp
+++ b/lib/AST/MicrosoftMangle.cpp
@@ -2028,7 +2028,7 @@ void MicrosoftCXXNameMangler::mangleType(const BuiltinType *T, Qualifiers,
 
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case BuiltinType::Id: \
-    Out << "PAUocl_" #ImgType "_" #Suffix "@@"; \
+    Out << "PAUocl_" #ImgType #Suffix "@@"; \
     break;
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
diff --git a/lib/AST/Type.cpp b/lib/AST/Type.cpp
index 0dbc88c045..8c2afce4ef 100644
--- a/lib/AST/Type.cpp
+++ b/lib/AST/Type.cpp
@@ -1927,6 +1927,13 @@ bool Type::isFloatingType() const {
   return false;
 }
 
+bool Type::isDoubleType() const {
+  if (const BuiltinType *BT = dyn_cast<BuiltinType>(CanonicalType))
+    return BT->getKind() >= BuiltinType::Double &&
+           BT->getKind() <= BuiltinType::LongDouble;
+  return false;
+}
+
 bool Type::hasFloatingRepresentation() const {
   if (const auto *VT = dyn_cast<VectorType>(CanonicalType))
     return VT->getElementType()->isFloatingType();
@@ -1949,6 +1956,30 @@ bool Type::isRealType() const {
   return false;
 }
 
+bool Type::isFloatingVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isFloatingType();
+  return false;
+}
+
+bool Type::isDoubleVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isDoubleType();
+  return false;
+}
+
+bool Type::isIntegerVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isIntegerType();
+  return false;
+}
+
+bool Type::isRealVecType() const {
+  if (const VectorType *VT = dyn_cast<VectorType>(CanonicalType))
+    return VT->getElementType()->isRealType();
+  return false;
+}
+
 bool Type::isArithmeticType() const {
   if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType))
     return BT->getKind() >= BuiltinType::Bool &&
@@ -2288,6 +2319,9 @@ bool Type::isLiteralType(const ASTContext &Ctx) const {
   if (isDependentType())
     return false;
 
+  if (Ctx.getLangOpts().OpenCL && isSamplerT())
+    return true;
+
   // C++1y [basic.types]p10:
   //   A type is a literal type if it is:
   //   -- cv void; or
@@ -2778,10 +2812,17 @@ StringRef BuiltinType::getName(const PrintingPolicy &Policy) const {
     return "Class";
   case ObjCSel:
     return "SEL";
+#if 0 // TODO: enable this again when using ro/wo/rw image types
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case Id: \
     return "__" #Access " " #ImgType "_t";
 #include "clang/Basic/OpenCLImageTypes.def"
+#else
+#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
+  case Id: \
+    return #ImgType "_t";
+#include "clang/Basic/OpenCLImageTypes.def"
+#endif
   case OCLSampler:
     return "sampler_t";
   case OCLEvent:
@@ -2834,8 +2875,10 @@ StringRef FunctionType::getNameForCallConv(CallingConv CC) {
   case CC_AAPCS_VFP: return "aapcs-vfp";
   case CC_AArch64VectorCall: return "aarch64_vector_pcs";
   case CC_IntelOclBicc: return "intel_ocl_bicc";
-  case CC_SpirFunction: return "spir_function";
-  case CC_OpenCLKernel: return "opencl_kernel";
+  case CC_FloorFunction: return "floor_function";
+  case CC_FloorKernel: return "floor_kernel";
+  case CC_FloorVertex: return "floor_vertex";
+  case CC_FloorFragment: return "floor_fragment";
   case CC_Swift: return "swiftcall";
   case CC_PreserveMost: return "preserve_most";
   case CC_PreserveAll: return "preserve_all";
@@ -3247,6 +3290,9 @@ bool AttributedType::isCallingConv() const {
   case attr::IntelOclBicc:
   case attr::PreserveMost:
   case attr::PreserveAll:
+  case attr::GraphicsVertexShader:
+  case attr::GraphicsFragmentShader:
+  case attr::ComputeKernel:
     return true;
   }
   llvm_unreachable("invalid attr kind");
@@ -4038,3 +4084,102 @@ void clang::FixedPointValueToString(SmallVectorImpl<char> &Str,
     FractPart = (FractPart * RadixInt) & FractPartMask;
   } while (FractPart != 0);
 }
+
+static std::pair<bool, bool> isAggregateImageTypeRecurse(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return { false, false };
+	
+	// union is not allowed
+	if(decl->isUnion()) return { false, false };
+	
+	// must have definition
+	if(!decl->hasDefinition()) return { false, false };
+	
+	// iterate over all fields/members and check if all are image types
+	bool has_any_image = false;
+	for(const auto& field : decl->fields()) {
+		// direct image type or array thereof
+		if(!field->getType()->isImageType() &&
+		   !field->getType()->isArrayImageType(false)) {
+			return { false, false };
+		}
+		has_any_image = true;
+	}
+	
+	// iterate over / recurse into all bases, check if they only consist of image types
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = isAggregateImageTypeRecurse(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.first) {
+			return { false, false };
+		}
+		has_any_image |= base_ret.second;
+	}
+	
+	// all passed
+	return { true, has_any_image };
+}
+
+bool Type::isAggregateImageType() const {
+  // must be struct or class, union is not allowed
+  if(!isStructureOrClassType()) return false;
+
+  // check class/struct itself + all inherited base classes/structs
+  const auto valid_and_has_image = isAggregateImageTypeRecurse(getAsCXXRecordDecl());
+  return valid_and_has_image.first && valid_and_has_image.second;
+}
+
+// TODO: this probably isn't right (also detects other arrays)
+bool Type::isArrayImageType(bool single_field_arr) const {
+  // only check/match this for C-style arrays of builtin images
+  if(!single_field_arr) {
+    if(isPointerType() && getPointeeType()->isArrayType()) {
+      return getPointeeType()->isArrayImageType(single_field_arr);
+    }
+
+    // simple C-style array that contains an image type
+    if(isArrayType()) {
+      return (getAsArrayTypeUnsafe()->getElementType()->isAggregateImageType() ||
+              getAsArrayTypeUnsafe()->getElementType()->isImageType());
+    }
+  }
+
+  // must be struct or class, union is not allowed
+  if(!isStructureOrClassType()) return false;
+
+  // must be a cxx rdecl
+  const auto decl = getAsCXXRecordDecl();
+  if(!decl) return false;
+
+  // must have definition
+  if(!decl->hasDefinition()) return false;
+
+  // must have at least one field
+  const auto field_count = std::distance(decl->field_begin(), decl->field_end());
+  if(field_count == 0) return false;
+
+  // handle "array of agg images" (single_field_arr == true) and "agg image with array of *images" (false)
+  if(single_field_arr) {
+  if(field_count != 1) return false;
+
+  // field must be an array
+  const QualType arr_field_type = decl->field_begin()->getType();
+  if(!arr_field_type->isArrayType()) return false;
+
+  // element type must be an aggregate image type
+  return arr_field_type->getArrayElementTypeNoTypeQual()->isAggregateImageType();
+}
+  else {
+    // must have an array field
+    bool has_array = false;
+    QualType arr_field_type;
+    for(const auto& field : decl->fields()) {
+      arr_field_type = field->getType();
+      has_array = arr_field_type->isArrayType();
+      if(has_array) break;
+    }
+    if(!has_array) return false;
+
+    // either the enclosing/parent type or the array field type must be an aggregate image type
+    return (isAggregateType() ||
+            arr_field_type->getArrayElementTypeNoTypeQual()->isAggregateImageType());
+  }
+}
diff --git a/lib/AST/TypePrinter.cpp b/lib/AST/TypePrinter.cpp
index 031b44f11e..b6f1ebf43f 100644
--- a/lib/AST/TypePrinter.cpp
+++ b/lib/AST/TypePrinter.cpp
@@ -874,9 +874,17 @@ void TypePrinter::printFunctionAfter(const FunctionType::ExtInfo &Info,
     case CC_X86RegCall:
       OS << " __attribute__((regcall))";
       break;
-    case CC_SpirFunction:
-    case CC_OpenCLKernel:
-      // Do nothing. These CCs are not available as attributes.
+    case CC_FloorFunction:
+      OS << "floor_function";
+      break;
+    case CC_FloorKernel:
+      OS << "floor_kernel";
+      break;
+    case CC_FloorVertex:
+      OS << "floor_vertex";
+      break;
+    case CC_FloorFragment:
+      OS << "floor_fragment";
       break;
     case CC_Swift:
       OS << " __attribute__((swiftcall))";
@@ -1446,11 +1454,11 @@ void TypePrinter::printAttributedAfter(const AttributedType *T,
 #include "clang/Basic/AttrList.inc"
     llvm_unreachable("non-type attribute attached to type");
 
-  case attr::OpenCLPrivateAddressSpace:
-  case attr::OpenCLGlobalAddressSpace:
-  case attr::OpenCLLocalAddressSpace:
-  case attr::OpenCLConstantAddressSpace:
-  case attr::OpenCLGenericAddressSpace:
+  case attr::PrivateAddressSpace:
+  case attr::GlobalAddressSpace:
+  case attr::LocalAddressSpace:
+  case attr::ConstantAddressSpace:
+  case attr::GenericAddressSpace:
     // FIXME: Update printAttributedBefore to print these once we generate
     // AttributedType nodes for them.
     break;
@@ -1487,6 +1495,9 @@ void TypePrinter::printAttributedAfter(const AttributedType *T,
   case attr::MSABI: OS << "ms_abi"; break;
   case attr::SysVABI: OS << "sysv_abi"; break;
   case attr::RegCall: OS << "regcall"; break;
+  case attr::ComputeKernel: OS << "floor_kernel"; break;
+  case attr::GraphicsFragmentShader: OS << "floor_fragment"; break;
+  case attr::GraphicsVertexShader: OS << "floor_vertex"; break;
   case attr::Pcs: {
     OS << "pcs(";
    QualType t = T->getEquivalentType();
@@ -1738,25 +1749,27 @@ void Qualifiers::print(raw_ostream &OS, const PrintingPolicy& Policy,
       addSpace = true;
       switch (addrspace) {
       case LangAS::opencl_global:
-        OS << "__global";
+        OS << "__cl_global";
         break;
       case LangAS::opencl_local:
-        OS << "__local";
+        OS << "__cl_local";
         break;
       case LangAS::opencl_private:
         break;
       case LangAS::opencl_constant:
+        OS << "__cl_constant";
+        break;
       case LangAS::cuda_constant:
-        OS << "__constant";
+        OS << "__cuda_constant";
         break;
       case LangAS::opencl_generic:
-        OS << "__generic";
+        OS << "__cl_generic";
         break;
       case LangAS::cuda_device:
-        OS << "__device";
+        OS << "__cuda_device";
         break;
       case LangAS::cuda_shared:
-        OS << "__shared";
+        OS << "__cuda_shared";
         break;
       default:
         OS << "__attribute__((address_space(";
diff --git a/lib/Basic/Builtins.cpp b/lib/Basic/Builtins.cpp
index 7e7f67ca87..ffa2e8d21d 100644
--- a/lib/Basic/Builtins.cpp
+++ b/lib/Basic/Builtins.cpp
@@ -71,7 +71,7 @@ bool Builtin::Context::builtinIsSupported(const Builtin::Info &BuiltinInfo,
   bool ObjCUnsupported = !LangOpts.ObjC && BuiltinInfo.Langs == OBJC_LANG;
   bool OclC1Unsupported = (LangOpts.OpenCLVersion / 100) != 1 &&
                           (BuiltinInfo.Langs & ALL_OCLC_LANGUAGES ) ==  OCLC1X_LANG;
-  bool OclC2Unsupported = LangOpts.OpenCLVersion != 200 &&
+  bool OclC2Unsupported = LangOpts.OpenCLVersion < 200 &&
                           (BuiltinInfo.Langs & ALL_OCLC_LANGUAGES) == OCLC20_LANG;
   bool OclCUnsupported = !LangOpts.OpenCL &&
                          (BuiltinInfo.Langs & ALL_OCLC_LANGUAGES);
diff --git a/lib/Basic/Cuda.cpp b/lib/Basic/Cuda.cpp
index 6c34856dfd..8b4405ff5c 100644
--- a/lib/Basic/Cuda.cpp
+++ b/lib/Basic/Cuda.cpp
@@ -24,6 +24,8 @@ const char *CudaVersionToString(CudaVersion V) {
     return "9.2";
   case CudaVersion::CUDA_100:
     return "10.0";
+  case CudaVersion::CUDA_101:
+    return "10.1";
   }
   llvm_unreachable("invalid enum");
 }
@@ -62,8 +64,12 @@ const char *CudaArchToString(CudaArch A) {
     return "sm_70";
   case CudaArch::SM_72:
     return "sm_72";
+  case CudaArch::SM_73:
+    return "sm_73";
   case CudaArch::SM_75:
     return "sm_75";
+  case CudaArch::SM_82:
+    return "sm_82";
   case CudaArch::GFX600: // tahiti
     return "gfx600";
   case CudaArch::GFX601: // pitcairn, verde, oland,hainan
@@ -116,7 +122,9 @@ CudaArch StringToCudaArch(llvm::StringRef S) {
       .Case("sm_62", CudaArch::SM_62)
       .Case("sm_70", CudaArch::SM_70)
       .Case("sm_72", CudaArch::SM_72)
+      .Case("sm_73", CudaArch::SM_73)
       .Case("sm_75", CudaArch::SM_75)
+      .Case("sm_82", CudaArch::SM_82)
       .Case("gfx600", CudaArch::GFX600)
       .Case("gfx601", CudaArch::GFX601)
       .Case("gfx700", CudaArch::GFX700)
@@ -166,8 +174,12 @@ const char *CudaVirtualArchToString(CudaVirtualArch A) {
     return "compute_70";
   case CudaVirtualArch::COMPUTE_72:
     return "compute_72";
+  case CudaVirtualArch::COMPUTE_73:
+    return "compute_73";
   case CudaVirtualArch::COMPUTE_75:
     return "compute_75";
+  case CudaVirtualArch::COMPUTE_82:
+    return "compute_82";
   case CudaVirtualArch::COMPUTE_AMDGCN:
     return "compute_amdgcn";
   }
@@ -189,7 +201,9 @@ CudaVirtualArch StringToCudaVirtualArch(llvm::StringRef S) {
       .Case("compute_62", CudaVirtualArch::COMPUTE_62)
       .Case("compute_70", CudaVirtualArch::COMPUTE_70)
       .Case("compute_72", CudaVirtualArch::COMPUTE_72)
+      .Case("compute_73", CudaVirtualArch::COMPUTE_73)
       .Case("compute_75", CudaVirtualArch::COMPUTE_75)
+      .Case("compute_82", CudaVirtualArch::COMPUTE_82)
       .Case("compute_amdgcn", CudaVirtualArch::COMPUTE_AMDGCN)
       .Default(CudaVirtualArch::UNKNOWN);
 }
@@ -227,8 +241,12 @@ CudaVirtualArch VirtualArchForCudaArch(CudaArch A) {
     return CudaVirtualArch::COMPUTE_70;
   case CudaArch::SM_72:
     return CudaVirtualArch::COMPUTE_72;
+  case CudaArch::SM_73:
+    return CudaVirtualArch::COMPUTE_73;
   case CudaArch::SM_75:
     return CudaVirtualArch::COMPUTE_75;
+  case CudaArch::SM_82:
+    return CudaVirtualArch::COMPUTE_82;
   case CudaArch::GFX600:
   case CudaArch::GFX601:
   case CudaArch::GFX700:
@@ -265,7 +283,7 @@ CudaVersion MinVersionForCudaArch(CudaArch A) {
   case CudaArch::SM_50:
   case CudaArch::SM_52:
   case CudaArch::SM_53:
-    return CudaVersion::CUDA_70;
+    return CudaVersion::CUDA_75;
   case CudaArch::SM_60:
   case CudaArch::SM_61:
   case CudaArch::SM_62:
@@ -274,8 +292,11 @@ CudaVersion MinVersionForCudaArch(CudaArch A) {
     return CudaVersion::CUDA_90;
   case CudaArch::SM_72:
     return CudaVersion::CUDA_91;
+  case CudaArch::SM_73:
   case CudaArch::SM_75:
     return CudaVersion::CUDA_100;
+  case CudaArch::SM_82:
+    return CudaVersion::CUDA_101;
   case CudaArch::GFX600:
   case CudaArch::GFX601:
   case CudaArch::GFX700:
diff --git a/lib/Basic/TargetInfo.cpp b/lib/Basic/TargetInfo.cpp
index 7b69cb097c..112a364db9 100644
--- a/lib/Basic/TargetInfo.cpp
+++ b/lib/Basic/TargetInfo.cpp
@@ -345,7 +345,8 @@ void TargetInfo::adjust(LangOptions &Opts) {
     // OpenCL standard only mentions these as "reserved".
     IntWidth = IntAlign = 32;
     LongWidth = LongAlign = 64;
-    LongLongWidth = LongLongAlign = 128;
+    //LongLongWidth = LongLongAlign = 128; // NOTE: there is no 128-bit type support in OpenCL!
+    LongLongWidth = LongLongAlign = LongWidth;
     HalfWidth = HalfAlign = 16;
     FloatWidth = FloatAlign = 32;
 
@@ -356,7 +357,8 @@ void TargetInfo::adjust(LangOptions &Opts) {
       DoubleWidth = DoubleAlign = 64;
       DoubleFormat = &llvm::APFloat::IEEEdouble();
     }
-    LongDoubleWidth = LongDoubleAlign = 128;
+    //LongDoubleWidth = LongDoubleAlign = 128; // NOTE: there is no 128-bit type support in OpenCL!
+    LongDoubleWidth = LongDoubleAlign = DoubleWidth;
 
     unsigned MaxPointerWidth = getMaxPointerWidth();
     assert(MaxPointerWidth == 32 || MaxPointerWidth == 64);
diff --git a/lib/Basic/Targets.cpp b/lib/Basic/Targets.cpp
index f79da4e576..c4d4aab7c1 100644
--- a/lib/Basic/Targets.cpp
+++ b/lib/Basic/Targets.cpp
@@ -557,18 +557,12 @@ TargetInfo *AllocateTarget(const llvm::Triple &Triple,
       return new X86_64TargetInfo(Triple, Opts);
     }
 
-  case llvm::Triple::spir: {
-    if (Triple.getOS() != llvm::Triple::UnknownOS ||
-        Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-      return nullptr;
+  case llvm::Triple::spir:
     return new SPIR32TargetInfo(Triple, Opts);
-  }
-  case llvm::Triple::spir64: {
-    if (Triple.getOS() != llvm::Triple::UnknownOS ||
-        Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-      return nullptr;
+  case llvm::Triple::spir64:
     return new SPIR64TargetInfo(Triple, Opts);
-  }
+  case llvm::Triple::air64:
+    return new AIR64TargetInfo(Triple, Opts);
   case llvm::Triple::wasm32:
     if (Triple.getSubArch() != llvm::Triple::NoSubArch ||
         Triple.getVendor() != llvm::Triple::UnknownVendor ||
diff --git a/lib/Basic/Targets/AArch64.cpp b/lib/Basic/Targets/AArch64.cpp
index 376cba6e45..be37916503 100644
--- a/lib/Basic/Targets/AArch64.cpp
+++ b/lib/Basic/Targets/AArch64.cpp
@@ -272,7 +272,7 @@ AArch64TargetInfo::checkCallingConvention(CallingConv CC) const {
   case CC_Swift:
   case CC_PreserveMost:
   case CC_PreserveAll:
-  case CC_OpenCLKernel:
+  case CC_FloorKernel:
   case CC_AArch64VectorCall:
   case CC_Win64:
     return CCCR_OK;
@@ -511,7 +511,7 @@ WindowsARM64TargetInfo::checkCallingConvention(CallingConv CC) const {
   case CC_X86VectorCall:
     return CCCR_Ignore;
   case CC_C:
-  case CC_OpenCLKernel:
+  case CC_FloorKernel:
   case CC_PreserveMost:
   case CC_PreserveAll:
   case CC_Swift:
diff --git a/lib/Basic/Targets/AMDGPU.cpp b/lib/Basic/Targets/AMDGPU.cpp
index 4f17b17ff4..dd501643ea 100644
--- a/lib/Basic/Targets/AMDGPU.cpp
+++ b/lib/Basic/Targets/AMDGPU.cpp
@@ -44,6 +44,7 @@ const LangASMap AMDGPUTargetInfo::AMDGPUDefIsGenMap = {
     Constant, // opencl_constant
     Private,  // opencl_private
     Generic,  // opencl_generic
+    Generic,  // vulkan_input
     Global,   // cuda_device
     Constant, // cuda_constant
     Local     // cuda_shared
@@ -56,6 +57,7 @@ const LangASMap AMDGPUTargetInfo::AMDGPUDefIsPrivMap = {
     Constant, // opencl_constant
     Private,  // opencl_private
     Generic,  // opencl_generic
+    Generic,  // vulkan_input
     Global,   // cuda_device
     Constant, // cuda_constant
     Local     // cuda_shared
diff --git a/lib/Basic/Targets/AMDGPU.h b/lib/Basic/Targets/AMDGPU.h
index 926772809a..6f322dbe36 100644
--- a/lib/Basic/Targets/AMDGPU.h
+++ b/lib/Basic/Targets/AMDGPU.h
@@ -341,7 +341,7 @@ public:
     default:
       return CCCR_Warning;
     case CC_C:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     }
   }
diff --git a/lib/Basic/Targets/ARM.cpp b/lib/Basic/Targets/ARM.cpp
index cb202eac98..57a5d43f35 100644
--- a/lib/Basic/Targets/ARM.cpp
+++ b/lib/Basic/Targets/ARM.cpp
@@ -916,7 +916,7 @@ ARMTargetInfo::checkCallingConvention(CallingConv CC) const {
   case CC_AAPCS:
   case CC_AAPCS_VFP:
   case CC_Swift:
-  case CC_OpenCLKernel:
+  case CC_FloorKernel:
     return CCCR_OK;
   default:
     return CCCR_Warning;
@@ -993,7 +993,7 @@ WindowsARMTargetInfo::checkCallingConvention(CallingConv CC) const {
   case CC_X86VectorCall:
     return CCCR_Ignore;
   case CC_C:
-  case CC_OpenCLKernel:
+  case CC_FloorKernel:
   case CC_PreserveMost:
   case CC_PreserveAll:
   case CC_Swift:
diff --git a/lib/Basic/Targets/BPF.h b/lib/Basic/Targets/BPF.h
index 7f97f81891..61d2acbfc7 100644
--- a/lib/Basic/Targets/BPF.h
+++ b/lib/Basic/Targets/BPF.h
@@ -80,7 +80,7 @@ public:
     default:
       return CCCR_Warning;
     case CC_C:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     }
   }
diff --git a/lib/Basic/Targets/NVPTX.cpp b/lib/Basic/Targets/NVPTX.cpp
index ca41c4d14c..26d3198b00 100644
--- a/lib/Basic/Targets/NVPTX.cpp
+++ b/lib/Basic/Targets/NVPTX.cpp
@@ -45,6 +45,9 @@ NVPTXTargetInfo::NVPTXTargetInfo(const llvm::Triple &Triple,
     if (!Feature.startswith("+ptx"))
       continue;
     PTXVersion = llvm::StringSwitch<unsigned>(Feature)
+                     .Case("+ptx64", 64)
+                     .Case("+ptx63", 63)
+                     .Case("+ptx62", 62)
                      .Case("+ptx61", 61)
                      .Case("+ptx60", 60)
                      .Case("+ptx50", 50)
@@ -224,8 +227,12 @@ void NVPTXTargetInfo::getTargetDefines(const LangOptions &Opts,
         return "700";
       case CudaArch::SM_72:
         return "720";
+      case CudaArch::SM_73:
+        return "730";
       case CudaArch::SM_75:
         return "750";
+      case CudaArch::SM_82:
+        return "820";
       }
       llvm_unreachable("unhandled CudaArch");
     }();
diff --git a/lib/Basic/Targets/NVPTX.h b/lib/Basic/Targets/NVPTX.h
index 84d466d2f4..718293431d 100644
--- a/lib/Basic/Targets/NVPTX.h
+++ b/lib/Basic/Targets/NVPTX.h
@@ -31,6 +31,7 @@ static const unsigned NVPTXAddrSpaceMap[] = {
     0, // opencl_private
     // FIXME: generic has to be added to the target
     0, // opencl_generic
+    0, // vulkan_input
     1, // cuda_device
     4, // cuda_constant
     3, // cuda_shared
@@ -81,6 +82,7 @@ public:
     case 'l':
     case 'f':
     case 'd':
+    case 'b':
       Info.setAllowsRegister();
       return true;
     }
@@ -126,6 +128,13 @@ public:
   }
 
   CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+
     // CUDA compilations support all of the host's calling conventions.
     //
     // TODO: We should warn if you apply a non-default CC to anything other than
@@ -134,6 +143,10 @@ public:
       return HostTarget->checkCallingConvention(CC);
     return CCCR_Warning;
   }
+
+  CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
+    return CC_FloorFunction;
+  }
 };
 } // namespace targets
 } // namespace clang
diff --git a/lib/Basic/Targets/SPIR.cpp b/lib/Basic/Targets/SPIR.cpp
index 304d904368..bf023c405d 100644
--- a/lib/Basic/Targets/SPIR.cpp
+++ b/lib/Basic/Targets/SPIR.cpp
@@ -31,3 +31,8 @@ void SPIR64TargetInfo::getTargetDefines(const LangOptions &Opts,
                                         MacroBuilder &Builder) const {
   DefineStd(Builder, "SPIR64", Opts);
 }
+
+void AIR64TargetInfo::getTargetDefines(const LangOptions &Opts,
+                                       MacroBuilder &Builder) const {
+  DefineStd(Builder, "AIR64", Opts);
+}
diff --git a/lib/Basic/Targets/SPIR.h b/lib/Basic/Targets/SPIR.h
index 9815292fc2..ce0f560bb4 100644
--- a/lib/Basic/Targets/SPIR.h
+++ b/lib/Basic/Targets/SPIR.h
@@ -29,23 +29,39 @@ static const unsigned SPIRAddrSpaceMap[] = {
     2, // opencl_constant
     0, // opencl_private
     4, // opencl_generic
+    0, // vulkan_input
+    0, // cuda_device
+    0, // cuda_constant
+    0  // cuda_shared
+};
+
+// Vulkan/SPIR-V can't use global/CrossWorkgroup, but uses Uniform instead
+static const unsigned VulkanAddrSpaceMap[] = {
+    0, // Default
+    5, // opencl_global == SPIRAS_Uniform
+    3, // opencl_local
+    2, // opencl_constant
+    0, // opencl_private
+    4, // opencl_generic
+    6, // vulkan_input == SPIRAS_Input
     0, // cuda_device
     0, // cuda_constant
     0  // cuda_shared
 };
 
 class LLVM_LIBRARY_VISIBILITY SPIRTargetInfo : public TargetInfo {
+private:
+  // true for spir-unknown-* and spir64-unknown-* (-> false for AIR/Metal)
+  const bool is_pure_spir;
+  const bool is_vulkan;
 public:
   SPIRTargetInfo(const llvm::Triple &Triple, const TargetOptions &)
-      : TargetInfo(Triple) {
-    assert(getTriple().getOS() == llvm::Triple::UnknownOS &&
-           "SPIR target must use unknown OS");
-    assert(getTriple().getEnvironment() == llvm::Triple::UnknownEnvironment &&
-           "SPIR target must use unknown environment type");
+      : TargetInfo(Triple), is_pure_spir(Triple.getVendorName().str() == "unknown"),
+        is_vulkan(Triple.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan) {
     TLSSupported = false;
     VLASupported = false;
     LongWidth = LongAlign = 64;
-    AddrSpaceMap = &SPIRAddrSpaceMap;
+    AddrSpaceMap = (!is_vulkan ? &SPIRAddrSpaceMap : &VulkanAddrSpaceMap);
     UseAddrSpaceMapMangling = true;
     HasLegalHalfType = true;
     // Define available target features
@@ -60,6 +76,9 @@ public:
     return Feature == "spir";
   }
 
+  bool isCLZForZeroUndef() const override { return false; }
+  bool isVulkan() const { return is_vulkan; }
+
   // SPIR supports the half type and the only llvm intrinsic allowed in SPIR is
   // memcpy as per section 3 of the SPIR spec.
   bool useFP16ConversionIntrinsics() const override { return false; }
@@ -84,12 +103,18 @@ public:
   }
 
   CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
-    return (CC == CC_SpirFunction || CC == CC_OpenCLKernel) ? CCCR_OK
-                                                            : CCCR_Warning;
+    if (!is_pure_spir) return CCCR_OK;
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+    return CCCR_Warning;
   }
 
   CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
-    return CC_SpirFunction;
+    return (is_pure_spir ? CC_FloorFunction : CC_C);
   }
 
   void setSupportedOpenCLOpts() override {
@@ -97,6 +122,45 @@ public:
     // for SPIR since it is a generic target.
     getSupportedOpenCLOpts().supportAll();
   }
+
+  LangAS getOpenCLTypeAddrSpace(OpenCLTypeKind TK) const override {
+    switch (TK) {
+    case OCLTK_Image:
+    case OCLTK_Pipe:
+      return LangAS::opencl_global;
+
+    case OCLTK_Sampler:
+      return LangAS::opencl_constant;
+
+    default:
+      return LangAS::Default;
+    }
+  }
+
+  LangAS getOpenCLBuiltinAddressSpace(unsigned AS) const override {
+    switch (AS) {
+    case 0:
+      return LangAS::opencl_private;
+    case 1:
+      return LangAS::opencl_global;
+    case 2:
+      return LangAS::opencl_constant;
+    case 3:
+      return LangAS::opencl_local;
+    case 4:
+      return LangAS::opencl_generic;
+    default:
+      return getLangASFromTargetAS(AS);
+    }
+  }
+
+  LangAS getCUDABuiltinAddressSpace(unsigned AS) const override {
+    return LangAS::Default;
+  }
+
+  llvm::Optional<LangAS> getConstantAddressSpace() const override {
+    return LangAS::opencl_constant;
+  }
 };
 class LLVM_LIBRARY_VISIBILITY SPIR32TargetInfo : public SPIRTargetInfo {
 public:
@@ -106,7 +170,8 @@ public:
     SizeType = TargetInfo::UnsignedInt;
     PtrDiffType = IntPtrType = TargetInfo::SignedInt;
     resetDataLayout("e-p:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-"
-                    "v96:128-v192:256-v256:256-v512:512-v1024:1024");
+                    "v96:128-v192:256-v256:256-v512:512-v1024:1024"
+                    "-n8:16:32:64");
   }
 
   void getTargetDefines(const LangOptions &Opts,
@@ -121,12 +186,47 @@ public:
     SizeType = TargetInfo::UnsignedLong;
     PtrDiffType = IntPtrType = TargetInfo::SignedLong;
     resetDataLayout("e-i64:64-v16:16-v24:32-v32:32-v48:64-"
-                    "v96:128-v192:256-v256:256-v512:512-v1024:1024");
+                    "v96:128-v192:256-v256:256-v512:512-v1024:1024"
+                    "-n8:16:32:64");
   }
 
   void getTargetDefines(const LangOptions &Opts,
                         MacroBuilder &Builder) const override;
 };
+
+// Metal/AIR target based on SPIR
+class LLVM_LIBRARY_VISIBILITY AIR64TargetInfo : public SPIRTargetInfo {
+public:
+  AIR64TargetInfo(const llvm::Triple &Triple, const TargetOptions &TO) : SPIRTargetInfo(Triple, TO) {
+    PointerWidth = PointerAlign = 64;
+    SizeType     = TargetInfo::UnsignedLong;
+    PtrDiffType = IntPtrType = TargetInfo::SignedLong;
+    if(Triple.getOS() == llvm::Triple::IOS) {
+      resetDataLayout("e-i64:64-f80:128-v16:16-v24:32-v32:32-v48:64-"
+                      "v96:128-v192:256-v256:256-v512:512-v1024:1024-n8:16:32");
+    } else { // os x, or default
+      resetDataLayout("e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-f80:128:128-v16:16:16-v24:32:32-v32:32:32-v48:64:64-v64:64:64-v96:128:128-v128:128:128-v192:256:256-v256:256:256-v512:512:512-v1024:1024:1024-f80:128:128-n8:16:32");
+    }
+  }
+  
+  void getTargetDefines(const LangOptions &Opts,
+                        MacroBuilder &Builder) const override;
+
+  CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
+    if (CC == CC_FloorFunction ||
+        CC == CC_FloorVertex ||
+        CC == CC_FloorFragment ||
+        CC == CC_FloorKernel) {
+        return CCCR_OK;
+    }
+    return CCCR_Warning;
+  }
+
+  CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
+    return CC_FloorFunction;
+  }
+};
+
 } // namespace targets
 } // namespace clang
 #endif // LLVM_CLANG_LIB_BASIC_TARGETS_SPIR_H
diff --git a/lib/Basic/Targets/SystemZ.h b/lib/Basic/Targets/SystemZ.h
index 842316005e..c9b4b2b796 100644
--- a/lib/Basic/Targets/SystemZ.h
+++ b/lib/Basic/Targets/SystemZ.h
@@ -129,7 +129,7 @@ public:
     switch (CC) {
     case CC_C:
     case CC_Swift:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     default:
       return CCCR_Warning;
diff --git a/lib/Basic/Targets/TCE.h b/lib/Basic/Targets/TCE.h
index be43bed98d..dea32961e7 100644
--- a/lib/Basic/Targets/TCE.h
+++ b/lib/Basic/Targets/TCE.h
@@ -38,6 +38,7 @@ static const unsigned TCEOpenCLAddrSpaceMap[] = {
     0, // opencl_private
     // FIXME: generic has to be added to the target
     0, // opencl_generic
+    0, // vulkan_input
     0, // cuda_device
     0, // cuda_constant
     0  // cuda_shared
diff --git a/lib/Basic/Targets/X86.h b/lib/Basic/Targets/X86.h
index 05930ae9ee..a88417f122 100644
--- a/lib/Basic/Targets/X86.h
+++ b/lib/Basic/Targets/X86.h
@@ -308,7 +308,7 @@ public:
     case CC_Swift:
     case CC_X86Pascal:
     case CC_IntelOclBicc:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     default:
       return CCCR_Warning;
@@ -644,7 +644,7 @@ public:
     case CC_PreserveMost:
     case CC_PreserveAll:
     case CC_X86RegCall:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     default:
       return CCCR_Warning;
@@ -718,7 +718,7 @@ public:
     case CC_X86_64SysV:
     case CC_Swift:
     case CC_X86RegCall:
-    case CC_OpenCLKernel:
+    case CC_FloorKernel:
       return CCCR_OK;
     default:
       return CCCR_Warning;
diff --git a/lib/CodeGen/BackendUtil.cpp b/lib/CodeGen/BackendUtil.cpp
index 52fc08de9b..29cd72a0c7 100644
--- a/lib/CodeGen/BackendUtil.cpp
+++ b/lib/CodeGen/BackendUtil.cpp
@@ -41,9 +41,12 @@
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Support/MemoryBuffer.h"
 #include "llvm/Support/PrettyStackTrace.h"
+#include "llvm/Support/SPIRV.h"
 #include "llvm/Support/TargetRegistry.h"
 #include "llvm/Support/Timer.h"
 #include "llvm/Support/raw_ostream.h"
+#include "llvm/SPIRV/SPIRVWriterPass.h"
+#include "llvm/SPIRV/SPIRVContainerWriterPass.h"
 #include "llvm/Target/TargetMachine.h"
 #include "llvm/Target/TargetOptions.h"
 #include "llvm/Transforms/Coroutines.h"
@@ -62,6 +65,7 @@
 #include "llvm/Transforms/Utils/NameAnonGlobals.h"
 #include "llvm/Transforms/Utils/SymbolRewriter.h"
 #include <memory>
+#include <fstream>
 using namespace clang;
 using namespace llvm;
 
@@ -529,6 +533,10 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
 
   PassManagerBuilderWrapper PMBuilder(TargetTriple, CodeGenOpts, LangOpts);
 
+  // always inline everything for metal/cuda/opencl/vulkan, otherwise we run into trouble when fixing the IR
+  if (LangOpts.Metal || LangOpts.CUDA || LangOpts.OpenCL || LangOpts.Vulkan) {
+    PMBuilder.Inliner = createEverythingInlinerPass();
+  } else {
   // At O0 and O1 we only run the always inliner which is more efficient. At
   // higher optimization levels we run the normal inliner.
   if (CodeGenOpts.OptimizationLevel <= 1) {
@@ -544,6 +552,7 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
         (!CodeGenOpts.SampleProfileFile.empty() &&
          CodeGenOpts.PrepareForThinLTO));
   }
+  }
 
   PMBuilder.OptLevel = CodeGenOpts.OptimizationLevel;
   PMBuilder.SizeLevel = CodeGenOpts.OptimizeSize;
@@ -558,6 +567,47 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
 
   MPM.add(new TargetLibraryInfoWrapperPass(*TLII));
 
+  // close floor function info file, this is no longer needed
+  if ((LangOpts.Metal || LangOpts.CUDA || LangOpts.OpenCL || LangOpts.Vulkan) &&
+      LangOpts.floor_function_info != nullptr) {
+    LangOpts.floor_function_info->close();
+    delete LangOpts.floor_function_info;
+  }
+  
+  PMBuilder.floor_image_capabilities = LangOpts.floor_image_capabilities;
+  
+  PMBuilder.EnableAddressSpaceFix = LangOpts.OpenCL;
+  if(PMBuilder.EnableAddressSpaceFix && CodeGenOpts.OptimizationLevel == 0) {
+    unsigned DiagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "compiling OpenCL/Metal/Vulkan with -O0 is not possible!");
+    Diags.Report(DiagID);
+    return;
+  }
+  
+  // only enable this for CUDA
+  PMBuilder.EnableCUDAPasses = LangOpts.CUDA;
+  
+  // only enable this for Metal/AIR
+  PMBuilder.EnableMetalPasses = LangOpts.Metal;
+  PMBuilder.EnableMetalIntelWorkarounds = CodeGenOpts.MetalIntelWorkarounds;
+  PMBuilder.EnableMetalNvidiaWorkarounds = CodeGenOpts.MetalNvidiaWorkarounds;
+  
+  // only enable this for OpenCL/SPIR and Vulkan/SPIR-V (don't want this for Metal)
+  PMBuilder.EnableSPIRPasses = (LangOpts.OpenCL &&
+                                (Triple(TheModule->getTargetTriple()).getArch() == Triple::spir64 ||
+                                 Triple(TheModule->getTargetTriple()).getArch() == Triple::spir));
+  PMBuilder.EnableSPIRIntelWorkarounds = CodeGenOpts.SPIRIntelWorkarounds;
+  PMBuilder.EnableVerifySPIR = PMBuilder.EnableSPIRPasses && LangOpts.CLVerifySPIR;
+  
+  // only enable this for Vulkan/SPIR-V
+  PMBuilder.EnableVulkanPasses = (PMBuilder.EnableSPIRPasses &&
+                                  Triple(TheModule->getTargetTriple()).getEnvironment() == Triple::Vulkan);
+
+  // don't enable any vectorization for Vulkan, this would lead to illegal pointer bitcasts and possibly unsupported vector dims
+  if (PMBuilder.EnableVulkanPasses) {
+    PMBuilder.SLPVectorize = false;
+    PMBuilder.LoopVectorize = false;
+  }
+
   if (TM)
     TM->adjustPassManager(PMBuilder);
 
@@ -667,6 +717,10 @@ void EmitAssemblyHelper::CreatePasses(legacy::PassManager &MPM,
   if (!CodeGenOpts.RewriteMapFiles.empty())
     addSymbolRewriterPass(CodeGenOpts, &MPM);
 
+  if (LangOpts.OpenCL || LangOpts.CUDA) {
+    MPM.add(createInternalizePass());
+  }
+
   if (Optional<GCOVOptions> Options = getGCOVOptions(CodeGenOpts)) {
     MPM.add(createGCOVProfilerPass(*Options));
     if (CodeGenOpts.getDebugInfo() == codegenoptions::NoDebugInfo)
@@ -777,6 +831,11 @@ void EmitAssemblyHelper::EmitAssembly(BackendAction Action,
 
   bool UsesCodeGen = (Action != Backend_EmitNothing &&
                       Action != Backend_EmitBC &&
+                      Action != Backend_EmitBC32 &&
+                      Action != Backend_EmitBC35 &&
+                      Action != Backend_EmitSPIRV &&
+                      Action != Backend_EmitSPIRVContainer &&
+                      Action != Backend_EmitMetalLib &&
                       Action != Backend_EmitLL);
   CreateTargetMachine(UsesCodeGen);
 
@@ -831,6 +890,26 @@ void EmitAssemblyHelper::EmitAssembly(BackendAction Action,
     }
     break;
 
+  case Backend_EmitBC32:
+    PerModulePasses.add(createBitcode32WriterPass(*OS));
+    break;
+
+  case Backend_EmitBC35:
+    PerModulePasses.add(createBitcode35WriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRV:
+    PerModulePasses.add(createSPIRVWriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRVContainer:
+    PerModulePasses.add(createSPIRVContainerWriterPass(*OS));
+    break;
+
+  case Backend_EmitMetalLib:
+    PerModulePasses.add(createMetalLibWriterPass(*OS));
+    break;
+
   case Backend_EmitLL:
     PerModulePasses.add(
         createPrintModulePass(*OS, "", CodeGenOpts.EmitLLVMUseLists));
@@ -1066,6 +1145,26 @@ void EmitAssemblyHelper::EmitAssemblyWithNewPassManager(
     }
     break;
 
+  case Backend_EmitBC32:
+    MPM.addPass(Bitcode32WriterPass(*OS));
+    break;
+
+  case Backend_EmitBC35:
+    MPM.addPass(Bitcode35WriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRV:
+    MPM.addPass(SPIRVWriterPass(*OS));
+    break;
+
+  case Backend_EmitSPIRVContainer:
+    MPM.addPass(SPIRVContainerWriterPass(*OS));
+    break;
+
+  case Backend_EmitMetalLib:
+    MPM.addPass(MetalLibWriterPass(*OS));
+    break;
+
   case Backend_EmitLL:
     MPM.addPass(PrintModulePass(*OS, "", CodeGenOpts.EmitLLVMUseLists));
     break;
diff --git a/lib/CodeGen/CGBlocks.cpp b/lib/CodeGen/CGBlocks.cpp
index 6631bfb0df..af0da487d9 100644
--- a/lib/CodeGen/CGBlocks.cpp
+++ b/lib/CodeGen/CGBlocks.cpp
@@ -239,8 +239,14 @@ static llvm::Constant *buildBlockDescriptor(CodeGenModule &CGM,
   // Signature.  Mandatory ObjC-style method descriptor @encode sequence.
   std::string typeAtEncoding =
     CGM.getContext().getObjCEncodingForBlock(blockInfo.getBlockExpr());
-  elements.add(llvm::ConstantExpr::getBitCast(
+
+  if (C.getLangOpts().OpenCL) {
+    elements.add(llvm::ConstantExpr::getAddrSpaceCast(
     CGM.GetAddrOfConstantCString(typeAtEncoding).getPointer(), i8p));
+  } else {
+    elements.add(llvm::ConstantExpr::getBitCast(
+      CGM.GetAddrOfConstantCString(typeAtEncoding).getPointer(), i8p));
+  }
 
   // GC layout.
   if (C.getLangOpts().ObjC) {
@@ -521,6 +527,9 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
   const BlockDecl *block = info.getBlockDecl();
 
   SmallVector<llvm::Type*, 8> elementTypes;
+
+  // OpenCL doesn't use block header (Guy)
+  if (!CGM.getLangOpts().OpenCL)
   initializeForBlockHeader(CGM, info, elementTypes);
   bool hasNonConstantCustomFields = false;
   if (auto *OpenCLHelper =
@@ -727,7 +736,9 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
 
   // At this point, we just have to add padding if the end align still
   // isn't aligned right.
-  if (endAlign < maxFieldAlign) {
+  if (CGM.getLangOpts().OpenCL && blockSize.getQuantity() == 0)
+    endAlign = maxFieldAlign;
+  else if (endAlign < maxFieldAlign) {
     CharUnits newBlockSize = blockSize.alignTo(maxFieldAlign);
     CharUnits padding = newBlockSize - blockSize;
 
@@ -744,7 +755,7 @@ static void computeBlockInfo(CodeGenModule &CGM, CodeGenFunction *CGF,
   }
 
   assert(endAlign >= maxFieldAlign);
-  assert(endAlign == getLowBit(blockSize));
+  assert((CGM.getLangOpts().OpenCL && blockSize.isZero()) || (endAlign == getLowBit(blockSize)));
   // Slam everything else on now.  This works because they have
   // strictly decreasing alignment and we expect that size is always a
   // multiple of alignment.
@@ -794,6 +805,11 @@ static void enterBlockScope(CodeGenFunction &CGF, BlockDecl *block) {
   blockInfo.LocalAddress = CGF.CreateTempAlloca(blockInfo.StructureType,
                                                 blockInfo.BlockAlign, "block");
 
+  if (CGF.getLangOpts().OpenCL) {
+    blockInfo.LocalAddress.getPointer()->setName("captured");
+    return;
+  }
+
   // If there are cleanups to emit, enter them (but inactive).
   if (!blockInfo.NeedsCopyDispose) return;
 
@@ -919,6 +935,24 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const BlockExpr *blockExpr) {
   return EmitBlockLiteral(*blockInfo);
 }
 
+llvm::Value *CodeGenFunction::GenerateOCLBlockBind(llvm::Constant *blockFunc,
+                                                   int ctxSize,
+                                                   int ctxAlign,
+                                                   llvm::Value *ctx) {
+    llvm::Type *ArgTys[] = {VoidPtrTy, IntTy, IntTy, VoidPtrTy};
+    llvm::FunctionType *FTy = llvm::FunctionType::get(
+                                            CGM.getOpenCLRuntime().getBlockType(),
+                                            llvm::ArrayRef<llvm::Type*>(ArgTys),
+                                            false);
+    return Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_block_bind"),
+                              {
+                                blockFunc,
+                                Builder.getInt32(ctxSize),
+                                Builder.getInt32(ctxAlign),
+                                ctx
+                              });
+}
+
 llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
   bool IsOpenCL = CGM.getContext().getLangOpts().OpenCL;
   auto GenVoidPtrTy =
@@ -936,6 +970,13 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
       CurGD, blockInfo, LocalDeclMap, isLambdaConv, blockInfo.CanBeGlobal);
   auto *blockFn = llvm::ConstantExpr::getPointerCast(InvokeFn, GenVoidPtrTy);
 
+  if (CGM.getLangOpts().OpenCL) {
+    if (blockInfo.CanBeGlobal)
+      return GenerateOCLBlockBind(blockFn, blockInfo.BlockSize.getQuantity(),
+                                  blockInfo.BlockAlign.getQuantity(),
+                                  llvm::Constant::getNullValue(VoidPtrTy));
+  }
+
   // If there is nothing to capture, we can emit this as a global block.
   if (blockInfo.CanBeGlobal)
     return CGM.getAddrOfGlobalBlockIfEmitted(blockInfo.BlockExpression);
@@ -1179,6 +1220,9 @@ llvm::Value *CodeGenFunction::EmitBlockLiteral(const CGBlockInfo &blockInfo) {
   if (IsOpenCL) {
     CGM.getOpenCLRuntime().recordBlockInfo(blockInfo.BlockExpression, InvokeFn,
                                            result);
+    result = GenerateOCLBlockBind(blockFn, blockInfo.BlockSize.getQuantity(),
+                                  blockInfo.BlockAlign.getQuantity(),
+                                  Builder.CreateBitCast(blockInfo.LocalAddress.getPointer(), VoidPtrTy));
   }
 
   return result;
@@ -1261,26 +1305,28 @@ RValue CodeGenFunction::EmitBlockCallExpr(const CallExpr *E,
 
   llvm::Value *BlockPtr = EmitScalarExpr(E->getCallee());
 
-  // Get a pointer to the generic block literal.
-  // For OpenCL we generate generic AS void ptr to be able to reuse the same
-  // block definition for blocks with captures generated as private AS local
-  // variables and without captures generated as global AS program scope
-  // variables.
-  unsigned AddrSpace = 0;
-  if (getLangOpts().OpenCL)
-    AddrSpace = getContext().getTargetAddressSpace(LangAS::opencl_generic);
+  llvm::Value *Func;
+  llvm::Value *FuncPtr = nullptr;
 
+  if (CGM.getLangOpts().OpenCL) {
+    llvm::Type *ArgTy[] = {CGM.getOpenCLRuntime().getBlockType()};
+    llvm::FunctionType *FTy = llvm::FunctionType::get(
+                                            VoidPtrTy,
+                                            llvm::ArrayRef<llvm::Type*>(ArgTy),
+                                            false);
+    Func = Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_get_block_invoke"), BlockPtr);
+    BlockPtr = Builder.CreateCall(CGM.CreateRuntimeFunction(FTy, "spir_get_block_context"), BlockPtr);
+  } else {
+  // Get a pointer to the generic block literal.
   llvm::Type *BlockLiteralTy =
-      llvm::PointerType::get(CGM.getGenericBlockLiteralType(), AddrSpace);
+      llvm::PointerType::get(CGM.getGenericBlockLiteralType(), 0);
 
   // Bitcast the callee to a block literal.
-  BlockPtr =
-      Builder.CreatePointerCast(BlockPtr, BlockLiteralTy, "block.literal");
+    BlockPtr = Builder.CreatePointerCast(BlockPtr, BlockLiteralTy, "block.literal");
 
   // Get the function pointer from the literal.
-  llvm::Value *FuncPtr =
-      Builder.CreateStructGEP(CGM.getGenericBlockLiteralType(), BlockPtr,
-                              CGM.getLangOpts().OpenCL ? 2 : 3);
+    FuncPtr = Builder.CreateStructGEP(CGM.getGenericBlockLiteralType(), BlockPtr, 3);
+  }
 
   // Add the block literal.
   CallArgList Args;
@@ -1302,8 +1348,11 @@ RValue CodeGenFunction::EmitBlockCallExpr(const CallExpr *E,
   // And the rest of the arguments.
   EmitCallArgs(Args, FnType->getAs<FunctionProtoType>(), E->arguments());
 
+  if (!CGM.getLangOpts().OpenCL) {
+    assert(FuncPtr);
   // Load the function.
-  llvm::Value *Func = Builder.CreateAlignedLoad(FuncPtr, getPointerAlign());
+    Func = Builder.CreateAlignedLoad(FuncPtr, getPointerAlign());
+  }
 
   const FunctionType *FuncTy = FnType->castAs<FunctionType>();
   const CGFunctionInfo &FnInfo =
@@ -1377,13 +1426,20 @@ CodeGenModule::GetAddrOfGlobalBlock(const BlockExpr *BE,
   computeBlockInfo(*this, nullptr, blockInfo);
 
   // Using that metadata, generate the actual block function.
+  llvm::Constant *blockFn;
   {
     CodeGenFunction::DeclMapTy LocalDeclMap;
-    CodeGenFunction(*this).GenerateBlockFunction(
+    blockFn = CodeGenFunction(*this).GenerateBlockFunction(
         GlobalDecl(), blockInfo, LocalDeclMap,
         /*IsLambdaConversionToBlock*/ false, /*BuildGlobalBlock*/ true);
   }
 
+  if (getLangOpts().OpenCL) {
+    // In OpenCL, we bind the block lazily, so here we just generate the
+    // block invoke function
+    return blockFn;
+  }
+
   return getAddrOfGlobalBlockIfEmitted(BE);
 }
 
diff --git a/lib/CodeGen/CGBuiltin.cpp b/lib/CodeGen/CGBuiltin.cpp
index eea9207a34..9dc1999123 100644
--- a/lib/CodeGen/CGBuiltin.cpp
+++ b/lib/CodeGen/CGBuiltin.cpp
@@ -21,6 +21,7 @@
 #include "TargetInfo.h"
 #include "clang/AST/ASTContext.h"
 #include "clang/AST/Decl.h"
+#include "clang/AST/Expr.h"
 #include "clang/AST/OSLog.h"
 #include "clang/Basic/TargetBuiltins.h"
 #include "clang/Basic/TargetInfo.h"
@@ -2729,28 +2730,30 @@ RValue CodeGenFunction::EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       AtomicRMWInst *Result = nullptr;
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
                                          llvm::AtomicOrdering::Monotonic);
         break;
-      case 1: // memory_order_consume
-      case 2: // memory_order_acquire
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_consume:
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acquire:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::Acquire);
         break;
-      case 3: // memory_order_release
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::Release);
         break;
-      case 4: // memory_order_acq_rel
-
-        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acq_rel:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
                                          llvm::AtomicOrdering::AcquireRelease);
         break;
-      case 5: // memory_order_seq_cst
-        Result = Builder.CreateAtomicRMW(
-            llvm::AtomicRMWInst::Xchg, Ptr, NewVal,
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:
+        Result = Builder.CreateAtomicRMW(llvm::AtomicRMWInst::Xchg,
+                                         Ptr, NewVal,
             llvm::AtomicOrdering::SequentiallyConsistent);
         break;
       }
@@ -2812,14 +2815,14 @@ RValue CodeGenFunction::EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       StoreInst *Store = Builder.CreateStore(NewVal, Ptr, Volatile);
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         Store->setOrdering(llvm::AtomicOrdering::Monotonic);
         break;
-      case 3:  // memory_order_release
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:
         Store->setOrdering(llvm::AtomicOrdering::Release);
         break;
-      case 5:  // memory_order_seq_cst
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:
         Store->setOrdering(llvm::AtomicOrdering::SequentiallyConsistent);
         break;
       }
@@ -2869,20 +2872,20 @@ RValue CodeGenFunction::EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,
     if (isa<llvm::ConstantInt>(Order)) {
       int ord = cast<llvm::ConstantInt>(Order)->getZExtValue();
       switch (ord) {
-      case 0:  // memory_order_relaxed
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_relaxed:
       default: // invalid order
         break;
-      case 1:  // memory_order_consume
-      case 2:  // memory_order_acquire
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_consume:  // memory_order_consume
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acquire:  // memory_order_acquire
         Builder.CreateFence(llvm::AtomicOrdering::Acquire, SSID);
         break;
-      case 3:  // memory_order_release
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_release:  // memory_order_release
         Builder.CreateFence(llvm::AtomicOrdering::Release, SSID);
         break;
-      case 4:  // memory_order_acq_rel
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_acq_rel:  // memory_order_acq_rel
         Builder.CreateFence(llvm::AtomicOrdering::AcquireRelease, SSID);
         break;
-      case 5:  // memory_order_seq_cst
+      case AtomicExpr::AtomicOrderingKind::AO_ABI_memory_order_seq_cst:  // memory_order_seq_cst
         Builder.CreateFence(llvm::AtomicOrdering::SequentiallyConsistent, SSID);
         break;
       }
diff --git a/lib/CodeGen/CGCall.cpp b/lib/CodeGen/CGCall.cpp
index 64e18e171e..857bd160b2 100644
--- a/lib/CodeGen/CGCall.cpp
+++ b/lib/CodeGen/CGCall.cpp
@@ -60,8 +60,10 @@ unsigned CodeGenTypes::ClangCallConvToLLVMCallConv(CallingConv CC) {
   // TODO: Add support for __vectorcall to LLVM.
   case CC_X86VectorCall: return llvm::CallingConv::X86_VectorCall;
   case CC_AArch64VectorCall: return llvm::CallingConv::AArch64_VectorCall;
-  case CC_SpirFunction: return llvm::CallingConv::SPIR_FUNC;
-  case CC_OpenCLKernel: return CGM.getTargetCodeGenInfo().getOpenCLKernelCallingConv();
+  case CC_FloorFunction: return llvm::CallingConv::FLOOR_FUNC;
+  case CC_FloorKernel: return llvm::CallingConv::FLOOR_KERNEL;
+  case CC_FloorVertex: return llvm::CallingConv::FLOOR_VERTEX;
+  case CC_FloorFragment: return llvm::CallingConv::FLOOR_FRAGMENT;
   case CC_PreserveMost: return llvm::CallingConv::PreserveMost;
   case CC_PreserveAll: return llvm::CallingConv::PreserveAll;
   case CC_Swift: return llvm::CallingConv::Swift;
@@ -73,8 +75,10 @@ unsigned CodeGenTypes::ClangCallConvToLLVMCallConv(CallingConv CC) {
 static CanQualType GetThisType(ASTContext &Context, const CXXRecordDecl *RD,
                                const CXXMethodDecl *MD) {
   QualType RecTy = Context.getTagDeclType(RD)->getCanonicalTypeInternal();
+#if 0 // we don't want this
   if (MD)
     RecTy = Context.getAddrSpaceQualType(RecTy, MD->getType().getAddressSpace());
+#endif
   return Context.getPointerType(CanQualType::CreateUnsafe(RecTy));
 }
 
@@ -229,6 +233,15 @@ static CallingConv getCallingConventionForDecl(const Decl *D, bool IsWindows) {
   if (D->hasAttr<SysVABIAttr>())
     return IsWindows ? CC_X86_64SysV : CC_C;
 
+  if (D->hasAttr<GraphicsVertexShaderAttr>())
+    return CC_FloorVertex;
+
+  if (D->hasAttr<GraphicsFragmentShaderAttr>())
+    return CC_FloorFragment;
+
+  if (D->hasAttr<ComputeKernelAttr>())
+    return CC_FloorKernel;
+
   if (D->hasAttr<PreserveMostAttr>())
     return CC_PreserveMost;
 
@@ -264,7 +277,7 @@ CodeGenTypes::arrangeCXXMethodType(const CXXRecordDecl *RD,
 /// Set calling convention for CUDA/HIP kernel.
 static void setCUDAKernelCallingConvention(CanQualType &FTy, CodeGenModule &CGM,
                                            const FunctionDecl *FD) {
-  if (FD->hasAttr<CUDAGlobalAttr>()) {
+  if (FD->hasAttr<ComputeKernelAttr>()) {
     const FunctionType *FT = FTy->getAs<FunctionType>();
     CGM.getTargetCodeGenInfo().setCUDAKernelCallingConvention(FT);
     FTy = FT->getCanonicalTypeUnqualified();
@@ -431,6 +444,153 @@ CodeGenTypes::arrangeCXXConstructorCall(const CallArgList &args,
                                  ParamInfos, Required);
 }
 
+uint32_t CodeGenTypes::getMetalVulkanImplicitArgCount(const FunctionDecl* FD) const {
+  if (!FD) return 0;
+
+  if (!CGM.getLangOpts().Metal && !CGM.getLangOpts().Vulkan) {
+    return 0;
+  }
+
+  if (CGM.getLangOpts().Metal) {
+    const uint32_t printf_arg = (CGM.getCodeGenOpts().MetalSoftPrintf > 0 ? 1 : 0);
+    if (FD->hasAttr<ComputeKernelAttr>()) {
+      if (CGM.getLangOpts().MetalVersion < 200 || CGM.getTriple().getOS() != llvm::Triple::OSType::MacOSX) {
+        return 6 + printf_arg;
+      } else {
+        return 10 + printf_arg;
+      }
+    } else if (FD->hasAttr<GraphicsVertexShaderAttr>()) {
+      return 1 + printf_arg;
+    } else if (FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+      return 1 + printf_arg;
+    }
+  } else if(CGM.getLangOpts().Vulkan) {
+    const uint32_t printf_arg = (CGM.getCodeGenOpts().VulkanSoftPrintf > 0 ? 1 : 0);
+    if (FD->hasAttr<ComputeKernelAttr>()) {
+      return 4 + printf_arg;
+    } else if (FD->hasAttr<GraphicsVertexShaderAttr>()) {
+      return 1 + printf_arg;
+    } else if (FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+      return 2 + printf_arg;
+    }
+  }
+
+  return 0;
+}
+
+// for all entry functions/points: handle the function type -> add implicit internal args
+void CodeGenTypes::handleMetalVulkanEntryFunction(CanQualType* FTy, FunctionArgList* ArgList, const FunctionDecl* FD) {
+  if (!FD) return; // just in case
+
+  if (!CGM.getLangOpts().Metal && !CGM.getLangOpts().Vulkan) {
+    return; // nothing to change here
+  }
+
+  if (!FD->hasAttr<ComputeKernelAttr>() &&
+      !FD->hasAttr<GraphicsVertexShaderAttr>() &&
+      !FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    return; // no entry function/point
+  }
+
+  // if FTy is specified, we will update it with the new function type
+  const FunctionProtoType *FPT = nullptr;
+  if (FTy) {
+    FPT = (*FTy)->getAs<FunctionProtoType>();
+    if (!FPT) {
+      return; // just in case
+    }
+  }
+
+  // get/init original function type info
+  auto& Ctx = CGM.getContext();
+  SmallVector<QualType, 16> ft_args;
+  if (FPT) {
+    for (auto& param : FPT->param_types()) {
+      ft_args.emplace_back(param);
+    }
+  }
+
+  // adds an implicit argument
+  uint32_t added_args_count = 0; // for sanity checking
+  const auto add_arg = [&ft_args, &ArgList, &FD, &Ctx, &added_args_count](QualType type, const char* name) {
+    ++added_args_count;
+    ft_args.emplace_back(type);
+
+    if (ArgList) {
+      auto* arg_decl = ImplicitParamDecl::Create(Ctx, /*DC=*/nullptr, FD->getLocation(),
+                                                 &Ctx.Idents.get(name), type, ImplicitParamDecl::Other);
+      ArgList->emplace_back(arg_decl);
+    }
+  };
+
+  // add implicit internal args
+  // NOTE: Metal and Vulkan handle these differently: Metal uses direct params, Vulkan uses pointers in input AS
+  if (CGM.getLangOpts().Metal) {
+	if (CGM.getCodeGenOpts().MetalSoftPrintf > 0) {
+	  add_arg(Ctx.getPointerType(Context.getAddrSpaceQualType(Ctx.IntTy, LangAS::opencl_global)), "__metal__printf_buffer__");
+	}
+
+    if (FD->hasAttr<ComputeKernelAttr>()) {
+      // id types, all int3:
+      auto int3_type = Ctx.getExtVectorType(Ctx.IntTy, 3);
+      add_arg(int3_type, "__metal__global_id__");
+      add_arg(int3_type, "__metal__global_size__");
+      add_arg(int3_type, "__metal__local_id__");
+      add_arg(int3_type, "__metal__local_size__");
+      add_arg(int3_type, "__metal__group_id__");
+      add_arg(int3_type, "__metal__group_size__");
+      if (CGM.getLangOpts().MetalVersion >= 200 && CGM.getTriple().getOS() == llvm::Triple::OSType::MacOSX) {
+        // SIMD-group / sub-group ids
+        add_arg(Ctx.IntTy, "__metal__sub_group_id__");
+        add_arg(Ctx.IntTy, "__metal__sub_group_local_id__");
+        add_arg(Ctx.IntTy, "__metal__sub_group_size__");
+        add_arg(Ctx.IntTy, "__metal__num_sub_groups__");
+      }
+    } else if (FD->hasAttr<GraphicsVertexShaderAttr>()) {
+      // only vertex id for now:
+      add_arg(Ctx.IntTy, "__metal__vertex_id__");
+    } else if (FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+      // only point coord for now:
+      auto float2_type = Ctx.getExtVectorType(Ctx.FloatTy, 2);
+      add_arg(float2_type, "__metal__point_coord__");
+    }
+  } else if(CGM.getLangOpts().Vulkan) {
+	if (CGM.getCodeGenOpts().VulkanSoftPrintf > 0) {
+	  add_arg(Ctx.getPointerType(Context.getAddrSpaceQualType(Ctx.IntTy, LangAS::opencl_global)), "vulkan.printf_buffer");
+	}
+
+    if (FD->hasAttr<ComputeKernelAttr>()) {
+      // id types, all int3*:
+      auto int3_type = Ctx.getExtVectorType(Ctx.IntTy, 3);
+      auto int3_ptr_type = Ctx.getPointerType(Context.getAddrSpaceQualType(int3_type, LangAS::vulkan_input));
+      add_arg(int3_ptr_type, "vulkan.global_invocation_id");
+      add_arg(int3_ptr_type, "vulkan.local_invocation_id");
+      add_arg(int3_ptr_type, "vulkan.workgroup_id");
+      add_arg(int3_ptr_type, "vulkan.num_workgroups");
+    } else if (FD->hasAttr<GraphicsVertexShaderAttr>()) {
+      // only vertex id for now:
+      add_arg(Ctx.getPointerType(Context.getAddrSpaceQualType(Ctx.IntTy, LangAS::vulkan_input)), "vulkan.vertex_index");
+    } else if (FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+      // only point + frag coord for now:
+      auto float2_ptr_type = Ctx.getPointerType(Context.getAddrSpaceQualType(Ctx.getExtVectorType(Ctx.FloatTy, 2), LangAS::vulkan_input));
+      add_arg(float2_ptr_type, "vulkan.point_coord");
+      auto float4_ptr_type = Ctx.getPointerType(Context.getAddrSpaceQualType(Ctx.getExtVectorType(Ctx.FloatTy, 4), LangAS::vulkan_input));
+      add_arg(float4_ptr_type, "vulkan.frag_coord");
+    }
+  }
+
+  // sanity check
+  assert(added_args_count == getMetalVulkanImplicitArgCount(FD) &&
+         "invalid added implicit argument count");
+
+  // create new function type and update FTy
+  if (FTy) {
+    FunctionProtoType::ExtProtoInfo EPI = FPT->getExtProtoInfo();
+    QualType NewFT = Ctx.getFunctionType(FPT->getReturnType(), ft_args, EPI);
+    *FTy = NewFT.getTypePtr()->getCanonicalTypeUnqualified();
+  }
+}
+
 /// Arrange the argument and result information for the declaration or
 /// definition of the given function.
 const CGFunctionInfo &
@@ -444,6 +604,8 @@ CodeGenTypes::arrangeFunctionDeclaration(const FunctionDecl *FD) {
   assert(isa<FunctionType>(FTy));
   setCUDAKernelCallingConvention(FTy, CGM, FD);
 
+  handleMetalVulkanEntryFunction(&FTy, nullptr, FD);
+
   // When declaring a function without a prototype, always use a
   // non-variadic type.
   if (CanQual<FunctionNoProtoType> noProto = FTy.getAs<FunctionNoProtoType>()) {
@@ -772,11 +934,14 @@ CodeGenTypes::arrangeLLVMFunctionInfo(CanQualType resultType,
   assert(inserted && "Recursively being processed?");
 
   // Compute ABI information.
-  if (CC == llvm::CallingConv::SPIR_KERNEL) {
+#if 0 // this is stupid ... rather: use a proper ABI implementation as before, which does the correct thing
+  if (CC == llvm::CallingConv::FLOOR_KERNEL) {
     // Force target independent argument handling for the host visible
     // kernel functions.
     computeSPIRKernelABIInfo(CGM, *FI);
-  } else if (info.getCC() == CC_Swift) {
+  } else
+#endif
+  if (info.getCC() == CC_Swift) {
     swiftcall::computeABIInfo(CGM, *FI);
   } else {
     getABIInfo().computeInfo(*FI);
@@ -853,6 +1018,10 @@ struct TypeExpansion {
     TEK_Record,
     // For complex types, real and imaginary parts are expanded recursively.
     TEK_Complex,
+    // Special libfloor vector compat expansion (aggregate -> clang/llvm vector).
+    TEK_FloorVectorCompat,
+    // Special libfloor aggregate/record expansion.
+    TEK_FloorAggregate,
     // All other types are not expandable.
     TEK_None
   };
@@ -897,6 +1066,31 @@ struct ComplexExpansion : TypeExpansion {
   }
 };
 
+struct FloorVectorCompatExpansion : TypeExpansion {
+  QualType orig_type;
+  QualType vector_type;
+
+  FloorVectorCompatExpansion(QualType orig_type_, QualType vector_type_)
+      : TypeExpansion(TEK_FloorVectorCompat), orig_type(orig_type_), vector_type(vector_type_) {}
+  static bool classof(const TypeExpansion *TE) {
+    return TE->Kind == TEK_FloorVectorCompat;
+  }
+};
+
+struct FloorAggregateExpansion : TypeExpansion {
+  SmallVector<const CXXBaseSpecifier *, 1> bases;
+  SmallVector<const FieldDecl *, 1> field_decls;
+  std::vector<CodeGenTypes::aggregate_scalar_entry> fields;
+
+  FloorAggregateExpansion(SmallVector<const CXXBaseSpecifier *, 1> &&bases_,
+                          SmallVector<const FieldDecl *, 1> &&field_decls_,
+                          std::vector<CodeGenTypes::aggregate_scalar_entry> &&fields_)
+      : TypeExpansion(TEK_FloorAggregate), bases(bases_), field_decls(field_decls_), fields(fields_) {}
+  static bool classof(const TypeExpansion *TE) {
+    return TE->Kind == TEK_FloorAggregate;
+  }
+};
+
 struct NoExpansion : TypeExpansion {
   NoExpansion() : TypeExpansion(TEK_None) {}
   static bool classof(const TypeExpansion *TE) {
@@ -906,12 +1100,61 @@ struct NoExpansion : TypeExpansion {
 }  // namespace
 
 static std::unique_ptr<TypeExpansion>
-getTypeExpansion(QualType Ty, const ASTContext &Context) {
+getTypeExpansion(QualType Ty, const ASTContext &Context,
+                 const CodeGenTypes& CGT, const CallingConv CC) {
   if (const ConstantArrayType *AT = Context.getAsConstantArrayType(Ty)) {
     return llvm::make_unique<ConstantArrayExpansion>(
         AT->getElementType(), AT->getSize().getZExtValue());
   }
-  if (const RecordType *RT = Ty->getAs<RecordType>()) {
+  const RecordType *RT = Ty->getAs<RecordType>();
+  const CXXRecordDecl* cxx_rdecl = (RT != nullptr ? RT->getAsCXXRecordDecl() : nullptr);
+  if (cxx_rdecl) {
+    // libfloor vector compat expansion (metal/vulkan vertex/fragment shader only, or vulkan compute shader)
+    if (cxx_rdecl->hasAttr<VectorCompatAttr>() &&
+        ((Context.getLangOpts().Metal && (CC == CallingConv::CC_FloorVertex ||
+                                          CC == CallingConv::CC_FloorFragment)) ||
+         (Context.getLangOpts().Vulkan && (CC == CallingConv::CC_FloorKernel ||
+                                           CC == CallingConv::CC_FloorVertex ||
+                                           CC == CallingConv::CC_FloorFragment)))) {
+      const auto vec_type = CGT.get_compat_vector_type(cxx_rdecl);
+      return llvm::make_unique<FloorVectorCompatExpansion>(Ty, vec_type);
+    }
+    // libfloor aggregate expansion:
+    // * any aggregate image type
+    // * any aggregate if calling a metal vertex/fragment shader function
+    // similar to (non-union) record expansion below, but also stores some additional information
+    if ((Ty->isAggregateImageType() ||
+         ((Context.getLangOpts().Metal && (CC == CallingConv::CC_FloorVertex ||
+                                           CC == CallingConv::CC_FloorFragment)) ||
+          (Context.getLangOpts().Vulkan && (CC == CallingConv::CC_FloorKernel ||
+                                            CC == CallingConv::CC_FloorVertex ||
+                                            CC == CallingConv::CC_FloorFragment)))) &&
+        !cxx_rdecl->isUnion()) {
+      SmallVector<const CXXBaseSpecifier *, 1> bases;
+      SmallVector<const FieldDecl *, 1> field_decls;
+
+      assert(!cxx_rdecl->isDynamicClass() &&
+             "cannot expand vtable pointers in dynamic classes");
+      for (const CXXBaseSpecifier &BS : cxx_rdecl->bases()) {
+        bases.push_back(&BS);
+      }
+
+      for (const auto *FD : cxx_rdecl->fields()) {
+        // Skip zero length bitfields.
+        if (FD->isBitField() && FD->getBitWidthValue(Context) == 0)
+          continue;
+        assert(!FD->isBitField() &&
+               "Cannot expand structure with bit-field members.");
+        field_decls.push_back(FD);
+      }
+
+      auto fields = CGT.get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl, false, false,
+                                                    !(Context.getLangOpts().Vulkan ||
+                                                      Context.getLangOpts().Metal));
+      return llvm::make_unique<FloorAggregateExpansion>(std::move(bases), std::move(field_decls), std::move(fields));
+    }
+  }
+  if (RT) {
     SmallVector<const CXXBaseSpecifier *, 1> Bases;
     SmallVector<const FieldDecl *, 1> Fields;
     const RecordDecl *RD = RT->getDecl();
@@ -961,17 +1204,24 @@ getTypeExpansion(QualType Ty, const ASTContext &Context) {
   return llvm::make_unique<NoExpansion>();
 }
 
-static int getExpansionSize(QualType Ty, const ASTContext &Context) {
-  auto Exp = getTypeExpansion(Ty, Context);
+static int getExpansionSize(QualType Ty, const ASTContext &Context,
+                            const CodeGenTypes& CGT, const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, Context, CGT, CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
-    return CAExp->NumElts * getExpansionSize(CAExp->EltTy, Context);
+    return CAExp->NumElts * getExpansionSize(CAExp->EltTy, Context, CGT, CC);
+  }
+  if (isa<FloorVectorCompatExpansion>(Exp.get())) {
+    return 1;
+  }
+  if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    return FAExp->fields.size();
   }
   if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     int Res = 0;
     for (auto BS : RExp->Bases)
-      Res += getExpansionSize(BS->getType(), Context);
+      Res += getExpansionSize(BS->getType(), Context, CGT, CC);
     for (auto FD : RExp->Fields)
-      Res += getExpansionSize(FD->getType(), Context);
+      Res += getExpansionSize(FD->getType(), Context, CGT, CC);
     return Res;
   }
   if (isa<ComplexExpansion>(Exp.get()))
@@ -982,17 +1232,30 @@ static int getExpansionSize(QualType Ty, const ASTContext &Context) {
 
 void
 CodeGenTypes::getExpandedTypes(QualType Ty,
-                               SmallVectorImpl<llvm::Type *>::iterator &TI) {
-  auto Exp = getTypeExpansion(Ty, Context);
+                               SmallVectorImpl<llvm::Type *>::iterator &TI,
+                               const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, Context, *this, CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     for (int i = 0, n = CAExp->NumElts; i < n; i++) {
-      getExpandedTypes(CAExp->EltTy, TI);
+      getExpandedTypes(CAExp->EltTy, TI, CC);
+    }
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    *TI++ = ConvertType(FVCExp->vector_type);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    for(const auto& field : FAExp->fields) {
+      auto conv_type = ConvertType(field.type);;
+      if (field.type->isArrayImageType(false)) {
+        *TI++ = (!conv_type->isPointerTy() ?
+                  llvm::PointerType::get(conv_type, 0) : conv_type);
+      } else {
+        *TI++ = conv_type;
+      }
     }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     for (auto BS : RExp->Bases)
-      getExpandedTypes(BS->getType(), TI);
+      getExpandedTypes(BS->getType(), TI, CC);
     for (auto FD : RExp->Fields)
-      getExpandedTypes(FD->getType(), TI);
+      getExpandedTypes(FD->getType(), TI, CC);
   } else if (auto CExp = dyn_cast<ComplexExpansion>(Exp.get())) {
     llvm::Type *EltTy = ConvertType(CExp->EltTy);
     *TI++ = EltTy;
@@ -1018,18 +1281,55 @@ static void forConstantArrayExpansion(CodeGenFunction &CGF,
   }
 }
 
-void CodeGenFunction::ExpandTypeFromArgs(
-    QualType Ty, LValue LV, SmallVectorImpl<llvm::Value *>::iterator &AI) {
+void CodeGenFunction::ExpandTypeFromArgs(QualType Ty, LValue LV,
+                                         SmallVectorImpl<llvm::Value *>::iterator &AI,
+                                         const CallingConv CC) {
   assert(LV.isSimple() &&
          "Unexpected non-simple lvalue during struct expansion.");
 
-  auto Exp = getTypeExpansion(Ty, getContext());
+  auto Exp = getTypeExpansion(Ty, getContext(), getTypes(), CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     forConstantArrayExpansion(*this, CAExp, LV.getAddress(),
                               [&](Address EltAddr) {
       LValue LV = MakeAddrLValue(EltAddr, CAExp->EltTy);
-      ExpandTypeFromArgs(CAExp->EltTy, LV, AI);
+      ExpandTypeFromArgs(CAExp->EltTy, LV, AI, CC);
     });
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    LValue VecLV = MakeAddrLValue(LV.getAddress(), FVCExp->vector_type);
+    ExpandTypeFromArgs(FVCExp->vector_type, VecLV, AI, CC);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    // TODO: should this recurse into bases with ExpandTypeFromArgs or do this manually?
+    Address This = LV.getAddress();
+    for (const CXXBaseSpecifier *BS : FAExp->bases) {
+      // Perform a single step derived-to-base conversion.
+      Address Base =
+          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,
+                                /*NullCheckValue=*/false, SourceLocation());
+      LValue SubLV = MakeAddrLValue(Base, BS->getType());
+
+      // Recurse onto bases.
+      ExpandTypeFromArgs(BS->getType(), SubLV, AI, CC);
+    }
+
+    for(const auto& field : FAExp->fields) {
+      if(field.is_in_base) continue; // already handled
+      // TODO: non-image arrays -> these have no FD
+      if (field.field_decl) {
+        // array of images
+        if (field.type->isArrayImageType(false)) {
+          LValue SubLV = EmitLValueForField(LV, field.field_decl);
+          Builder.CreateStore(*AI++, SubLV.getAddress());
+        }
+        // all else
+        else {
+      LValue SubLV = EmitLValueForFieldInitialization(LV, field.field_decl);
+      ExpandTypeFromArgs(SubLV.getType(), SubLV, AI, CC);
+    }
+      } else {
+        // will probably fail, but still try -> TODO above
+        EmitStoreThroughLValue(RValue::get(*AI++), LV);
+      }
+    }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     Address This = LV.getAddress();
     for (const CXXBaseSpecifier *BS : RExp->Bases) {
@@ -1040,12 +1340,12 @@ void CodeGenFunction::ExpandTypeFromArgs(
       LValue SubLV = MakeAddrLValue(Base, BS->getType());
 
       // Recurse onto bases.
-      ExpandTypeFromArgs(BS->getType(), SubLV, AI);
+      ExpandTypeFromArgs(BS->getType(), SubLV, AI, CC);
     }
     for (auto FD : RExp->Fields) {
       // FIXME: What are the right qualifiers here?
       LValue SubLV = EmitLValueForFieldInitialization(LV, FD);
-      ExpandTypeFromArgs(FD->getType(), SubLV, AI);
+      ExpandTypeFromArgs(FD->getType(), SubLV, AI, CC);
     }
   } else if (isa<ComplexExpansion>(Exp.get())) {
     auto realValue = *AI++;
@@ -1059,8 +1359,9 @@ void CodeGenFunction::ExpandTypeFromArgs(
 
 void CodeGenFunction::ExpandTypeToArgs(
     QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,
-    SmallVectorImpl<llvm::Value *> &IRCallArgs, unsigned &IRCallArgPos) {
-  auto Exp = getTypeExpansion(Ty, getContext());
+    SmallVectorImpl<llvm::Value *> &IRCallArgs, unsigned &IRCallArgPos,
+    const CallingConv CC) {
+  auto Exp = getTypeExpansion(Ty, getContext(), getTypes(), CC);
   if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {
     Address Addr = Arg.hasLValue() ? Arg.getKnownLValue().getAddress()
                                    : Arg.getKnownRValue().getAggregateAddress();
@@ -1070,8 +1371,41 @@ void CodeGenFunction::ExpandTypeToArgs(
               convertTempToRValue(EltAddr, CAExp->EltTy, SourceLocation()),
               CAExp->EltTy);
           ExpandTypeToArgs(CAExp->EltTy, EltArg, IRFuncTy, IRCallArgs,
-                           IRCallArgPos);
+                           IRCallArgPos, CC);
         });
+  } else if (auto FVCExp = dyn_cast<FloorVectorCompatExpansion>(Exp.get())) {
+    const auto llvm_vec_type = getTypes().ConvertType(FVCExp->vector_type);
+    Address This = Arg.hasLValue() ? Arg.getKnownLValue().getAddress()
+                                   : Arg.getKnownRValue().getAggregateAddress();
+    auto vec_ptr = Builder.CreateBitCast(This.getPointer(),
+                                         llvm::PointerType::get(llvm_vec_type,
+                                                                getContext().getTargetAddressSpace(Ty.getAddressSpace())));
+    Address vec_ptr_addr(vec_ptr, This.getAlignment());
+    IRCallArgs[IRCallArgPos++] = Builder.CreateLoad(vec_ptr_addr);
+  } else if (auto FAExp = dyn_cast<FloorAggregateExpansion>(Exp.get())) {
+    // TODO: should this recurse into bases with ExpandTypeToArgs or do this manually?
+    Address This = Arg.hasLValue() ? Arg.getKnownLValue().getAddress()
+                                   : Arg.getKnownRValue().getAggregateAddress();
+    for (const CXXBaseSpecifier *BS : FAExp->bases) {
+      // Perform a single step derived-to-base conversion.
+      Address Base =
+          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,
+                                /*NullCheckValue=*/false, SourceLocation());
+      CallArg BaseArg = CallArg(RValue::getAggregate(Base), BS->getType());
+
+      // Recurse onto bases.
+      ExpandTypeToArgs(BS->getType(), BaseArg, IRFuncTy, IRCallArgs,
+                       IRCallArgPos, CC);
+    }
+
+    LValue LV = MakeAddrLValue(This, Ty);
+    for(const auto& field : FAExp->fields) {
+      if(field.is_in_base) continue; // already handled
+      // TODO: arrays -> these have no FD
+      CallArg FldArg = CallArg(EmitRValueForField(LV, field.field_decl, SourceLocation()),
+                               field.field_decl->getType());
+      ExpandTypeToArgs(field.field_decl->getType(), FldArg, IRFuncTy, IRCallArgs, IRCallArgPos, CC);
+    }
   } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {
     Address This = Arg.hasLValue() ? Arg.getKnownLValue().getAddress()
                                    : Arg.getKnownRValue().getAggregateAddress();
@@ -1084,7 +1418,7 @@ void CodeGenFunction::ExpandTypeToArgs(
 
       // Recurse onto bases.
       ExpandTypeToArgs(BS->getType(), BaseArg, IRFuncTy, IRCallArgs,
-                       IRCallArgPos);
+                       IRCallArgPos, CC);
     }
 
     LValue LV = MakeAddrLValue(This, Ty);
@@ -1092,7 +1426,7 @@ void CodeGenFunction::ExpandTypeToArgs(
       CallArg FldArg =
           CallArg(EmitRValueForField(LV, FD, SourceLocation()), FD->getType());
       ExpandTypeToArgs(FD->getType(), FldArg, IRFuncTy, IRCallArgs,
-                       IRCallArgPos);
+                       IRCallArgPos, CC);
     }
   } else if (isa<ComplexExpansion>(Exp.get())) {
     ComplexPairTy CV = Arg.getKnownRValue().getComplexVal();
@@ -1386,11 +1720,11 @@ class ClangToLLVMArgMapping {
   SmallVector<IRArgs, 8> ArgInfo;
 
 public:
-  ClangToLLVMArgMapping(const ASTContext &Context, const CGFunctionInfo &FI,
+  ClangToLLVMArgMapping(const ASTContext &Context, const CGFunctionInfo &FI, const CodeGenTypes& CGT,
                         bool OnlyRequiredArgs = false)
       : InallocaArgNo(InvalidIndex), SRetArgNo(InvalidIndex), TotalIRArgs(0),
         ArgInfo(OnlyRequiredArgs ? FI.getNumRequiredArgs() : FI.arg_size()) {
-    construct(Context, FI, OnlyRequiredArgs);
+    construct(Context, FI, CGT, OnlyRequiredArgs);
   }
 
   bool hasInallocaArg() const { return InallocaArgNo != InvalidIndex; }
@@ -1425,12 +1759,13 @@ public:
   }
 
 private:
-  void construct(const ASTContext &Context, const CGFunctionInfo &FI,
+  void construct(const ASTContext &Context, const CGFunctionInfo &FI, const CodeGenTypes& CGT,
                  bool OnlyRequiredArgs);
 };
 
 void ClangToLLVMArgMapping::construct(const ASTContext &Context,
                                       const CGFunctionInfo &FI,
+                                      const CodeGenTypes& CGT,
                                       bool OnlyRequiredArgs) {
   unsigned IRArgNo = 0;
   bool SwapThisWithSRet = false;
@@ -1478,7 +1813,7 @@ void ClangToLLVMArgMapping::construct(const ASTContext &Context,
       IRArgs.NumberOfArgs = AI.getCoerceAndExpandTypeSequence().size();
       break;
     case ABIArgInfo::Expand:
-      IRArgs.NumberOfArgs = getExpansionSize(ArgType, Context);
+      IRArgs.NumberOfArgs = getExpansionSize(ArgType, Context, CGT, FI.getASTCallingConvention());
       break;
     }
 
@@ -1586,7 +1921,7 @@ CodeGenTypes::GetFunctionType(const CGFunctionInfo &FI) {
     break;
   }
 
-  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, true);
+  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, *this, true);
   SmallVector<llvm::Type*, 8> ArgTypes(IRFunctionArgs.totalIRArgs());
 
   // Add type for sret argument.
@@ -1663,7 +1998,7 @@ CodeGenTypes::GetFunctionType(const CGFunctionInfo &FI) {
 
     case ABIArgInfo::Expand:
       auto ArgTypesIter = ArgTypes.begin() + FirstIRArg;
-      getExpandedTypes(it->type, ArgTypesIter);
+      getExpandedTypes(it->type, ArgTypesIter, FI.getASTCallingConvention());
       assert(ArgTypesIter == ArgTypes.begin() + FirstIRArg + NumIRArgs);
       break;
     }
@@ -1918,7 +2253,7 @@ void CodeGenModule::ConstructAttributeList(
     }
   }
 
-  if (TargetDecl && TargetDecl->hasAttr<OpenCLKernelAttr>()) {
+  if (TargetDecl && TargetDecl->hasAttr<ComputeKernelAttr>()) {
     if (getLangOpts().OpenCLVersion <= 120) {
       // OpenCL v1.2 Work groups are always uniform
       FuncAttrs.addAttribute("uniform-work-group-size", "true");
@@ -1954,7 +2289,7 @@ void CodeGenModule::ConstructAttributeList(
     GetCPUAndFeaturesAttributes(CalleeInfo.getCalleeDecl(), FuncAttrs);
   }
 
-  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI);
+  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, getTypes());
 
   QualType RetTy = FI.getReturnType();
   const ABIArgInfo &RetAI = FI.getReturnInfo();
@@ -2244,7 +2579,7 @@ void CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,
   // FIXME: We no longer need the types from FunctionArgList; lift up and
   // simplify.
 
-  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), FI);
+  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), FI, getTypes());
   // Flattened function arguments.
   SmallVector<llvm::Value *, 16> FnArgs;
   FnArgs.reserve(IRFunctionArgs.totalIRArgs());
@@ -2547,7 +2882,7 @@ void CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,
       ArgVals.push_back(ParamValue::forIndirect(Alloca));
 
       auto FnArgIter = FnArgs.begin() + FirstIRArg;
-      ExpandTypeFromArgs(Ty, LV, FnArgIter);
+      ExpandTypeFromArgs(Ty, LV, FnArgIter, FI.getASTCallingConvention());
       assert(FnArgIter == FnArgs.begin() + FirstIRArg + NumIRArgs);
       for (unsigned i = 0, e = NumIRArgs; i != e; ++i) {
         auto AI = FnArgs[FirstIRArg + i];
@@ -3844,7 +4179,7 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     return Builder.CreateStructGEP(ArgMemory, FieldIndex, FieldOffset);
   };
 
-  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), CallInfo);
+  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), CallInfo, getTypes());
   SmallVector<llvm::Value *, 16> IRCallArgs(IRFunctionArgs.totalIRArgs());
 
   // If the call returns a temporary with struct return, create a temporary
@@ -4046,9 +4381,14 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
         // If the argument doesn't match, perform a bitcast to coerce it.  This
         // can happen due to trivial type mismatches.
         if (FirstIRArg < IRFuncTy->getNumParams() &&
-            V->getType() != IRFuncTy->getParamType(FirstIRArg))
-          V = Builder.CreateBitCast(V, IRFuncTy->getParamType(FirstIRArg));
-
+            V->getType() != IRFuncTy->getParamType(FirstIRArg)) {
+          const auto src_as = V->getType()->getPointerAddressSpace();
+          auto param_type = IRFuncTy->getParamType(FirstIRArg);
+          if(src_as > 0 && src_as != param_type->getPointerAddressSpace()) {
+            param_type = llvm::PointerType::get(cast<llvm::PointerType>(param_type->getScalarType())->getElementType(), src_as);
+          }
+          V = Builder.CreateBitCast(V, param_type);
+        }
         IRCallArgs[FirstIRArg] = V;
         break;
       }
@@ -4159,7 +4499,8 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
 
     case ABIArgInfo::Expand:
       unsigned IRArgPos = FirstIRArg;
-      ExpandTypeToArgs(I->Ty, *I, IRFuncTy, IRCallArgs, IRArgPos);
+      ExpandTypeToArgs(I->Ty, *I, IRFuncTy, IRCallArgs, IRArgPos,
+                       CallInfo.getASTCallingConvention());
       assert(IRArgPos == FirstIRArg + NumIRArgs);
       break;
     }
@@ -4259,9 +4600,18 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     if (IRFunctionArgs.hasInallocaArg() &&
         i == IRFunctionArgs.getInallocaArgNo())
       continue;
-    if (i < IRFuncTy->getNumParams())
+    if (i < IRFuncTy->getNumParams()) {
+      if (getLangOpts().OpenCL &&
+          IRFuncTy->getParamType(i)->isPointerTy() &&
+          IRCallArgs[i]->getType()->isPointerTy() &&
+          llvm::PointerType::get(IRFuncTy->getParamType(i)->getPointerElementType(), 0) ==
+          llvm::PointerType::get(IRCallArgs[i]->getType()->getPointerElementType(), 0)) {
+        // ignore address space mismatches for opencl/metal/vulkan
+        continue;
+      }
       assert(IRCallArgs[i]->getType() == IRFuncTy->getParamType(i));
   }
+  }
 #endif
 
   // Update the largest vector width if any arguments have vector types.
@@ -4482,6 +4832,13 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
             DestPtr = CreateMemTemp(RetTy, "agg.tmp");
             DestIsVolatile = false;
           }
+
+          // handle [[vector_compat]] stores from an aggregate to a vector type
+          if(DestPtr.getType()->getPointerElementType()->isVectorTy()) {
+            CreateCoercedStore(CI, DestPtr, DestIsVolatile, *this);
+            return RValue::get(DestPtr.getPointer());
+          }
+
           BuildAggStore(*this, CI, DestPtr, DestIsVolatile);
           return RValue::getAggregate(DestPtr);
         }
@@ -4539,6 +4896,27 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
     }
   }
 
+  // add LLVM [lower bound, upper bound] attribute if possible
+  if (llvm::CallInst *Call = dyn_cast<llvm::CallInst>(CI)) {
+    if (TargetDecl && Call->getType()->isIntegerTy()) {
+      RetRangeAttr* range_attr = TargetDecl->getAttr<RetRangeAttr>();
+      if (range_attr != nullptr) {
+        llvm::APSInt lower_bound(64), upper_bound(64);
+        lower_bound = range_attr->getLowerBound()->EvaluateKnownConstInt(getContext());
+        upper_bound = range_attr->getUpperBound()->EvaluateKnownConstInt(getContext());
+        llvm::Metadata* range_md[2] {
+          llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Call->getType(),
+                                                               lower_bound.getZExtValue(),
+                                                               lower_bound.isSigned())),
+          llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(Call->getType(),
+                                                               upper_bound.getZExtValue(),
+                                                               upper_bound.isSigned()))
+        };
+        Call->setMetadata(llvm::LLVMContext::MD_range, llvm::MDNode::get(getLLVMContext(), range_md));
+      }
+    }
+  }
+
   return Ret;
 }
 
diff --git a/lib/CodeGen/CGClass.cpp b/lib/CodeGen/CGClass.cpp
index cfc912cc9a..85a25f508b 100644
--- a/lib/CodeGen/CGClass.cpp
+++ b/lib/CodeGen/CGClass.cpp
@@ -301,9 +301,16 @@ Address CodeGenFunction::GetAddressOfBaseClass(
     VBase = nullptr; // we no longer have a virtual step
   }
 
-  // Get the base pointer type.
+  // Get the base pointer type, and keep the Values address space if it has one
+  const auto val_type = Value.getType();
+  unsigned val_as = 0;
+  if(val_type != nullptr &&
+     val_type->isPointerTy() &&
+     val_type->getPointerAddressSpace() != 0) {
+    val_as = val_type->getPointerAddressSpace();
+  }
   llvm::Type *BasePtrTy =
-    ConvertType((PathEnd[-1])->getType())->getPointerTo();
+    ConvertType((PathEnd[-1])->getType())->getPointerTo(val_as);
 
   QualType DerivedTy = getContext().getRecordType(Derived);
   CharUnits DerivedAlign = CGM.getClassPointerAlignment(Derived);
@@ -2013,6 +2020,7 @@ void CodeGenFunction::EmitCXXConstructorCall(const CXXConstructorDecl *D,
                                              bool NewPointerIsChecked) {
   CallArgList Args;
 
+#if 0 // we don't want this
   LangAS SlotAS = E->getType().getAddressSpace();
   QualType ThisType = D->getThisType(getContext());
   LangAS ThisAS = ThisType.getTypePtr()->getPointeeType().getAddressSpace();
@@ -2024,6 +2032,9 @@ void CodeGenFunction::EmitCXXConstructorCall(const CXXConstructorDecl *D,
     ThisPtr = getTargetHooks().performAddrSpaceCast(*this, This.getPointer(),
                                                     ThisAS, SlotAS, NewType);
   }
+#else
+  llvm::Value *ThisPtr = This.getPointer();
+#endif
   // Push the this ptr.
   Args.add(RValue::get(ThisPtr), D->getThisType(getContext()));
 
diff --git a/lib/CodeGen/CGDebugInfo.cpp b/lib/CodeGen/CGDebugInfo.cpp
index f3a07a30eb..ffbd5a0ed4 100644
--- a/lib/CodeGen/CGDebugInfo.cpp
+++ b/lib/CodeGen/CGDebugInfo.cpp
@@ -680,7 +680,7 @@ llvm::DIType *CGDebugInfo::CreateType(const BuiltinType *BT) {
 
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix)                   \
   case BuiltinType::Id:                                                        \
-    return getOrCreateStructPtrType("opencl_" #ImgType "_" #Suffix "_t",       \
+    return getOrCreateStructPtrType("opencl_" #ImgType #Suffix "_t",           \
                                     SingletonId);
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
@@ -775,12 +775,18 @@ llvm::DIType *CGDebugInfo::CreateType(const BuiltinType *BT) {
 
   switch (BT->getKind()) {
   case BuiltinType::Long:
+    if (CGM.getLangOpts().OpenCL)
+      BTName = "long";
+    else
     BTName = "long int";
     break;
   case BuiltinType::LongLong:
     BTName = "long long int";
     break;
   case BuiltinType::ULong:
+    if (CGM.getLangOpts().OpenCL)
+      BTName = "unsigned long";
+    else
     BTName = "long unsigned int";
     break;
   case BuiltinType::ULongLong:
@@ -1138,9 +1144,11 @@ static unsigned getDwarfCC(CallingConv CC) {
     return llvm::dwarf::DW_CC_LLVM_AAPCS_VFP;
   case CC_IntelOclBicc:
     return llvm::dwarf::DW_CC_LLVM_IntelOclBicc;
-  case CC_SpirFunction:
+  case CC_FloorFunction:
     return llvm::dwarf::DW_CC_LLVM_SpirFunction;
-  case CC_OpenCLKernel:
+  case CC_FloorKernel:
+  case CC_FloorVertex:
+  case CC_FloorFragment:
     return llvm::dwarf::DW_CC_LLVM_OpenCLKernel;
   case CC_Swift:
     return llvm::dwarf::DW_CC_LLVM_Swift;
@@ -2633,6 +2641,8 @@ llvm::DIType *CGDebugInfo::CreateType(const AtomicType *Ty, llvm::DIFile *U) {
 }
 
 llvm::DIType *CGDebugInfo::CreateType(const PipeType *Ty, llvm::DIFile *U) {
+  // Ignore the atomic wrapping
+  // FIXME: What is the correct representation?
   return getOrCreateType(Ty->getElementType(), U);
 }
 
diff --git a/lib/CodeGen/CGDecl.cpp b/lib/CodeGen/CGDecl.cpp
index f4fef45a12..e4cb99b07c 100644
--- a/lib/CodeGen/CGDecl.cpp
+++ b/lib/CodeGen/CGDecl.cpp
@@ -178,7 +178,9 @@ void CodeGenFunction::EmitVarDecl(const VarDecl &D) {
     return EmitStaticVarDecl(D, Linkage);
   }
 
-  if (D.getType().getAddressSpace() == LangAS::opencl_local)
+  if (D.getType().getAddressSpace() == LangAS::opencl_local ||
+      // TODO: -> SC_OpenCLConstant TODO
+      (D.getStorageClass() == SC_OpenCLConstant))
     return CGM.getOpenCLRuntime().EmitWorkGroupLocalVarDecl(*this, D);
 
   assert(D.hasLocalStorage());
@@ -186,8 +188,14 @@ void CodeGenFunction::EmitVarDecl(const VarDecl &D) {
 }
 
 static std::string getStaticDeclName(CodeGenModule &CGM, const VarDecl &D) {
-  if (CGM.getLangOpts().CPlusPlus)
+  // don't cxx mangle OpenCL "local" variables (only affects SPIR - Metal/AIR and SPIR-V/Vulkan uses cxx mangling)
+  if (CGM.getLangOpts().CPlusPlus &&
+      !(D.getType().getAddressSpace() == LangAS::opencl_local &&
+        CGM.getContext().getLangOpts().OpenCL &&
+        !CGM.getContext().getLangOpts().Metal &&
+        !CGM.getContext().getLangOpts().Vulkan)) {
     return CGM.getMangledName(&D).str();
+  }
 
   // If this isn't C++, we don't need a mangled name, just a pretty one.
   assert(!D.isExternallyVisible() && "name shouldn't matter");
diff --git a/lib/CodeGen/CGExpr.cpp b/lib/CodeGen/CGExpr.cpp
index 6ef1091cc0..4a7ab9835a 100644
--- a/lib/CodeGen/CGExpr.cpp
+++ b/lib/CodeGen/CGExpr.cpp
@@ -1619,6 +1619,7 @@ llvm::Value *CodeGenFunction::EmitLoadOfScalar(Address Addr, bool Volatile,
                                                LValueBaseInfo BaseInfo,
                                                TBAAAccessInfo TBAAInfo,
                                                bool isNontemporal) {
+#if 0 // incorrect and not at all beneficial for compute backends
   if (!CGM.getCodeGenOpts().PreserveVec3Type) {
     // For better performance, handle vector loads differently.
     if (Ty->isVectorType()) {
@@ -1643,6 +1644,7 @@ llvm::Value *CodeGenFunction::EmitLoadOfScalar(Address Addr, bool Volatile,
       }
     }
   }
+#endif
 
   // Atomic operations have to be done on integral types.
   LValue AtomicLValue =
@@ -1704,6 +1706,7 @@ void CodeGenFunction::EmitStoreOfScalar(llvm::Value *Value, Address Addr,
     // Handle vectors differently to get better performance.
     if (Ty->isVectorType()) {
       llvm::Type *SrcTy = Value->getType();
+#if 0 // incorrect and not at all beneficial for compute backends
       auto *VecTy = dyn_cast<llvm::VectorType>(SrcTy);
       // Handle vec3 special.
       if (VecTy && VecTy->getNumElements() == 3) {
@@ -1716,6 +1719,7 @@ void CodeGenFunction::EmitStoreOfScalar(llvm::Value *Value, Address Addr,
                                             MaskV, "extractVec");
         SrcTy = llvm::VectorType::get(VecTy->getElementType(), 4);
       }
+#endif
       if (Addr.getElementType() != SrcTy) {
         Addr = Builder.CreateElementBitCast(Addr, SrcTy, "storetmp");
       }
@@ -2518,8 +2522,19 @@ LValue CodeGenFunction::EmitDeclRefLValue(const DeclRefExpr *E) {
 
   if (const auto *VD = dyn_cast<VarDecl>(ND)) {
     // Check if this is a global variable.
-    if (VD->hasLinkage() || VD->isStaticDataMember())
+    if (VD->hasLinkage() || VD->isStaticDataMember()) {
+      if (CGM.getLangOpts().OpenCL && VD->getType()->isBlockPointerType()) {
+        // Look up the block function and bind it with NULL
+        llvm::Constant *blockFnc = CGM.GetOCLGlobalBlockFunction(VD);
+        blockFnc = llvm::ConstantExpr::getBitCast(blockFnc, Int8PtrTy);
+        llvm::Value *block = GenerateOCLBlockBind(blockFnc, 0, 0, llvm::Constant::getNullValue(Int8PtrTy));
+        Address addr = CreateMemTemp(VD->getType());
+        llvm::Value *Ptr = addr.getPointer();
+        Builder.CreateStore(block, addr);
+        return MakeNaturalAlignAddrLValue(Ptr, VD->getType());
+      }
       return EmitGlobalVarDeclLValue(*this, E, VD);
+    }
 
     Address addr = Address::invalid();
 
@@ -3809,11 +3824,11 @@ LValue CodeGenFunction::EmitLValueForLambdaField(const FieldDecl *Field) {
 ///
 /// The resulting address doesn't necessarily have the right type.
 static Address emitAddrOfFieldStorage(CodeGenFunction &CGF, Address base,
-                                      const FieldDecl *field) {
+                                      const FieldDecl *field, llvm::Type* elem_type) {
   const RecordDecl *rec = field->getParent();
 
   unsigned idx =
-    CGF.CGM.getTypes().getCGRecordLayout(rec).getLLVMFieldNo(field);
+    CGF.CGM.getTypes().getCGRecordLayout(rec, elem_type).getLLVMFieldNo(field);
 
   CharUnits offset;
   // Adjust the alignment down to the given offset.
@@ -3853,28 +3868,31 @@ static bool hasAnyVptr(const QualType Type, const ASTContext &Context) {
 LValue CodeGenFunction::EmitLValueForField(LValue base,
                                            const FieldDecl *field) {
   LValueBaseInfo BaseInfo = base.getBaseInfo();
+  Address addr = base.getAddress();
+  llvm::Type* elem_type = addr.getType()->getPointerElementType();
+  const RecordDecl *rec = field->getParent();
+  const CGRecordLayout &RL = CGM.getTypes().getCGRecordLayout(rec, elem_type);
 
   if (field->isBitField()) {
-    const CGRecordLayout &RL =
-      CGM.getTypes().getCGRecordLayout(field->getParent());
     const CGBitFieldInfo &Info = RL.getBitFieldInfo(field);
-    Address Addr = base.getAddress();
     unsigned Idx = RL.getLLVMFieldNo(field);
     if (Idx != 0)
       // For structs, we GEP to the field that the record layout suggests.
-      Addr = Builder.CreateStructGEP(Addr, Idx, Info.StorageOffset,
+      addr = Builder.CreateStructGEP(addr, Idx, Info.StorageOffset,
                                      field->getName());
     // Get the access type.
     llvm::Type *FieldIntTy =
       llvm::Type::getIntNTy(getLLVMContext(), Info.StorageSize);
-    if (Addr.getElementType() != FieldIntTy)
-      Addr = Builder.CreateElementBitCast(Addr, FieldIntTy);
+    if (addr.getElementType() != FieldIntTy)
+      addr = Builder.CreateElementBitCast(addr, FieldIntTy);
+
+    // TODO: (clang/llvm 3.8/8.0) check if address space is correct
 
     QualType fieldType =
       field->getType().withCVRQualifiers(base.getVRQualifiers());
     // TODO: Support TBAA for bit fields.
     LValueBaseInfo FieldBaseInfo(BaseInfo.getAlignmentSource());
-    return LValue::MakeBitfield(Addr, Info, fieldType, FieldBaseInfo,
+    return LValue::MakeBitfield(addr, Info, fieldType, FieldBaseInfo,
                                 TBAAAccessInfo());
   }
 
@@ -3882,7 +3900,6 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
   // FIXME: this should get propagated down through anonymous structs
   // and unions.
   QualType FieldType = field->getType();
-  const RecordDecl *rec = field->getParent();
   AlignmentSource BaseAlignSource = BaseInfo.getAlignmentSource();
   LValueBaseInfo FieldBaseInfo(getFieldAlignmentSource(BaseAlignSource));
   TBAAAccessInfo FieldTBAAInfo;
@@ -3916,7 +3933,6 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
         getContext().getTypeSizeInChars(FieldType).getQuantity();
   }
 
-  Address addr = base.getAddress();
   if (auto *ClassDef = dyn_cast<CXXRecordDecl>(rec)) {
     if (CGM.getCodeGenOpts().StrictVTablePointers &&
         ClassDef->isDynamicClass()) {
@@ -3941,7 +3957,7 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
                      addr.getAlignment());
   } else {
     // For structs, we GEP to the field that the record layout suggests.
-    addr = emitAddrOfFieldStorage(*this, addr, field);
+    addr = emitAddrOfFieldStorage(*this, addr, field, elem_type);
 
     // If this is a reference field, load the reference right now.
     if (FieldType->isReferenceType()) {
@@ -3985,7 +4001,8 @@ CodeGenFunction::EmitLValueForFieldInitialization(LValue Base,
   if (!FieldType->isReferenceType())
     return EmitLValueForField(Base, Field);
 
-  Address V = emitAddrOfFieldStorage(*this, Base.getAddress(), Field);
+  llvm::Type* elem_type = Base.getAddress().getType()->getPointerElementType();
+  Address V = emitAddrOfFieldStorage(*this, Base.getAddress(), Field, elem_type);
 
   // Make sure that the address is pointing to the right type.
   llvm::Type *llvmType = ConvertTypeForMem(FieldType);
@@ -4168,7 +4185,6 @@ LValue CodeGenFunction::EmitCastLValue(const CastExpr *E) {
   case CK_ARCReclaimReturnedObject:
   case CK_ARCExtendBlockObject:
   case CK_CopyAndAutoreleaseBlockObject:
-  case CK_IntToOCLSampler:
   case CK_FixedPointCast:
   case CK_FixedPointToBoolean:
     return EmitUnsupportedLValue(E, "unexpected cast lvalue");
@@ -4282,6 +4298,12 @@ LValue CodeGenFunction::EmitCastLValue(const CastExpr *E) {
   }
   case CK_ZeroToOCLOpaqueType:
     llvm_unreachable("NULL to OpenCL opaque type lvalue cast is not valid");
+  case CK_ZeroToOCLEvent:
+    llvm_unreachable("NULL to OpenCL event lvalue cast is not valid");
+  case CK_ZeroToOCLQueue:
+    llvm_unreachable("NULL to OpenCL queue lvalue cast is not valid");
+  case CK_IntToOCLSampler:
+    llvm_unreachable("int to OpenCL sampler lvalue cast is not valid");
   }
 
   llvm_unreachable("Unhandled lvalue cast kind?");
diff --git a/lib/CodeGen/CGExprAgg.cpp b/lib/CodeGen/CGExprAgg.cpp
index db49b3f28a..c05348001a 100644
--- a/lib/CodeGen/CGExprAgg.cpp
+++ b/lib/CodeGen/CGExprAgg.cpp
@@ -852,6 +852,8 @@ void AggExprEmitter::VisitCastExpr(CastExpr *E) {
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLOpaqueType:
+  case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_AddressSpaceConversion:
   case CK_IntToOCLSampler:
   case CK_FixedPointCast:
@@ -1831,13 +1833,14 @@ void CodeGenFunction::EmitAggregateCopy(LValue Dest, LValue Src, QualType Ty,
   if (getLangOpts().CPlusPlus) {
     if (const RecordType *RT = Ty->getAs<RecordType>()) {
       CXXRecordDecl *Record = cast<CXXRecordDecl>(RT->getDecl());
-      assert((Record->hasTrivialCopyConstructor() ||
+      // TODO: fix this!
+      /*assert((Record->hasTrivialCopyConstructor() ||
               Record->hasTrivialCopyAssignment() ||
               Record->hasTrivialMoveConstructor() ||
               Record->hasTrivialMoveAssignment() ||
               Record->isUnion()) &&
              "Trying to aggregate-copy a type without a trivial copy/move "
-             "constructor or assignment operator");
+             "constructor or assignment operator");*/
       // Ignore empty classes in C++.
       if (Record->isEmpty())
         return;
diff --git a/lib/CodeGen/CGExprCXX.cpp b/lib/CodeGen/CGExprCXX.cpp
index 2e0d4ca767..48111e6f15 100644
--- a/lib/CodeGen/CGExprCXX.cpp
+++ b/lib/CodeGen/CGExprCXX.cpp
@@ -25,6 +25,8 @@
 using namespace clang;
 using namespace CodeGen;
 
+// TODO: fix other This uses?
+
 namespace {
 struct MemberCallInfo {
   RequiredArgs ReqArgs;
@@ -47,8 +49,12 @@ commonEmitCXXMemberOrOperatorCall(CodeGenFunction &CGF, const CXXMethodDecl *MD,
   // Push the this ptr.
   const CXXRecordDecl *RD =
       CGF.CGM.getCXXABI().getThisArgumentTypeForMethod(MD);
-  Args.add(RValue::get(This),
-           RD ? C.getPointerType(C.getTypeDeclType(RD)) : C.VoidPtrTy);
+  QualType this_type = C.VoidPtrTy;
+  if (RD) {
+    this_type = C.getPointerType(CGF.getContext().getAddrSpaceQualType(C.getTypeDeclType(RD),
+                                                                       (LangAS)This->getType()->getPointerAddressSpace()));
+  }
+  Args.add(RValue::get(This), this_type);
 
   // If there is an implicit parameter (e.g. VTT), emit it.
   if (ImplicitParam) {
diff --git a/lib/CodeGen/CGExprComplex.cpp b/lib/CodeGen/CGExprComplex.cpp
index 2db693b44c..15dac03f98 100644
--- a/lib/CodeGen/CGExprComplex.cpp
+++ b/lib/CodeGen/CGExprComplex.cpp
@@ -509,6 +509,8 @@ ComplexPairTy ComplexExprEmitter::EmitCast(CastKind CK, Expr *Op,
   case CK_CopyAndAutoreleaseBlockObject:
   case CK_BuiltinFnToFnPtr:
   case CK_ZeroToOCLOpaqueType:
+  case CK_ZeroToOCLEvent:
+  case CK_ZeroToOCLQueue:
   case CK_AddressSpaceConversion:
   case CK_IntToOCLSampler:
   case CK_FixedPointCast:
diff --git a/lib/CodeGen/CGExprConstant.cpp b/lib/CodeGen/CGExprConstant.cpp
index c9475840ae..2a4151ae7e 100644
--- a/lib/CodeGen/CGExprConstant.cpp
+++ b/lib/CodeGen/CGExprConstant.cpp
@@ -809,8 +809,14 @@ public:
     case CK_ConstructorConversion:
       return Visit(subExpr, destType);
 
-    case CK_IntToOCLSampler:
-      llvm_unreachable("global sampler variables are not generated");
+    case CK_IntToOCLSampler: {
+      auto C = Emitter.tryEmitPrivateForMemory(subExpr, subExpr->getType());
+      if (!C)
+        return nullptr;
+      if (!CGM.getLangOpts().CLSamplerOpaque)
+        return C;
+      return CGM.createIntToSamplerConversion(subExpr, Emitter.CGF);
+    }
 
     case CK_Dependent: llvm_unreachable("saw dependent cast!");
 
@@ -876,6 +882,8 @@ public:
     case CK_FixedPointCast:
     case CK_FixedPointToBoolean:
     case CK_ZeroToOCLOpaqueType:
+    case CK_ZeroToOCLEvent:
+    case CK_ZeroToOCLQueue:
       return nullptr;
     }
     llvm_unreachable("Invalid CastKind");
diff --git a/lib/CodeGen/CGExprScalar.cpp b/lib/CodeGen/CGExprScalar.cpp
index f53bb33e46..13502ffa73 100644
--- a/lib/CodeGen/CGExprScalar.cpp
+++ b/lib/CodeGen/CGExprScalar.cpp
@@ -1983,9 +1983,15 @@ Value *ScalarExprEmitter::VisitCastExpr(CastExpr *CE) {
     llvm::Type *DstTy = ConvertType(DestTy);
     if (SrcTy->isPtrOrPtrVectorTy() && DstTy->isPtrOrPtrVectorTy() &&
         SrcTy->getPointerAddressSpace() != DstTy->getPointerAddressSpace()) {
+      // allow this with opencl/metal/vulkan
+      if (CGF.getLangOpts().OpenCL) {
+        llvm::Type *MidTy = CGF.CGM.getDataLayout().getIntPtrType(SrcTy);
+        return Builder.CreateIntToPtr(Builder.CreatePtrToInt(Src, MidTy), DstTy);
+      } else {
       llvm_unreachable("wrong cast for pointers in different address spaces"
                        "(must be an address space cast)!");
     }
+    }
 
     if (CGF.SanOpts.has(SanitizerKind::CFIUnrelatedCast)) {
       if (auto PT = DestTy->getAs<PointerType>())
@@ -2241,6 +2247,7 @@ Value *ScalarExprEmitter::VisitCastExpr(CastExpr *CE) {
                                          CE->getExprLoc());
   }
 
+  case CK_ZeroToOCLEvent:
   case CK_ZeroToOCLOpaqueType: {
     assert((DestTy->isEventT() || DestTy->isQueueT() ||
             DestTy->isOCLIntelSubgroupAVCType()) &&
@@ -2248,8 +2255,25 @@ Value *ScalarExprEmitter::VisitCastExpr(CastExpr *CE) {
     return llvm::Constant::getNullValue(ConvertType(DestTy));
   }
 
-  case CK_IntToOCLSampler:
-    return CGF.CGM.createOpenCLIntToSamplerConversion(E, CGF);
+  case CK_ZeroToOCLQueue: {
+    assert(DestTy->isQueueT() && "CK_ZeroToOCLQueue cast on non queue_t type");
+    return llvm::Constant::getNullValue(ConvertType(DestTy));
+  }
+
+  case CK_IntToOCLSampler: {
+    assert(DestTy->isSamplerT() && "CK_IntToOCLSampler cast to non sampler type");
+    if (!CGF.CGM.getLangOpts().CLSamplerOpaque)
+      return Visit(E);
+    if (const CastExpr* SCE = dyn_cast<CastExpr>(E)) {
+      if (const DeclRefExpr *DRE = cast<DeclRefExpr>(SCE->getSubExpr())) {
+        if (const VarDecl *VD = cast<VarDecl>(DRE->getDecl())) {
+          assert(VD->getInit() && "Invalid sampler initializer");
+          E = const_cast<Expr*>(VD->getInit());
+        }
+      }
+    }
+    return CGF.CGM.createIntToSamplerConversion(E, &CGF);
+  }
 
   } // end of switch
 
@@ -3221,9 +3245,9 @@ static Value *emitPointerArithmetic(CodeGenFunction &CGF,
   // GNU void* casts amount to no-ops since our void* type is i8*, but this is
   // future proof.
   if (elementType->isVoidType() || elementType->isFunctionType()) {
-    Value *result = CGF.Builder.CreateBitCast(pointer, CGF.VoidPtrTy);
+    Value *result = CGF.Builder.CreatePointerCast(pointer, CGF.VoidPtrTy);
     result = CGF.Builder.CreateGEP(result, index, "add.ptr");
-    return CGF.Builder.CreateBitCast(result, pointer->getType());
+    return CGF.Builder.CreatePointerCast(result, pointer->getType());
   }
 
   if (CGF.getLangOpts().isSignedOverflowDefined())
@@ -4042,35 +4066,9 @@ VisitAbstractConditionalOperator(const AbstractConditionalOperator *E) {
     llvm::Type *condType = ConvertType(condExpr->getType());
     llvm::VectorType *vecTy = cast<llvm::VectorType>(condType);
 
-    unsigned numElem = vecTy->getNumElements();
-    llvm::Type *elemType = vecTy->getElementType();
-
     llvm::Value *zeroVec = llvm::Constant::getNullValue(vecTy);
     llvm::Value *TestMSB = Builder.CreateICmpSLT(CondV, zeroVec);
-    llvm::Value *tmp = Builder.CreateSExt(TestMSB,
-                                          llvm::VectorType::get(elemType,
-                                                                numElem),
-                                          "sext");
-    llvm::Value *tmp2 = Builder.CreateNot(tmp);
-
-    // Cast float to int to perform ANDs if necessary.
-    llvm::Value *RHSTmp = RHS;
-    llvm::Value *LHSTmp = LHS;
-    bool wasCast = false;
-    llvm::VectorType *rhsVTy = cast<llvm::VectorType>(RHS->getType());
-    if (rhsVTy->getElementType()->isFloatingPointTy()) {
-      RHSTmp = Builder.CreateBitCast(RHS, tmp2->getType());
-      LHSTmp = Builder.CreateBitCast(LHS, tmp->getType());
-      wasCast = true;
-    }
-
-    llvm::Value *tmp3 = Builder.CreateAnd(RHSTmp, tmp2);
-    llvm::Value *tmp4 = Builder.CreateAnd(LHSTmp, tmp);
-    llvm::Value *tmp5 = Builder.CreateOr(tmp3, tmp4, "cond");
-    if (wasCast)
-      tmp5 = Builder.CreateBitCast(tmp5, RHS->getType());
-
-    return tmp5;
+    return Builder.CreateSelect(TestMSB, LHS, RHS);
   }
 
   // If this is a really simple expression (like x ? 4 : 5), emit this as a
@@ -4269,6 +4267,9 @@ Value *ScalarExprEmitter::VisitAsTypeExpr(AsTypeExpr *E) {
     return Src;
   }
 
+  if (SrcTy->isPointerTy() || DstTy->isPointerTy())
+    return Builder.CreatePointerCast(Src, DstTy, "astype");
+
   return Src = createCastsForTypeOfSameSize(Builder, CGF.CGM.getDataLayout(),
                                             Src, DstTy, "astype");
 }
diff --git a/lib/CodeGen/CGOpenCLRuntime.cpp b/lib/CodeGen/CGOpenCLRuntime.cpp
index 7f6f595dd5..b4d1092378 100644
--- a/lib/CodeGen/CGOpenCLRuntime.cpp
+++ b/lib/CodeGen/CGOpenCLRuntime.cpp
@@ -38,6 +38,9 @@ llvm::Type *CGOpenCLRuntime::convertOpenCLSpecificType(const Type *T) {
   llvm::LLVMContext& Ctx = CGM.getLLVMContext();
   uint32_t AddrSpc = CGM.getContext().getTargetAddressSpace(
       CGM.getContext().getOpenCLTypeAddrSpace(T));
+
+  // OpenCL/SPIR and SPIR-V/Vulkan
+  if(!CGM.getLangOpts().Metal) {
   switch (cast<BuiltinType>(T)->getKind()) {
   default:
     llvm_unreachable("Unexpected opencl builtin type!");
@@ -45,11 +48,17 @@ llvm::Type *CGOpenCLRuntime::convertOpenCLSpecificType(const Type *T) {
 #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
   case BuiltinType::Id: \
     return llvm::PointerType::get( \
-        llvm::StructType::create(Ctx, "opencl." #ImgType "_" #Suffix "_t"), \
+        llvm::StructType::create(Ctx, "opencl." #ImgType #Suffix "_t"), \
         AddrSpc);
 #include "clang/Basic/OpenCLImageTypes.def"
   case BuiltinType::OCLSampler:
-    return getSamplerType(T);
+    if (CGM.getLangOpts().CLSamplerOpaque)
+	  return llvm::PointerType::get(llvm::StructType::create(
+                                    Ctx, "spirv.Sampler"),
+                                    CGM.getContext().getTargetAddressSpace(
+                                    LangAS::opencl_constant));
+    else
+	    return llvm::IntegerType::get(Ctx, 32);
   case BuiltinType::OCLEvent:
     return llvm::PointerType::get(
         llvm::StructType::create(Ctx, "opencl.event_t"), AddrSpc);
@@ -69,6 +78,127 @@ llvm::Type *CGOpenCLRuntime::convertOpenCLSpecificType(const Type *T) {
 #include "clang/Basic/OpenCLExtensionTypes.def"
   }
 }
+  // Metal/AIR
+  else if(CGM.getLangOpts().Metal) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+      default:
+        llvm_unreachable("Unexpected metal builtin type!");
+        return nullptr;
+#if 0 // TODO: enable this again when using ro/wo/rw image types
+      case BuiltinType::OCLImage1dRO:
+      case BuiltinType::OCLImage1dWO:
+      case BuiltinType::OCLImage1dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_t"), AddrSpc);
+      case BuiltinType::OCLImage1dArrayRO:
+      case BuiltinType::OCLImage1dArrayWO:
+      case BuiltinType::OCLImage1dArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage1dBufferRO:
+      case BuiltinType::OCLImage1dBufferWO:
+      case BuiltinType::OCLImage1dBufferRW:
+        llvm_unreachable("Unsupported image type (1D-buffer is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dRO:
+      case BuiltinType::OCLImage2dWO:
+      case BuiltinType::OCLImage2dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayRO:
+      case BuiltinType::OCLImage2dArrayWO:
+      case BuiltinType::OCLImage2dArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage2dDepthRO:
+      case BuiltinType::OCLImage2dDepthWO:
+      case BuiltinType::OCLImage2dDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayDepthRO:
+      case BuiltinType::OCLImage2dArrayDepthWO:
+      case BuiltinType::OCLImage2dArrayDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage2dMSAARO:
+      case BuiltinType::OCLImage2dMSAAWO:
+      case BuiltinType::OCLImage2dMSAARW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_ms_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAARO:
+      case BuiltinType::OCLImage2dArrayMSAAWO:
+      case BuiltinType::OCLImage2dArrayMSAARW:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dMSAADepthRO:
+      case BuiltinType::OCLImage2dMSAADepthWO:
+      case BuiltinType::OCLImage2dMSAADepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_ms_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepthRO:
+      case BuiltinType::OCLImage2dArrayMSAADepthWO:
+      case BuiltinType::OCLImage2dArrayMSAADepthRW:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA-Depth is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImageCubeRO:
+      case BuiltinType::OCLImageCubeWO:
+      case BuiltinType::OCLImageCubeRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeArrayRO:
+      case BuiltinType::OCLImageCubeArrayWO:
+      case BuiltinType::OCLImageCubeArrayRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_array_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeDepthRO:
+      case BuiltinType::OCLImageCubeDepthWO:
+      case BuiltinType::OCLImageCubeDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeArrayDepthRO:
+      case BuiltinType::OCLImageCubeArrayDepthWO:
+      case BuiltinType::OCLImageCubeArrayDepthRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_array_t"), AddrSpc);
+      case BuiltinType::OCLImage3dRO:
+      case BuiltinType::OCLImage3dWO:
+      case BuiltinType::OCLImage3dRW:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_3d_t"), AddrSpc);
+#else
+      case BuiltinType::OCLImage1d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_t"), AddrSpc);
+      case BuiltinType::OCLImage1dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage1dBuffer:
+        llvm_unreachable("Unsupported image type (1D-buffer is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage2dDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_array_t"), AddrSpc);
+      case BuiltinType::OCLImage2dMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_ms_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAA:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_ms_t"), AddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepth:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA-Depth is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImageCube:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_array_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_t"), AddrSpc);
+      case BuiltinType::OCLImageCubeArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_array_t"), AddrSpc);
+      case BuiltinType::OCLImage3d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_3d_t"), AddrSpc);
+#endif
+      case BuiltinType::OCLSampler:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._sampler_t"),
+                                      CGM.getContext().getTargetAddressSpace(LangAS::opencl_constant));
+      case BuiltinType::OCLEvent:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._event_t"), 0);
+    }
+  }
+  llvm_unreachable("Unexpected builtin type!");
+  return nullptr;
+}
 
 llvm::Type *CGOpenCLRuntime::getPipeType(const PipeType *T) {
   if (T->isReadOnly())
@@ -96,6 +226,68 @@ llvm::PointerType *CGOpenCLRuntime::getSamplerType(const Type *T) {
   return SamplerTy;
 }
 
+llvm::Type *CGOpenCLRuntime::getBlockType() {
+  if (!BlockTy) {
+    // TODO: correct address space?
+    BlockTy = llvm::PointerType::get(llvm::StructType::create(
+                                     CGM.getLLVMContext(), "opencl.block"), 0);
+  }
+
+  return BlockTy;
+}
+
+//
+// Ocl20Mangler
+//
+
+Ocl20Mangler::Ocl20Mangler(llvm::SmallVectorImpl<char>& SS): MangledString(&SS) {}
+
+Ocl20Mangler& Ocl20Mangler::appendReservedId() {
+  this->appendString("13ocl_reserveid");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPipe() {
+  this->appendString("8ocl_pipe");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendInt() {
+  MangledString->push_back('i');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendUint() {
+  MangledString->push_back('j');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendVoid() {
+  MangledString->push_back('v');
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPointer() {
+  this->appendString("P");
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendPointer(int addressSpace) {
+  assert(addressSpace >=0 && addressSpace <= 4 &&
+         "Illegal address space for OpenCL");
+  if (!addressSpace)
+    return appendPointer();
+
+  this->appendString("PU3AS");
+  MangledString->push_back('0' + addressSpace);
+  return *this;
+}
+
+Ocl20Mangler& Ocl20Mangler::appendString(llvm::StringRef S) {
+  MangledString->append(S.begin(), S.end());
+  return *this;
+}
+
 llvm::Value *CGOpenCLRuntime::getPipeElemSize(const Expr *PipeArg) {
   const PipeType *PipeTy = PipeArg->getType()->getAs<PipeType>();
   // The type of the last (implicit) argument to be passed.
@@ -167,7 +359,7 @@ CGOpenCLRuntime::emitOpenCLEnqueuedBlock(CodeGenFunction &CGF, const Expr *E) {
   // The common part of the post-processing of the kernel goes here.
   F->addFnAttr(llvm::Attribute::NoUnwind);
   F->setCallingConv(
-      CGF.getTypes().ClangCallConvToLLVMCallConv(CallingConv::CC_OpenCLKernel));
+      CGF.getTypes().ClangCallConvToLLVMCallConv(CallingConv::CC_FloorKernel));
   EnqueuedBlockMap[Block].Kernel = F;
   return EnqueuedBlockMap[Block];
 }
diff --git a/lib/CodeGen/CGOpenCLRuntime.h b/lib/CodeGen/CGOpenCLRuntime.h
index 3da55af065..dc9cb2c85c 100644
--- a/lib/CodeGen/CGOpenCLRuntime.h
+++ b/lib/CodeGen/CGOpenCLRuntime.h
@@ -38,6 +38,7 @@ protected:
   llvm::Type *PipeROTy;
   llvm::Type *PipeWOTy;
   llvm::PointerType *SamplerTy;
+  llvm::Type *BlockTy { nullptr };
 
   /// Structure for enqueued block information.
   struct EnqueuedBlockInfo {
@@ -91,6 +92,49 @@ public:
   /// \param Block block literal emitted for the block expression.
   void recordBlockInfo(const BlockExpr *E, llvm::Function *InvokeF,
                        llvm::Value *Block);
+
+  virtual llvm::Type *getBlockType();
+
+};
+
+class Ocl20Mangler {
+public:
+  Ocl20Mangler(llvm::SmallVectorImpl<char>&);
+
+  // \brief Appends the mangled representation of reserve_id_t parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendReservedId();
+
+  // \brief Appends the mangled representation of pipe_t parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendPipe();
+
+  // \brief Appends the mangled representation of 'int' parameter to the
+  //  mangled string.
+  Ocl20Mangler& appendInt();
+
+  // \brief Appends the mangled representation of 'unsigned int' parameter to the
+  // mangled string.
+  Ocl20Mangler& appendUint();
+
+  // \brief Appends the mangled representation of a pointer.
+  Ocl20Mangler& appendPointer();
+
+  // \brief Appends the mangled representation of void.
+  Ocl20Mangler& appendVoid();
+
+  // \brief Appends the mangled representation of a pointer with a given address
+  // space.
+  // \param addressSapace The address space of the pointer. Valid values are
+  // [0,4].
+  Ocl20Mangler& appendPointer(int addressSapace);
+
+private:
+
+  // \brief Appends the given string to the mangled prototype.
+  Ocl20Mangler& appendString(llvm::StringRef);
+
+  llvm::SmallVectorImpl<char> *MangledString;
 };
 
 }
diff --git a/lib/CodeGen/CGOpenMPRuntimeNVPTX.cpp b/lib/CodeGen/CGOpenMPRuntimeNVPTX.cpp
index b055132ef0..8044e39034 100644
--- a/lib/CodeGen/CGOpenMPRuntimeNVPTX.cpp
+++ b/lib/CodeGen/CGOpenMPRuntimeNVPTX.cpp
@@ -4388,7 +4388,9 @@ void CGOpenMPRuntimeNVPTX::checkArchForUnifiedAddressing(
         return;
       case CudaArch::SM_70:
       case CudaArch::SM_72:
+      case CudaArch::SM_73:
       case CudaArch::SM_75:
+      case CudaArch::SM_82:
       case CudaArch::GFX600:
       case CudaArch::GFX601:
       case CudaArch::GFX700:
@@ -4440,7 +4442,9 @@ static std::pair<unsigned, unsigned> getSMsBlocksPerSM(CodeGenModule &CGM) {
     return {56, 32};
   case CudaArch::SM_70:
   case CudaArch::SM_72:
+  case CudaArch::SM_73:
   case CudaArch::SM_75:
+  case CudaArch::SM_82:
     return {84, 32};
   case CudaArch::GFX600:
   case CudaArch::GFX601:
diff --git a/lib/CodeGen/CGRecordLayoutBuilder.cpp b/lib/CodeGen/CGRecordLayoutBuilder.cpp
index c754541ac1..dc5a335877 100644
--- a/lib/CodeGen/CGRecordLayoutBuilder.cpp
+++ b/lib/CodeGen/CGRecordLayoutBuilder.cpp
@@ -849,6 +849,42 @@ CGRecordLayout *CodeGenTypes::ComputeRecordLayout(const RecordDecl *D,
   return RL;
 }
 
+void CodeGenTypes::create_flattened_cg_layout(const CXXRecordDecl* D, llvm::StructType* Ty,
+											  const std::vector<CodeGenTypes::aggregate_scalar_entry>& fields) {
+	bool zero_init = true;
+	for(const auto& field : fields) {
+		// vector types (or replaced vector types) are always zero initializable
+		if(field.type->isExtVectorType() ||
+		   field.type->isVectorType()) {
+			continue;
+		}
+		
+		// else: need to make some calls based on the field decl type
+		const Type *Type = field.field_decl->getType()->getBaseElementTypeUnsafe();
+		if (const MemberPointerType *MPT = Type->getAs<MemberPointerType>()) {
+			if(!TheCXXABI.isZeroInitializable(MPT)) {
+				zero_init = false;
+				break;
+			}
+		}
+		else if (const CXXRecordDecl* cxx_rdecl = Type->getAsCXXRecordDecl()) {
+			if(!isZeroInitializable(cxx_rdecl)) {
+				zero_init = false;
+				break;
+			}
+		}
+		// else: it is zero initializable
+	}
+	
+	CGRecordLayout *RL = new CGRecordLayout(Ty, Ty, zero_init, zero_init);
+	uint32_t field_idx = 0;
+	for(const auto& field : fields) {
+		RL->FieldInfo.insert({ field.field_decl, field_idx++ });
+	}
+	
+	FlattenedCGRecordLayouts.insert({ Ty, RL });
+}
+
 void CGRecordLayout::print(raw_ostream &OS) const {
   OS << "<CGRecordLayout\n";
   OS << "  LLVMType:" << *CompleteObjectType << "\n";
diff --git a/lib/CodeGen/CGSPIRMetadataAdder.cpp b/lib/CodeGen/CGSPIRMetadataAdder.cpp
new file mode 100644
index 0000000000..761a54bbbb
--- /dev/null
+++ b/lib/CodeGen/CGSPIRMetadataAdder.cpp
@@ -0,0 +1,318 @@
+//===- SPIRMetadataAdder.cpp - Add SPIR related module scope metadata -----===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+//
+//===----------------------------------------------------------------------===//
+
+
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SmallString.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/IR/TypeFinder.h"
+#include "CGSPIRMetadataAdder.h"
+#include <set>
+
+using namespace llvm;
+using namespace clang;
+using namespace CodeGen;
+
+static const char *ImageTypeNames[] = {
+  "opencl.image1d_t", "opencl.image1d_array_t", "opencl.image1d_buffer_t",
+  "opencl.image2d_t", "opencl.image2d_array_t",
+  "opencl.image2d_depth_t", "opencl.image2d_array_depth_t",
+  "opencl.image2d_msaa_t", "opencl.image2d_array_msaa_t",
+  "opencl.image2d_msaa_depth_t", "opencl.image2d_array_msaa_depth_t",
+  "opencl.image3d_t",
+  "opencl.imagecube_t", "opencl.imagecube_array_t",
+  "opencl.imagecube_depth_t", "opencl.imagecube_array_depth_t",
+};
+
+static const char *ImageDepthTypeNames[] = {
+  "opencl.image2d_depth_t", "opencl.image2d_array_depth_t"
+};
+
+static const char *ImageMSAATypeNames[] = {
+  "opencl.image2d_msaa_t", "opencl.image2d_array_msaa_t",
+  "opencl.image2d_msaa_depth_t", "opencl.image2d_array_msaa_depth_t"
+};
+
+struct OCLExtensionsTy {
+#define OPENCLEXT(nm)  unsigned _##nm : 1;
+#include "clang/Basic/OpenCLExtensions.def"
+
+  OCLExtensionsTy() {
+#define OPENCLEXT(nm)   _##nm = 0;
+#include "clang/Basic/OpenCLExtensions.def"
+  }
+};
+
+typedef void (*func_call_handler)(CallInst *callInstr, OCLExtensionsTy &exts);
+
+void baseAtomics64(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isIntegerTy() &&
+      firstArgType->getPointerElementType()->getScalarSizeInBits() == 64)
+    exts._cl_khr_int64_base_atomics = 1;
+}
+
+void extAtomics64(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isIntegerTy() &&
+      firstArgType->getPointerElementType()->getScalarSizeInBits() == 64)
+    exts._cl_khr_int64_extended_atomics = 1;
+}
+
+void image3DWrite(CallInst *callInstr, OCLExtensionsTy &exts) {
+  PointerType *firstArgType = dyn_cast<PointerType>(callInstr->getArgOperand(0)->getType());
+
+  if (firstArgType &&
+      firstArgType->getPointerElementType()->isStructTy() &&
+      !firstArgType->getPointerElementType()->getStructName().compare("opencl.image3d_t"))
+    exts._cl_khr_3d_image_writes = 1;
+}
+
+typedef struct {
+  const char *funcName;
+  func_call_handler handler;
+} funcCallHandlersTy;
+
+static const funcCallHandlersTy funcCallHandlers[] = {
+  {"_Z8atom_add", baseAtomics64},
+  {"_Z8atom_sub", baseAtomics64},
+  {"_Z9atom_xchg", baseAtomics64},
+  {"_Z8atom_inc", baseAtomics64},
+  {"_Z8atom_dec", baseAtomics64},
+  {"_Z12atom_cmpxchg", baseAtomics64},
+  {"_Z8atom_min", extAtomics64},
+  {"_Z8atom_max", extAtomics64},
+  {"_Z8atom_and", extAtomics64},
+  {"_Z7atom_or", extAtomics64},
+  {"_Z8atom_xor", extAtomics64},
+  {"_Z12write_imagef", image3DWrite},
+  {"_Z12write_imagei", image3DWrite},
+  {"_Z13write_imageui", image3DWrite}
+};
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs);
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs, std::set<llvm::Type*> &typesList) {
+  if (ty1 == ty2)
+    return true;
+
+  if (ty1->isVectorTy())
+    return searchTypeInType(ty1->getVectorElementType(), ty2, ignorePtrs, typesList);
+
+  if (ty1->isArrayTy())
+    return searchTypeInType(ty1->getArrayElementType(), ty2, ignorePtrs, typesList);
+
+  if (!ignorePtrs && ty1->isPointerTy()) {
+    // prevent infinte loop (such a struct that conatinc pointer to itself)
+    std::set<llvm::Type*>::iterator itr = typesList.find(ty1->getPointerElementType());
+    if ( itr != typesList.end() ) {
+      return false;
+    }
+    return searchTypeInType(ty1->getPointerElementType(), ty2, ignorePtrs, typesList);
+  }
+
+  if (ty1->isStructTy()) {
+    typesList.insert( ty1 );
+    llvm::StructType *strTy = dyn_cast<llvm::StructType>(ty1);
+
+    for (StructType::element_iterator EI = strTy->element_begin(),
+         EE = strTy->element_end(); EI != EE; ++EI)
+      if (searchTypeInType((*EI), ty2, ignorePtrs, typesList))
+        return true;
+  }
+
+  if (ty1->isFunctionTy()) {
+    typesList.insert( ty1 );
+    FunctionType *FuncTy = dyn_cast<llvm::FunctionType>(ty1);
+
+    if (searchTypeInType(FuncTy->getReturnType(), ty2, ignorePtrs))
+      return true;
+
+    for (FunctionType::param_iterator PI = FuncTy->param_begin(),
+         PE = FuncTy->param_end(); PI != PE; ++PI)
+      if (searchTypeInType((*PI), ty2, ignorePtrs))
+        return true;
+  }
+
+  return false;
+}
+
+static bool searchTypeInType (llvm::Type *ty1, llvm::Type *ty2, bool ignorePtrs) {
+  std::set<llvm::Type*> typesList;
+  return searchTypeInType( ty1, ty2, ignorePtrs, typesList);
+}
+
+static void FunctionAddSPIRMetadata(Function &F, bool &bUseDoubles, OCLExtensionsTy &sUsedExts);
+
+void clang::CodeGen::AddSPIRMetadata(Module &M, int OCLVersion, std::list<std::string> sBuildOptions, const OpenCLOptions& cl_options) {
+  Type *pDoubleType = Type::getDoubleTy(M.getContext());
+  Type *pHalfType = Type::getHalfTy(M.getContext());
+
+  OCLExtensionsTy sUsedExts;
+
+  bool bUseDoubles = false;
+  bool bUseImages  = false;
+
+  for (Module::global_iterator GI = M.global_begin(), GE = M.global_end();
+       GI != GE; ++GI) {
+    if (searchTypeInType(GI->getType(), pDoubleType, false))
+      bUseDoubles = true;
+    if (searchTypeInType(GI->getType(), pHalfType, true))
+      sUsedExts._cl_khr_fp16 = true;
+  }
+
+  //check if image types are defined
+  for (size_t i = 0; i < sizeof(ImageTypeNames)/sizeof(ImageTypeNames[0]); i++) {
+    if (M.getTypeByName(ImageTypeNames[i])) {
+      bUseImages = true;
+      break;
+    }
+  }
+
+  //check if depth image types are defined
+  for (size_t i = 0; i < sizeof(ImageDepthTypeNames)/sizeof(ImageDepthTypeNames[0]); i++) {
+    if (M.getTypeByName(ImageDepthTypeNames[i])) {
+      sUsedExts._cl_khr_depth_images = true;
+      break;
+    }
+  }
+
+  //check if msaa image types are defined
+  for (size_t i = 0; i < sizeof(ImageMSAATypeNames)/sizeof(ImageMSAATypeNames[0]); i++) {
+    if (M.getTypeByName(ImageMSAATypeNames[i])) {
+      sUsedExts._cl_khr_gl_msaa_sharing = true;
+      break;
+    }
+  }
+
+  // scan all functions
+  for (Module::iterator FI = M.begin(), FE = M.end();
+       FI != FE; ++FI) {
+    FunctionAddSPIRMetadata(*FI, bUseDoubles, sUsedExts);
+  }
+
+  // enable/add explicitly enabled pragma extensions
+#define OPENCLEXT(nm) if (cl_options.isEnabled(#nm)) sUsedExts._##nm = true;
+#include "clang/Basic/OpenCLExtensions.def"
+
+  // Add SPIR version (1.2)
+  llvm::Metadata *SPIRVerElts[] = {
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), 1)),
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), 2))
+  };
+  llvm::NamedMDNode *SPIRVerMD =
+    M.getOrInsertNamedMetadata("opencl.spir.version");
+  SPIRVerMD->addOperand(llvm::MDNode::get(M.getContext(), SPIRVerElts));
+
+  // Add OpenCL version
+  llvm::Metadata *OCLVerElts[] = {
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), OCLVersion / 100)),
+    llvm::ConstantAsMetadata::get(ConstantInt::get(Type::getInt32Ty(M.getContext()), (OCLVersion % 100) / 10))
+  };
+  llvm::NamedMDNode *OCLVerMD =
+    M.getOrInsertNamedMetadata("opencl.ocl.version");
+  OCLVerMD->addOperand(llvm::MDNode::get(M.getContext(), OCLVerElts));
+
+  // Add used extensions
+  llvm::SmallVector<llvm::Metadata*, 5> OCLExtElts;
+
+#define OPENCLEXT(nm)  if (sUsedExts._##nm) \
+  OCLExtElts.push_back(llvm::MDString::get(M.getContext(), #nm));
+#include "clang/Basic/OpenCLExtensions.def"
+
+  llvm::NamedMDNode *OCLExtMD =
+    M.getOrInsertNamedMetadata("opencl.used.extensions");
+
+  OCLExtMD->addOperand(llvm::MDNode::get(M.getContext(), OCLExtElts));
+
+  // Add used optional core features
+  llvm::SmallVector<llvm::Metadata*, 5> OCLOptCoreElts;
+
+  // TODO: flag for this?
+  if (bUseDoubles)
+    OCLOptCoreElts.push_back(llvm::MDString::get(M.getContext(), "cl_doubles"));
+
+  if (bUseImages)
+    OCLOptCoreElts.push_back(llvm::MDString::get(M.getContext(), "cl_images"));
+
+  llvm::NamedMDNode *OptCoreMD =
+    M.getOrInsertNamedMetadata("opencl.used.optional.core.features");
+  OptCoreMD->addOperand(llvm::MDNode::get(M.getContext(), OCLOptCoreElts));
+
+  // Add build options
+  llvm::NamedMDNode *OCLCompOptsMD =
+    M.getOrInsertNamedMetadata("opencl.compiler.options");
+      llvm::SmallVector<llvm::Metadata*,5> OCLBuildOptions;
+  // TODO: should probably parse clang args, -cl-spir-compile-options doesn't seem to work?
+  sBuildOptions.push_back("-cl-kernel-arg-info");
+  sBuildOptions.push_back("-cl-mad-enable");
+  sBuildOptions.push_back("-cl-denorms-are-zero");
+  sBuildOptions.push_back("-cl-unsafe-math-optimizations");
+  for (std::list<std::string>::const_iterator it = sBuildOptions.begin(),
+       e = sBuildOptions.end(); it != e ; ++it) {
+    OCLBuildOptions.push_back(llvm::MDString::get(M.getContext(), *it));
+  }
+  OCLCompOptsMD->addOperand(llvm::MDNode::get(M.getContext(), OCLBuildOptions));
+}
+
+static void FunctionAddSPIRMetadata(Function &F, bool &bUseDoubles, OCLExtensionsTy &sUsedExts) {
+  Type *pDoubleType = Type::getDoubleTy(F.getParent()->getContext());
+  Type *pHalfType = Type::getHalfTy(F.getParent()->getContext());
+
+  for (Function::arg_iterator AI = F.arg_begin(), AE = F.arg_end();
+       AI != AE; ++AI) {
+    if (searchTypeInType(AI->getType(), pDoubleType, false))
+      bUseDoubles = true;
+    if (searchTypeInType(AI->getType(), pHalfType, true))
+      sUsedExts._cl_khr_fp16 = true;
+  }
+
+  for (Function::iterator BB = F.begin(), E = F.end(); BB != E; ++BB)
+    for (BasicBlock::iterator I = BB->begin(), E = BB->end(); I != E; ++I) {
+      if (searchTypeInType(I->getType(), pDoubleType, false))
+        if (!(dyn_cast<FPExtInst>(I)))
+          bUseDoubles = true;
+      if (searchTypeInType(I->getType(), pHalfType, true))
+        sUsedExts._cl_khr_fp16 = true;
+
+      for (Instruction::op_iterator OI = (*I).op_begin(), OE = (*I).op_end();
+           OI != OE; ++OI) {
+        if (searchTypeInType((*OI)->getType(), pDoubleType, false))
+          if (!(dyn_cast<CallInst>(I) &&
+                dyn_cast<CallInst>(I)->getCalledFunction() &&
+                dyn_cast<CallInst>(I)->getCalledFunction()->isVarArg()))
+            bUseDoubles = true;
+        if (searchTypeInType((*OI)->getType(), pHalfType, true))
+          sUsedExts._cl_khr_fp16 = true;
+      }
+
+      CallInst* pCallInst = dyn_cast<CallInst>(I);
+      if (pCallInst && pCallInst->getCalledFunction()) {
+        std::string funcName = pCallInst->getCalledFunction()->getName().str();
+
+        for (size_t i = 0; i < sizeof(funcCallHandlers)/sizeof(funcCallHandlers[0]); i++) {
+          if (funcName.find(funcCallHandlers[i].funcName) == 0)
+            funcCallHandlers[i].handler(pCallInst, sUsedExts);
+        }
+      }
+    }
+}
diff --git a/lib/CodeGen/CGSPIRMetadataAdder.h b/lib/CodeGen/CGSPIRMetadataAdder.h
new file mode 100644
index 0000000000..863ee98b71
--- /dev/null
+++ b/lib/CodeGen/CGSPIRMetadataAdder.h
@@ -0,0 +1,29 @@
+//===- SPIRMetadataAdder.h - Add SPIR related module scope metadata -------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/IR/Module.h"
+#include "clang/Basic/LangOptions.h"
+#include <list>
+#include <string>
+
+#ifndef CLANG_CODEGEN_SPIRMETADATAADDER_H
+#define CLANG_CODEGEN_SPIRMETADATAADDER_H
+
+namespace clang {
+
+namespace CodeGen {
+
+  void AddSPIRMetadata(llvm::Module &M, int OCLVersion, std::list<std::string> sBuildOptions, const OpenCLOptions& cl_options);
+
+} // end namespace CodeGen
+} // end namespace clang
+#endif
diff --git a/lib/CodeGen/CGStmt.cpp b/lib/CodeGen/CGStmt.cpp
index bc7a18af1e..fd1dfc1392 100644
--- a/lib/CodeGen/CGStmt.cpp
+++ b/lib/CodeGen/CGStmt.cpp
@@ -2175,6 +2175,7 @@ void CodeGenFunction::EmitAsmStmt(const AsmStmt &S) {
                                           llvm::ConstantAsMetadata::get(Loc)));
   }
 
+#if 0 // TODO: don't do this pessimistically, check asm code for convergent instructions instead
   if (getLangOpts().assumeFunctionsAreConvergent()) {
     // Conservatively, mark all inline asm blocks in CUDA or OpenCL as
     // convergent (meaning, they may call an intrinsically convergent op, such
@@ -2183,6 +2184,7 @@ void CodeGenFunction::EmitAsmStmt(const AsmStmt &S) {
     Result->addAttribute(llvm::AttributeList::FunctionIndex,
                          llvm::Attribute::Convergent);
   }
+#endif
 
   // Extract all of the register value results from the asm.
   std::vector<llvm::Value*> RegResults;
diff --git a/lib/CodeGen/CMakeLists.txt b/lib/CodeGen/CMakeLists.txt
index 29c6793c60..beb40232a0 100644
--- a/lib/CodeGen/CMakeLists.txt
+++ b/lib/CodeGen/CMakeLists.txt
@@ -2,6 +2,9 @@ set(LLVM_LINK_COMPONENTS
   Analysis
   BitReader
   BitWriter
+  BitWriter32
+  BitWriter35
+  MetalLib
   Core
   Coroutines
   Coverage
@@ -18,6 +21,7 @@ set(LLVM_LINK_COMPONENTS
   Passes
   ProfileData
   ScalarOpts
+  SPIRVlib
   Support
   Target
   TransformUtils
@@ -70,6 +74,7 @@ add_clang_library(clangCodeGen
   CGOpenMPRuntime.cpp
   CGOpenMPRuntimeNVPTX.cpp
   CGRecordLayoutBuilder.cpp
+  CGSPIRMetadataAdder.cpp
   CGStmt.cpp
   CGStmtOpenMP.cpp
   CGVTT.cpp
diff --git a/lib/CodeGen/CodeGenAction.cpp b/lib/CodeGen/CodeGenAction.cpp
index fd4506f2d1..f3bc986b12 100644
--- a/lib/CodeGen/CodeGenAction.cpp
+++ b/lib/CodeGen/CodeGenAction.cpp
@@ -836,7 +836,15 @@ GetOutputStream(CompilerInstance &CI, StringRef InFile, BackendAction Action) {
   case Backend_EmitLL:
     return CI.createDefaultOutputFile(false, InFile, "ll");
   case Backend_EmitBC:
+  case Backend_EmitBC32:
+  case Backend_EmitBC35:
     return CI.createDefaultOutputFile(true, InFile, "bc");
+  case Backend_EmitSPIRV:
+    return CI.createDefaultOutputFile(true, InFile, "spv");
+  case Backend_EmitSPIRVContainer:
+    return CI.createDefaultOutputFile(true, InFile, "spvc");
+  case Backend_EmitMetalLib:
+    return CI.createDefaultOutputFile(true, InFile, "metallib");
   case Backend_EmitNothing:
     return nullptr;
   case Backend_EmitMCNull:
@@ -1058,6 +1066,26 @@ void EmitBCAction::anchor() { }
 EmitBCAction::EmitBCAction(llvm::LLVMContext *_VMContext)
   : CodeGenAction(Backend_EmitBC, _VMContext) {}
 
+void EmitBC32Action::anchor() { }
+EmitBC32Action::EmitBC32Action(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitBC32, _VMContext) {}
+
+void EmitBC35Action::anchor() { }
+EmitBC35Action::EmitBC35Action(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitBC35, _VMContext) {}
+
+void EmitSPIRVAction::anchor() { }
+EmitSPIRVAction::EmitSPIRVAction(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitSPIRV, _VMContext) {}
+
+void EmitSPIRVContainerAction::anchor() { }
+EmitSPIRVContainerAction::EmitSPIRVContainerAction(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitSPIRVContainer, _VMContext) {}
+
+void EmitMetalLibAction::anchor() { }
+EmitMetalLibAction::EmitMetalLibAction(llvm::LLVMContext *_VMContext)
+  : CodeGenAction(Backend_EmitMetalLib, _VMContext) {}
+
 void EmitLLVMAction::anchor() { }
 EmitLLVMAction::EmitLLVMAction(llvm::LLVMContext *_VMContext)
   : CodeGenAction(Backend_EmitLL, _VMContext) {}
diff --git a/lib/CodeGen/CodeGenFunction.cpp b/lib/CodeGen/CodeGenFunction.cpp
index f012384f3d..78058c1e03 100644
--- a/lib/CodeGen/CodeGenFunction.cpp
+++ b/lib/CodeGen/CodeGenFunction.cpp
@@ -38,6 +38,9 @@
 #include "llvm/IR/MDBuilder.h"
 #include "llvm/IR/Operator.h"
 #include "llvm/Transforms/Utils/PromoteMemToReg.h"
+#include <sstream>
+#include <unordered_set>
+#include <fstream>
 using namespace clang;
 using namespace CodeGen;
 
@@ -559,191 +562,1867 @@ static unsigned ArgInfoAddressSpace(LangAS AS) {
   }
 }
 
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained fields
+static std::vector<RecordDecl::field_iterator> get_aggregate_fields(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	//
+	std::vector<RecordDecl::field_iterator> ret;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_fields(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.empty()) {
+			ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+		}
+	}
+	
+	// iterate over all fields/members
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		ret.push_back(iter);
+	}
+	
+	return ret;
+}
+
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained image types
+// NOTE: will return an empty vector if not a proper aggregate image
+static std::vector<RecordDecl::field_iterator> get_aggregate_image_fields(const CXXRecordDecl* decl) {
+	// extract all fields, then check if all are image types (if one isn't, fail)
+	const auto ret = get_aggregate_fields(decl);
+	for(const auto& iter : ret) {
+		if(!iter->getType()->isImageType() &&
+		   !iter->getType()->isArrayImageType(false)) {
+			return {};
+		}
+	}
+	return ret;
+}
+
+static std::pair<FieldDecl*, uint32_t> get_array_image_info(const CXXRecordDecl* decl, const ASTContext& ASTCtx) {
+	const auto ret = get_aggregate_fields(decl);
+	if(ret.size() != 1) return { nullptr, 0 };
+	
+	FieldDecl* arr_field_decl = *ret[0];
+	const ConstantArrayType *CAT = ASTCtx.getAsConstantArrayType(arr_field_decl->getType());
+	if(!CAT) return { nullptr, 0 };
+	
+	auto img_cxx_rdecl = CAT->getElementType()->getAsCXXRecordDecl();
+	if(!img_cxx_rdecl) return { nullptr, 0 };
+	
+	auto img_fields = get_aggregate_fields(img_cxx_rdecl);
+	if(img_fields.size() != 1) return { nullptr, 0 };
+	
+	return { *img_fields[0], uint32_t(CAT->getSize().getZExtValue()) };
+}
+
+// will recurse through the specified class/struct decl and its base classes,
+// returning the first image access attribute that it encounters (or nullptr if none)
+static const ImageAccessAttr* get_aggregate_access_attr(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return nullptr;
+	
+	// must have definition
+	if(!decl->hasDefinition()) return nullptr;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_access_attr(base.getTypeSourceInfo()->getType()->getAsCXXRecordDecl());
+		if(base_ret != nullptr) {
+			return base_ret;
+		}
+	}
+	
+	// iterate over all fields/members and return the first access attr
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		// try direct attr first
+		const ImageAccessAttr* access_attr = iter->getAttr<ImageAccessAttr>();
+		if(access_attr != nullptr) {
+			return access_attr;
+		}
+		
+		// then check if this is a c++ decl (struct/union/class) and check if it has the attr
+		const auto as_decl = iter->getType()->getAsCXXRecordDecl();
+		if(as_decl != nullptr) {
+			access_attr = as_decl->getAttr<ImageAccessAttr>();
+			if(access_attr != nullptr) {
+				return access_attr;
+			}
+		}
+	}
+	
+	return nullptr;
+}
+
+
+// Metadata values extractors.
+static std::string getScalarMetadataValue(const clang::Type *Ty,
+										  const PrintingPolicy &Policy) {
+	assert(Ty && "NULL type");
+
+	if (Ty->isHalfType()) return "half";
+	
+	if (!Ty->isUnsignedIntegerType()) {
+		return QualType(Ty, 0).getAsString(Policy);
+	}
+	
+	std::string TyName = QualType(Ty, 0).getAsString();
+	if (llvm::StringRef(TyName).startswith("unsigned")) {
+		// Replace unsigned <ty> with u<ty>
+		TyName.erase(1, 8);
+	}
+	
+	return TyName;
+}
+static std::string getVectorMetadataValue(const clang::ExtVectorType *Ty,
+										  const PrintingPolicy &Policy) {
+	assert(Ty && "NULL type");
+
+	const clang::VectorType *VTy = llvm::dyn_cast<clang::VectorType>(Ty);
+	assert(VTy && "Cast to vector failed");
+	
+	std::stringstream Ret;
+	Ret << getScalarMetadataValue(VTy->getElementType().getTypePtr(), Policy);
+	Ret << VTy->getNumElements();
+	
+	return Ret.str();
+}
+
+// Returns true if the given module has SPIR (32/64) target
+static bool isSpirTarget(const llvm::Module *M) {
+  assert (M && "NULL module given");
+  return llvm::StringRef(M->getTargetTriple()).startswith("spir");
+}
+
+static std::string getPipeMetadataValue(const clang::PipeType *Ty,
+                                        const PrintingPolicy &Policy) {
+  assert(Ty && "Null type");
+
+  const clang::QualType ElemTy = Ty->getElementType();
+  if (const clang::ExtVectorType *VTy = ElemTy->getAs<ExtVectorType>())
+    return getVectorMetadataValue(VTy, Policy);
+
+  return getScalarMetadataValue(ElemTy.getTypePtr(), Policy);
+}
+
+// NOTE/TODO: unused for now, until pipe metadata generation works correctly
+/*static llvm::MDString *getAccessAttribute(const ParmVarDecl *PDecl,
+                                          llvm::LLVMContext &Context) {
+  if (PDecl->hasAttr<ImageAccessAttr>() &&
+    PDecl->getAttr<ImageAccessAttr>()->isWriteOnly())
+    return llvm::MDString::get(Context, "write_only");
+
+  if (PDecl->hasAttr<ImageAccessAttr>() &&
+    PDecl->getAttr<ImageAccessAttr>()->isReadWrite())
+    return llvm::MDString::get(Context, "read_write");
+
+  return llvm::MDString::get(Context, "read_only");
+}*/
+
 // OpenCL v1.2 s5.6.4.6 allows the compiler to store kernel argument
 // information in the program executable. The argument information stored
 // includes the argument name, its type, the address and access qualifiers used.
 static void GenOpenCLArgMetadata(const FunctionDecl *FD, llvm::Function *Fn,
                                  CodeGenModule &CGM, llvm::LLVMContext &Context,
+                                 SmallVector<llvm::Metadata *, 5> &kernelMDArgs,
                                  CGBuilderTy &Builder, ASTContext &ASTCtx) {
   // Create MDNodes that represent the kernel arg metadata.
   // Each MDNode is a list in the form of "key", N number of values which is
   // the same number of values as their are kernel arguments.
 
+  // TODO: proper handling of EmitVerbose + kernel arg names
   const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
+	const bool EmitVerbose = CGM.getCodeGenOpts().EmitOpenCLArgMetadata;
+
+	if (!isSpirTarget(Fn->getParent()) && !EmitVerbose) {
+		return;
+	}
 
   // MDNode for the kernel argument address space qualifiers.
   SmallVector<llvm::Metadata *, 8> addressQuals;
+	addressQuals.push_back(llvm::MDString::get(Context, "kernel_arg_addr_space"));
 
   // MDNode for the kernel argument access qualifiers (images only).
   SmallVector<llvm::Metadata *, 8> accessQuals;
+	accessQuals.push_back(llvm::MDString::get(Context, "kernel_arg_access_qual"));
 
   // MDNode for the kernel argument type names.
   SmallVector<llvm::Metadata *, 8> argTypeNames;
+	argTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_type"));
 
   // MDNode for the kernel argument base type names.
   SmallVector<llvm::Metadata *, 8> argBaseTypeNames;
+	argBaseTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_base_type"));
 
   // MDNode for the kernel argument type qualifiers.
   SmallVector<llvm::Metadata *, 8> argTypeQuals;
+	argTypeQuals.push_back(llvm::MDString::get(Context, "kernel_arg_type_qual"));
 
   // MDNode for the kernel argument names.
   SmallVector<llvm::Metadata *, 8> argNames;
-
-  for (unsigned i = 0, e = FD->getNumParams(); i != e; ++i) {
-    const ParmVarDecl *parm = FD->getParamDecl(i);
-    QualType ty = parm->getType();
-    std::string typeQuals;
-
-    if (ty->isPointerType()) {
-      QualType pointeeTy = ty->getPointeeType();
-
-      // Get address qualifier.
-      addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(
-        ArgInfoAddressSpace(pointeeTy.getAddressSpace()))));
-
-      // Get argument type name.
-      std::string typeName =
-          pointeeTy.getUnqualifiedType().getAsString(Policy) + "*";
-
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (pointeeTy.isCanonical() && pos != std::string::npos)
-        typeName.erase(pos+1, 8);
-
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
-
-      std::string baseTypeName =
-          pointeeTy.getUnqualifiedType().getCanonicalType().getAsString(
-              Policy) +
-          "*";
-
-      // Turn "unsigned type" to "utype"
-      pos = baseTypeName.find("unsigned");
-      if (pos != std::string::npos)
-        baseTypeName.erase(pos+1, 8);
-
-      argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTypeName));
-
-      // Get argument type qualifiers:
-      if (ty.isRestrictQualified())
-        typeQuals = "restrict";
-      if (pointeeTy.isConstQualified() ||
-          (pointeeTy.getAddressSpace() == LangAS::opencl_constant))
-        typeQuals += typeQuals.empty() ? "const" : " const";
-      if (pointeeTy.isVolatileQualified())
-        typeQuals += typeQuals.empty() ? "volatile" : " volatile";
-    } else {
-      uint32_t AddrSpc = 0;
-      bool isPipe = ty->isPipeType();
-      if (ty->isImageType() || isPipe)
-        AddrSpc = ArgInfoAddressSpace(LangAS::opencl_global);
-
-      addressQuals.push_back(
-          llvm::ConstantAsMetadata::get(Builder.getInt32(AddrSpc)));
-
-      // Get argument type name.
-      std::string typeName;
-      if (isPipe)
-        typeName = ty.getCanonicalType()->getAs<PipeType>()->getElementType()
-                     .getAsString(Policy);
-      else
-        typeName = ty.getUnqualifiedType().getAsString(Policy);
-
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (ty.isCanonical() && pos != std::string::npos)
-        typeName.erase(pos+1, 8);
-
-      std::string baseTypeName;
-      if (isPipe)
-        baseTypeName = ty.getCanonicalType()->getAs<PipeType>()
-                          ->getElementType().getCanonicalType()
-                          .getAsString(Policy);
-      else
-        baseTypeName =
-          ty.getUnqualifiedType().getCanonicalType().getAsString(Policy);
-
-      // Remove access qualifiers on images
-      // (as they are inseparable from type in clang implementation,
-      // but OpenCL spec provides a special query to get access qualifier
-      // via clGetKernelArgInfo with CL_KERNEL_ARG_ACCESS_QUALIFIER):
-      if (ty->isImageType()) {
-        removeImageAccessQualifier(typeName);
-        removeImageAccessQualifier(baseTypeName);
+	if (EmitVerbose) {
+		argNames.push_back(llvm::MDString::get(Context, "kernel_arg_name"));
+	}
+
+	// Creates a canonical name for complex types. In case of anonymous types, the
+	// function appends the meta-type name as prefix: e.g., in case the type is
+	// defined as: typedef struct {...} S, the method returns struct S.
+	static const auto canonicalName = [](const std::string &TyName,
+										 const std::string &MetaTyName) {
+		if (StringRef(TyName).startswith(MetaTyName)) {
+			return TyName;
+		}
+
+		return std::string(MetaTyName) + " __" + TyName;
+	};
+
+	static const auto getComplexMetadataValue = [](const clang::Type *Ty,
+												   const PrintingPolicy &Policy) {
+		std::string TyName = QualType(Ty, 0).getCanonicalType().getAsString();
+
+		if (Ty->isStructureOrClassType()) {
+			return canonicalName(TyName, "struct");
+		}
+
+		if (Ty->isUnionType()) {
+			return canonicalName(TyName, "union");
+		}
+
+		if (Ty->isEnumeralType()) {
+			return canonicalName(TyName, "enum");
       }
 
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
+		return getScalarMetadataValue(Ty, Policy);
+	};
 
-      // Turn "unsigned type" to "utype"
-      pos = baseTypeName.find("unsigned");
-      if (pos != std::string::npos)
-        baseTypeName.erase(pos+1, 8);
+	static const auto getPointerOrRefMetadataValue = [](const clang::Type *PTy,
+														bool CanTy,
+														const PrintingPolicy &Policy) {
+		assert(PTy && "Null type");
 
-      argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTypeName));
+		std::string Ret;
 
-      if (isPipe)
-        typeQuals = "pipe";
+		if (const ExtVectorType *VTy = llvm::dyn_cast<ExtVectorType>(PTy)) {
+			Ret = getVectorMetadataValue(VTy, Policy);
+		}
+		else {
+			Ret = CanTy ? getComplexMetadataValue(PTy, Policy) : getScalarMetadataValue(PTy, Policy);
     }
 
-    argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
-
-    // Get image and pipe access qualifier:
-    if (ty->isImageType()|| ty->isPipeType()) {
-      const Decl *PDecl = parm;
-      if (auto *TD = dyn_cast<TypedefType>(ty))
-        PDecl = TD->getDecl();
-      const OpenCLAccessAttr *A = PDecl->getAttr<OpenCLAccessAttr>();
-      if (A && A->isWriteOnly())
+		return Ret + "*";
+	};
+	
+	const auto add_image_arg = [&Builder, &Context, &CGM, &Policy,
+								&addressQuals, &accessQuals, &argTypeNames, &argBaseTypeNames,
+								&argNames, &argTypeQuals](const clang::QualType& type,
+														  const ImageAccessAttr* access_attr,
+														  const std::string& name) {
+		// image is always in global address space
+		addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getContext().getTargetAddressSpace(LangAS::opencl_global))));
+
+		// set access qualifier
+		if (access_attr && access_attr->isWriteOnly()) {
         accessQuals.push_back(llvm::MDString::get(Context, "write_only"));
-      else if (A && A->isReadWrite())
+		}
+		else if (access_attr && access_attr->isReadWrite()) {
         accessQuals.push_back(llvm::MDString::get(Context, "read_write"));
-      else
+		}
+		else {
         accessQuals.push_back(llvm::MDString::get(Context, "read_only"));
-    } else
+		}
+		
+		// image type / base type
+		// NOTE: always set base type, because types in image aggregates might be "weird", but should be considered normal
+		const QualType baseTy = type.isCanonical() ? type : type.getCanonicalType();
+		const auto type_name = getComplexMetadataValue(baseTy.getTypePtr(), Policy);
+		argTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		argBaseTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		
+		// set arg name
+		argNames.push_back(llvm::MDString::get(Context, name));
+		
+		// type quals is always empty for images
+		argTypeQuals.push_back(llvm::MDString::get(Context, ""));
+	};
+	
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const bool IsCanonical = clang_type.isCanonical();
+		
+		// pointer / buffer
+		if (clang_type->isPointerType() || clang_type->isReferenceType()) {
+			// Get argument type name.
+			std::string tyName;
+			if (const PointerType *PTy = dyn_cast<PointerType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(PTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else if (const ReferenceType *RTy = dyn_cast<ReferenceType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(RTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else if (const DecayedType *DTy = dyn_cast<DecayedType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(DTy->getPointeeType().getTypePtr(), false, Policy);
+			}
+			else {
+				tyName = getScalarMetadataValue(clang_type.getTypePtr(), Policy);
+			}
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			std::string baseTyName;
+			if (IsCanonical) baseTyName = tyName;
+			else {
+				QualType can_pointee_type;
+				if(clang_type->isPointerType()) {
+					can_pointee_type = clang_type.getCanonicalType()->getAs<PointerType>()->getPointeeType();
+				}
+				else { // ref
+					can_pointee_type = clang_type.getCanonicalType()->getAs<ReferenceType>()->getPointeeType();
+				}
+				baseTyName = getPointerOrRefMetadataValue(can_pointee_type.getTypePtr(), true, Policy);
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get address qualifier.
+			QualType pointeeTy = clang_type->getPointeeType();
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(ASTCtx.getTargetAddressSpace(pointeeTy.getAddressSpace()))));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isRestrictQualified()) {
+				typeQuals = "restrict";
+			}
+			if (pointeeTy.isConstQualified() ||
+				(pointeeTy.getAddressSpace() == LangAS::opencl_constant)) {
+				typeQuals += typeQuals.empty() ? "const" : " const";
+			}
+			if (pointeeTy.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
       accessQuals.push_back(llvm::MDString::get(Context, "none"));
-
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+		// normal image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getName().str());
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto decl = clang_type->getAsCXXRecordDecl();
+			const auto agg_images = get_aggregate_image_fields(decl);
+
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				const auto img_type = img->getType();
+				
+				add_image_arg(img_type, img->getAttr<ImageAccessAttr>(),
+							  base_name + std::to_string(img_idx));
+				++img_idx;
+			}
+		}
+		else if (clang_type->isPipeType()) {
+			// Get argument type name.
+			std::string tyName = getPipeMetadataValue(clang_type->getAs<PipeType>(), Policy);
+			
+			// Acquiring the base type of the parameter.
+			std::string baseTyName;
+			if (IsCanonical) {
+				baseTyName = tyName;
+			}
+			else {
+				baseTyName = getPipeMetadataValue(clang_type.getCanonicalType()->getAs<PipeType>(), Policy);
+			}
+			
+			// Get address qualifier.
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(ASTCtx.getTargetAddressSpace(LangAS::opencl_global))));
+			
+			// Get argument type qualifiers.
+			std::string typeQuals = "pipe";
+			
+			// Adding the type and base type to the metadata.
+			assert(!tyName.empty() && "Empty type name");
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			assert(!baseTyName.empty() && "Empty base type name");
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			// TODO: Get image access qualifier: (also for pipe?)
+			//accessQuals.push_back(getAccessAttribute(parm, Context));
+			
+			if (EmitVerbose) {
     // Get argument name.
     argNames.push_back(llvm::MDString::get(Context, parm->getName()));
   }
+		}
+		// kernel parameter
+		else {
+			// TODO: merge pipe functionality
+
+			addressQuals.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(0 /* private address space*/)));
+			
+			// Get argument type name.
+			std::string tyName = getScalarMetadataValue(clang_type.getTypePtr(), Policy);
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			QualType baseTy = IsCanonical ? clang_type : clang_type.getCanonicalType();
+			std::string baseTyName;
+			if (clang_type->isVectorType()) {
+				baseTyName = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(baseTy.getTypePtr()), Policy);
+			}
+			else {
+				baseTyName = getComplexMetadataValue(baseTy.getTypePtr(), Policy);
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isConstQualified()) {
+				typeQuals = "const";
+			}
+			if (clang_type.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			accessQuals.push_back(llvm::MDString::get(Context, "none"));
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+	}
+	
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, addressQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, accessQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argBaseTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeQuals));
+	if(EmitVerbose) {
+		kernelMDArgs.push_back(llvm::MDNode::get(Context, argNames));
+	}
+}
 
-  Fn->setMetadata("kernel_arg_addr_space",
-                  llvm::MDNode::get(Context, addressQuals));
-  Fn->setMetadata("kernel_arg_access_qual",
-                  llvm::MDNode::get(Context, accessQuals));
-  Fn->setMetadata("kernel_arg_type",
-                  llvm::MDNode::get(Context, argTypeNames));
-  Fn->setMetadata("kernel_arg_base_type",
-                  llvm::MDNode::get(Context, argBaseTypeNames));
-  Fn->setMetadata("kernel_arg_type_qual",
-                  llvm::MDNode::get(Context, argTypeQuals));
-  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata)
-    Fn->setMetadata("kernel_arg_name",
-                    llvm::MDNode::get(Context, argNames));
+static void GenVulkanMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+                              CodeGenModule &CGM, llvm::LLVMContext &Context,
+                              CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	
+	SmallVector<llvm::Metadata*, 8> stage_infos;
+	stage_infos.push_back(llvm::MDString::get(Context, FD->getName()));
+	
+	static const std::string prefix_builtin = "builtin:";
+	static const std::string prefix_stage = "stage:";
+	static const std::string prefix_arg = "arg:";
+	static const std::string prefix_iub = "iub:";
+	
+	//
+	const auto handle_stage_input_output = [&Context, &CGM, &stage_infos,
+											&is_kernel, &is_vertex, &is_fragment,
+											&FD, &Fn](const QualType& clang_type,
+													  llvm::Type* llvm_type,
+													  const bool is_return,
+													  uint32_t* arg_idx) {
+		assert((arg_idx != nullptr && !is_return) || (arg_idx == nullptr && is_return) && "invalid args");
+		
+		const bool is_vertex_io = (is_return && is_vertex) || (!is_return && is_fragment);
+		const bool is_fragment_io = (is_return && is_fragment);
+		
+		const auto add_fbo_output = [&stage_infos, &Context](const QualType& type, const uint32_t location) {
+			const auto canon_data_type = type.getCanonicalType();
+			std::string output_type_str = "float";
+			if(canon_data_type->isIntegerType()) output_type_str = "int";
+			if(canon_data_type->isUnsignedIntegerType()) output_type_str = "uint";
+			stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "fbo_output:" + output_type_str + ":" + std::to_string(location)));
+		};
+		
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		if(cxx_rdecl) {
+			if(!cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				
+				// fbo output location resolve/computation needs to happen in two passes:
+				// * gather all fixed/attr locations, make sure none conflict
+				// * used fixed locations + generate automatic location for non-fixed outputs
+				std::unordered_set<uint32_t> fbo_locations;
+				if(is_fragment_io) {
+					for(const auto& field : fields) {
+						if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+							const auto loc_attr = field.getAttr<GraphicsFBOColorLocationAttr>();
+							if(!fbo_locations.insert(loc_attr->getEvalLocation()).second) {
+								// TODO: should have been detected earlier ...
+								CGM.Error(loc_attr->getLocation(), StringRef("location already in use"));
+								// TODO: add note of prev location?
+								return;
+							}
+						}
+					}
+				}
+				
+				uint32_t struct_arg_idx = 0, fbo_location = 0;
+				for(const auto& field : fields) {
+					llvm::Type* field_llvm_type = nullptr;
+					// get llvm type from function args (if !return), else get it from the struct type itself
+					if(arg_idx) {
+						field_llvm_type = std::next(Fn->arg_begin(), *arg_idx)->getType();
+					}
+					else {
+						field_llvm_type = llvm_type->getStructElementType(struct_arg_idx++);
+					}
+					
+					if(is_vertex_io) {
+						if(field.hasAttr<GraphicsVertexPositionAttr>()) {
+							stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+						}
+						else if(field.hasAttr<GraphicsPointSizeAttr>()) {
+							stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "point_size"));
+						}
+						else {
+							stage_infos.push_back(llvm::MDString::get(Context, "none"));
+						}
+					}
+					else if(is_fragment_io) {
+						if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+							add_fbo_output(field.type, field.getAttr<GraphicsFBOColorLocationAttr>()->getEvalLocation());
+						}
+						else if(field.hasAttr<GraphicsFBODepthTypeAttr>()) {
+							const auto depth_attr = field.getAttr<GraphicsFBODepthTypeAttr>();
+							if(!field.type->isFloatingType()) {
+								// TODO: should have been detected earlier ...
+								CGM.Error(depth_attr->getLocation(),
+										  StringRef("depth attribute can only be applied to floating point types"));
+								return;
+							}
+							
+							// TODO: add/handle!
+							std::string depth_qual = "depth_qualifier:";
+							switch(depth_attr->getDepthQualifier()) {
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeAny: depth_qual += "any"; break;
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeLess: depth_qual += "less"; break;
+								case clang::GraphicsFBODepthTypeAttr::FBODepthTypeGreater: depth_qual += "greater"; break;
+							}
+						}
+						else {
+							for(;;) {
+								if(fbo_locations.count(fbo_location) > 0) {
+									++fbo_location;
+								}
+								else break;
+							}
+							add_fbo_output(field.type, fbo_location);
+							++fbo_location;
+						}
+					}
+					
+					// next
+					if(arg_idx) ++*arg_idx;
+				}
+				if(arg_idx) --*arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// stage defaults (can only be those)
+				if(is_vertex_io) {
+					stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+				}
+				else if(is_fragment_io) {
+					add_fbo_output(clang_type, 0);
+				}
+			}
+		}
+		else if(!clang_type->isVoidType()) {
+			// TODO: anything else?
+			// stage defaults (can only be those)
+			if(is_vertex_io) {
+				stage_infos.push_back(llvm::MDString::get(Context, prefix_stage + "position"));
+			}
+			else if(is_fragment_io) {
+				add_fbo_output(clang_type, 0);
+			}
+		}
+		else return;
+	};
+	
+	//
+	stage_infos.push_back(llvm::MDString::get(Context, "stage_input"));
+	
+	const auto add_image_arg = [&stage_infos,
+								&Context, &ASTCtx, &CGM](const clang::QualType& type,
+														 const ImageAccessAttr* access_attr,
+														 const FloorImageDataTypeAttr* data_type,
+														 const std::string& name,
+														 const uint32_t elem_count = 1,
+														 const bool is_array = false) {
+		std::string access_str = "read";
+		if(access_attr && access_attr->isWriteOnly()) {
+			access_str = "write";
+		}
+		else if(access_attr && access_attr->isReadWrite()) {
+			assert(false && "read/write is not supported");
+		}
+		
+		std::string sample_type_str = "float";
+		if(data_type) {
+			const auto canon_data_type = data_type->getImageDataType().getCanonicalType();
+			if(canon_data_type->isIntegerType()) sample_type_str = "int";
+			if(canon_data_type->isUnsignedIntegerType()) sample_type_str = "uint";
+			// else: just assume float
+		}
+		
+		stage_infos.push_back(llvm::MDString::get(Context, (prefix_arg + access_str +
+															(is_array ? ":array" : ":scalar") +
+															":" + std::to_string(elem_count) +
+															":" + sample_type_str)));
+	};
+	
+	uint32_t arg_idx = 0;
+	uint32_t iub_count = 0;
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = std::next(Fn->arg_begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		
+		// TODO: put into static func
+		const auto compute_type_size = [&parm, &Fn, &CGM](llvm::Type* type) {
+			if(!type->isSized()) {
+				auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "%0");
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), err_diagID) << "parameter uses a type with an unknown size (NOTE: this can happen when internal vector/array type conversion/replacement has failed)";
+				
+				auto param_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM type: %0");
+				std::string param_type = "";
+				llvm::raw_string_ostream param_type_stream(param_type);
+				type->print(param_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), param_note_diagID) << param_type_stream.str();
+				
+				auto func_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+				std::string fun_type = "";
+				llvm::raw_string_ostream fun_type_stream(fun_type);
+				Fn->getFunctionType()->print(fun_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), func_note_diagID) << fun_type_stream.str();
+				
+				return uint64_t(0);
+			}
+			return CGM.getDataLayout().getTypeStoreSize(type);
+		};
+		
+		// stage input
+		if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			handle_stage_input_output(clang_type, llvm_type, false, &arg_idx);
+		}
+		// image array
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, ASTCtx);
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(array_image_info.first->getType(),
+							  array_image_info.first->getAttr<ImageAccessAttr>(),
+							  array_image_info.first->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  array_image_info.second,
+							  true /* always an array */);
+			}
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(clang_type->getAsCXXRecordDecl());
+			for(const auto& img : agg_images) {
+				uint32_t elem_count = 1;
+				bool is_array = false;
+				if(img->getType()->isPointerType()) {
+					elem_count = ASTCtx.getAsConstantArrayType(img->getType()->getPointeeType())->getSize().getZExtValue();
+					is_array = true;
+				}
+				add_image_arg(img->getType(),
+							  img->getAttr<ImageAccessAttr>(),
+							  img->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  elem_count,
+							  is_array);
+				
+				// next llvm arg
+				++arg_idx;
+			}
+			// fix up llvm arg count (will inc again after this)
+			--arg_idx;
+		}
+		// make parameters a IUB if their size is <= the size limit and we are still below the IUB count limit
+		else if(clang_type->isReferenceType() &&
+				clang_type->getPointeeType().getAddressSpace() == LangAS::opencl_global &&
+				compute_type_size(llvm_type->getPointerElementType()) <= CGM.getCodeGenOpts().VulkanIUBSize &&
+				iub_count < CGM.getCodeGenOpts().VulkanIUBCount) {
+			stage_infos.push_back(llvm::MDString::get(Context, prefix_iub + std::to_string(iub_count)));
+			++iub_count;
+		}
+		// anything else
+		else {
+			stage_infos.push_back(llvm::MDString::get(Context, "none"));
+		}
+		
+		// next llvm arg
+		++arg_idx;
+	}
+	
+	// add fixed input
+	if (CGM.getCodeGenOpts().VulkanSoftPrintf > 0) {
+		// soft-printf buffer metadata (plain parameter/buffer)
+		stage_infos.push_back(llvm::MDString::get(Context, "none"));
+	}
+	if(is_kernel) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "global_invocation_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "local_invocation_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "workgroup_id"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "num_workgroups"));
+	}
+	else if(is_vertex) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "vertex_index"));
+	}
+	else if(is_fragment) {
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "point_coord"));
+		stage_infos.push_back(llvm::MDString::get(Context, prefix_builtin + "frag_coord"));
+	}
+	
+	// handle return value
+	stage_infos.push_back(llvm::MDString::get(Context, "stage_output"));
+	if(is_vertex || is_fragment) {
+		handle_stage_input_output(FD->getReturnType(), Fn->getReturnType(), true, nullptr);
+	}
+	
+	// add to global stage_io node
+	auto stage_infos_node = llvm::MDNode::get(Context, stage_infos);
+	auto vk_stage_io = CGM.getModule().getOrInsertNamedMetadata("vulkan.stage_io");
+	vk_stage_io->addOperand(stage_infos_node);
+}
+
+static void GenAIRMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+						   const CGFunctionInfo &FnInfo,
+						   CodeGenModule &CGM,llvm::LLVMContext &Context,
+						   SmallVector <llvm::Metadata*, 5> &kernelMDArgs,
+						   CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	
+	//
+	SmallVector<llvm::Metadata*, 4> stage_infos;
+	SmallVector<llvm::Metadata*, 8> arg_infos;
+	
+	//
+	const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
+	const auto make_type_name = [&Policy](const clang::QualType& type) {
+		// NOTE: air wants the type w/o qualifiers
+		const auto base_unq_type = type.getTypePtr()->getBaseElementTypeUnsafe();
+		const auto unqualified_type = base_unq_type->getCanonicalTypeInternal();
+		std::string type_name = "";
+		if(type->isVectorType()) {
+			type_name = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(unqualified_type.getTypePtr()), Policy);
+		}
+		else if(type->isHalfType()) type_name = "half";
+		else type_name = unqualified_type.getAsString(Policy);
+		// Turn "unsigned type" to "utype"
+		const auto pos = type_name.find("unsigned");
+		if(pos != std::string::npos) type_name.erase(pos + 1, 8);
+		return type_name;
+	};
+	
+	//
+	auto abi_arg_info_iter = FnInfo.arg_begin();
+	unsigned int arg_idx = 0, buffer_idx = 0, tex_idx = 0;
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = std::next(Fn->arg_begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+
+		const auto add_image_arg = [&Builder, &tex_idx, &arg_infos, &arg_idx, &parm,
+									&Context, &ASTCtx, &CGM](const clang::QualType& type,
+															 const ImageAccessAttr* access_attr,
+															 const FloorImageDataTypeAttr* data_type,
+															 const std::string& name,
+															 const uint32_t elem_count = 1) {
+			SmallVector<llvm::Metadata*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.texture"));
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(tex_idx)));
+			tex_idx += elem_count;
+			// #4: index count/range
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(elem_count)));
+			// #5: access type (sample = 0, read = 1 or write = 2)
+			// note that "read" is essentially a subset of "sample" -> use "sample" for r/o
+			if(access_attr && access_attr->isWriteOnly()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else if(access_attr && access_attr->isReadWrite()) {
+				// TODO: this isn't really supported
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.sample"));
+			}
+			
+			// #6/#7: texture type
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// proper type is necessary for metal debugging purposes
+			std::string tex_type_name = "";
+			if(elem_count > 1) {
+				tex_type_name += "array<";
+			}
+			const auto builtin_type = type->getAs<BuiltinType>();
+			if(!builtin_type) {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image type (not a builtin type)!"));
+				return;
+			}
+			switch(builtin_type->getKind()) {
+				case BuiltinType::OCLImage1d:
+					tex_type_name += "texture1d";
+					break;
+				case BuiltinType::OCLImage1dArray:
+					tex_type_name += "texture1d_array";
+					break;
+				case BuiltinType::OCLImage2d:
+					tex_type_name += "texture2d";
+					break;
+				case BuiltinType::OCLImage2dArray:
+					tex_type_name += "texture2d_array";
+					break;
+				case BuiltinType::OCLImage2dDepth:
+					tex_type_name += "depth2d";
+					break;
+				case BuiltinType::OCLImage2dArrayDepth:
+					tex_type_name += "depth2d_array";
+					break;
+				case BuiltinType::OCLImage2dMSAA:
+					tex_type_name += "texture2d_ms";
+					break;
+				case BuiltinType::OCLImage2dMSAADepth:
+					tex_type_name += "depth2d_ms";
+					break;
+				case BuiltinType::OCLImage3d:
+					tex_type_name += "texture3d";
+					break;
+				case BuiltinType::OCLImageCube:
+					tex_type_name += "texturecube";
+					break;
+				case BuiltinType::OCLImageCubeArray:
+					tex_type_name += "texturecube_array";
+					break;
+				case BuiltinType::OCLImageCubeDepth:
+					tex_type_name += "depthcube";
+					break;
+				case BuiltinType::OCLImageCubeArrayDepth:
+					tex_type_name += "depthcube_array";
+					break;
+				default:
+					CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image type!"));
+					return;
+			}
+			
+			tex_type_name += "<";
+			std::string sample_type_str = "float";
+			if(data_type) {
+				const auto canon_data_type = data_type->getImageDataType().getCanonicalType();
+				if(canon_data_type->isIntegerType()) sample_type_str = "int";
+				if(canon_data_type->isUnsignedIntegerType()) sample_type_str = "uint";
+				// else: just assume float
+			}
+			tex_type_name += sample_type_str;
+			tex_type_name += ", ";
+			if(access_attr && access_attr->isReadOnly()) {
+				tex_type_name += "sample";
+			}
+			else tex_type_name += "write";
+			tex_type_name += ">";
+			
+			if(elem_count > 1) {
+				tex_type_name += ", " + std::to_string(elem_count) + ">";
+			}
+			
+			arg_info.push_back(llvm::MDString::get(Context, tex_type_name));
+			
+			// #8/#9: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, StringRef(name)));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		};
+		
+		// pointer / buffer
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			SmallVector<llvm::Metadata*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.buffer"));
+			
+			// references / single-object parameters also store/require the buffer_size
+			if(clang_type->isReferenceType()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.buffer_size"));
+				arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type))));
+			}
+			
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(buffer_idx)));
+			++buffer_idx;
+			// #4: index count/range
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(1)));
+			// #5: access (read/read_write, TODO: write?)
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			if(clang_pointee_type.isConstQualified() ||
+			   (clang_pointee_type.getAddressSpace() == LangAS::opencl_constant)) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read_write"));
+			}
+			
+			// #6/#7: struct info
+			if(const auto pointee_rdecl = clang_pointee_type->getAsCXXRecordDecl()) {
+				SmallVector<llvm::Metadata*, 16> struct_info;
+				// TODO: this is not ideal and doesn't handle properly handle unions
+				const auto fields = get_aggregate_fields(pointee_rdecl);
+				bool ignore = false;
+				for(const auto& field : fields) {
+					if(field->isAnonymousStructOrUnion() ||
+					   field->isBitField()) {
+						ignore = true;
+						break;
+					}
+				}
+				
+				// TODO/NOTE: ignore anonymous structs/unions and bitfields for now
+				if(!ignore) {
+					SmallVector<llvm::Metadata*, 16> struct_info;
+					arg_info.push_back(llvm::MDString::get(Context, "air.struct_type_info"));
+					
+					uint32_t offset = 0;
+					for(const auto& field : fields) {
+						// #0: offset
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(offset)));
+						// #1: sizeof
+						const auto llvm_mem_type = CGM.getTypes().ConvertTypeForMem(field->getType()); // TODO: should use this _everywhere_ instead of llvm type tracking/matching!
+						const auto size = (uint32_t)CGM.getDataLayout().getTypeStoreSize(llvm_mem_type);
+						offset += size;
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(size)));
+						// #2: TODO? array or padding maybe?
+						struct_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(0)));
+						// #3: type name
+						struct_info.push_back(llvm::MDString::get(Context, make_type_name(field->getType())));
+						// #4: name/identifier
+						struct_info.push_back(llvm::MDString::get(Context, field->getName()));
+					}
+					arg_info.push_back(llvm::MDNode::get(Context, struct_info));
+				}
+			}
+			
+			// #8/#9: type size
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_size"));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type))));
+			// #10/#11: type alignment
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_align_size"));
+			// max out at 16, anything higher is unreasonable
+			// TODO: make sure this is POT
+			const auto align_size = std::min(CGM.getDataLayout().getTypeAllocSize(pointee_type), uint64_t(16));
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(align_size)));
+			//getPrimitiveSizeInBits
+			// #12/#13: type name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// NOTE: air wants the pointed-to/pointee type here
+			arg_info.push_back(llvm::MDString::get(Context, make_type_name(clang_type->getPointeeType())));
+			// #14/#15: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, parm->getName()));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		}
+		// image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getAttr<FloorImageDataTypeAttr>(), parm->getName().str());
+		}
+		// image array
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, ASTCtx);
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(array_image_info.first->getType(),
+							  array_image_info.first->getAttr<ImageAccessAttr>(),
+							  array_image_info.first->getAttr<FloorImageDataTypeAttr>(),
+							  parm->getName().str(),
+							  array_image_info.second);
+			}
+			else {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image array!"));
+				return;
+			}
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				add_image_arg(img->getType(),
+							  img->getAttr<ImageAccessAttr>(),
+							  img->getAttr<FloorImageDataTypeAttr>(),
+							  base_name + std::to_string(img_idx));
+				++img_idx;
+				
+				// next llvm arg
+				++arg_idx;
+			}
+			// fix up llvm arg count (will inc again after this)
+			--arg_idx;
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					SmallVector<llvm::Metadata*, 16> arg_info;
+					
+					// #0: param index
+					arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+					
+					// #1: type
+					// TODO: handle perspective/center correctly
+					if(field.hasAttr<GraphicsVertexPositionAttr>()) {
+						arg_info.push_back(llvm::MDString::get(Context, "air.position"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.no_perspective"));
+					}
+					else {
+						arg_info.push_back(llvm::MDString::get(Context, "air.fragment_input"));
+						arg_info.push_back(llvm::MDString::get(Context, StringRef(field.mangled_name)));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.perspective"));
+					}
+					
+					// type name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					arg_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// arg name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					arg_info.push_back(llvm::MDString::get(Context, field.name));
+					arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+					
+					// next
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// TODO: add as-is
+			}
+		}
+		// unsupported simple kernel parameter
+		else {
+			CGM.Error(parm->getSourceRange().getBegin(),
+					  StringRef("metal kernel parameter must be a pointer or an image type!"));
+			return;
+		}
+		
+		// next llvm arg
+		++abi_arg_info_iter;
+		++arg_idx;
+	}
+	
+	// soft-printf buffer metadata
+	if (CGM.getCodeGenOpts().MetalSoftPrintf > 0) {
+		SmallVector<llvm::Metadata*, 16> arg_info;
+		
+		// #0: param index
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+		// #1: storage type
+		arg_info.push_back(llvm::MDString::get(Context, "air.buffer"));
+		// #2/#3: location_index (note: separate for buffers and textures)
+		arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(buffer_idx)));
+		++buffer_idx;
+		// #4: index count/range
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(1)));
+		// #5: access
+		arg_info.push_back(llvm::MDString::get(Context, "air.read_write"));
+		// #8/#9: type size
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_size"));
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(4)));
+		// #10/#11: type alignment
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_align_size"));
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(4)));
+		// #12/#13: type name
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "uint"));
+		// #14/#15: arg name
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__printf_buffer__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		
+		++arg_idx;
+	}
+	
+	// limits check
+	// https://developer.apple.com/metal/limits/
+	const bool is_osx = (CGM.getModule().getTargetTriple().find("macosx") != std::string::npos);
+	const uint32_t buf_limit = 31;
+	const uint32_t tex_limit = (is_osx ? 128 : 31);
+	if(buffer_idx > buf_limit) {
+		CGM.Error(FD->getSourceRange().getBegin(),
+				  StringRef("can't use more than " + std::to_string(buf_limit) + " buffers per function"));
+		return;
+	}
+	if(tex_idx > tex_limit) {
+		CGM.Error(FD->getSourceRange().getBegin(),
+				  StringRef("can't use more than " + std::to_string(tex_limit) + " images per function"));
+		return;
+	}
+	
+	//
+	if(is_kernel) {
+		// add id handling arg metadata
+		// NOTE: the actual args are added by handleMetalVulkanEntryFunction + the order in here must match the order in there
+		const auto add_id_arg = [&arg_idx, &arg_infos, &Builder, &Context](const char* name, const char* air_name, const char* air_type) {
+			SmallVector<llvm::Metadata*, 6> arg_info;
+			arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+			arg_info.push_back(llvm::MDString::get(Context, air_name));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			arg_info.push_back(llvm::MDString::get(Context, air_type));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, name));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+			
+			// next llvm arg
+			++arg_idx;
+		};
+		
+		add_id_arg("__metal__global_id__", "air.thread_position_in_grid", "uint3");
+		add_id_arg("__metal__global_size__", "air.threads_per_grid", "uint3");
+		add_id_arg("__metal__local_id__", "air.thread_position_in_threadgroup", "uint3");
+		add_id_arg("__metal__local_size__", "air.threads_per_threadgroup", "uint3");
+		add_id_arg("__metal__group_id__", "air.threadgroup_position_in_grid", "uint3");
+		add_id_arg("__metal__group_size__", "air.threadgroups_per_grid", "uint3");
+		
+		if (CGM.getLangOpts().MetalVersion >= 200 && CGM.getTriple().getOS() == llvm::Triple::OSType::MacOSX) {
+			add_id_arg("__metal__sub_group_id__", "air.simdgroup_index_in_threadgroup", "uint");
+			add_id_arg("__metal__sub_group_local_id__", "air.thread_index_in_simdgroup", "uint");
+			add_id_arg("__metal__sub_group_size__", "air.threads_per_simdgroup", "uint");
+			add_id_arg("__metal__num_sub_groups__", "air.simdgroups_per_threadgroup", "uint");
+		}
+	}
+	else if(is_vertex) {
+		// TODO: instance id
+		
+		SmallVector<llvm::Metadata*, 6> arg_info;
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+		arg_info.push_back(llvm::MDString::get(Context, "air.vertex_id"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "uint"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__vertex_id__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_vs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const bool force_position = false) {
+			SmallVector<llvm::Metadata*, 6> ret_info;
+			
+			if(entry.hasAttr<GraphicsVertexPositionAttr>() || force_position) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.position"));
+			}
+			else if(entry.hasAttr<GraphicsPointSizeAttr>()) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.point_size"));
+			}
+			else {
+				ret_info.push_back(llvm::MDString::get(Context, "air.vertex_output"));
+				ret_info.push_back(llvm::MDString::get(Context, StringRef(entry.mangled_name)));
+			}
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			ret_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			ret_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, ret_info));
+		};
+		
+		// vertex output
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			for(const auto& field : fields) {
+				add_vs_output(field);
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			// direct output: always vertex position, no mangled name
+			add_vs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()),
+				false
+			}, true);
+		}
+	}
+	else if(is_fragment) {
+		// TODO: other stuff
+		
+		SmallVector<llvm::Metadata*, 6> arg_info;
+		arg_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(arg_idx)));
+		arg_info.push_back(llvm::MDString::get(Context, "air.point_coord"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "float2"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__point_coord__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_fs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const unsigned int& location) {
+			SmallVector<llvm::Metadata*, 6> rtt_info;
+			
+			// #0/1: render target location index
+			rtt_info.push_back(llvm::MDString::get(Context, "air.render_target"));
+			rtt_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(location)));
+			if(CGM.getLangOpts().MetalVersion >= 120) {
+				// NOTE: this isn't handled yet, so just always set it to 0
+				rtt_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(0)));
+			}
+			
+			// #2/3: type name
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			// #4/#5: name/identifier
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, rtt_info));
+		};
+		
+		// render targets / return types
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			
+			// fbo output location resolve/computation needs to happen in two passes:
+			// * gather all fixed/attr locations, make sure none conflict
+			// * used fixed locations + generate automatic location for non-fixed outputs
+			std::unordered_set<unsigned int> fbo_locations;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					const auto loc_attr = field.getAttr<GraphicsFBOColorLocationAttr>();
+					if(!fbo_locations.insert(loc_attr->getEvalLocation()).second) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(loc_attr->getLocation(), StringRef("location already in use"));
+						// TODO: add note of prev location?
+						return;
+					}
+				}
+			}
+			
+			unsigned int location = 0;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					add_fs_output(field, field.getAttr<GraphicsFBOColorLocationAttr>()->getEvalLocation());
+				}
+				else if(field.hasAttr<GraphicsFBODepthTypeAttr>()) {
+					const auto depth_attr = field.getAttr<GraphicsFBODepthTypeAttr>();
+					if(!field.type->isFloatingType()) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(depth_attr->getLocation(),
+								  StringRef("depth attribute can only be applied to floating point types"));
+						return;
+					}
+					
+					SmallVector<llvm::Metadata*, 7> depth_info;
+					
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth"));
+					
+					// #1/2: depth qualifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth_qualifier"));
+					std::string depth_qual = "air.";
+					switch(depth_attr->getDepthQualifier()) {
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeAny: depth_qual += "any"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeLess: depth_qual += "less"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeGreater: depth_qual += "greater"; break;
+					}
+					depth_info.push_back(llvm::MDString::get(Context, depth_qual));
+					
+					// #3/4: type name
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					depth_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// #5/#6: name/identifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					depth_info.push_back(llvm::MDString::get(Context, field.name));
+					
+					stage_infos.push_back(llvm::MDNode::get(Context, depth_info));
+				}
+				else {
+					for(;;) {
+						if(fbo_locations.count(location) > 0) {
+							++location;
+						}
+						else break;
+					}
+					add_fs_output(field, location);
+					++location;
+				}
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			add_fs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()),
+				false
+			}, 0);
+		}
+	}
+
+	// insert into kernel metadata
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, stage_infos));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, arg_infos));
+
+	// Metal 2.1+ supports defining a max work-group size via max_total_threads_per_threadgroup/air.max_work_group_size
+	if (const ReqdWorkGroupSizeAttr *reg_local_size = FD->getAttr<ReqdWorkGroupSizeAttr>()) {
+		if (CGM.getLangOpts().MetalVersion >= 210) {
+			// NOTE: this is a 1D extent, not a 3D size
+			const uint32_t max_work_group_size {
+				std::max(1u, reg_local_size->getXDim()) *
+				std::max(1u, reg_local_size->getYDim()) *
+				std::max(1u, reg_local_size->getZDim())
+			};
+			
+			SmallVector<llvm::Metadata*, 7> max_work_group_size_info;
+			max_work_group_size_info.push_back(llvm::MDString::get(Context, "air.max_work_group_size"));
+			max_work_group_size_info.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(max_work_group_size)));
+			
+			kernelMDArgs.push_back(llvm::MDNode::get(Context, max_work_group_size_info));
+		}
+	}
+}
+
+void CodeGenFunction::EmitFloorKernelMetadata(const FunctionDecl *FD,
+											  llvm::Function *Fn,
+											  const FunctionArgList &Args,
+											  const CGFunctionInfo &FnInfo) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	if(!is_kernel && !is_vertex && !is_fragment) {
+		return;
+	}
+
+ 	if(getLangOpts().floor_function_info == nullptr) {
+ 		return;
+ 	}
+ 	std::fstream& file = *getLangOpts().floor_function_info;
+	std::stringstream info;
+	
+	const PrintingPolicy &Policy = getContext().getPrintingPolicy();
+	
+	// #0: info version
+	info << "4,";
+	// #1: function name
+	info << Fn->getName().str() << ",";
+	// #2: function type
+	info << (is_kernel ? "1" : (is_vertex ? "2" : "3")) << ",";
+	// #3: function flags
+	if ((getLangOpts().Metal && CGM.getCodeGenOpts().MetalSoftPrintf > 0) ||
+		(getLangOpts().Vulkan && CGM.getCodeGenOpts().VulkanSoftPrintf > 0)) {
+		info << "1,";
+	} else {
+		info << "0,";
+	}
+	// #4,5,6: local size/dim
+	if(const ReqdWorkGroupSizeAttr *reg_local_size = FD->getAttr<ReqdWorkGroupSizeAttr>()) {
+		info << reg_local_size->getXDim() << ",";
+		info << reg_local_size->getYDim() << ",";
+		info << reg_local_size->getZDim() << ",";
+	} else {
+		info << "0,0,0,";
+	}
+	
+	// iterate over clang function decl parameters
+	// NOTE: in case of struct expansion, this doesn't match the llvm parameters
+	// (which is why it iterates over the original clang list!)
+	unsigned int arg_idx = 0;
+	auto abi_arg_info_iter = FnInfo.arg_begin();
+	uint32_t vulkan_iub_count = 0;
+	for(const auto& parm : FD->parameters()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = std::next(Fn->arg_begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		
+		enum class FLOOR_ARG_INFO : uint64_t {
+			// 0 == invalid!
+			NONE						= (0ull),
+			
+			// sets: -------- 000000-- -------- 00000xxx 00000000 00000000 00000000 00000000
+			__AS_SHIFT					= (32ull),
+			__AS_MASK					= (0x0000000700000000ull),
+			AS_NONE						= NONE,
+			AS_GLOBAL					= (1ull << __AS_SHIFT),
+			AS_LOCAL					= (2ull << __AS_SHIFT),
+			AS_CONSTANT					= (3ull << __AS_SHIFT),
+			AS_IMAGE					= (4ull << __AS_SHIFT),
+			
+			// sets: -------- 000000-- xxxxxxxx 00000--- 00000000 00000000 00000000 00000000
+			__IMG_TYPE_SHIFT			= (40ull),
+			__IMG_TYPE_MASK				= (0x0000FF0000000000ull),
+			IMG_1D						= (1ull << __IMG_TYPE_SHIFT),
+			IMG_1D_ARRAY				= (2ull << __IMG_TYPE_SHIFT),
+			IMG_1D_BUFFER				= (3ull << __IMG_TYPE_SHIFT),
+			IMG_2D						= (4ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY				= (5ull << __IMG_TYPE_SHIFT),
+			IMG_2D_DEPTH				= (6ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_DEPTH			= (7ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA					= (8ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA			= (9ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA_DEPTH			= (10ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA_DEPTH		= (11ull << __IMG_TYPE_SHIFT),
+			IMG_3D						= (12ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE					= (13ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY				= (14ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_DEPTH				= (15ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY_DEPTH		= (16ull << __IMG_TYPE_SHIFT),
+			
+			// sets: -------- 000000xx -------- 00000--- 00000000 00000000 00000000 00000000
+			__IMG_ACCESS_SHIFT			= (48ull),
+			__IMG_ACCESS_MASK			= (0x0003000000000000ull),
+			IMG_ACCESS_READ				= (1ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_WRITE			= (2ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_READ_WRITE		= (IMG_ACCESS_READ | IMG_ACCESS_WRITE),
+			
+			// sets: xxxxxxxx 000000-- -------- 00000--- 00000000 00000000 00000000 00000000
+			__SPECIAL_TYPE_SHIFT		= (56ull),
+			__SPECIAL_TYPE_MASK			= (0xFF00000000000000ull),
+			STAGE_INPUT					= (1ull << __SPECIAL_TYPE_SHIFT),
+			PUSH_CONSTANT				= (2ull << __SPECIAL_TYPE_SHIFT),
+			SSBO						= (3ull << __SPECIAL_TYPE_SHIFT),
+			IMAGE_ARRAY					= (4ull << __SPECIAL_TYPE_SHIFT),
+			IUB							= (5ull << __SPECIAL_TYPE_SHIFT),
+		};
+		static const auto to_fas = [](const LangAS& addr_space) {
+			if(addr_space == LangAS::opencl_global) {
+				return FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			else if(addr_space == LangAS::opencl_local) {
+				return FLOOR_ARG_INFO::AS_LOCAL;
+			}
+			else if(addr_space == LangAS::opencl_constant) {
+				return FLOOR_ARG_INFO::AS_CONSTANT;
+			}
+			return FLOOR_ARG_INFO::AS_NONE;
+		};
+		
+		const auto compute_type_size = [this, &parm, &Fn](llvm::Type* type) {
+			if(!type->isSized()) {
+				auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "%0");
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), err_diagID) << "parameter uses a type with an unknown size (NOTE: this can happen when internal vector/array type conversion/replacement has failed)";
+				
+				auto param_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM type: %0");
+				std::string param_type = "";
+				llvm::raw_string_ostream param_type_stream(param_type);
+				type->print(param_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), param_note_diagID) << param_type_stream.str();
+				
+				auto func_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+				std::string fun_type = "";
+				llvm::raw_string_ostream fun_type_stream(fun_type);
+				Fn->getFunctionType()->print(fun_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), func_note_diagID) << fun_type_stream.str();
+				
+				return uint64_t(0);
+			}
+			return CGM.getDataLayout().getTypeStoreSize(type);
+		};
+		
+		static const auto get_image_access = [](const ImageAccessAttr* access_attr) {
+			if(access_attr != nullptr) {
+				if(access_attr->isWriteOnly()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_WRITE;
+				}
+				else if(access_attr->isReadWrite()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE;
+				}
+			}
+			return FLOOR_ARG_INFO::IMG_ACCESS_READ;
+		};
+		static const auto img_type_to_floor_type = [](const clang::Type* type) {
+			const auto builtin_type = type->getAs<BuiltinType>();
+			if(!builtin_type) {
+				return (FLOOR_ARG_INFO)~0ull;
+			}
+			switch(builtin_type->getKind()) {
+				case BuiltinType::OCLImage1d:
+					return FLOOR_ARG_INFO::IMG_1D;
+				case BuiltinType::OCLImage1dArray:
+					return FLOOR_ARG_INFO::IMG_1D_ARRAY;
+				case BuiltinType::OCLImage1dBuffer:
+					return FLOOR_ARG_INFO::IMG_1D_BUFFER;
+				case BuiltinType::OCLImage2d:
+					return FLOOR_ARG_INFO::IMG_2D;
+				case BuiltinType::OCLImage2dArray:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY;
+				case BuiltinType::OCLImage2dDepth:
+					return FLOOR_ARG_INFO::IMG_2D_DEPTH;
+				case BuiltinType::OCLImage2dArrayDepth:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_DEPTH;
+				case BuiltinType::OCLImage2dMSAA:
+					return FLOOR_ARG_INFO::IMG_2D_MSAA;
+				case BuiltinType::OCLImage2dArrayMSAA:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA;
+				case BuiltinType::OCLImage2dMSAADepth:
+					return FLOOR_ARG_INFO::IMG_2D_MSAA_DEPTH;
+				case BuiltinType::OCLImage2dArrayMSAADepth:
+					return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA_DEPTH;
+				case BuiltinType::OCLImage3d:
+					return FLOOR_ARG_INFO::IMG_3D;
+				case BuiltinType::OCLImageCube:
+					return FLOOR_ARG_INFO::IMG_CUBE;
+				case BuiltinType::OCLImageCubeArray:
+					return FLOOR_ARG_INFO::IMG_CUBE_ARRAY;
+				case BuiltinType::OCLImageCubeDepth:
+					return FLOOR_ARG_INFO::IMG_CUBE_DEPTH;
+				case BuiltinType::OCLImageCubeArrayDepth:
+					return FLOOR_ARG_INFO::IMG_CUBE_ARRAY_DEPTH;
+				default: break;
+			}
+			return (FLOOR_ARG_INFO)~0ull;
+		};
+ 		const auto add_image_arg = [this, &info](const FLOOR_ARG_INFO& floor_img_type,
+ 												 const FLOOR_ARG_INFO& access,
+												 const uint32_t elem_count = 1) {
+			uint64_t arg_info = uint64_t(FLOOR_ARG_INFO::AS_IMAGE);
+			arg_info |= uint64_t(floor_img_type);
+			arg_info |= uint64_t(access);
+			if(elem_count > 1) {
+				arg_info |= elem_count;
+				arg_info |= uint64_t(FLOOR_ARG_INFO::IMAGE_ARRAY);
+			}
+			info << arg_info << ",";
+		};
+		// anything that isn't a pointer or special type
+		const auto add_normal_arg = [this, &info,
+									 &compute_type_size](llvm::Type* llvm_type,
+														 const clang::QualType& clang_type,
+														 const FLOOR_ARG_INFO init_info = FLOOR_ARG_INFO::NONE) {
+			// for now: just use the direct type size + no address space
+			uint64_t arg_info = (uint64_t)init_info;
+			// handle some llvm weirdness? why can this be a pointer still?
+			if(llvm_type->isPointerTy()) {
+				arg_info |= compute_type_size(llvm_type->getPointerElementType());
+			}
+			else {
+				arg_info |= compute_type_size(llvm_type);
+			}
+			arg_info |= (uint64_t)to_fas(clang_type.getAddressSpace());
+			info << arg_info << ",";
+		};
+		
+		// #2+: argument sizes + types
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			const uint64_t arg_size = compute_type_size(pointee_type);
+			uint64_t arg_info = arg_size;
+			if(getLangOpts().OpenCL) {
+				arg_info |= (uint64_t)to_fas(clang_pointee_type.getAddressSpace());
+			}
+			else if(getLangOpts().CUDA) {
+				// always pretend this is global
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			if(getLangOpts().Vulkan) {
+				// NOTE: only using global& for const parameters (aka uniforms) right now,
+				//       if this should change, this must also be modified
+				//       -> global pointer must always be a SSBO
+				if(!clang_type->isReferenceType() &&
+				   clang_pointee_type.getAddressSpace() == LangAS::opencl_global) {
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::SSBO;
+				}
+				
+				// make parameters a IUB if their size is <= the size limit and we are still below the IUB count limit
+				if(clang_type->isReferenceType() &&
+				   clang_pointee_type.getAddressSpace() == LangAS::opencl_global &&
+				   arg_size <= CGM.getCodeGenOpts().VulkanIUBSize &&
+				   vulkan_iub_count < CGM.getCodeGenOpts().VulkanIUBCount) {
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::IUB;
+					++vulkan_iub_count;
+				}
+			}
+			info << arg_info << ",";
+		}
+		// handle image types
+		else if(clang_type->isImageType()) {
+			add_image_arg(img_type_to_floor_type(clang_type.getTypePtr()),
+						  get_image_access(parm->getAttr<ImageAccessAttr>()));
+		}
+		// image array (std::array<*image_*<type>, extent>)
+		// NOTE: check before "isAggregateImageType()", because this is essentially a sub-type of it
+		else if(clang_type->isArrayImageType(true)) {
+			const auto array_image_info = get_array_image_info(cxx_rdecl, getContext());
+			if(array_image_info.first != nullptr &&
+			   array_image_info.second > 0) {
+				add_image_arg(img_type_to_floor_type(array_image_info.first->getType().getTypePtr()),
+							  get_image_access(array_image_info.first->getAttr<ImageAccessAttr>()),
+							  array_image_info.second);
+			}
+			else {
+				CGM.Error(parm->getSourceRange().getBegin(), StringRef("invalid image array!"));
+				return;
+			}
+		}
+		// image array (image*_t[N])
+		else if(!getLangOpts().CUDA && clang_type->isArrayImageType(false)) {
+			CGM.Error(parm->getSourceRange().getBegin(), StringRef("C array of images not supported yet"));
+			return;
+		}
+		// aggregate of image types (used with opencl/metal/vulkan)
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			// image count must either be 1 (for single read or write images) or 2 (one read, one write image)
+			const auto field_count = agg_images.size();
+			if(field_count == 0) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("no images in aggregate-image (min: 1)"));
+				return;
+			}
+			else if(field_count > 2) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("too many images in aggregate-image (max: 2)"));
+				return;
+			}
+			
+			// sanity check that all field types are actually images, have proper access attributes and image types match
+			// (should probably put this somewhere else, since it is sema-checking, but then I'd need to duplicate code)
+			FLOOR_ARG_INFO floor_img_type = FLOOR_ARG_INFO::NONE;
+			uint64_t floor_img_access = 0;
+			for(const auto& img : agg_images) {
+				const auto access_attr = img->getAttr<ImageAccessAttr>();
+				if(access_attr == nullptr) {
+					CGM.Error(img->getSourceRange().getBegin(),
+							  StringRef("image type in an aggregate-image must have an access qualifier"));
+					return;
+				}
+				floor_img_access |= uint64_t(get_image_access(access_attr));
+				
+				// first field initializes this
+				auto img_type = img->getType();
+				if(img_type->isArrayImageType(false)) {
+					// get element image type if this is an array
+					if(img_type->isPointerType()) {
+						img_type = img_type->getPointeeType();
+					}
+					img_type = img_type->getAsArrayTypeUnsafe()->getElementType();
+				}
+				if(floor_img_type == FLOOR_ARG_INFO::NONE) {
+					floor_img_type = img_type_to_floor_type(img_type.getTypePtr());
+				}
+				else {
+					// second field must have the same type!
+					if(floor_img_type != img_type_to_floor_type(img_type.getTypePtr())) {
+						CGM.Error(img->getSourceRange().getBegin(),
+								  StringRef("second image in aggregate-image does not have the same type as the first"));
+						return;
+					}
+				}
+			}
+			
+			// if the aggregate has two image objects, one must be read, one must be write -> read/write
+			if(field_count == 2 && floor_img_access != uint64_t(FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE)) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("aggregate-image has 2 image fields, but joint access is not read-write"));
+				return;
+			}
+			
+			// everything works out, add this as a single kernel argument (floor backends will handle r/w images as necessary)
+			// NOTE: for aggregate images that contain an array of images we still only count this as one image,
+			//       since this is behind-the-scenes stuff and not part of the user interface!
+			add_image_arg(floor_img_type, (FLOOR_ARG_INFO)floor_img_access);
+			
+			// 1 clang aggregate-image == 2 llvm image types -> inc index once more
+			if(field_count == 2) ++arg_idx;
+		}
+		// handle non-pointer parameters
+		else if(getLangOpts().CUDA) {
+			// is this an aggregate that is expanded into multiple llvm arguments?
+			if(cxx_rdecl &&
+			   (abi_arg_info_iter->info.isDirect() || abi_arg_info_iter->info.isIndirect()) &&
+			   TargetCodeGenInfo::isAggregateTypeForABI(abi_arg_info_iter->type)) {
+				// check if this is an aggregate image (must have image access qualifiers)
+				const ImageAccessAttr* access_attr = get_aggregate_access_attr(cxx_rdecl);
+				if(access_attr != nullptr) {
+					uint64_t arg_info = 0; // size is irrelevant for cuda images
+					arg_info |= uint64_t(get_image_access(access_attr));
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_IMAGE;
+					info << arg_info << ",";
+				}
+				else if(abi_arg_info_iter->info.isDirect()) {
+					// simple aggregate, all constant -> must handle each field individually
+					// note that we're only interested in the first expanded layer, not multiple expansion
+					// (i.e. fully scalarized), as this is identical to what cuda / nvptx / the abi do
+					uint64_t arg_info = 0; // sizes will be accumulated
+					const auto fields = get_aggregate_fields(cxx_rdecl);
+					for(size_t i = 0; i < fields.size(); ++i) {
+						const auto field_llvm_type = std::next(Fn->arg_begin(), arg_idx)->getType();
+						arg_info += compute_type_size(field_llvm_type);
+						++arg_idx;
+					}
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+					info << arg_info << ",";
+					--arg_idx; // fixup, b/c of inc later
+				}
+				else { // -> indirect
+					// simple aggregate, all constant -> single pointer on either side of clang/llvm
+					uint64_t arg_info = 0;
+					arg_info |= compute_type_size(llvm_type->getPointerElementType());
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+					info << arg_info << ",";
+				}
+			}
+			else {
+				// -> this is a simple constant (scalar or aggregate with scalar eval)
+				// store the parameter size
+				uint64_t arg_info = compute_type_size(llvm_type);
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+				info << arg_info << ",";
+			}
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(!is_vertex && !is_fragment) {
+				// TODO: should check this in sema
+				// TODO: should also make sure that only 1 exists
+				CGM.Error(FD->getSourceRange().getBegin(), "[[stage_input]] only allowed on vertex and fragment functions");
+			}
+			
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					// TODO: check if field type is int or float!
+					const auto field_llvm_type = std::next(Fn->arg_begin(), arg_idx)->getType();
+					add_normal_arg(field_llvm_type, field.type, FLOOR_ARG_INFO::STAGE_INPUT);
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// add as-is
+				// TODO: check if type is int or float!
+				add_normal_arg(llvm_type, clang_type, FLOOR_ARG_INFO::STAGE_INPUT);
+			}
+		}
+		else {
+			add_normal_arg(llvm_type, clang_type);
+		}
+		
+		// next arg
+		++arg_idx;
+		++abi_arg_info_iter;
+	}
+	
+	info << "\n";
+	file << info.str();
+	
+#if 0 // for debugging purposes
+	printf("floor function info: %s", info.str().c_str()); fflush(stdout);
+#endif
+	
+	// if this is wrong, the kernel will almost certainly not be usable
+	arg_idx += CGM.getTypes().getMetalVulkanImplicitArgCount(FD); // account for implicit args
+	if(arg_idx != Fn->arg_size()) {
+		// signal that this is _very_ bad
+		auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "kernel function parameter count mismatch: %0 (clang), %1 (llvm)");
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), err_diagID) << std::to_string(arg_idx) << std::to_string(Fn->arg_size());
+		
+		auto llvm_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+		std::string llvm_fun_type = "";
+		llvm::raw_string_ostream llvm_fun_type_stream(llvm_fun_type);
+		Fn->getFunctionType()->print(llvm_fun_type_stream);
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), llvm_note_diagID) << llvm_fun_type_stream.str();
+		
+		auto clang_note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "clang function type: %0");
+		std::string clang_fun_type = "";
+		llvm::raw_string_ostream clang_fun_type_stream(clang_fun_type);
+		FD->getType().print(clang_fun_type_stream, Policy);
+		CGM.getDiags().Report(FD->getSourceRange().getBegin(), clang_note_diagID) << clang_fun_type_stream.str();
+		return;
+	}
 }
 
 void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
-                                               llvm::Function *Fn)
+                                               llvm::Function *Fn,
+                                               const CGFunctionInfo &FnInfo)
 {
-  if (!FD->hasAttr<OpenCLKernelAttr>())
+  if (!FD->hasAttr<ComputeKernelAttr>() &&
+      !FD->hasAttr<GraphicsVertexShaderAttr>() &&
+      !FD->hasAttr<GraphicsFragmentShaderAttr>())
     return;
 
   llvm::LLVMContext &Context = getLLVMContext();
 
-  GenOpenCLArgMetadata(FD, Fn, CGM, Context, Builder, getContext());
+  SmallVector<llvm::Metadata *, 5> kernelMDArgs;
+  kernelMDArgs.push_back(llvm::ConstantAsMetadata::get(Fn));
+
+  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata)
+    GenOpenCLArgMetadata(FD, Fn, CGM, Context, kernelMDArgs, Builder,
+                         getContext());
+
+  if (CGM.getLangOpts().Metal)
+    GenAIRMetadata(FD, Fn, FnInfo, CGM, Context, kernelMDArgs, Builder, getContext());
+
+  if (CGM.getLangOpts().Vulkan)
+    GenVulkanMetadata(FD, Fn, CGM, Context, Builder, getContext());
 
   if (const VecTypeHintAttr *A = FD->getAttr<VecTypeHintAttr>()) {
-    QualType HintQTy = A->getTypeHint();
-    const ExtVectorType *HintEltQTy = HintQTy->getAs<ExtVectorType>();
-    bool IsSignedInteger =
-        HintQTy->isSignedIntegerType() ||
-        (HintEltQTy && HintEltQTy->getElementType()->isSignedIntegerType());
-    llvm::Metadata *AttrMDArgs[] = {
+    QualType hintQTy = A->getTypeHint();
+    const ExtVectorType *hintEltQTy = hintQTy->getAs<ExtVectorType>();
+    bool isSignedType =
+        hintQTy->isSignedIntegerType() ||
+        (hintEltQTy && hintEltQTy->getElementType()->isSignedIntegerType()) ||
+        hintQTy->isFloatingType() ||
+        (hintEltQTy && hintEltQTy->getElementType()->isFloatingType());
+    llvm::Metadata *attrMDArgs[] = {
         llvm::ConstantAsMetadata::get(llvm::UndefValue::get(
             CGM.getTypes().ConvertType(A->getTypeHint()))),
         llvm::ConstantAsMetadata::get(llvm::ConstantInt::get(
             llvm::IntegerType::get(Context, 32),
-            llvm::APInt(32, (uint64_t)(IsSignedInteger ? 1 : 0))))};
-    Fn->setMetadata("vec_type_hint", llvm::MDNode::get(Context, AttrMDArgs));
+            llvm::APInt(32, (uint64_t)(isSignedType ? 1 : 0))))};
+    kernelMDArgs.push_back(llvm::MDNode::get(Context, attrMDArgs));
   }
 
   if (const WorkGroupSizeHintAttr *A = FD->getAttr<WorkGroupSizeHintAttr>()) {
@@ -769,6 +2448,102 @@ void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
     Fn->setMetadata("intel_reqd_sub_group_size",
                     llvm::MDNode::get(Context, AttrMDArgs));
   }
+
+  llvm::MDNode *kernelMDNode = llvm::MDNode::get(Context, kernelMDArgs);
+  llvm::NamedMDNode *MainMetadataNode;
+  if (!CGM.getLangOpts().Metal) {
+    MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata("opencl.kernels");
+  } else {
+    MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata(
+      (FD->hasAttr<GraphicsVertexShaderAttr>() ? "air.vertex" :
+       (FD->hasAttr<GraphicsFragmentShaderAttr>() ? "air.fragment" : "air.kernel")));
+  }
+  // add soft-printf info
+  if (CGM.getCodeGenOpts().MetalSoftPrintf > 0 || CGM.getCodeGenOpts().VulkanSoftPrintf > 0) {
+    CGM.getModule().getOrInsertNamedMetadata("floor.soft_printf");
+  }
+  MainMetadataNode->addOperand(kernelMDNode);
+
+  // additional air info
+  if(CGM.getLangOpts().Metal) {
+	  // only do this once
+	  llvm::NamedMDNode *AIRVersion = CGM.getModule().getOrInsertNamedMetadata("air.version");
+	  if(AIRVersion->getNumOperands() > 0) return;
+	  
+	  // insert empty sampler state for Metal 2.0+, this will be filled in by MetalImage later on
+	  if (CGM.getLangOpts().MetalVersion >= 200) {
+		  CGM.getModule().getOrInsertNamedMetadata("air.sampler_states");
+	  }
+	  
+	  // figure out which metal versions we should emit
+	  std::array<uint32_t, 3> metal_version;
+	  std::array<uint32_t, 3> metal_language_version;
+	  if(CGM.getLangOpts().MetalVersion == 210) {
+		  // Metal 2.1
+		  metal_version = {{ 2, 1, 0 }};
+		  metal_language_version = {{ 2, 1, 0 }};
+	  } else if(CGM.getLangOpts().MetalVersion == 200) {
+		  // Metal 2.0
+		  metal_version = {{ 2, 0, 0 }};
+		  metal_language_version = {{ 2, 0, 0 }};
+	  } else if(CGM.getLangOpts().MetalVersion == 120) {
+		  // Metal 1.2
+		  metal_version = {{ 1, 11, 0 }};
+		  metal_language_version = {{ 1, 2, 0 }};
+	  } else {
+		  // Metal 1.1
+		  metal_version = {{ 1, 8, 0 }};
+		  metal_language_version = {{ 1, 1, 0 }};
+	  }
+	  
+	  SmallVector <llvm::Metadata*, 3> air_version;
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[0])));
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[1])));
+	  air_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_version[2])));
+	  AIRVersion->addOperand(llvm::MDNode::get(Context, air_version));
+	  
+	  llvm::NamedMDNode *AIRLangVersion = CGM.getModule().getOrInsertNamedMetadata("air.language_version");
+	  SmallVector <llvm::Metadata*, 4> air_lang_version;
+	  air_lang_version.push_back(llvm::MDString::get(Context, "Metal"));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[0])));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[1])));
+	  air_lang_version.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(metal_language_version[2])));
+	  AIRLangVersion->addOperand(llvm::MDNode::get(Context, air_lang_version));
+	  
+	  llvm::NamedMDNode *AIRCompOpts = CGM.getModule().getOrInsertNamedMetadata("air.compile_options");
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.denorms_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.fast_math_enable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.framebuffer_fetch_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.native_double_disable")));
+  }
+
+  // additional vulkan info
+  if(CGM.getLangOpts().Vulkan) {
+	  // only do this once
+	  llvm::NamedMDNode *VulkanVersion = CGM.getModule().getOrInsertNamedMetadata("vulkan.version");
+	  if(VulkanVersion->getNumOperands() > 0) return;
+	  
+	  // figure out which vulkan versions we should emit
+	  std::array<uint32_t, 2> vulkan_version;
+	  if(CGM.getLangOpts().VulkanVersion == 110) {
+		  // Vulkan 1.1
+		  vulkan_version = {{ 1, 1 }};
+	  } else {
+		  // Vulkan 1.0
+		  vulkan_version = {{ 1, 0 }};
+	  }
+	  
+	  SmallVector <llvm::Metadata*, 2> vulkan_version_md;
+	  vulkan_version_md.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(vulkan_version[0])));
+	  vulkan_version_md.push_back(llvm::ConstantAsMetadata::get(Builder.getInt32(vulkan_version[1])));
+	  VulkanVersion->addOperand(llvm::MDNode::get(Context, vulkan_version_md));
+  }
+
+  // NOTE: additional/global opencl metadata is handled in CGSPIRMetadataAdder
 }
 
 /// Determine whether the function F ends with a return stmt.
@@ -834,10 +2609,11 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
          "Do not use a CodeGenFunction object for more than one function");
 
   const Decl *D = GD.getDecl();
+  const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D);
 
   DidCallStackSave = false;
   CurCodeDecl = D;
-  if (const auto *FD = dyn_cast_or_null<FunctionDecl>(D))
+  if (FD)
     if (FD->usesSEHTry())
       CurSEHParent = FD;
   CurFuncDecl = (D ? D->getNonClosureContext() : nullptr);
@@ -945,16 +2721,24 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   if (CGM.getCodeGenOpts().ProfileSampleAccurate)
     Fn->addFnAttr("profile-sample-accurate");
 
-  if (getLangOpts().OpenCL) {
-    // Add metadata for a kernel function.
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
-      EmitOpenCLKernelMetadata(FD, Fn);
+  // emit compute metadata
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
+    if(FD) {
+      // add floor specific metadata for kernel functions
+      EmitFloorKernelMetadata(FD, Fn, Args, FnInfo);
+    }
+    
+    // opencl/spir, metal and vulkan specific metadata
+    if (getLangOpts().OpenCL) {
+      // Add metadata for a kernel function.
+      EmitOpenCLKernelMetadata(FD, Fn, FnInfo);
+    }
   }
 
   // If we are checking function types, emit a function type signature as
   // prologue data.
   if (getLangOpts().CPlusPlus && SanOpts.has(SanitizerKind::Function)) {
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D)) {
+    if (FD) {
       if (llvm::Constant *PrologueSig = getPrologueSignature(CGM, FD)) {
         // Remove any (C++17) exception specifications, to allow calling e.g. a
         // noexcept function through a non-noexcept pointer.
@@ -990,13 +2774,13 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   // to be norecurse by the standard (3.6.1.3 "The function main shall not be
   // used within a program").
   if (getLangOpts().CPlusPlus)
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
+    if (FD)
       if (FD->isMain())
         Fn->addFnAttr(llvm::Attribute::NoRecurse);
 
   // If a custom alignment is used, force realigning to this alignment on
   // any main function which certainly will need it.
-  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
+  if (FD)
     if ((FD->isMain() || FD->isMSVCRTEntryPoint()) &&
         CGM.getCodeGenOpts().StackAlignment)
       Fn->addFnAttr("stackrealign");
@@ -1090,7 +2874,16 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
     Addr = Builder.CreateAlignedLoad(Addr, getPointerAlign(), "agg.result");
     ReturnValue = Address(Addr, getNaturalTypeAlignment(RetTy));
   } else {
-    ReturnValue = CreateIRTemp(RetTy, "retval");
+    // fix retval allocation for vertex/fragment shader return values (use the computed coerce type)
+    if(FD &&
+       (FD->hasAttr<GraphicsVertexShaderAttr>() ||
+        FD->hasAttr<GraphicsFragmentShaderAttr>())) {
+      auto RetAlloc = CreateTempAlloca(FnInfo.getReturnInfo().getCoerceToType(), "retval");
+      CharUnits Align = getContext().getTypeAlignInChars(RetTy);
+      RetAlloc->setAlignment(Align.getQuantity());
+      ReturnValue = Address(RetAlloc, Align);
+    }
+    else ReturnValue = CreateIRTemp(RetTy, "retval");
 
     // Tell the epilog emitter to autorelease the result.  We do this
     // now so that various specialized functions can suppress it
@@ -1137,11 +2930,11 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
               EmitLoadOfLValue(ThisFieldLValue, SourceLocation()).getScalarVal();
         }
       }
-      for (auto *FD : MD->getParent()->fields()) {
-        if (FD->hasCapturedVLAType()) {
-          auto *ExprArg = EmitLoadOfLValue(EmitLValueForLambdaField(FD),
+      for (auto *field : MD->getParent()->fields()) {
+        if (field->hasCapturedVLAType()) {
+          auto *ExprArg = EmitLoadOfLValue(EmitLValueForLambdaField(field),
                                            SourceLocation()).getScalarVal();
-          auto VAT = FD->getCapturedVLAType();
+          auto VAT = field->getCapturedVLAType();
           VLASizeMap[VAT->getSizeExpr()] = ExprArg;
         }
       }
@@ -1288,6 +3081,9 @@ QualType CodeGenFunction::BuildFunctionArgList(GlobalDecl GD,
   if (MD && (isa<CXXConstructorDecl>(MD) || isa<CXXDestructorDecl>(MD)))
     CGM.getCXXABI().addImplicitStructorParams(*this, ResTy, Args);
 
+  // add additional implicit internal args if necessary
+  CGM.getTypes().handleMetalVulkanEntryFunction(nullptr, &Args, FD);
+
   return ResTy;
 }
 
@@ -1356,7 +3152,7 @@ void CodeGenFunction::GenerateCode(GlobalDecl GD, llvm::Function *Fn,
     EmitConstructorBody(Args);
   else if (getLangOpts().CUDA &&
            !getLangOpts().CUDAIsDevice &&
-           FD->hasAttr<CUDAGlobalAttr>())
+           FD->hasAttr<ComputeKernelAttr>())
     CGM.getCUDARuntime().emitDeviceStub(*this, Args);
   else if (isa<CXXMethodDecl>(FD) &&
            cast<CXXMethodDecl>(FD)->isLambdaStaticInvoker()) {
diff --git a/lib/CodeGen/CodeGenFunction.h b/lib/CodeGen/CodeGenFunction.h
index 8971accdcd..4f1c1bcec6 100644
--- a/lib/CodeGen/CodeGenFunction.h
+++ b/lib/CodeGen/CodeGenFunction.h
@@ -1585,8 +1585,14 @@ private:
   /// Add OpenCL kernel arg metadata and the kernel attribute metadata to
   /// the function metadata.
   void EmitOpenCLKernelMetadata(const FunctionDecl *FD,
-                                llvm::Function *Fn);
-
+                                llvm::Function *Fn,
+                                const CGFunctionInfo &FnInfo);
+
+  void EmitFloorKernelMetadata(const FunctionDecl *FD,
+                               llvm::Function *Fn,
+                               const FunctionArgList &Args,
+                               const CGFunctionInfo &FnInfo);
+	
 public:
   CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);
   ~CodeGenFunction();
@@ -1751,6 +1757,11 @@ public:
   /// Check if \p T is a C++ class that has a destructor that can throw.
   static bool cxxDestructorCanThrow(QualType T);
 
+  llvm::Value *GenerateOCLBlockBind(llvm::Constant *blockFunc,
+                                    int ctxSize,
+                                    int ctxAlign,
+                                    llvm::Value *ctx);
+
   llvm::Constant *GenerateCopyHelperFunction(const CGBlockInfo &blockInfo);
   llvm::Constant *GenerateDestroyHelperFunction(const CGBlockInfo &blockInfo);
   llvm::Constant *GenerateObjCAtomicSetterCopyHelperFunction(
@@ -4137,14 +4148,16 @@ private:
   ///
   /// \param AI - The first function argument of the expansion.
   void ExpandTypeFromArgs(QualType Ty, LValue Dst,
-                          SmallVectorImpl<llvm::Value *>::iterator &AI);
+                          SmallVectorImpl<llvm::Value *>::iterator &AI,
+                          const CallingConv CC);
 
   /// ExpandTypeToArgs - Expand an CallArg \arg Arg, with the LLVM type for \arg
   /// Ty, into individual arguments on the provided vector \arg IRCallArgs,
   /// starting at index \arg IRCallArgPos. See ABIArgInfo::Expand.
   void ExpandTypeToArgs(QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,
                         SmallVectorImpl<llvm::Value *> &IRCallArgs,
-                        unsigned &IRCallArgPos);
+                        unsigned &IRCallArgPos,
+                        const CallingConv CC);
 
   llvm::Value* EmitAsmInput(const TargetInfo::ConstraintInfo &Info,
                             const Expr *InputExpr, std::string &ConstraintStr);
diff --git a/lib/CodeGen/CodeGenModule.cpp b/lib/CodeGen/CodeGenModule.cpp
index df814d6386..e043705eb1 100644
--- a/lib/CodeGen/CodeGenModule.cpp
+++ b/lib/CodeGen/CodeGenModule.cpp
@@ -19,6 +19,7 @@
 #include "CGDebugInfo.h"
 #include "CGObjCRuntime.h"
 #include "CGOpenCLRuntime.h"
+#include "CGSPIRMetadataAdder.h"
 #include "CGOpenMPRuntime.h"
 #include "CGOpenMPRuntimeNVPTX.h"
 #include "CodeGenFunction.h"
@@ -38,6 +39,7 @@
 #include "clang/Basic/CharInfo.h"
 #include "clang/Basic/CodeGenOptions.h"
 #include "clang/Basic/Diagnostic.h"
+#include "clang/Basic/DiagnosticSema.h"
 #include "clang/Basic/Module.h"
 #include "clang/Basic/SourceManager.h"
 #include "clang/Basic/TargetInfo.h"
@@ -486,7 +488,10 @@ void CodeGenModule::Release() {
     // parser will drop debug info with a different version number
     // (and warn about it, too).
     getModule().addModuleFlag(llvm::Module::Warning, "Debug Info Version",
-                              llvm::DEBUG_METADATA_VERSION);
+                              Context.getTargetInfo().getTriple().getOS() != llvm::Triple::IOS ?
+                              llvm::DEBUG_METADATA_VERSION :
+                              // metal/ios uses/requires a very specific metadata version number
+                              llvm::IOS_METAL_DEBUG_METADATA_VERSION);
 
   // We need to record the widths of enums and wchar_t, so that we can generate
   // the correct build attributes in the ARM backend. wchar_size is also used by
@@ -534,10 +539,11 @@ void CodeGenModule::Release() {
 
   // Emit OpenCL specific module metadata: OpenCL/SPIR version.
   if (LangOpts.OpenCL) {
-    EmitOpenCLMetadata();
     // Emit SPIR version.
     if (getTriple().getArch() == llvm::Triple::spir ||
         getTriple().getArch() == llvm::Triple::spir64) {
+      EmitOpenCLMetadata();
+
       // SPIR v2.0 s2.12 - The SPIR version used by the module is stored in the
       // opencl.spir.version named metadata.
       llvm::Metadata *SPIRVerElts[] = {
@@ -578,6 +584,9 @@ void CodeGenModule::Release() {
 
   SimplifyPersonality();
 
+  if (getLangOpts().OpenCL && !getLangOpts().Metal)
+    EmitOCLAnnotations();
+
   if (getCodeGenOpts().EmitDeclMetadata)
     EmitDeclMetadata();
 
@@ -587,6 +596,34 @@ void CodeGenModule::Release() {
   if (DebugInfo)
     DebugInfo->finalize();
 
+  const llvm::Triple TT(TheModule.getTargetTriple());
+  if (TT.getArch() == llvm::Triple::ArchType::spir ||
+      TT.getArch() == llvm::Triple::ArchType::spir64) {
+    std::list<std::string> sBuildOptions;
+    std::string tmp = getCodeGenOpts().SPIRCompileOptions;
+    while (!tmp.empty()) {
+      auto first = tmp.find_first_not_of(' ');
+      auto last = tmp.find_first_of(' ', first);
+
+      std::string s;
+      if (last != std::string::npos)
+        s = tmp.substr(first, last-first);
+      else if (first != std::string::npos)
+        s = tmp.substr(first);
+      else
+        s = "";
+
+      if (!s.empty())
+        sBuildOptions.push_back(s);
+
+      if (last != std::string::npos)
+        tmp = tmp.substr(last);
+      else
+        tmp = "";
+    }
+    AddSPIRMetadata(TheModule, getLangOpts().OpenCLVersion, sBuildOptions, getContext().getOpenCLFeatures());
+  }
+
   if (getCodeGenOpts().EmitVersionIdentMetadata)
     EmitVersionIdentMetadata();
 
@@ -1881,6 +1918,108 @@ void CodeGenModule::EmitGlobalAnnotations() {
   gv->setSection(AnnotationSection);
 }
 
+void CodeGenModule::EmitOCLAnnotations() {
+  // For SPIR, we generate this metadata in a seperate pass
+  if (getTarget().getTriple().getArch() != llvm::Triple::spir &&
+      getTarget().getTriple().getArch() != llvm::Triple::spir64)
+    EmitOCLBuildOptions();
+
+  if (!Context.isFPContractDisabled() && (LangOptions::FPC_Off != getLangOpts().getDefaultFPContractMode()))
+  {
+    TheModule.getOrInsertNamedMetadata("opencl.enable.FP_CONTRACT");
+  }
+}
+
+llvm::SmallVector<llvm::Metadata *, 5> CodeGenModule::getBuildOptions() {
+  llvm::SmallVector<llvm::Metadata *, 5> BuildOption;
+
+  if(!getLangOpts().OpenCL)
+    return BuildOption;
+
+  // Math Intrinsics Options
+  if(getLangOpts().SinglePrecisionConstants)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-single-precision-constant")));
+
+  if(getCodeGenOpts().DenormsAreZero)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-denorms-are-zero")));
+
+  if(getCodeGenOpts().CorrectFPDivideSqrt)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-fp32-correctly-rounded-divide-sqrt")));
+
+  //Optimization Options
+  if(getCodeGenOpts().OptDisable)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-opt-disable")));
+
+  if(getCodeGenOpts().LessPreciseFPMAD)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-mad-enable")));
+
+  if(getCodeGenOpts().NoSignedZeros)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-no-signed-zeros")));
+
+  if(getCodeGenOpts().UnsafeFPMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-unsafe-math-optimizations")));
+
+  if(getCodeGenOpts().NoInfsFPMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-finite-math-only")));
+
+  if(getLangOpts().FastRelaxedMath)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-fast-relaxed-math")));
+
+  if(getCodeGenOpts().getDebugInfo() != codegenoptions::NoDebugInfo)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-g")));
+
+  //Options Controlling the OpenCL C version
+  if(110 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL1.1")));
+
+  if(120 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL1.2")));
+
+  if(200 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.0")));
+
+  if(210 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.1")));
+
+  if(220 == getLangOpts().OpenCLVersion)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-std=CL2.2")));
+
+  // Options for Querying Kernel Argument Information
+  if(getCodeGenOpts().EmitOpenCLArgMetadata)
+    BuildOption.push_back(llvm::MDString::get(
+    VMContext, llvm::StringRef("-cl-kernel-arg-info")));
+
+  return BuildOption;
+}
+
+void CodeGenModule::EmitOCLBuildOptions()
+{
+  llvm::SmallVector<llvm::Metadata *, 5> BuildOptions = getBuildOptions();
+
+  if (BuildOptions.empty())
+    return;
+
+  llvm::NamedMDNode *OpenCLMetadata =
+    TheModule.getOrInsertNamedMetadata("opencl.compiler.options");
+
+  OpenCLMetadata->addOperand(llvm::MDNode::get(VMContext, BuildOptions));
+}
+
 llvm::Constant *CodeGenModule::EmitAnnotationString(StringRef Str) {
   llvm::Constant *&AStr = AnnotationStrings[Str];
   if (AStr)
@@ -2132,30 +2271,6 @@ void CodeGenModule::EmitGlobal(GlobalDecl GD) {
   if (Global->hasAttr<CPUDispatchAttr>())
     return emitCPUDispatchDefinition(GD);
 
-  // If this is CUDA, be selective about which declarations we emit.
-  if (LangOpts.CUDA) {
-    if (LangOpts.CUDAIsDevice) {
-      if (!Global->hasAttr<CUDADeviceAttr>() &&
-          !Global->hasAttr<CUDAGlobalAttr>() &&
-          !Global->hasAttr<CUDAConstantAttr>() &&
-          !Global->hasAttr<CUDASharedAttr>())
-        return;
-    } else {
-      // We need to emit host-side 'shadows' for all global
-      // device-side variables because the CUDA runtime needs their
-      // size and host-side address in order to provide access to
-      // their device-side incarnations.
-
-      // So device-only functions are the only things we skip.
-      if (isa<FunctionDecl>(Global) && !Global->hasAttr<CUDAHostAttr>() &&
-          Global->hasAttr<CUDADeviceAttr>())
-        return;
-
-      assert((isa<FunctionDecl>(Global) || isa<VarDecl>(Global)) &&
-             "Expected Variable or Function");
-    }
-  }
-
   if (LangOpts.OpenMP) {
     // If this is OpenMP device, check if it is legal to emit this global
     // normally.
@@ -3627,6 +3742,11 @@ void CodeGenModule::EmitGlobalVarDefinition(const VarDecl *D,
     }
   }
 
+  if (LangOpts.OpenCL && D->getType()->isBlockPointerType()) {
+    GV->eraseFromParent();
+    OCLGlobalBlockFunctions[D] = Init;
+    return;
+  } else
   GV->setInitializer(Init);
   if (emitter) emitter->finalize(GV);
 
@@ -3810,7 +3930,7 @@ llvm::GlobalValue::LinkageTypes CodeGenModule::getLLVMLinkageForDeclarator(
     if (Context.getLangOpts().AppleKext)
       return llvm::Function::ExternalLinkage;
     if (Context.getLangOpts().CUDA && Context.getLangOpts().CUDAIsDevice)
-      return D->hasAttr<CUDAGlobalAttr>() ? llvm::Function::ExternalLinkage
+      return D->hasAttr<ComputeKernelAttr>() ? llvm::Function::ExternalLinkage
                                           : llvm::Function::InternalLinkage;
     return llvm::Function::WeakODRLinkage;
   }
@@ -3970,12 +4090,51 @@ void CodeGenModule::HandleCXXStaticMemberVarInstantiation(VarDecl *VD) {
   EmitTopLevelDecl(VD);
 }
 
+static llvm::Type* GraphicsExpandReturnType(const CanQualType& type,
+                                            llvm::Type* llvm_type,
+                                            CodeGenTypes& CGT) {
+	const llvm::StructType* ST = dyn_cast<llvm::StructType>(llvm_type);
+	if(!ST) return llvm_type;
+	
+	const auto cxx_rdecl = type->getAsCXXRecordDecl();
+	
+	// if the top decl already is a compat vector, return it directly
+	if(cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+		return CGT.ConvertType(CGT.get_compat_vector_type(cxx_rdecl));
+	}
+	
+	// else: extract all fields and create a flat llvm struct from them
+	const auto fields = CGT.get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+	std::vector<llvm::Type*> llvm_fields;
+	for(const auto& field : fields) {
+		llvm_fields.push_back(CGT.ConvertType(field.type));
+	}
+	
+	// TODO: only create once?
+	const std::string name = "struct.floor.flat." + cxx_rdecl->getName().str() + ".packed";
+	auto ret = llvm::StructType::create(llvm_fields, name, true); // always make this packed
+	ret->setGraphicsReturnType(); // fix up alignment/sizes/offsets
+	CGT.create_flattened_cg_layout(cxx_rdecl, ret, fields); // create corresponding flattend CGRecordLayout
+	return ret;
+}
+
 void CodeGenModule::EmitGlobalFunctionDefinition(GlobalDecl GD,
                                                  llvm::GlobalValue *GV) {
   const auto *D = cast<FunctionDecl>(GD.getDecl());
 
   // Compute the function info and LLVM type.
   const CGFunctionInfo &FI = getTypes().arrangeGlobalDeclaration(GD);
+  if (D && (getLangOpts().Metal || getLangOpts().Vulkan)) {
+    // TODO: do this properly in CGCall
+    // if this is a vertex/fragment shader function and the return type is a struct/aggregate,
+    // fully expand/flatten all types within (i.e. structs and arrays to scalars, keep existing scalars)
+    if ((D->hasAttr<GraphicsVertexShaderAttr>() ||
+         D->hasAttr<GraphicsFragmentShaderAttr>()) &&
+        FI.getReturnType()->isStructureOrClassType()) {
+      auto& retInfo = const_cast<ABIArgInfo&>(FI.getReturnInfo());
+      retInfo.setCoerceToType(GraphicsExpandReturnType(FI.getReturnType(), retInfo.getCoerceToType(), getTypes()));
+    }
+  }
   llvm::FunctionType *Ty = getTypes().GetFunctionType(FI);
 
   // Get or create the prototype for the function.
@@ -4070,8 +4229,7 @@ void CodeGenModule::EmitAliasDefinition(GlobalDecl GD) {
     // Remove it and replace uses of it with the alias.
     GA->takeName(Entry);
 
-    Entry->replaceAllUsesWith(llvm::ConstantExpr::getBitCast(GA,
-                                                          Entry->getType()));
+    Entry->replaceAllUsesWith(llvm::ConstantExpr::getPointerBitCastOrAddrSpaceCast(GA, Entry->getType()));
     Entry->eraseFromParent();
   } else {
     GA->setName(MangledName);
@@ -5327,6 +5485,73 @@ void CodeGenModule::EmitOMPThreadPrivateDecl(const OMPThreadPrivateDecl *D) {
   }
 }
 
+llvm::Constant*
+CodeGenModule::createIntToSamplerConversion(const Expr *E,
+                                            CodeGenFunction *CGF,
+                                            llvm::GlobalVariable *InsertBefore,
+                                            StringRef Name) {
+  ConstantEmitter emitter(*this, CGF);
+  llvm::Constant *C = emitter.tryEmitForInitializer(E, E->getType().getAddressSpace(),
+                                                    E->getType());
+  assert(C && "Sampler must be initialized by constant");
+  assert(isa<llvm::ConstantInt>(C) && "Sampler must be initialized by integer");
+  if (!getLangOpts().CLSamplerOpaque)
+    return C;
+
+  llvm::StructType*
+    ConstSamplerTy = TheModule.getTypeByName("spirv.ConstantSampler");
+  if (!ConstSamplerTy ) {
+    llvm::Type* Elements[] = {Int32Ty, Int32Ty, Int32Ty};
+    ConstSamplerTy = llvm::StructType::create(VMContext, Elements,
+                                              "spirv.ConstantSampler");
+  }
+  const llvm::ConstantInt *CI = static_cast<llvm::ConstantInt*>(C);
+  const uint64_t SamplerValue = CI->getValue().getZExtValue();
+  // 32-bit value of sampler's initializer is interpreted as
+  // bit-field with the following structure:
+  // |unspecified|Filter|Addressing Mode| Normalized Coords|
+  // |31        6|5    4|3             1|                 0|
+  // This structure corresponds to values of sampler properties from opencl.h
+  // Mapping these bits to values defined by SPIR-V specification.
+  unsigned NormalizedCoords = 0x01 & SamplerValue;
+  unsigned AddressingMode  = (0x0E & SamplerValue) >> 1;
+  unsigned FilterMode      = (0x30 & SamplerValue) >> 4;
+  // In SPIR sampler's filter bits are defined as the following
+  // #define CLK_FILTER_NEAREST 0x10
+  // #define CLK_FILTER_LINEAR 0x20
+  // corresponding to 1 and 2 in bits 4-5.
+  // SPIR-V defines sampler filter mode enum as: nearest=0, linear=1,
+  // Therefore, to convert FilterMode from SPIR to SPIR-V,
+  // FilterMode value must be decremented
+  if (FilterMode == 1 || FilterMode == 2)
+    --FilterMode;
+   else
+    getDiags().Report(Context.getFullLoc(E->getBeginLoc()),
+      diag::warn_sampler_initializer_invalid_bits) << "Filter Mode";
+  if (AddressingMode > 4)
+    getDiags().Report(Context.getFullLoc(E->getBeginLoc()),
+      diag::warn_sampler_initializer_invalid_bits) << "Addressing Mode";
+
+  llvm::Constant *Initializer = llvm::ConstantStruct::get(ConstSamplerTy,
+    llvm::ConstantInt::get(Int32Ty, AddressingMode),
+    llvm::ConstantInt::get(Int32Ty, NormalizedCoords),
+    llvm::ConstantInt::get(Int32Ty, FilterMode));
+  llvm::StructType*
+    SamplerTy = TheModule.getTypeByName("spirv.Sampler");
+  if(!SamplerTy)
+    SamplerTy = llvm::StructType::create(VMContext, "spirv.Sampler");
+
+  unsigned AS = Context.getTargetAddressSpace(LangAS::opencl_constant);
+  llvm::GlobalVariable *GV =
+    new llvm::GlobalVariable(TheModule, ConstSamplerTy, true,
+                             llvm::GlobalVariable::InternalLinkage,
+                             Initializer, Name + ".sampler.init", InsertBefore,
+                             llvm::GlobalVariable::NotThreadLocal, AS);
+
+  return llvm::ConstantExpr::getBitCast(GV,
+                                        llvm::PointerType::get(SamplerTy, AS));
+}
+
 llvm::Metadata *
 CodeGenModule::CreateMetadataIdentifierImpl(QualType T, MetadataTypeMap &Map,
                                             StringRef Suffix) {
@@ -5485,13 +5710,3 @@ llvm::SanitizerStatReport &CodeGenModule::getSanStats() {
 
   return *SanStats;
 }
-llvm::Value *
-CodeGenModule::createOpenCLIntToSamplerConversion(const Expr *E,
-                                                  CodeGenFunction &CGF) {
-  llvm::Constant *C = ConstantEmitter(CGF).emitAbstract(E, E->getType());
-  auto SamplerT = getOpenCLRuntime().getSamplerType(E->getType().getTypePtr());
-  auto FTy = llvm::FunctionType::get(SamplerT, {C->getType()}, false);
-  return CGF.Builder.CreateCall(CreateRuntimeFunction(FTy,
-                                "__translate_sampler_initializer"),
-                                {C});
-}
diff --git a/lib/CodeGen/CodeGenModule.h b/lib/CodeGen/CodeGenModule.h
index 0f6c3bec9e..fb9679acce 100644
--- a/lib/CodeGen/CodeGenModule.h
+++ b/lib/CodeGen/CodeGenModule.h
@@ -491,6 +491,8 @@ private:
   llvm::Type *BlockDescriptorType = nullptr;
   llvm::Type *GenericBlockLiteralType = nullptr;
 
+  llvm::DenseMap<const VarDecl*, llvm::Constant *> OCLGlobalBlockFunctions;
+
   struct {
     int GlobalUniqueCount;
   } Block;
@@ -879,6 +881,11 @@ public:
   /// isn't already emitted.
   void setAddrOfGlobalBlock(const BlockExpr *BE, llvm::Constant *Addr);
 
+  /// 
+  llvm::Constant *GetOCLGlobalBlockFunction(const VarDecl *D) {
+    return OCLGlobalBlockFunctions[D];
+  }
+
   /// Return a pointer to a constant CFString object for the given string.
   ConstantAddress GetAddrOfConstantCFString(const StringLiteral *Literal);
 
@@ -1157,6 +1164,12 @@ public:
   /// Emit all the global annotations.
   void EmitGlobalAnnotations();
 
+  /// Emit OpenCL related annotations.
+  void EmitOCLAnnotations();
+
+  /// Emit OCL compiler options
+  void EmitOCLBuildOptions();
+
   /// Emit an annotation string.
   llvm::Constant *EmitAnnotationString(StringRef Str);
 
@@ -1282,8 +1295,11 @@ public:
 
   llvm::SanitizerStatReport &getSanStats();
 
-  llvm::Value *
-  createOpenCLIntToSamplerConversion(const Expr *E, CodeGenFunction &CGF);
+  llvm::Constant*
+  createIntToSamplerConversion(const Expr *E,
+                               CodeGenFunction *CGF,
+                               llvm::GlobalVariable *InsertBefore = nullptr,
+                               StringRef Name = "");
 
   /// Get target specific null pointer.
   /// \param T is the LLVM type of the null pointer.
@@ -1446,6 +1462,10 @@ private:
 
   llvm::Metadata *CreateMetadataIdentifierImpl(QualType T, MetadataTypeMap &Map,
                                                StringRef Suffix);
+
+  // Get a metadata vector containing the build options
+  llvm::SmallVector<llvm::Metadata *, 5> getBuildOptions();
+
 };
 
 }  // end namespace CodeGen
diff --git a/lib/CodeGen/CodeGenTypes.cpp b/lib/CodeGen/CodeGenTypes.cpp
index 2acf1ac161..c95df50b3c 100644
--- a/lib/CodeGen/CodeGenTypes.cpp
+++ b/lib/CodeGen/CodeGenTypes.cpp
@@ -385,6 +385,10 @@ llvm::Type *CodeGenTypes::ConvertType(QualType T) {
 
   const Type *Ty = T.getTypePtr();
 
+  // intercept image arrays before RT conversion
+  if (Ty->isArrayImageType(true))
+    return ConvertArrayImageType(Ty);
+
   // RecordTypes are cached and processed specially.
   if (const RecordType *RT = dyn_cast<RecordType>(Ty))
     return ConvertRecordDeclType(RT->getDecl());
@@ -636,6 +640,10 @@ llvm::Type *CodeGenTypes::ConvertType(QualType T) {
   }
 
   case Type::BlockPointer: {
+    if (Context.getLangOpts().OpenCL) {
+      ResultType = CGM.getOpenCLRuntime().getBlockType();
+      break;
+    }
     const QualType FTy = cast<BlockPointerType>(Ty)->getPointeeType();
     llvm::Type *PointeeType = ConvertTypeForMem(FTy);
     unsigned AS = Context.getTargetAddressSpace(FTy);
@@ -756,9 +764,71 @@ llvm::StructType *CodeGenTypes::ConvertRecordDeclType(const RecordDecl *RD) {
   return Ty;
 }
 
+llvm::Type *CodeGenTypes::ConvertArrayImageType(const Type* Ty) {
+  // ptr to array of images
+  if(Ty->isPointerType() &&
+     Ty->getPointeeType()->isArrayType() &&
+     Ty->getPointeeType()->getArrayElementTypeNoTypeQual()->isImageType()) {
+    return llvm::PointerType::get(ConvertArrayImageType(Ty->getPointeeType().getTypePtr()), 0);
+  }
+	
+  // simple C-style array that contains an image type
+  if(Ty->isArrayType() &&
+     Ty->getArrayElementTypeNoTypeQual()->isImageType()) {
+    const ConstantArrayType *CAT = Context.getAsConstantArrayType(QualType(Ty, 0));
+    const auto elem_type = CAT->getElementType();
+    if(elem_type->isImageType()) {
+      return llvm::ArrayType::get(ConvertType(elem_type), CAT->getSize().getZExtValue());
+    } else if(elem_type->isAggregateImageType()) {
+      // must be an aggregate image with exactly one image
+      const auto agg_img_type = elem_type->getAsCXXRecordDecl();
+      auto agg_img_fields = get_aggregate_scalar_fields(agg_img_type, agg_img_type, false, false,
+                                                        true /* TODO */);
+      if(agg_img_fields.size() != 1) return nullptr;
+      return llvm::ArrayType::get(ConvertType(agg_img_fields[0].type), CAT->getSize().getZExtValue());
+    }
+    assert(false && "invalid array of images type");
+  }
+
+  // must be struct or class, union is not allowed
+  if(!Ty->isStructureOrClassType()) return nullptr;
+
+  // must be a cxx rdecl
+  const auto decl = Ty->getAsCXXRecordDecl();
+  if(!decl) return nullptr;
+
+  // must have definition
+  if(!decl->hasDefinition()) return nullptr;
+
+  // must have exactly one field
+  const auto field_count = std::distance(decl->field_begin(), decl->field_end());
+  if(field_count != 1) return nullptr;
+
+  // field must be an array
+  const QualType arr_field_type = decl->field_begin()->getType();
+  const ConstantArrayType *CAT = Context.getAsConstantArrayType(arr_field_type);
+  if(!CAT) return nullptr;
+
+  // must be an aggregate image with exactly one image
+  const auto agg_img_type = CAT->getElementType()->getAsCXXRecordDecl();
+  auto agg_img_fields = get_aggregate_scalar_fields(agg_img_type, agg_img_type, false, false,
+                                                    true /* TODO */);
+  if(agg_img_fields.size() != 1) return nullptr;
+
+  // got everything we need
+  return llvm::ArrayType::get(ConvertType(agg_img_fields[0].type), CAT->getSize().getZExtValue());
+}
+
 /// getCGRecordLayout - Return record layout info for the given record decl.
 const CGRecordLayout &
-CodeGenTypes::getCGRecordLayout(const RecordDecl *RD) {
+CodeGenTypes::getCGRecordLayout(const RecordDecl *RD, llvm::Type* struct_type) {
+  // check if there is a flattened layout for this llvm struct type,
+  // return it if so, otherwise continue as usual
+  if (struct_type != nullptr) {
+    const auto flat_layout = FlattenedCGRecordLayouts.lookup(struct_type);
+    if(flat_layout) return *flat_layout;
+  }
+
   const Type *Key = Context.getTagDeclType(RD).getTypePtr();
 
   const CGRecordLayout *Layout = CGRecordLayouts.lookup(Key);
@@ -810,3 +880,230 @@ bool CodeGenTypes::isZeroInitializable(QualType T) {
 bool CodeGenTypes::isZeroInitializable(const RecordDecl *RD) {
   return getCGRecordLayout(RD).isZeroInitializable();
 }
+
+//
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  RecordDecl::field_iterator field_iter) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalFieldName(*field_iter, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  const std::string& name,
+												  const clang::QualType type) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalGeneric(name, type, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+
+clang::QualType CodeGenTypes::get_compat_vector_type(const CXXRecordDecl* decl) const {
+	const auto fields = get_aggregate_scalar_fields(decl, decl, true, false, true);
+	
+	const auto vec_size = fields.size();
+	if(vec_size < 1 || vec_size > 4) {
+		assert(false && "invalid vector size (must be >= 1 && <= 4)");
+		return Context.VoidTy;
+	}
+	
+	const auto elem_type = fields[0].type.getUnqualifiedType();
+	for(size_t i = 1; i < vec_size; ++i) {
+		if(fields[i].type.getUnqualifiedType() != elem_type) {
+			assert(false && "all vector-compat element types must be equal");
+			return Context.VoidTy;
+		}
+	}
+	
+	return Context.getExtVectorType(elem_type, vec_size);
+}
+
+void CodeGenTypes::aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+													 const CXXRecordDecl* parent_decl,
+													 const ConstantArrayType* CAT,
+													 const AttrVec* attrs,
+													 const FieldDecl* parent_field_decl,
+													 const std::string& name,
+													 const bool expand_array_image,
+													 std::vector<CodeGenTypes::aggregate_scalar_entry>& ret) const {
+	if(expand_array_image ||
+	   !(CAT->getElementType()->isAggregateImageType() ||
+		 CAT->getElementType()->isImageType())) {
+	const auto count = CAT->getSize().getZExtValue();
+	const auto ET = CAT->getElementType();
+	if(const auto arr_rdecl = ET->getAsCXXRecordDecl()) {
+			auto contained_ret = get_aggregate_scalar_fields(root_decl, arr_rdecl, false, false, expand_array_image);
+		for(auto& entry : contained_ret) {
+			entry.parents.push_back(parent_decl);
+		}
+		for(uint64_t i = 0; i < count; ++i) {
+			ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+		}
+	}
+	else if(ET->isArrayType()) {
+		const auto aoa_decl = dyn_cast<ConstantArrayType>(ET->getAsArrayTypeUnsafe());
+		if(aoa_decl) {
+			for(uint64_t i = 0; i < count; ++i) {
+				const auto idx_str = "_" + std::to_string(i);
+					aggregate_scalar_fields_add_array(root_decl, parent_decl, aoa_decl, attrs, parent_field_decl,
+													  name + idx_str, expand_array_image, ret);
+			}
+		}
+		else {
+			// TODO: error
+		}
+	}
+	else {
+		for(uint64_t i = 0; i < count; ++i) {
+			const auto idx_str = "_" + std::to_string(i);
+			ret.push_back(aggregate_scalar_entry {
+				ET,
+				name + idx_str,
+				aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), name + idx_str, ET),
+				attrs,
+					parent_field_decl,
+				{ parent_decl },
+				false,
+				false
+			});
+		}
+	}
+}
+	else {
+		// directly add an array entry
+		ret.push_back(aggregate_scalar_entry {
+			clang::QualType(CAT, 0),
+			name,
+			aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), name, clang::QualType(CAT, 0)),
+			attrs,
+			parent_field_decl,
+			{ parent_decl },
+			false,
+			false
+		});
+	}
+}
+
+std::vector<CodeGenTypes::aggregate_scalar_entry>
+CodeGenTypes::get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+										  const CXXRecordDecl* decl,
+										  const bool ignore_root_vec_compat,
+										  const bool ignore_bases,
+										  const bool expand_array_image) const {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	// if the root decl is a direct compat vector, return it directly
+	if(!ignore_root_vec_compat &&
+	   decl->hasAttr<VectorCompatAttr>()) {
+		return {
+			aggregate_scalar_entry {
+				get_compat_vector_type(decl),
+				"",
+				"",
+				&decl->getAttrs(),
+				nullptr,
+				{},
+				true,
+				false
+			}
+		};
+	}
+	
+	//
+	std::vector<aggregate_scalar_entry> ret;
+	
+	// iterate over / recurse into all bases
+	if(!ignore_bases) {
+		for(const auto& base : decl->bases()) {
+			auto base_ret = get_aggregate_scalar_fields(root_decl, base.getType()->getAsCXXRecordDecl(),
+														false, false, expand_array_image);
+			for(auto& elem : base_ret) {
+				elem.is_in_base = true;
+			}
+			if(!base_ret.empty()) {
+				ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+			}
+		}
+	}
+	
+	// TODO/NOTE: make sure attrs are correctly forwarded/inherited/passed-through
+	const auto add_field = [this, &root_decl, &decl, &expand_array_image, &ret](RecordDecl::field_iterator field_iter) {
+		if(const auto rdecl = field_iter->getType()->getAsCXXRecordDecl()) {
+			if(rdecl->hasAttr<VectorCompatAttr>() ||
+			   field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+				const auto vec_type = get_compat_vector_type(rdecl);
+				
+				if(field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+					const auto as_vec_type = vec_type->getAs<ExtVectorType>();
+					if(as_vec_type->getNumElements() != 4 ||
+					   !as_vec_type->getElementType()->isFloatingType()) {
+						// TODO: error!
+					}
+				}
+				
+				ret.push_back(aggregate_scalar_entry {
+					vec_type,
+					field_iter->getName().str(),
+					aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(),
+												   field_iter->getName().str(), vec_type),
+					field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+					*field_iter,
+					{ decl },
+					true,
+					false
+				});
+			}
+			else {
+				auto contained_ret = get_aggregate_scalar_fields(root_decl, rdecl,
+																 false, false, expand_array_image);
+				for(auto& entry : contained_ret) {
+					entry.parents.push_back(decl);
+				}
+				if(!contained_ret.empty()) {
+					ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+				}
+			}
+		}
+		else if(field_iter->getType()->isArrayType()) {
+			const auto arr_decl = dyn_cast<ConstantArrayType>(field_iter->getType()->getAsArrayTypeUnsafe());
+			if(arr_decl) {
+				aggregate_scalar_fields_add_array(root_decl, decl, arr_decl,
+												  field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+												  *field_iter, field_iter->getName().str(), expand_array_image, ret);
+			}
+			else {
+				// TODO: error
+			}
+		}
+		else {
+			ret.push_back(aggregate_scalar_entry {
+				field_iter->getType(),
+				field_iter->getName().str(),
+				aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), field_iter),
+				field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+				*field_iter,
+				{ decl },
+				false,
+				false
+			});
+		}
+	};
+	
+	if(!decl->isUnion()) {
+		// iterate over all fields/members
+		for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+			add_field(iter);
+		}
+	}
+	else {
+		// for unions: only use the first field
+		add_field(decl->field_begin());
+	}
+	
+	return ret;
+}
diff --git a/lib/CodeGen/CodeGenTypes.h b/lib/CodeGen/CodeGenTypes.h
index 8e344e91b8..f782cce3f8 100644
--- a/lib/CodeGen/CodeGenTypes.h
+++ b/lib/CodeGen/CodeGenTypes.h
@@ -137,6 +137,10 @@ class CodeGenTypes {
   /// Maps clang struct type with corresponding record layout info.
   llvm::DenseMap<const Type*, CGRecordLayout *> CGRecordLayouts;
 
+  /// This maps special flattened llvm struct types
+  /// with the corresponding record layout info.
+  llvm::DenseMap<const llvm::Type*, CGRecordLayout *> FlattenedCGRecordLayouts;
+
   /// Contains the LLVM IR type for any converted RecordDecl.
   llvm::DenseMap<const Type*, llvm::StructType *> RecordDeclTypes;
 
@@ -218,7 +222,8 @@ public:
   /// and/or incomplete argument types, this will return the opaque type.
   llvm::Type *GetFunctionTypeForVTable(GlobalDecl GD);
 
-  const CGRecordLayout &getCGRecordLayout(const RecordDecl*);
+  const CGRecordLayout &getCGRecordLayout(const RecordDecl*,
+										  llvm::Type* struct_type = nullptr);
 
   /// UpdateCompletedType - When we find the full definition for a TagDecl,
   /// replace the 'opaque' type we previously made for it if applicable.
@@ -343,15 +348,79 @@ public:
   void addRecordTypeName(const RecordDecl *RD, llvm::StructType *Ty,
                          StringRef suffix);
 
+  //
+  struct aggregate_scalar_entry {
+	clang::QualType type;
+	std::string name;
+	std::string mangled_name;
+    const AttrVec* attrs;
+	// NOTE: this is nullptr for non-fields!
+    const FieldDecl* field_decl;
+    std::vector<const CXXRecordDecl*> parents;
+    bool compat_vector;
+    bool is_in_base;
+	
+	template <typename SpecificAttr>
+	bool hasAttr() const {
+		if(attrs == nullptr) return false;
+		return hasSpecificAttr<SpecificAttr>(*attrs);
+	}
+	
+	template <typename SpecificAttr>
+	SpecificAttr* getAttr() const {
+		if(attrs == nullptr) return nullptr;
+		return getSpecificAttr<SpecificAttr>(*attrs);
+	}
+  };
+
+  // will recurse through the specified class/struct decl, its base classes,
+  // all its contained class/struct/union decls, all its contained arrays,
+  // returning a vector of all contained/scalarized fields + info
+  // NOTE: for unions, only the first field will be considered
+  // NOTE: this also transform/converts [[vector_compat]] types to clang vector types
+  std::vector<aggregate_scalar_entry> get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+                                                                  const CXXRecordDecl* decl,
+																  const bool ignore_root_vec_compat = false,
+																  const bool ignore_bases = false,
+																  const bool expand_array_image = true) const;
+
+  // returns the corresponding clang vector type for a [[vector_compat]] aggregate
+  clang::QualType get_compat_vector_type(const CXXRecordDecl* decl) const;
+
+  //
+  void create_flattened_cg_layout(const CXXRecordDecl* decl, llvm::StructType* type,
+								  const std::vector<aggregate_scalar_entry>& fields);
+
+  // for all entry functions/points: handle the function type -> add implicit internal args
+  // "FTy" is optional and if specified will update the function type
+  // "Args" is optional and if specified, will add all additional args to this the specified list
+  void handleMetalVulkanEntryFunction(CanQualType* FTy, FunctionArgList* ArgList, const FunctionDecl* FD);
+
+  // returns the amount of implicit internal args that are added for the specified FunctionDecl
+  uint32_t getMetalVulkanImplicitArgCount(const FunctionDecl* FD) const;
+
+private:
+  // helper function for get_aggregate_scalar_fields
+  void aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+										 const CXXRecordDecl* parent_decl,
+                                         const ConstantArrayType* CAT,
+                                         const AttrVec* attrs,
+										 const FieldDecl* parent_field_decl,
+                                         const std::string& name,
+										 const bool expand_array_image,
+                                         std::vector<CodeGenTypes::aggregate_scalar_entry>& ret) const;
 
 public:  // These are internal details of CGT that shouldn't be used externally.
   /// ConvertRecordDeclType - Lay out a tagged decl type like struct or union.
   llvm::StructType *ConvertRecordDeclType(const RecordDecl *TD);
 
+  llvm::Type *ConvertArrayImageType(const Type* Ty);
+
   /// getExpandedTypes - Expand the type \arg Ty into the LLVM
   /// argument types it would be passed as. See ABIArgInfo::Expand.
   void getExpandedTypes(QualType Ty,
-                        SmallVectorImpl<llvm::Type *>::iterator &TI);
+                        SmallVectorImpl<llvm::Type *>::iterator &TI,
+                        const CallingConv CC);
 
   /// IsZeroInitializable - Return whether a type can be
   /// zero-initialized (in the C++ sense) with an LLVM zeroinitializer.
diff --git a/lib/CodeGen/TargetInfo.cpp b/lib/CodeGen/TargetInfo.cpp
index ae080f5bbd..bd286e5243 100644
--- a/lib/CodeGen/TargetInfo.cpp
+++ b/lib/CodeGen/TargetInfo.cpp
@@ -72,11 +72,15 @@ static void AssignToArrayRange(CodeGen::CGBuilderTy &Builder,
   }
 }
 
-static bool isAggregateTypeForABI(QualType T) {
+bool TargetCodeGenInfo::isAggregateTypeForABI(QualType T) {
   return !CodeGenFunction::hasScalarEvaluationKind(T) ||
          T->isMemberFunctionPointerType();
 }
 
+static bool isAggregateImageType(QualType T) {
+  return CodeGenFunction::hasAggregateEvaluationKind(T) && T->isAggregateImageType();
+}
+
 ABIArgInfo
 ABIInfo::getNaturalAlignIndirect(QualType Ty, bool ByRef, bool Realign,
                                  llvm::Type *Padding) const {
@@ -95,6 +99,22 @@ Address ABIInfo::EmitMSVAArg(CodeGenFunction &CGF, Address VAListAddr,
   return Address::invalid();
 }
 
+static ABIArgInfo classifyOpenCL(QualType Ty) {
+  if (Ty->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  if (Ty->isRecordType())
+    return ABIArgInfo::getIndirect(CharUnits::Zero(), /*ByVal=*/false);
+
+  if (Ty->isPromotableIntegerType())
+    return ABIArgInfo::getExtend(Ty);
+
+  return ABIArgInfo::getDirect();
+}
+
 ABIInfo::~ABIInfo() {}
 
 /// Does the given lowering require more than the given number of
@@ -420,7 +440,7 @@ TargetCodeGenInfo::getDependentLibraryOption(llvm::StringRef Lib,
 unsigned TargetCodeGenInfo::getOpenCLKernelCallingConv() const {
   // OpenCL kernels are called via an explicit runtime API with arguments
   // set with clSetKernelArg(), not as normal sub-functions.
-  // Return SPIR_KERNEL by default as the kernel calling convention to
+  // Return FLOOR_KERNEL by default as the kernel calling convention to
   // ensure the fingerprint is fixed such way that each OpenCL argument
   // gets one matching argument in the produced kernel function argument
   // list to enable feasible implementation of clSetKernelArg() with
@@ -428,7 +448,7 @@ unsigned TargetCodeGenInfo::getOpenCLKernelCallingConv() const {
   // clSetKernelArg() might break depending on the target-specific
   // conventions; different targets might split structs passed as values
   // to multiple function arguments etc.
-  return llvm::CallingConv::SPIR_KERNEL;
+  return llvm::CallingConv::FLOOR_KERNEL;
 }
 
 llvm::Constant *TargetCodeGenInfo::getNullPointer(const CodeGen::CodeGenModule &CGM,
@@ -583,7 +603,7 @@ static const Type *isSingleElementStruct(QualType T, ASTContext &Context) {
       FT = AT->getElementType();
     }
 
-    if (!isAggregateTypeForABI(FT)) {
+    if (!TargetCodeGenInfo::isAggregateTypeForABI(FT)) {
       Found = FT.getTypePtr();
     } else {
       Found = isSingleElementStruct(FT, Context);
@@ -680,9 +700,12 @@ public:
 };
 
 ABIArgInfo DefaultABIInfo::classifyArgumentType(QualType Ty) const {
+  if (isAggregateImageType(Ty))
+    return ABIArgInfo::getExpand();
+
   Ty = useFirstFieldIfTransparentUnion(Ty);
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // passed by value.
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
@@ -703,7 +726,7 @@ ABIArgInfo DefaultABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVoidType())
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return getNaturalAlignIndirect(RetTy);
 
   // Treat an enum type as its underlying type.
@@ -762,7 +785,7 @@ public:
 ABIArgInfo WebAssemblyABIInfo::classifyArgumentType(QualType Ty) const {
   Ty = useFirstFieldIfTransparentUnion(Ty);
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // passed by value.
     if (auto RAA = getRecordArgABI(Ty, getCXXABI()))
@@ -782,7 +805,7 @@ ABIArgInfo WebAssemblyABIInfo::classifyArgumentType(QualType Ty) const {
 }
 
 ABIArgInfo WebAssemblyABIInfo::classifyReturnType(QualType RetTy) const {
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // returned by value.
     if (!getRecordArgABI(RetTy, getCXXABI())) {
@@ -855,7 +878,7 @@ Address PNaClABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
 
 /// Classify argument of given type \p Ty.
 ABIArgInfo PNaClABIInfo::classifyArgumentType(QualType Ty) const {
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
     return getNaturalAlignIndirect(Ty);
@@ -876,7 +899,7 @@ ABIArgInfo PNaClABIInfo::classifyReturnType(QualType RetTy) const {
     return ABIArgInfo::getIgnore();
 
   // In the PNaCl ABI we always return records/structures on the stack.
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return getNaturalAlignIndirect(RetTy);
 
   // Treat an enum type as its underlying type.
@@ -1382,7 +1405,7 @@ ABIArgInfo X86_32ABIInfo::classifyReturnType(QualType RetTy,
     return ABIArgInfo::getDirect();
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     if (const RecordType *RT = RetTy->getAs<RecordType>()) {
       // Structures with flexible arrays are always indirect.
       if (RT->getDecl()->hasFlexibleArrayMember())
@@ -1552,7 +1575,7 @@ bool X86_32ABIInfo::shouldAggregateUseDirect(QualType Ty, CCState &State,
   // On Windows, aggregates other than HFAs are never passed in registers, and
   // they do not consume register slots. Homogenous floating-point aggregates
   // (HFAs) have already been dealt with at this point.
-  if (IsWin32StructABI && isAggregateTypeForABI(Ty))
+  if (IsWin32StructABI && TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return false;
 
   NeedsPadding = false;
@@ -1630,7 +1653,7 @@ ABIArgInfo X86_32ABIInfo::classifyArgumentType(QualType Ty,
     return getIndirectResult(Ty, /*ByVal=*/false, State);
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Structures with flexible arrays are always indirect.
     // FIXME: This should not be byval!
     if (RT && RT->getDecl()->hasFlexibleArrayMember())
@@ -1759,6 +1782,19 @@ void X86_32ABIInfo::computeVectorCallArgs(CGFunctionInfo &FI, CCState &State,
 }
 
 void X86_32ABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  QualType RetTy = FI.getReturnType();
+
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL classify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(RetTy);
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
+
   CCState State(FI.getCallingConvention());
   if (IsMCUABI)
     State.FreeRegs = 3;
@@ -2859,7 +2895,7 @@ void X86_64ABIInfo::classify(QualType Ty, uint64_t OffsetBase,
 ABIArgInfo X86_64ABIInfo::getIndirectReturnResult(QualType Ty) const {
   // If this is a scalar LLVM value then assume LLVM will pass it in the right
   // place naturally.
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -2892,7 +2928,7 @@ ABIArgInfo X86_64ABIInfo::getIndirectResult(QualType Ty,
   // the argument in the free register. This does not seem to happen currently,
   // but this code would be much safer if we could mark the argument with
   // 'onstack'. See PR12193.
-  if (!isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -3538,6 +3574,18 @@ ABIArgInfo X86_64ABIInfo::classifyRegCallStructType(QualType Ty,
 }
 
 void X86_64ABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  QualType RetTy = FI.getReturnType();
+
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL classify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(RetTy);
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
 
   const unsigned CallingConv = FI.getCallingConvention();
   // It is possible to force Win64 calling convention on any x86_64 target by
@@ -4025,6 +4073,17 @@ void WinX86_64ABIInfo::computeInfo(CGFunctionInfo &FI) const {
     FI.getReturnInfo() = classify(FI.getReturnType(), FreeSSERegs, true,
                                   IsVectorCall, IsRegCall);
 
+  if (getContext().getLangOpts().OpenCL) {
+    // Use OpenCL classify to prevent coercing
+    FI.getReturnInfo() = classifyOpenCL(FI.getReturnType());
+
+    for (CGFunctionInfo::arg_iterator it = FI.arg_begin(), ie = FI.arg_end();
+         it != ie; ++it)
+      it->info= classifyOpenCL(it->type);
+
+    return;
+  }
+
   if (IsVectorCall) {
     // We can use up to 6 SSE register parameters with vectorcall.
     FreeSSERegs = 6;
@@ -4049,7 +4108,7 @@ Address WinX86_64ABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
 
   // MS x64 ABI requirement: "Any argument that doesn't fit in 8 bytes, or is
   // not 1, 2, 4, or 8 bytes, must be passed by reference."
-  if (isAggregateTypeForABI(Ty) || Ty->isMemberPointerType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) || Ty->isMemberPointerType()) {
     uint64_t Width = getContext().getTypeSize(Ty);
     IsIndirect = Width > 64 || !llvm::isPowerOf2_64(Width);
   }
@@ -4508,7 +4567,7 @@ CharUnits PPC64_SVR4_ABIInfo::getParamTypeAlignment(QualType Ty) const {
   const Type *Base = nullptr;
   uint64_t Members = 0;
   if (!AlignAsType && Kind == ELFv2 &&
-      isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
+      TargetCodeGenInfo::isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
     AlignAsType = Base;
 
   // With special case aggregates, only vector base types need alignment.
@@ -4523,7 +4582,7 @@ CharUnits PPC64_SVR4_ABIInfo::getParamTypeAlignment(QualType Ty) const {
 
   // Otherwise, we only need alignment for any aggregate type that
   // has an alignment requirement of >= 16 bytes.
-  if (isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128) {
     if (HasQPX && getContext().getTypeAlign(Ty) >= 256)
       return CharUnits::fromQuantity(32);
     return CharUnits::fromQuantity(16);
@@ -4688,7 +4747,7 @@ PPC64_SVR4_ABIInfo::classifyArgumentType(QualType Ty) const {
     }
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
 
@@ -4760,7 +4819,7 @@ PPC64_SVR4_ABIInfo::classifyReturnType(QualType RetTy) const {
     }
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // ELFv2 homogeneous aggregates are returned as array types.
     const Type *Base = nullptr;
     uint64_t Members = 0;
@@ -5073,7 +5132,7 @@ ABIArgInfo AArch64ABIInfo::classifyArgumentType(QualType Ty) const {
     return getNaturalAlignIndirect(Ty, /*ByVal=*/false);
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -5149,7 +5208,7 @@ ABIArgInfo AArch64ABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 128)
     return getNaturalAlignIndirect(RetTy);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -5413,7 +5472,7 @@ Address AArch64ABIInfo::EmitAAPCSVAArg(Address VAListAddr,
     // It might be right-aligned in its slot.
     CharUnits SlotSize = BaseAddr.getAlignment();
     if (CGF.CGM.getDataLayout().isBigEndian() && !IsIndirect &&
-        (IsHFA || !isAggregateTypeForABI(Ty)) &&
+        (IsHFA || !TargetCodeGenInfo::isAggregateTypeForABI(Ty)) &&
         TyInfo.first < SlotSize) {
       CharUnits Offset = SlotSize - TyInfo.first;
       BaseAddr = CGF.Builder.CreateConstInBoundsByteGEP(BaseAddr, Offset);
@@ -5467,7 +5526,7 @@ Address AArch64ABIInfo::EmitAAPCSVAArg(Address VAListAddr,
   // Write the new value of __stack for the next call to va_arg
   CGF.Builder.CreateStore(NewStack, stack_p);
 
-  if (CGF.CGM.getDataLayout().isBigEndian() && !isAggregateTypeForABI(Ty) &&
+  if (CGF.CGM.getDataLayout().isBigEndian() && !TargetCodeGenInfo::isAggregateTypeForABI(Ty) &&
       TyInfo.first < StackSlotSize) {
     CharUnits Offset = StackSlotSize - TyInfo.first;
     OnStackAddr = CGF.Builder.CreateConstInBoundsByteGEP(OnStackAddr, Offset);
@@ -5497,7 +5556,7 @@ Address AArch64ABIInfo::EmitDarwinVAArg(Address VAListAddr, QualType Ty,
   // The backend's lowering doesn't support va_arg for aggregates or
   // illegal vector types.  Lower VAArg here for these cases and use
   // the LLVM va_arg instruction for everything else.
-  if (!isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
     return EmitVAArgInstr(CGF, VAListAddr, Ty, ABIArgInfo::getDirect());
 
   CharUnits SlotSize = CharUnits::fromQuantity(8);
@@ -5829,7 +5888,7 @@ ABIArgInfo ARMABIInfo::classifyArgumentType(QualType Ty,
     return ABIArgInfo::getDirect(ResType);
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>()) {
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -6034,7 +6093,7 @@ ABIArgInfo ARMABIInfo::classifyReturnType(QualType RetTy,
     return ABIArgInfo::getDirect(ResType);
   }
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -6286,7 +6345,7 @@ ABIArgInfo NVPTXABIInfo::classifyArgumentType(QualType Ty) const {
     Ty = EnumTy->getDecl()->getIntegerType();
 
   // Return aggregates type as indirect by value
-  if (isAggregateTypeForABI(Ty))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return getNaturalAlignIndirect(Ty, /* byval */ true);
 
   return (Ty->isPromotableIntegerType() ? ABIArgInfo::getExtend(Ty)
@@ -6324,7 +6383,7 @@ void NVPTXTargetCodeGenInfo::setTargetAttributes(
   if (M.getLangOpts().OpenCL) {
     // Use OpenCL function attributes to check for kernel functions
     // By default, all functions are device functions
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL __kernel functions get kernel metadata
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
@@ -6338,7 +6397,7 @@ void NVPTXTargetCodeGenInfo::setTargetAttributes(
     // CUDA __global__ functions get a kernel metadata entry.  Since
     // __global__ functions cannot be called from the device, we do not
     // need to set the noinline attribute.
-    if (FD->hasAttr<CUDAGlobalAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
     }
@@ -6359,6 +6418,10 @@ void NVPTXTargetCodeGenInfo::setTargetAttributes(
           // Create !{<func-ref>, metadata !"minctasm", i32 <val>} node
           addNVVMMetadata(F, "minctasm", MinBlocks.getExtValue());
       }
+    } else if (const ReqdWorkGroupSizeAttr *reg_local_size = FD->getAttr<ReqdWorkGroupSizeAttr>()) {
+      addNVVMMetadata(F, "reqntidx", reg_local_size->getXDim());
+      addNVVMMetadata(F, "reqntidy", reg_local_size->getYDim());
+      addNVVMMetadata(F, "reqntidz", reg_local_size->getZDim());
     }
   }
 }
@@ -6384,6 +6447,207 @@ bool NVPTXTargetCodeGenInfo::shouldEmitStaticExternCAliases() const {
 }
 }
 
+//===----------------------------------------------------------------------===//
+// OpenCL/SPIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+class SPIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  SPIRTargetCodeGenInfo(CodeGen::CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new DefaultABIInfo(CGT)) {}
+  unsigned getOpenCLKernelCallingConv() const override;
+};
+
+} // End anonymous namespace.
+
+namespace clang {
+namespace CodeGen {
+void computeSPIRKernelABIInfo(CodeGenModule &CGM, CGFunctionInfo &FI) {
+  DefaultABIInfo SPIRABI(CGM.getTypes());
+  SPIRABI.computeInfo(FI);
+}
+}
+}
+
+unsigned SPIRTargetCodeGenInfo::getOpenCLKernelCallingConv() const {
+  return llvm::CallingConv::FLOOR_KERNEL;
+}
+
+
+//===----------------------------------------------------------------------===//
+// Metal/AIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class AIRABIInfo : public ABIInfo {
+public:
+  AIRABIInfo(CodeGenTypes &CGT) : ABIInfo(CGT) {}
+
+  ABIArgInfo classifyReturnType(QualType RetTy) const;
+  ABIArgInfo classifyArgumentType(QualType Ty) const;
+
+  void computeInfo(CGFunctionInfo &FI) const override;
+  Address EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                    QualType Ty) const override;
+};
+
+class AIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  AIRTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new AIRABIInfo(CGT)) {}
+};
+
+ABIArgInfo AIRABIInfo::classifyReturnType(QualType RetTy) const {
+  if (RetTy->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  // note: this is different from default ABI
+  if (!RetTy->isScalarType())
+    return ABIArgInfo::getDirect();
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
+    RetTy = EnumTy->getDecl()->getIntegerType();
+
+  return (RetTy->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend(RetTy) : ABIArgInfo::getDirect());
+}
+
+ABIArgInfo AIRABIInfo::classifyArgumentType(QualType Ty) const {
+  // CGT.getTarget() // TODO: native array image test
+  // direct array of images (not writable)
+  if (Ty->isArrayImageType(true))
+    return getNaturalAlignIndirect(Ty);
+
+  if (CodeGenFunction::hasAggregateEvaluationKind(Ty) &&
+      Ty->isStructureOrClassType()) {
+    return ABIArgInfo::getExpand();
+  }
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  return (Ty->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend(Ty) : ABIArgInfo::getDirect());
+}
+
+void AIRABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  // return type should never be indirect
+  // TODO: ... if the function is a kernel/vs/fs
+  FI.getReturnInfo() = classifyReturnType(FI.getReturnType());
+
+  for (auto &I : FI.arguments())
+    I.info = classifyArgumentType(I.type);
+
+  // Always honor user-specified calling convention.
+  if (FI.getCallingConvention() != llvm::CallingConv::C)
+    return;
+
+  FI.setEffectiveCallingConvention(getRuntimeCC());
+}
+
+Address AIRABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                              QualType Ty) const {
+  llvm_unreachable("AIR does not support varargs");
+}
+
+}
+
+//===----------------------------------------------------------------------===//
+// Vulkan/SPIR-V ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class VulkanABIInfo : public ABIInfo {
+public:
+  VulkanABIInfo(CodeGenTypes &CGT) : ABIInfo(CGT) {}
+
+  ABIArgInfo classifyReturnType(QualType RetTy, unsigned int CC) const;
+  ABIArgInfo classifyArgumentType(QualType Ty, unsigned int CC) const;
+
+  void computeInfo(CGFunctionInfo &FI) const override;
+  Address EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                    QualType Ty) const override;
+};
+
+class VulkanTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  VulkanTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new VulkanABIInfo(CGT)) {}
+};
+
+ABIArgInfo VulkanABIInfo::classifyReturnType(QualType RetTy, unsigned int CC) const {
+  if (RetTy->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  // note: this is different from default ABI
+  if (!RetTy->isScalarType())
+    return ABIArgInfo::getDirect();
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
+    RetTy = EnumTy->getDecl()->getIntegerType();
+
+  return (RetTy->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend(RetTy) : ABIArgInfo::getDirect());
+}
+
+ABIArgInfo VulkanABIInfo::classifyArgumentType(QualType Ty, unsigned int CC) const {
+  // direct array of images (not writable)
+  if (Ty->isArrayImageType(true))
+    return getNaturalAlignIndirect(Ty);
+
+  // all shader inputs must either be scalar or vector types, or arrays thereof
+  // -> expand all aggregates
+  if (CodeGenFunction::hasAggregateEvaluationKind(Ty) &&
+      Ty->isStructureOrClassType() &&
+      (CC == llvm::CallingConv::FLOOR_VERTEX ||
+       CC == llvm::CallingConv::FLOOR_FRAGMENT ||
+       CC == llvm::CallingConv::FLOOR_KERNEL)) {
+    return ABIArgInfo::getExpand();
+  }
+
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
+    // Records with non-trivial destructors/copy-constructors should not be
+    // passed by value.
+    if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
+      return getNaturalAlignIndirect(Ty, RAA == CGCXXABI::RAA_DirectInMemory);
+
+    return getNaturalAlignIndirect(Ty);
+  }
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  return (Ty->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend(Ty) : ABIArgInfo::getDirect());
+}
+
+void VulkanABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  FI.getReturnInfo() = classifyReturnType(FI.getReturnType(), FI.getCallingConvention());
+
+  for (auto &I : FI.arguments())
+    I.info = classifyArgumentType(I.type, FI.getCallingConvention());
+
+  // Always honor user-specified calling convention.
+  if (FI.getCallingConvention() != llvm::CallingConv::C)
+    return;
+
+  FI.setEffectiveCallingConvention(getRuntimeCC());
+}
+
+Address VulkanABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
+                                 QualType Ty) const {
+  llvm_unreachable("Vulkan/SPIR-V does not support varargs");
+}
+
+}
+
 //===----------------------------------------------------------------------===//
 // SystemZ ABI Implementation
 //===----------------------------------------------------------------------===//
@@ -6457,7 +6721,7 @@ bool SystemZABIInfo::isPromotableIntegerType(QualType Ty) const {
 bool SystemZABIInfo::isCompoundType(QualType Ty) const {
   return (Ty->isAnyComplexType() ||
           Ty->isVectorType() ||
-          isAggregateTypeForABI(Ty));
+          TargetCodeGenInfo::isAggregateTypeForABI(Ty));
 }
 
 bool SystemZABIInfo::isVectorArgumentType(QualType Ty) const {
@@ -6971,7 +7235,7 @@ MipsABIInfo::classifyArgumentType(QualType Ty, uint64_t &Offset) const {
   unsigned CurrOffset = llvm::alignTo(Offset, Align);
   Offset = CurrOffset + llvm::alignTo(TySize, Align * 8) / 8;
 
-  if (isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
     // Ignore empty aggregates.
     if (TySize == 0)
       return ABIArgInfo::getIgnore();
@@ -7056,7 +7320,7 @@ ABIArgInfo MipsABIInfo::classifyReturnType(QualType RetTy) const {
   if (!IsO32 && Size == 0)
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
     if (Size <= 128) {
       if (RetTy->isAnyComplexType())
         return ABIArgInfo::getDirect();
@@ -7244,7 +7508,7 @@ void TCETargetCodeGenInfo::setTargetAttributes(
   llvm::Function *F = cast<llvm::Function>(GV);
 
   if (M.getLangOpts().OpenCL) {
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL C Kernel functions are not subject to inlining
       F->addFnAttr(llvm::Attribute::NoInline);
       const ReqdWorkGroupSizeAttr *Attr = FD->getAttr<ReqdWorkGroupSizeAttr>();
@@ -7324,7 +7588,7 @@ void HexagonABIInfo::computeInfo(CGFunctionInfo &FI) const {
 }
 
 ABIArgInfo HexagonABIInfo::classifyArgumentType(QualType Ty) const {
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -7362,7 +7626,7 @@ ABIArgInfo HexagonABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 64)
     return getNaturalAlignIndirect(RetTy);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -7480,7 +7744,7 @@ ABIArgInfo LanaiABIInfo::classifyArgumentType(QualType Ty,
     }
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Structures with flexible arrays are always indirect.
     if (RT && RT->getDecl()->hasFlexibleArrayMember())
       return getIndirectResult(Ty, /*ByVal=*/true, State);
@@ -7615,7 +7879,7 @@ void AMDGPUABIInfo::computeInfo(CGFunctionInfo &FI) const {
 }
 
 ABIArgInfo AMDGPUABIInfo::classifyReturnType(QualType RetTy) const {
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // returned by value.
     if (!getRecordArgABI(RetTy, getCXXABI())) {
@@ -7678,7 +7942,7 @@ ABIArgInfo AMDGPUABIInfo::classifyArgumentType(QualType Ty,
 
   Ty = useFirstFieldIfTransparentUnion(Ty);
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Records with non-trivial destructors/copy-constructors should not be
     // passed by value.
     if (auto RAA = getRecordArgABI(Ty, getCXXABI()))
@@ -7777,7 +8041,7 @@ void AMDGPUTargetCodeGenInfo::setTargetAttributes(
   const auto *ReqdWGS = M.getLangOpts().OpenCL ?
     FD->getAttr<ReqdWorkGroupSizeAttr>() : nullptr;
 
-  if (M.getLangOpts().OpenCL && FD->hasAttr<OpenCLKernelAttr>() &&
+  if (M.getLangOpts().OpenCL && FD->hasAttr<ComputeKernelAttr>() &&
       (M.getTriple().getOS() == llvm::Triple::AMDHSA))
     F->addFnAttr("amdgpu-implicitarg-num-bytes", "48");
 
@@ -7899,7 +8163,7 @@ bool AMDGPUTargetCodeGenInfo::shouldEmitStaticExternCAliases() const {
 void AMDGPUTargetCodeGenInfo::setCUDAKernelCallingConvention(
     const FunctionType *&FT) const {
   FT = getABIInfo().getContext().adjustFunctionType(
-      FT, FT->getExtInfo().withCallingConv(CC_OpenCLKernel));
+      FT, FT->getExtInfo().withCallingConv(CC_FloorKernel));
 }
 
 //===----------------------------------------------------------------------===//
@@ -8111,7 +8375,7 @@ SparcV9ABIInfo::classifyType(QualType Ty, unsigned SizeLimit) const {
     return ABIArgInfo::getExtend(Ty);
 
   // Other non-aggregates go in registers.
-  if (!isAggregateTypeForABI(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return ABIArgInfo::getDirect();
 
   // If a C++ object has either a non-trivial copy constructor or a non-trivial
@@ -8340,7 +8604,7 @@ ABIArgInfo ARCABIInfo::classifyArgumentType(QualType Ty,
 
   auto SizeInRegs = llvm::alignTo(getContext().getTypeSize(Ty), 32) / 32;
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Structures with flexible arrays are always indirect.
     if (RT && RT->getDecl()->hasFlexibleArrayMember())
       return getIndirectByValue(Ty);
@@ -8670,33 +8934,6 @@ void XCoreTargetCodeGenInfo::emitTargetMD(const Decl *D, llvm::GlobalValue *GV,
   }
 }
 
-//===----------------------------------------------------------------------===//
-// SPIR ABI Implementation
-//===----------------------------------------------------------------------===//
-
-namespace {
-class SPIRTargetCodeGenInfo : public TargetCodeGenInfo {
-public:
-  SPIRTargetCodeGenInfo(CodeGen::CodeGenTypes &CGT)
-    : TargetCodeGenInfo(new DefaultABIInfo(CGT)) {}
-  unsigned getOpenCLKernelCallingConv() const override;
-};
-
-} // End anonymous namespace.
-
-namespace clang {
-namespace CodeGen {
-void computeSPIRKernelABIInfo(CodeGenModule &CGM, CGFunctionInfo &FI) {
-  DefaultABIInfo SPIRABI(CGM.getTypes());
-  SPIRABI.computeInfo(FI);
-}
-}
-}
-
-unsigned SPIRTargetCodeGenInfo::getOpenCLKernelCallingConv() const {
-  return llvm::CallingConv::SPIR_KERNEL;
-}
-
 static bool appendType(SmallStringEnc &Enc, QualType QType,
                        const CodeGen::CodeGenModule &CGM,
                        TypeStringCache &TSC);
@@ -9122,7 +9359,7 @@ ABIArgInfo RISCVABIInfo::classifyArgumentType(QualType Ty, bool IsFixed,
 
   ArgGPRsLeft -= NeededArgGPRs;
 
-  if (!isAggregateTypeForABI(Ty) && !Ty->isVectorType()) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !Ty->isVectorType()) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -9405,7 +9642,12 @@ const TargetCodeGenInfo &CodeGenModule::getTargetCodeGenInfo() {
     return SetCGInfo(new ARCTargetCodeGenInfo(Types));
   case llvm::Triple::spir:
   case llvm::Triple::spir64:
+    if(Triple.getEnvironment() == llvm::Triple::EnvironmentType::Vulkan) {
+      return SetCGInfo(new VulkanTargetCodeGenInfo(Types));
+    }
     return SetCGInfo(new SPIRTargetCodeGenInfo(Types));
+  case llvm::Triple::air64:
+    return SetCGInfo(new AIRTargetCodeGenInfo(Types));
   }
 }
 
diff --git a/lib/CodeGen/TargetInfo.h b/lib/CodeGen/TargetInfo.h
index b530260ea4..4dbc0a129a 100644
--- a/lib/CodeGen/TargetInfo.h
+++ b/lib/CodeGen/TargetInfo.h
@@ -303,6 +303,9 @@ public:
   virtual bool shouldEmitStaticExternCAliases() const { return true; }
 
   virtual void setCUDAKernelCallingConvention(const FunctionType *&FT) const {}
+
+  static bool isAggregateTypeForABI(QualType T);
+
 };
 
 } // namespace CodeGen
diff --git a/lib/Driver/Driver.cpp b/lib/Driver/Driver.cpp
index 413956eb18..538a6b464a 100644
--- a/lib/Driver/Driver.cpp
+++ b/lib/Driver/Driver.cpp
@@ -3408,6 +3408,16 @@ Action *Driver::ConstructPhaseAction(
       return C.MakeAction<CompileJobAction>(Input, types::TY_ModuleFile);
     if (Args.hasArg(options::OPT_verify_pch))
       return C.MakeAction<VerifyPCHJobAction>(Input, types::TY_Nothing);
+    if (Args.hasArg(options::OPT_llvm_bc_32))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC_32);
+    if (Args.hasArg(options::OPT_llvm_bc_35))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC_35);
+    if (Args.hasArg(options::OPT_llvm_spirv))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_SPIRV);
+    if (Args.hasArg(options::OPT_llvm_spirv_container))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_SPIRVC);
+    if (Args.hasArg(options::OPT_llvm_metallib))
+      return C.MakeAction<CompileJobAction>(Input, types::TY_METALLIB);
     return C.MakeAction<CompileJobAction>(Input, types::TY_LLVM_BC);
   }
   case phases::Backend: {
@@ -3417,8 +3427,17 @@ Action *Driver::ConstructPhaseAction(
       return C.MakeAction<BackendJobAction>(Input, Output);
     }
     if (Args.hasArg(options::OPT_emit_llvm)) {
-      types::ID Output =
-          Args.hasArg(options::OPT_S) ? types::TY_LLVM_IR : types::TY_LLVM_BC;
+      types::ID Output = types::TY_LLVM_BC;
+      if (Args.hasArg(options::OPT_S)) {
+        Output = types::TY_LLVM_IR;
+      }
+      else {
+        if (Args.hasArg(options::OPT_llvm_bc_32)) Output = types::TY_LLVM_BC_32;
+        if (Args.hasArg(options::OPT_llvm_bc_35)) Output = types::TY_LLVM_BC_35;
+        if (Args.hasArg(options::OPT_llvm_spirv)) Output = types::TY_SPIRV;
+        if (Args.hasArg(options::OPT_llvm_spirv_container)) Output = types::TY_SPIRVC;
+        if (Args.hasArg(options::OPT_llvm_metallib)) Output = types::TY_METALLIB;
+      }
       return C.MakeAction<BackendJobAction>(Input, Output);
     }
     return C.MakeAction<BackendJobAction>(Input, types::TY_PP_Asm);
@@ -4304,8 +4323,14 @@ const char *Driver::GetNamedOutputPath(Compilation &C, const JobAction &JA,
     // the unoptimized bitcode so that it does not get overwritten by the ".bc"
     // optimized bitcode output.
     if (!AtTopLevel && C.getArgs().hasArg(options::OPT_emit_llvm) &&
-        JA.getType() == types::TY_LLVM_BC)
+        (JA.getType() == types::TY_LLVM_BC ||
+         JA.getType() == types::TY_LLVM_BC_32 ||
+         JA.getType() == types::TY_LLVM_BC_35 ||
+         JA.getType() == types::TY_SPIRV ||
+         JA.getType() == types::TY_SPIRVC ||
+         JA.getType() == types::TY_METALLIB)) {
       Suffixed += ".tmp";
+    }
     Suffixed += '.';
     Suffixed += Suffix;
     NamedOutput = C.getArgs().MakeArgString(Suffixed.c_str());
diff --git a/lib/Driver/ToolChains/Clang.cpp b/lib/Driver/ToolChains/Clang.cpp
index e3dfb09c73..740002ae37 100644
--- a/lib/Driver/ToolChains/Clang.cpp
+++ b/lib/Driver/ToolChains/Clang.cpp
@@ -3494,6 +3494,18 @@ void Clang::ConstructJob(Compilation &C, const JobAction &JA,
     } else if (JA.getType() == types::TY_LLVM_BC ||
                JA.getType() == types::TY_LTO_BC) {
       CmdArgs.push_back("-emit-llvm-bc");
+    } else if (JA.getType() == types::TY_LLVM_BC_32) {
+      CmdArgs.push_back("-emit-llvm-bc"); // order matters
+      CmdArgs.push_back("-llvm-bc-32");
+    } else if (JA.getType() == types::TY_LLVM_BC_35) {
+      CmdArgs.push_back("-emit-llvm-bc"); // order matters
+      CmdArgs.push_back("-llvm-bc-35");
+    } else if (JA.getType() == types::TY_SPIRV) {
+      CmdArgs.push_back("-emit-spirv");
+    } else if (JA.getType() == types::TY_SPIRVC) {
+      CmdArgs.push_back("-emit-spirv-container");
+    } else if (JA.getType() == types::TY_METALLIB) {
+      CmdArgs.push_back("-emit-metallib");
     } else if (JA.getType() == types::TY_PP_Asm) {
       CmdArgs.push_back("-S");
     } else if (JA.getType() == types::TY_AST) {
@@ -3514,7 +3526,7 @@ void Clang::ConstructJob(Compilation &C, const JobAction &JA,
     // loading the bitcode up in 'opt' or 'llc' and running passes gives the
     // same result as running passes here.  For LTO, we don't need to preserve
     // the use-list order, since serialization to bitcode is part of the flow.
-    if (JA.getType() == types::TY_LLVM_BC)
+    if (JA.getType() == types::TY_LLVM_BC) // NOTE: don't do this for 3.2/3.5
       CmdArgs.push_back("-emit-llvm-uselists");
 
     // Device-side jobs do not support LTO.
diff --git a/lib/Driver/ToolChains/Cuda.cpp b/lib/Driver/ToolChains/Cuda.cpp
index 57b8d4340e..617b1f1584 100644
--- a/lib/Driver/ToolChains/Cuda.cpp
+++ b/lib/Driver/ToolChains/Cuda.cpp
@@ -61,6 +61,8 @@ static CudaVersion ParseCudaVersionFile(llvm::StringRef V) {
     return CudaVersion::CUDA_92;
   if (Major == 10 && Minor == 0)
     return CudaVersion::CUDA_100;
+  if (Major == 10 && Minor == 1)
+    return CudaVersion::CUDA_101;
   return CudaVersion::UNKNOWN;
 }
 
@@ -167,7 +169,7 @@ CudaInstallationDetector::CudaInstallationDetector(
       if (FS.exists(FilePath)) {
         for (const char *GpuArchName :
              {"sm_30", "sm_32", "sm_35", "sm_37", "sm_50", "sm_52", "sm_53",
-              "sm_60", "sm_61", "sm_62", "sm_70", "sm_72", "sm_75"}) {
+              "sm_60", "sm_61", "sm_62", "sm_70", "sm_72", "sm_73", "sm_75", "sm_82"}) {
           const CudaArch GpuArch = StringToCudaArch(GpuArchName);
           if (Version >= MinVersionForCudaArch(GpuArch) &&
               Version <= MaxVersionForCudaArch(GpuArch))
@@ -643,10 +645,10 @@ void CudaToolChain::addClangTargetOptions(
   CC1Args.push_back("-mlink-builtin-bitcode");
   CC1Args.push_back(DriverArgs.MakeArgString(LibDeviceFile));
 
-  // Libdevice in CUDA-7.0 requires PTX version that's more recent than LLVM
-  // defaults to. Use PTX4.2 by default, which is the PTX version that came with
-  // CUDA-7.0.
-  const char *PtxFeature = "+ptx42";
+  // Libdevice in CUDA-7.5 requires PTX version that's more recent than LLVM
+  // defaults to. Use PTX4.3 by default, which is the PTX version that came with
+  // CUDA-7.5.
+  const char *PtxFeature = "+ptx43";
   // TODO(tra): CUDA-10+ needs PTX 6.3 to support new features. However that
   // requires fair amount of work on LLVM side. We'll keep using PTX 6.1 until
   // all prerequisites are in place.
diff --git a/lib/Driver/ToolChains/Darwin.cpp b/lib/Driver/ToolChains/Darwin.cpp
index e5dafa2b09..638b957d2d 100644
--- a/lib/Driver/ToolChains/Darwin.cpp
+++ b/lib/Driver/ToolChains/Darwin.cpp
@@ -63,6 +63,8 @@ llvm::Triple::ArchType darwin::getArchTypeForMachOArchName(StringRef Str) {
       .Case("nvptx64", llvm::Triple::nvptx64)
       .Case("amdil", llvm::Triple::amdil)
       .Case("spir", llvm::Triple::spir)
+      .Case("spir64", llvm::Triple::spir64)
+      .Case("air64", llvm::Triple::air64)
       .Default(llvm::Triple::UnknownArch);
 }
 
@@ -702,6 +704,8 @@ ToolChain::CXXStdlibType Darwin::GetDefaultCXXStdlibType() const {
 
 /// Darwin provides an ARC runtime starting in MacOS X 10.7 and iOS 5.0.
 ObjCRuntime Darwin::getDefaultObjCRuntime(bool isNonFragile) const {
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return ObjCRuntime(ObjCRuntime::FragileMacOSX, TargetVersion);
   if (isTargetWatchOSBased())
     return ObjCRuntime(ObjCRuntime::WatchOS, TargetVersion);
   if (isTargetIOSBased())
@@ -713,6 +717,8 @@ ObjCRuntime Darwin::getDefaultObjCRuntime(bool isNonFragile) const {
 
 /// Darwin provides a blocks runtime starting in MacOS X 10.6 and iOS 3.2.
 bool Darwin::hasBlocksRuntime() const {
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return false;
   if (isTargetWatchOSBased())
     return true;
   else if (isTargetIOSBased())
@@ -848,6 +854,10 @@ DarwinClang::DarwinClang(const Driver &D, const llvm::Triple &Triple,
     : Darwin(D, Triple, Args) {}
 
 void DarwinClang::addClangWarningOptions(ArgStringList &CC1Args) const {
+  // nothing of interest in here for air/metal
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return;
+
   // For modern targets, promote certain warnings to errors.
   if (isTargetWatchOSBased() || getTriple().isArch64Bit()) {
     // Always enable -Wdeprecated-objc-isa-usage and promote it
@@ -2017,6 +2027,8 @@ void MachO::AddLinkRuntimeLibArgs(const ArgList &Args,
 }
 
 bool Darwin::isAlignedAllocationUnavailable() const {
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64) return false;
+
   llvm::Triple::OSType OS;
 
   switch (TargetPlatform) {
@@ -2293,6 +2305,11 @@ void Darwin::CheckObjCARC() const {
 SanitizerMask Darwin::getSupportedSanitizers() const {
   const bool IsX86_64 = getTriple().getArch() == llvm::Triple::x86_64;
   SanitizerMask Res = ToolChain::getSupportedSanitizers();
+
+  // no additional ones
+  if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+    return Res;
+
   Res |= SanitizerKind::Address;
   Res |= SanitizerKind::Leak;
   Res |= SanitizerKind::Fuzzer;
diff --git a/lib/Driver/ToolChains/Darwin.h b/lib/Driver/ToolChains/Darwin.h
index e6a88dce3c..2ac5ab17af 100644
--- a/lib/Driver/ToolChains/Darwin.h
+++ b/lib/Driver/ToolChains/Darwin.h
@@ -456,6 +456,10 @@ public:
   }
 
   unsigned GetDefaultStackProtectorLevel(bool KernelOrKext) const override {
+    // not supported on air/metal
+    if (getTriple().getArch() == llvm::Triple::ArchType::air64)
+      return 0;
+
     // Stack protectors default to on for user code on 10.5,
     // and for everything in 10.6 and beyond
     if (isTargetIOSBased() || isTargetWatchOSBased())
diff --git a/lib/Driver/ToolChains/Gnu.cpp b/lib/Driver/ToolChains/Gnu.cpp
index 3850e1c02e..4084f31927 100644
--- a/lib/Driver/ToolChains/Gnu.cpp
+++ b/lib/Driver/ToolChains/Gnu.cpp
@@ -205,6 +205,9 @@ void tools::gcc::Compiler::RenderExtraToolArgs(const JobAction &JA,
   case types::TY_LTO_IR:
   case types::TY_LLVM_BC:
   case types::TY_LTO_BC:
+  case types::TY_LLVM_BC_32:
+  case types::TY_LLVM_BC_35:
+  case types::TY_METALLIB:
     CmdArgs.push_back("-c");
     break;
   // We assume we've got an "integrated" assembler in that gcc will produce an
diff --git a/lib/Driver/Types.cpp b/lib/Driver/Types.cpp
index 9d2737bbc7..c8cd0a4e02 100644
--- a/lib/Driver/Types.cpp
+++ b/lib/Driver/Types.cpp
@@ -116,6 +116,9 @@ bool types::isAcceptedByClang(ID Id) {
   case TY_CXXModule: case TY_PP_CXXModule:
   case TY_AST: case TY_ModuleFile:
   case TY_LLVM_IR: case TY_LLVM_BC:
+  case TY_LLVM_BC_32: case TY_LLVM_BC_35:
+  case TY_SPIRV: case TY_SPIRVC:
+  case TY_METALLIB:
     return true;
   }
 }
@@ -158,6 +161,8 @@ bool types::isLLVMIR(ID Id) {
 
   case TY_LLVM_IR:
   case TY_LLVM_BC:
+  case TY_LLVM_BC_32:
+  case TY_LLVM_BC_35:
   case TY_LTO_IR:
   case TY_LTO_BC:
     return true;
@@ -207,6 +212,11 @@ types::ID types::lookupTypeForExtension(llvm::StringRef Ext) {
            .Case("S", TY_Asm)
            .Case("s", TY_PP_Asm)
            .Case("bc", TY_LLVM_BC)
+           .Case("bc32", TY_LLVM_BC_32) // not ideal
+           .Case("bc35", TY_LLVM_BC_35) // not ideal
+           .Case("spv", TY_SPIRV)
+           .Case("spvc", TY_SPIRVC)
+           .Case("metallib", TY_METALLIB)
            .Case("cc", TY_CXX)
            .Case("CC", TY_CXX)
            .Case("cl", TY_CL)
diff --git a/lib/Edit/RewriteObjCFoundationAPI.cpp b/lib/Edit/RewriteObjCFoundationAPI.cpp
index 7c9ab17009..21a9eab512 100644
--- a/lib/Edit/RewriteObjCFoundationAPI.cpp
+++ b/lib/Edit/RewriteObjCFoundationAPI.cpp
@@ -1079,6 +1079,8 @@ static bool rewriteToNumericBoxedExpression(const ObjCMessageExpr *Msg,
     case CK_CopyAndAutoreleaseBlockObject:
     case CK_BuiltinFnToFnPtr:
     case CK_ZeroToOCLOpaqueType:
+    case CK_ZeroToOCLEvent:
+    case CK_ZeroToOCLQueue:
     case CK_IntToOCLSampler:
       return false;
 
diff --git a/lib/Frontend/CompilerInstance.cpp b/lib/Frontend/CompilerInstance.cpp
index f666745354..cd892defac 100644
--- a/lib/Frontend/CompilerInstance.cpp
+++ b/lib/Frontend/CompilerInstance.cpp
@@ -1011,6 +1011,10 @@ bool CompilerInstance::ExecuteAction(FrontendAction &Act) {
 /// Determine the appropriate source input kind based on language
 /// options.
 static InputKind::Language getLanguageFromOptions(const LangOptions &LangOpts) {
+  if (LangOpts.Metal)
+    return InputKind::Metal;
+  if (LangOpts.Vulkan)
+    return InputKind::Vulkan;
   if (LangOpts.OpenCL)
     return InputKind::OpenCL;
   if (LangOpts.CUDA)
diff --git a/lib/Frontend/CompilerInvocation.cpp b/lib/Frontend/CompilerInvocation.cpp
index d491f35769..2d3f38e1a6 100644
--- a/lib/Frontend/CompilerInvocation.cpp
+++ b/lib/Frontend/CompilerInvocation.cpp
@@ -86,6 +86,7 @@
 #include <cstring>
 #include <memory>
 #include <string>
+#include <fstream>
 #include <tuple>
 #include <utility>
 #include <vector>
@@ -121,7 +122,10 @@ CompilerInvocationBase::~CompilerInvocationBase() = default;
 static unsigned getOptimizationLevel(ArgList &Args, InputKind IK,
                                      DiagnosticsEngine &Diags) {
   unsigned DefaultOpt = llvm::CodeGenOpt::None;
-  if (IK.getLanguage() == InputKind::OpenCL && !Args.hasArg(OPT_cl_opt_disable))
+  if ((IK.getLanguage() == InputKind::OpenCL ||
+       IK.getLanguage() == InputKind::Metal ||
+       IK.getLanguage() == InputKind::Vulkan) &&
+      !Args.hasArg(OPT_cl_opt_disable) && !Args.hasArg(OPT_emit_spirv))
     DefaultOpt = llvm::CodeGenOpt::Default;
 
   if (Arg *A = Args.getLastArg(options::OPT_O_Group)) {
@@ -932,6 +936,10 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
 
   Opts.ControlFlowGuard = Args.hasArg(OPT_cfguard);
 
+  Opts.DenormsAreZero = Args.hasArg(OPT_cl_denorms_are_zero);
+  Opts.CorrectFPDivideSqrt = Args.hasArg(OPT_cl_fp32_correctly_rounded_divide_sqrt);
+  Opts.OptDisable = Args.hasArg(OPT_cl_opt_disable);
+
   Opts.DisableGCov = Args.hasArg(OPT_test_coverage);
   Opts.EmitGcovArcs = Args.hasArg(OPT_femit_coverage_data);
   Opts.EmitGcovNotes = Args.hasArg(OPT_femit_coverage_notes);
@@ -1025,7 +1033,6 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
 
   Opts.InstrumentForProfiling = Args.hasArg(OPT_pg);
   Opts.CallFEntry = Args.hasArg(OPT_mfentry);
-  Opts.EmitOpenCLArgMetadata = Args.hasArg(OPT_cl_kernel_arg_info);
 
   if (const Arg *A = Args.getLastArg(OPT_fcf_protection_EQ)) {
     StringRef Name = A->getValue();
@@ -1057,6 +1064,24 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
     }
   }
 
+  Opts.EmitOpenCLArgMetadata = (Args.hasArg(OPT_cl_kernel_arg_info) ||
+                                Args.hasArg(OPT_emit_spirv) ||
+                                Args.hasArg(OPT_emit_spirv_container));
+  if (IK.getLanguage() == InputKind::Metal) {
+    // dwarf version must always be 2 for metal/air
+    Opts.DwarfVersion = 2;
+  }
+  Opts.MetalIntelWorkarounds = Args.hasArg(OPT_metal_intel_workarounds);
+  Opts.MetalNvidiaWorkarounds = Args.hasArg(OPT_metal_nvidia_workarounds);
+  Opts.MetalNoArrayImage = Args.hasArg(OPT_metal_no_array_image);
+  Opts.MetalSoftPrintf = Args.hasArg(OPT_metal_soft_printf);
+  Opts.SPIRIntelWorkarounds = Args.hasArg(OPT_cl_spir_intel_workarounds);
+  Opts.VulkanIUBSize = uint32_t(std::min(uint64_t(~0u),
+      getLastArgUInt64Value(Args, OPT_vulkan_iub_size_EQ, 256)));
+  Opts.VulkanIUBCount = uint32_t(std::min(uint64_t(~0u),
+      getLastArgUInt64Value(Args, OPT_vulkan_iub_count_EQ, 4)));
+  Opts.VulkanSoftPrintf = Args.hasArg(OPT_vulkan_soft_printf);
+
   Opts.RelaxELFRelocations = Args.hasArg(OPT_mrelax_relocations);
   Opts.DebugCompilationDir = Args.getLastArgValue(OPT_fdebug_compilation_dir);
   for (auto *A :
@@ -1183,6 +1208,8 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
     }
   }
 
+  Opts.SPIRCompileOptions = Args.getLastArgValue(OPT_cl_spir_compile_options).trim("\t\n\v\f\r\" ");
+
   if (Arg *A = Args.getLastArg(OPT_fdenormal_fp_math_EQ)) {
     StringRef Val = A->getValue();
     if (Val == "ieee")
@@ -1606,6 +1633,16 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
       Opts.ProgramAction = frontend::EmitAssembly; break;
     case OPT_emit_llvm_bc:
       Opts.ProgramAction = frontend::EmitBC; break;
+    case OPT_llvm_bc_32:
+      Opts.ProgramAction = frontend::EmitBC32; break;
+    case OPT_llvm_bc_35:
+      Opts.ProgramAction = frontend::EmitBC35; break;
+    case OPT_emit_spirv:
+      Opts.ProgramAction = frontend::EmitSPIRV; break;
+    case OPT_emit_spirv_container:
+      Opts.ProgramAction = frontend::EmitSPIRVContainer; break;
+    case OPT_emit_metallib:
+      Opts.ProgramAction = frontend::EmitMetalLib; break;
     case OPT_emit_html:
       Opts.ProgramAction = frontend::EmitHTML; break;
     case OPT_emit_llvm:
@@ -1821,6 +1858,8 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
     DashX = llvm::StringSwitch<InputKind>(XValue)
                 .Case("c", InputKind::C)
                 .Case("cl", InputKind::OpenCL)
+                .Case("metal", InputKind::Metal)
+                .Case("vulkan", InputKind::Vulkan)
                 .Case("cuda", InputKind::CUDA)
                 .Case("hip", InputKind::HIP)
                 .Case("c++", InputKind::CXX)
@@ -2069,6 +2108,12 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     case InputKind::OpenCL:
       LangStd = LangStandard::lang_opencl10;
       break;
+    case InputKind::Metal:
+      LangStd = LangStandard::lang_metal11;
+      break;
+    case InputKind::Vulkan:
+      LangStd = LangStandard::lang_vulkan10;
+      break;
     case InputKind::CUDA:
       LangStd = LangStandard::lang_cuda;
       break;
@@ -2134,9 +2179,47 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     Opts.OpenCLVersion = 120;
   else if (LangStd == LangStandard::lang_opencl20)
     Opts.OpenCLVersion = 200;
+  else if (LangStd == LangStandard::lang_opencl21)
+    Opts.OpenCLVersion = 210;
+  else if (LangStd == LangStandard::lang_opencl22)
+    Opts.OpenCLVersion = 220;
   else if (LangStd == LangStandard::lang_openclcpp)
     Opts.OpenCLCPlusPlusVersion = 100;
 
+  // as Metal is largely compiled as OpenCL, also enable + init opencl
+  if (LangStd == LangStandard::lang_metal11 ||
+      LangStd == LangStandard::lang_metal12 ||
+      LangStd == LangStandard::lang_metal20 ||
+      LangStd == LangStandard::lang_metal21 ||
+      IK.getLanguage() == InputKind::Metal) {
+    Opts.Metal = 1;
+    Opts.OpenCL = 1;
+    Opts.OpenCLVersion = 120;
+
+    if (LangStd == LangStandard::lang_metal11)
+      Opts.MetalVersion = 110;
+    else if (LangStd == LangStandard::lang_metal12)
+      Opts.MetalVersion = 120;
+    else if (LangStd == LangStandard::lang_metal20)
+      Opts.MetalVersion = 200;
+    else if (LangStd == LangStandard::lang_metal21)
+      Opts.MetalVersion = 210;
+  }
+
+  // as Vulkan is largely compiled as OpenCL, also enable + init opencl
+  if (LangStd == LangStandard::lang_vulkan10 ||
+      LangStd == LangStandard::lang_vulkan11 ||
+      IK.getLanguage() == InputKind::Vulkan) {
+    Opts.Vulkan = 1;
+    Opts.OpenCL = 1;
+    Opts.OpenCLVersion = 200;
+
+    if (LangStd == LangStandard::lang_vulkan10)
+      Opts.VulkanVersion = 100;
+    else if (LangStd == LangStandard::lang_vulkan11)
+      Opts.VulkanVersion = 110;
+  }
+
   // OpenCL has some additional defaults.
   if (Opts.OpenCL) {
     Opts.AltiVec = 0;
@@ -2145,18 +2228,23 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     Opts.setDefaultFPContractMode(LangOptions::FPC_On);
     Opts.NativeHalfType = 1;
     Opts.NativeHalfArgsAndReturns = 1;
-    Opts.OpenCLCPlusPlus = Opts.CPlusPlus;
+    Opts.OpenCLCPlusPlus = 0; // no, just no ...
     // Include default header file for OpenCL.
+#if 0
     if (Opts.IncludeDefaultHeader) {
       PPOpts.Includes.push_back("opencl-c.h");
     }
+#endif
   }
 
   Opts.HIP = IK.getLanguage() == InputKind::HIP;
   Opts.CUDA = IK.getLanguage() == InputKind::CUDA || Opts.HIP;
-  if (Opts.CUDA)
+  if (Opts.CUDA) {
     // Set default FP_CONTRACT to FAST.
     Opts.setDefaultFPContractMode(LangOptions::FPC_Fast);
+    Opts.NativeHalfType = 1;
+    Opts.NativeHalfArgsAndReturns = 1;
+  }
 
   Opts.RenderScript = IK.getLanguage() == InputKind::RenderScript;
   if (Opts.RenderScript) {
@@ -2167,8 +2255,8 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
   // OpenCL and C++ both have bool, true, false keywords.
   Opts.Bool = Opts.OpenCL || Opts.CPlusPlus;
 
-  // OpenCL has half keyword
-  Opts.Half = Opts.OpenCL;
+  // OpenCL and CUDA have half keyword
+  Opts.Half = Opts.OpenCL || Opts.CUDA;
 
   // C++ has wchar_t keyword.
   Opts.WChar = Opts.CPlusPlus;
@@ -2215,6 +2303,12 @@ static bool IsInputCompatibleWithStandard(InputKind IK,
   case InputKind::OpenCL:
     return S.getLanguage() == InputKind::OpenCL;
 
+  case InputKind::Metal:
+    return S.getLanguage() == InputKind::Metal;
+
+  case InputKind::Vulkan:
+    return S.getLanguage() == InputKind::Vulkan;
+
   case InputKind::CXX:
   case InputKind::ObjCXX:
     return S.getLanguage() == InputKind::CXX;
@@ -2251,6 +2345,10 @@ static const StringRef GetInputKindName(InputKind IK) {
     return "Objective-C++";
   case InputKind::OpenCL:
     return "OpenCL";
+  case InputKind::Metal:
+    return "Metal";
+  case InputKind::Vulkan:
+    return "Vulkan";
   case InputKind::CUDA:
     return "CUDA";
   case InputKind::RenderScript:
@@ -2338,6 +2436,8 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
         .Cases("cl1.1", "CL1.1", LangStandard::lang_opencl11)
         .Cases("cl1.2", "CL1.2", LangStandard::lang_opencl12)
         .Cases("cl2.0", "CL2.0", LangStandard::lang_opencl20)
+        .Cases("cl2.1", "CL2.1", LangStandard::lang_opencl21)
+        .Cases("cl2.2", "CL2.2", LangStandard::lang_opencl22)
         .Case("c++", LangStandard::lang_openclcpp)
         .Default(LangStandard::lang_unspecified);
 
@@ -2364,6 +2464,36 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
         << Args.getLastArg(OPT_cl_strict_aliasing)->getAsString(Args);
   }
 
+  // open libfloor function info file
+  if (const Arg *A = Args.getLastArg(OPT_floor_function_info)) {
+    if (A->getValue() != nullptr && strlen(A->getValue()) > 0) {
+      Opts.floor_function_info = new std::fstream(A->getValue(), std::ios::out | std::ios::binary);
+      if (Opts.floor_function_info == nullptr ||
+          !Opts.floor_function_info->is_open()) {
+        Diags.Report(diag::err_drv_floor_function_info);
+      }
+    }
+  }
+
+  // extract libfloor image capabilities
+  if (const Arg *A = Args.getLastArg(OPT_floor_image_capabilities)) {
+    StringRef image_caps = A->getValue();
+    Opts.floor_image_capabilities = (unsigned int)std::stoul(image_caps);
+  }
+
+  // metal lang options
+  if (Args.hasArg(OPT_metal_no_array_image)) {
+    Opts.metal_no_array_image = true;
+  }
+  if (Args.hasArg(OPT_metal_soft_printf)) {
+    Opts.metal_soft_printf = true;
+  }
+
+  // Vulkan lang options
+  if (Args.hasArg(OPT_vulkan_soft_printf)) {
+    Opts.vulkan_soft_printf = true;
+  }
+
   // We abuse '-f[no-]gnu-keywords' to force overriding all GNU-extension
   // keywords. This behavior is provided by GCC's poorly named '-fasm' flag,
   // while a subset (the non-C++ GNU keywords) is provided by GCC's
@@ -2577,7 +2707,7 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   Opts.RTTI = Opts.CPlusPlus && !Args.hasArg(OPT_fno_rtti);
   Opts.RTTIData = Opts.RTTI && !Args.hasArg(OPT_fno_rtti_data);
   Opts.Blocks = Args.hasArg(OPT_fblocks) || (Opts.OpenCL
-    && Opts.OpenCLVersion == 200);
+    && Opts.OpenCLVersion >= 200);
   Opts.BlocksRuntimeOptional = Args.hasArg(OPT_fblocks_runtime_optional);
   Opts.CoroutinesTS = Args.hasArg(OPT_fcoroutines_ts);
 
@@ -2830,7 +2960,7 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   // Set the flag to prevent the implementation from emitting device exception
   // handling code for those requiring so.
   Opts.OpenMPHostCXXExceptions = Opts.Exceptions && Opts.CXXExceptions;
-  if ((Opts.OpenMPIsDevice && T.isNVPTX()) || Opts.OpenCLCPlusPlus) {
+  if ((Opts.OpenMPIsDevice && T.isNVPTX()) || Opts.OpenCL) {
     Opts.Exceptions = 0;
     Opts.CXXExceptions = 0;
   }
@@ -2926,6 +3056,20 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   Opts.RetainCommentsFromSystemHeaders =
       Args.hasArg(OPT_fretain_comments_from_system_headers);
 
+  Opts.CLEnableHalf = Args.hasArg(OPT_cl_enable_half);
+  Opts.CLVerifySPIR = Args.hasArg(OPT_cl_verify_spir);
+
+  if(const Arg* A = Args.getLastArg(OPT_cl_sampler_type)) {
+      Opts.CLSamplerOpaque  = llvm::StringSwitch<unsigned int>(A->getValue())
+        .Case("i32", 0u)
+        .Case("opaque", 1u)
+        .Default(~0u);
+      if(Opts.CLSamplerOpaque == ~0u)
+        Diags.Report(diag::err_drv_invalid_value) << A->getAsString(Args)
+                                                  << A->getValue();
+  } else
+    Opts.CLSamplerOpaque = 1;
+
   unsigned SSP = getLastArgIntValue(Args, OPT_stack_protector, 0, Diags);
   switch (SSP) {
   default:
@@ -3018,6 +3162,11 @@ static bool isStrictlyPreprocessorAction(frontend::ActionKind Action) {
   case frontend::ASTView:
   case frontend::EmitAssembly:
   case frontend::EmitBC:
+  case frontend::EmitBC32:
+  case frontend::EmitBC35:
+  case frontend::EmitSPIRV:
+  case frontend::EmitSPIRVContainer:
+  case frontend::EmitMetalLib:
   case frontend::EmitHTML:
   case frontend::EmitLLVM:
   case frontend::EmitLLVMOnly:
diff --git a/lib/Frontend/FrontendActions.cpp b/lib/Frontend/FrontendActions.cpp
index a407dfc162..753052bdf1 100644
--- a/lib/Frontend/FrontendActions.cpp
+++ b/lib/Frontend/FrontendActions.cpp
@@ -836,6 +836,8 @@ void PrintPreambleAction::ExecuteAction() {
   case InputKind::ObjC:
   case InputKind::ObjCXX:
   case InputKind::OpenCL:
+  case InputKind::Metal:
+  case InputKind::Vulkan:
   case InputKind::CUDA:
   case InputKind::HIP:
     break;
diff --git a/lib/Frontend/InitPreprocessor.cpp b/lib/Frontend/InitPreprocessor.cpp
index 77b2f479a7..db6eea4695 100644
--- a/lib/Frontend/InitPreprocessor.cpp
+++ b/lib/Frontend/InitPreprocessor.cpp
@@ -408,7 +408,7 @@ static void InitializeStandardPredefinedMacros(const TargetInfo &TI,
 
   // OpenCL v1.0/1.1 s6.9, v1.2/2.0 s6.10: Preprocessor Directives and Macros.
   if (LangOpts.OpenCL) {
-    if (LangOpts.CPlusPlus) {
+    if (LangOpts.OpenCLCPlusPlus) {
       if (LangOpts.OpenCLCPlusPlusVersion == 100)
         Builder.defineMacro("__OPENCL_CPP_VERSION__", "100");
       else
@@ -433,6 +433,8 @@ static void InitializeStandardPredefinedMacros(const TargetInfo &TI,
         Builder.defineMacro("__OPENCL_C_VERSION__", "120");
         break;
       case 200:
+      case 210:
+      case 220:
         Builder.defineMacro("__OPENCL_C_VERSION__", "200");
         break;
       default:
@@ -831,6 +833,7 @@ static void InitializePredefinedMacros(const TargetInfo &TI,
   DefineTypeWidth("__UINTPTR_WIDTH__", TI.getUIntPtrType(), TI, Builder);
 
   DefineFloatMacros(Builder, "FLT16", &TI.getHalfFormat(), "F16");
+  DefineFloatMacros(Builder, "HALF", &TI.getHalfFormat(), "H");
   DefineFloatMacros(Builder, "FLT", &TI.getFloatFormat(), "F");
   DefineFloatMacros(Builder, "DBL", &TI.getDoubleFormat(), "");
   DefineFloatMacros(Builder, "LDBL", &TI.getLongDoubleFormat(), "L");
@@ -1094,6 +1097,9 @@ void clang::InitializePreprocessor(
   llvm::raw_string_ostream Predefines(PredefineBuffer);
   MacroBuilder Builder(Predefines);
 
+  // Setup pragma support
+  PP.setSupportedPragmas(InitOpts.SupportedPragmas);
+
   // Emit line markers for various builtin sections of the file.  We don't do
   // this in asm preprocessor mode, because "# 4" is not a line marker directive
   // in this mode.
diff --git a/lib/FrontendTool/ExecuteCompilerInvocation.cpp b/lib/FrontendTool/ExecuteCompilerInvocation.cpp
index 7015772fa1..65744e2c80 100644
--- a/lib/FrontendTool/ExecuteCompilerInvocation.cpp
+++ b/lib/FrontendTool/ExecuteCompilerInvocation.cpp
@@ -52,6 +52,11 @@ CreateFrontendBaseAction(CompilerInstance &CI) {
   case DumpTokens:             return llvm::make_unique<DumpTokensAction>();
   case EmitAssembly:           return llvm::make_unique<EmitAssemblyAction>();
   case EmitBC:                 return llvm::make_unique<EmitBCAction>();
+  case EmitBC32:               return llvm::make_unique<EmitBC32Action>();
+  case EmitBC35:               return llvm::make_unique<EmitBC35Action>();
+  case EmitSPIRV:              return llvm::make_unique<EmitSPIRVAction>();
+  case EmitSPIRVContainer:     return llvm::make_unique<EmitSPIRVContainerAction>();
+  case EmitMetalLib:           return llvm::make_unique<EmitMetalLibAction>();
   case EmitHTML:               return llvm::make_unique<HTMLPrintAction>();
   case EmitLLVM:               return llvm::make_unique<EmitLLVMAction>();
   case EmitLLVMOnly:           return llvm::make_unique<EmitLLVMOnlyAction>();
diff --git a/lib/Headers/CMakeLists.txt b/lib/Headers/CMakeLists.txt
index e444c9c870..0d2f642ce5 100644
--- a/lib/Headers/CMakeLists.txt
+++ b/lib/Headers/CMakeLists.txt
@@ -31,14 +31,6 @@ set(files
   avxintrin.h
   bmi2intrin.h
   bmiintrin.h
-  __clang_cuda_builtin_vars.h
-  __clang_cuda_cmath.h
-  __clang_cuda_complex_builtins.h
-  __clang_cuda_device_functions.h
-  __clang_cuda_intrinsics.h
-  __clang_cuda_libdevice_declares.h
-  __clang_cuda_math_forward_declares.h
-  __clang_cuda_runtime_wrapper.h
   cetintrin.h
   cldemoteintrin.h
   clzerointrin.h
@@ -71,7 +63,6 @@ set(files
   msa.h
   mwaitxintrin.h
   nmmintrin.h
-  opencl-c.h
   pkuintrin.h
   pmmintrin.h
   pconfigintrin.h
@@ -116,12 +107,6 @@ set(files
   xtestintrin.h
   )
 
-set(cuda_wrapper_files
-  cuda_wrappers/algorithm
-  cuda_wrappers/complex
-  cuda_wrappers/new
-)
-
 set(output_dir ${LLVM_LIBRARY_OUTPUT_INTDIR}/clang/${CLANG_VERSION}/include)
 
 # Generate arm_neon.h
@@ -134,7 +119,7 @@ clang_tablegen(arm_fp16.h -gen-arm-fp16
   SOURCE ${CLANG_SOURCE_DIR}/include/clang/Basic/arm_fp16.td)
 
 set(out_files)
-foreach( f ${files} ${cuda_wrapper_files} )
+foreach( f ${files} )
   set( src ${CMAKE_CURRENT_SOURCE_DIR}/${f} )
   set( dst ${output_dir}/${f} )
   add_custom_command(OUTPUT ${dst}
@@ -172,12 +157,6 @@ install(
   PERMISSIONS OWNER_READ OWNER_WRITE GROUP_READ WORLD_READ
   DESTINATION lib${LLVM_LIBDIR_SUFFIX}/clang/${CLANG_VERSION}/include)
 
-install(
-  FILES ${cuda_wrapper_files}
-  COMPONENT clang-headers
-  PERMISSIONS OWNER_READ OWNER_WRITE GROUP_READ WORLD_READ
-  DESTINATION lib${LLVM_LIBDIR_SUFFIX}/clang/${CLANG_VERSION}/include/cuda_wrappers)
-
 if (NOT CMAKE_CONFIGURATION_TYPES) # don't add this for IDE's.
   add_llvm_install_targets(install-clang-headers
                            DEPENDS clang-headers
diff --git a/lib/Lex/PPDirectives.cpp b/lib/Lex/PPDirectives.cpp
index 15fc086f8a..cc85d0dc49 100644
--- a/lib/Lex/PPDirectives.cpp
+++ b/lib/Lex/PPDirectives.cpp
@@ -2189,7 +2189,7 @@ bool Preprocessor::ReadMacroParameterList(MacroInfo *MI, Token &Tok) {
              diag::ext_variadic_macro);
 
       // OpenCL v1.2 s6.9.e: variadic macros are not supported.
-      if (LangOpts.OpenCL) {
+      if (LangOpts.OpenCL && !LangOpts.CPlusPlus) {
         Diag(Tok, diag::err_pp_opencl_variadic_macros);
         return true;
       }
diff --git a/lib/Parse/ParseDecl.cpp b/lib/Parse/ParseDecl.cpp
index 7538b635f0..eaa688427b 100644
--- a/lib/Parse/ParseDecl.cpp
+++ b/lib/Parse/ParseDecl.cpp
@@ -727,23 +727,6 @@ void Parser::ParseBorlandTypeAttributes(ParsedAttributes &attrs) {
   }
 }
 
-void Parser::ParseOpenCLKernelAttributes(ParsedAttributes &attrs) {
-  // Treat these like attributes
-  while (Tok.is(tok::kw___kernel)) {
-    IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-    SourceLocation AttrNameLoc = ConsumeToken();
-    attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-                 ParsedAttr::AS_Keyword);
-  }
-}
-
-void Parser::ParseOpenCLQualifiers(ParsedAttributes &Attrs) {
-  IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-  SourceLocation AttrNameLoc = Tok.getLocation();
-  Attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-               ParsedAttr::AS_Keyword);
-}
-
 void Parser::ParseNullabilityTypeSpecifiers(ParsedAttributes &attrs) {
   // Treat these like attributes, even though they're type specifiers.
   while (true) {
@@ -2915,7 +2898,6 @@ static void SetupFixedPointError(const LangOptions &LangOpts,
 /// [C99]   'inline'
 /// [C++]   'virtual'
 /// [C++]   'explicit'
-/// [OpenCL] '__kernel'
 ///       'friend': [C++ dcl.friend]
 ///       'constexpr': [C++0x dcl.constexpr]
 void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
@@ -3387,11 +3369,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
       ParseBorlandTypeAttributes(DS.getAttributes());
       continue;
 
-    // OpenCL single token adornments.
-    case tok::kw___kernel:
-      ParseOpenCLKernelAttributes(DS.getAttributes());
-      continue;
-
     // Nullability type specifiers.
     case tok::kw__Nonnull:
     case tok::kw__Nullable:
@@ -3683,12 +3660,26 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
       }
       isInvalid = DS.SetTypePipe(true, Loc, PrevSpec, DiagID, Policy);
       break;
-#define GENERIC_IMAGE_TYPE(ImgType, Id) \
-  case tok::kw_##ImgType##_t: \
-    isInvalid = DS.SetTypeSpecType(DeclSpec::TST_##ImgType##_t, Loc, PrevSpec, \
-                                   DiagID, Policy); \
+    case tok::kw_sampler_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_sampler_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_event_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_event_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_queue_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_queue_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_clk_event_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_clk_event_t, Loc,
+                                     PrevSpec, DiagID, Policy);
+      break;
+    case tok::kw_reserve_id_t:
+      isInvalid = DS.SetTypeSpecType(DeclSpec::TST_reserve_id_t, Loc,
+                                     PrevSpec, DiagID, Policy);
     break;
-#include "clang/Basic/OpenCLImageTypes.def"
     case tok::kw___unknown_anytype:
       isInvalid = DS.SetTypeSpecType(TST_unknown_anytype, Loc,
                                      PrevSpec, DiagID, Policy);
@@ -3790,38 +3781,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
                                  getLangOpts());
       break;
 
-    // OpenCL access qualifiers:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      // OpenCL C++ 1.0 s2.2: access qualifiers are reserved keywords.
-      if (Actions.getLangOpts().OpenCLCPlusPlus) {
-        DiagID = diag::err_openclcxx_reserved;
-        PrevSpec = Tok.getIdentifierInfo()->getNameStart();
-        isInvalid = true;
-      }
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
-    // OpenCL address space qualifiers:
-    case tok::kw___generic:
-      // generic address space is introduced only in OpenCL v2.0
-      // see OpenCL C Spec v2.0 s6.5.5
-      if (Actions.getLangOpts().OpenCLVersion < 200 &&
-          !Actions.getLangOpts().OpenCLCPlusPlus) {
-        DiagID = diag::err_opencl_unknown_type_specifier;
-        PrevSpec = Tok.getIdentifierInfo()->getNameStart();
-        isInvalid = true;
-        break;
-      };
-      LLVM_FALLTHROUGH;
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
     case tok::less:
       // GCC ObjC supports types like "<SomeProtocol>" as a synonym for
       // "id<SomeProtocol>".  This is hopelessly old fashioned and dangerous,
@@ -4061,10 +4020,10 @@ void Parser::ParseStructUnionBody(SourceLocation RecordLoc,
       ExpectAndConsume(tok::r_paren);
     }
 
-    if (TryConsumeToken(tok::semi))
+    if (TryConsumeToken(tok::semi)) {
       continue;
 
-    if (Tok.is(tok::r_brace)) {
+    } else if (Tok.is(tok::r_brace) && !getLangOpts().OpenCL) {
       ExpectAndConsume(tok::semi, diag::ext_expected_semi_decl_list);
       break;
     }
@@ -4649,8 +4608,12 @@ bool Parser::isKnownToBeTypeSpecifier(const Token &Tok) const {
   case tok::kw__Decimal64:
   case tok::kw__Decimal128:
   case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
 
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
@@ -4728,8 +4691,12 @@ bool Parser::isTypeSpecifierQualifier() {
   case tok::kw__Decimal64:
   case tok::kw__Decimal128:
   case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
 
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
@@ -4774,17 +4741,11 @@ bool Parser::isTypeSpecifierQualifier() {
 
   case tok::kw___kindof:
 
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-
     return true;
 
+  case tok::kw_reserve_id_t:
+    return getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200;
+
   // C11 _Atomic
   case tok::kw__Atomic:
     return true;
@@ -4890,6 +4851,13 @@ bool Parser::isDeclarationSpecifier(bool DisambiguatingWithExpression) {
   case tok::kw__Decimal128:
   case tok::kw___vector:
 
+    // OpenCL specific types:
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
+  case tok::kw_reserve_id_t:
+
     // struct-or-union-specifier (C99) or class-specifier (C++)
   case tok::kw_class:
   case tok::kw_struct:
@@ -4963,18 +4931,6 @@ bool Parser::isDeclarationSpecifier(bool DisambiguatingWithExpression) {
   case tok::kw__Null_unspecified:
 
   case tok::kw___kindof:
-
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
-
     return true;
   }
 }
@@ -5175,18 +5131,6 @@ void Parser::ParseTypeQualifierListOpt(
                                  getLangOpts());
       break;
 
-    // OpenCL qualifiers:
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-    case tok::kw___generic:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
     case tok::kw___unaligned:
       isInvalid = DS.SetTypeQual(DeclSpec::TQ_unaligned, Loc, PrevSpec, DiagID,
                                  getLangOpts());
@@ -5393,6 +5337,8 @@ void Parser::ParseDeclaratorInternal(Declarator &D,
 
   tok::TokenKind Kind = Tok.getKind();
 
+  // Add pipe type info, only if it is not already there. (It may already been
+  // added by the recursive call).
   if (D.getDeclSpec().isTypeSpecPipe() && !isPipeDeclerator(D)) {
     DeclSpec DS(AttrFactory);
     ParseTypeQualifierListOpt(DS);
diff --git a/lib/Parse/ParseExpr.cpp b/lib/Parse/ParseExpr.cpp
index 194b07df46..f7e9d949b8 100644
--- a/lib/Parse/ParseExpr.cpp
+++ b/lib/Parse/ParseExpr.cpp
@@ -1136,7 +1136,7 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
   case tok::amp: {         // unary-expression: '&' cast-expression
     // Special treatment because of member pointers
     SourceLocation SavedLoc = ConsumeToken();
-    Res = ParseCastExpression(false, true);
+    Res = ParseCastExpression(false, true, NotTypeCast, false);
     if (!Res.isInvalid())
       Res = Actions.ActOnUnaryOp(getCurScope(), SavedLoc, SavedKind, Res.get());
     return Res;
@@ -1191,6 +1191,9 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
     if (Tok.isNot(tok::identifier))
       return ExprError(Diag(Tok, diag::err_expected) << tok::identifier);
 
+    if (getLangOpts().OpenCL)
+      return ExprError(Diag(Tok, diag::err_opencl_address_of_label));
+
     if (getCurScope()->getFnParent() == nullptr)
       return ExprError(Diag(Tok, diag::err_address_of_label_outside_fn));
 
@@ -1266,10 +1269,11 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
   case tok::kw_void:
   case tok::kw_typename:
   case tok::kw_typeof:
-  case tok::kw___vector:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
-  {
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
+  case tok::kw___vector: {
     if (!getLangOpts().CPlusPlus) {
       Diag(Tok, diag::err_expected_expression);
       return ExprError();
@@ -1460,7 +1464,7 @@ ExprResult Parser::ParseCastExpression(bool isUnaryExpression,
 
   // These can be followed by postfix-expr pieces.
   Res = ParsePostfixExpressionSuffix(Res);
-  if (getLangOpts().OpenCL)
+  if (getLangOpts().OpenCL && !getLangOpts().CPlusPlus)
     if (Expr *PostfixExpr = Res.get()) {
       QualType Ty = PostfixExpr->getType();
       if (!Ty.isNull() && Ty->isFunctionType()) {
diff --git a/lib/Parse/ParseExprCXX.cpp b/lib/Parse/ParseExprCXX.cpp
index 359bcf9e71..18676db366 100644
--- a/lib/Parse/ParseExprCXX.cpp
+++ b/lib/Parse/ParseExprCXX.cpp
@@ -1117,7 +1117,7 @@ ExprResult Parser::ParseLambdaExpressionAfterIntroducer(
       for (const ParsedAttr &A : Attr)
         if (A.getKind() == ParsedAttr::AT_CUDADevice ||
             A.getKind() == ParsedAttr::AT_CUDAHost ||
-            A.getKind() == ParsedAttr::AT_CUDAGlobal)
+            A.getKind() == ParsedAttr::AT_ComputeKernel)
           Diag(A.getLoc(), diag::warn_cuda_attr_lambda_position)
               << A.getName()->getName();
   };
diff --git a/lib/Parse/ParsePragma.cpp b/lib/Parse/ParsePragma.cpp
index e476c9b0f9..50bd330ef9 100644
--- a/lib/Parse/ParsePragma.cpp
+++ b/lib/Parse/ParsePragma.cpp
@@ -2962,12 +2962,6 @@ void PragmaUnrollHintHandler::HandlePragma(Preprocessor &PP,
     if (ParseLoopHintValue(PP, Tok, PragmaName, Option, ValueInParens, *Info))
       return;
 
-    // In CUDA, the argument to '#pragma unroll' should not be contained in
-    // parentheses.
-    if (PP.getLangOpts().CUDA && ValueInParens)
-      PP.Diag(Info->Toks[0].getLocation(),
-              diag::warn_pragma_unroll_cuda_value_in_parens);
-
     if (Tok.isNot(tok::eod)) {
       PP.Diag(Tok.getLocation(), diag::warn_pragma_extra_tokens_at_eol)
           << "unroll";
diff --git a/lib/Parse/ParseStmtAsm.cpp b/lib/Parse/ParseStmtAsm.cpp
index 9b96c5150e..37a4d9d509 100644
--- a/lib/Parse/ParseStmtAsm.cpp
+++ b/lib/Parse/ParseStmtAsm.cpp
@@ -359,14 +359,6 @@ static bool isTypeQualifier(const Token &Tok) {
   case tok::kw_const:
   case tok::kw_volatile:
   case tok::kw_restrict:
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
     return true;
   }
 }
diff --git a/lib/Parse/ParseTentative.cpp b/lib/Parse/ParseTentative.cpp
index de39e0675f..b527025bdb 100644
--- a/lib/Parse/ParseTentative.cpp
+++ b/lib/Parse/ParseTentative.cpp
@@ -1129,8 +1129,10 @@ Parser::isExpressionOrTypeSpecifierSimple(tok::TokenKind Kind) {
   case tok::kw___pixel:
   case tok::kw___bool:
   case tok::kw__Atomic:
-#define GENERIC_IMAGE_TYPE(ImgType, Id) case tok::kw_##ImgType##_t:
-#include "clang/Basic/OpenCLImageTypes.def"
+  case tok::kw_sampler_t:
+  case tok::kw_event_t:
+  case tok::kw_queue_t:
+  case tok::kw_clk_event_t:
   case tok::kw___unknown_anytype:
     return TPResult::False;
 
@@ -1411,11 +1413,6 @@ Parser::isCXXDeclarationSpecifier(Parser::TPResult BracedCastResult,
     // cv-qualifier
   case tok::kw_const:
   case tok::kw_volatile:
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___generic:
 
     // GNU
   case tok::kw_restrict:
diff --git a/lib/Sema/DeclSpec.cpp b/lib/Sema/DeclSpec.cpp
index 2efa0a7fd1..e1ee245a34 100644
--- a/lib/Sema/DeclSpec.cpp
+++ b/lib/Sema/DeclSpec.cpp
@@ -357,6 +357,11 @@ bool Declarator::isDeclarationOfFunction() const {
     case TST_wchar:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) case TST_##ImgType##_t:
 #include "clang/Basic/OpenCLImageTypes.def"
+    case TST_sampler_t:
+    case TST_event_t:
+    case TST_queue_t:
+    case TST_clk_event_t:
+    case TST_reserve_id_t:
       return false;
 
     case TST_decltype_auto:
@@ -538,6 +543,11 @@ const char *DeclSpec::getSpecifierName(DeclSpec::TST T,
   case DeclSpec::TST_##ImgType##_t: \
     return #ImgType "_t";
 #include "clang/Basic/OpenCLImageTypes.def"
+  case DeclSpec::TST_sampler_t:   return "sampler_t";
+  case DeclSpec::TST_event_t:     return "event_t";
+  case DeclSpec::TST_queue_t:     return "queue_t";
+  case DeclSpec::TST_clk_event_t: return "clk_event_t";
+  case DeclSpec::TST_reserve_id_t: return "reserve_id_t";
   case DeclSpec::TST_error:       return "(error)";
   }
   llvm_unreachable("Unknown typespec!");
diff --git a/lib/Sema/Sema.cpp b/lib/Sema/Sema.cpp
index a8e3b85fe0..310e4a00e4 100644
--- a/lib/Sema/Sema.cpp
+++ b/lib/Sema/Sema.cpp
@@ -117,6 +117,7 @@ public:
 Sema::Sema(Preprocessor &pp, ASTContext &ctxt, ASTConsumer &consumer,
            TranslationUnitKind TUKind, CodeCompleteConsumer *CodeCompleter)
     : ExternalSource(nullptr), isMultiplexExternalSource(false),
+      OpenCLFeatures(ctxt.getOpenCLFeatures()),
       FPFeatures(pp.getLangOpts()), LangOpts(pp.getLangOpts()), PP(pp),
       Context(ctxt), Consumer(consumer), Diags(PP.getDiagnostics()),
       SourceMgr(PP.getSourceManager()), CollectStats(false),
@@ -258,6 +259,11 @@ void Sema::Initialize() {
   if (getLangOpts().OpenCL) {
     getOpenCLOptions().addSupport(Context.getTargetInfo().getSupportedOpenCLOpts());
     getOpenCLOptions().enableSupportedCore(getLangOpts().OpenCLVersion);
+
+#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
+    addImplicitTypedef(#ImgType #Suffix "_t", Context. SingletonId);
+#include "clang/Basic/OpenCLImageTypes.def"
+
     addImplicitTypedef("sampler_t", Context.OCLSamplerTy);
     addImplicitTypedef("event_t", Context.OCLEventTy);
     if (getLangOpts().OpenCLVersion >= 200) {
diff --git a/lib/Sema/SemaAttr.cpp b/lib/Sema/SemaAttr.cpp
index f6ac9b44a8..3aa17efac2 100644
--- a/lib/Sema/SemaAttr.cpp
+++ b/lib/Sema/SemaAttr.cpp
@@ -785,6 +785,7 @@ void Sema::ActOnPragmaFPContract(LangOptions::FPContractModeKind FPC) {
     break;
   case LangOptions::FPC_Off:
     FPFeatures.setDisallowFPContract();
+    Context.disableFPContract();
     break;
   }
 }
diff --git a/lib/Sema/SemaCUDA.cpp b/lib/Sema/SemaCUDA.cpp
index 13dd8d936f..021b9decf6 100644
--- a/lib/Sema/SemaCUDA.cpp
+++ b/lib/Sema/SemaCUDA.cpp
@@ -63,7 +63,7 @@ Sema::IdentifyCUDATarget(const ParsedAttributesView &Attrs) {
   bool HasInvalidTargetAttr = false;
   for (const ParsedAttr &AL : Attrs) {
     switch (AL.getKind()) {
-    case ParsedAttr::AT_CUDAGlobal:
+    case ParsedAttr::AT_ComputeKernel:
       HasGlobalAttr = true;
       break;
     case ParsedAttr::AT_CUDAHost:
@@ -113,22 +113,13 @@ Sema::CUDAFunctionTarget Sema::IdentifyCUDATarget(const FunctionDecl *D,
   if (D->hasAttr<CUDAInvalidTargetAttr>())
     return CFT_InvalidTarget;
 
-  if (D->hasAttr<CUDAGlobalAttr>())
+  if (D->hasAttr<ComputeKernelAttr>())
     return CFT_Global;
 
-  if (hasAttr<CUDADeviceAttr>(D, IgnoreImplicitHDAttr)) {
-    if (hasAttr<CUDAHostAttr>(D, IgnoreImplicitHDAttr))
-      return CFT_HostDevice;
-    return CFT_Device;
-  } else if (hasAttr<CUDAHostAttr>(D, IgnoreImplicitHDAttr)) {
-    return CFT_Host;
-  } else if (D->isImplicit() && !IgnoreImplicitHDAttr) {
-    // Some implicit declarations (like intrinsic functions) are not marked.
-    // Set the most lenient target on them for maximal flexibility.
-    return CFT_HostDevice;
-  }
-
-  return CFT_Host;
+  // if not a kernel, always default to device
+  // this is IMO a much saner approach and doesn't require to add the __device__
+  // attribute to _all_ functions
+  return CFT_Device;
 }
 
 // * CUDA Call preference table
@@ -376,16 +367,16 @@ bool Sema::inferCUDATargetForImplicitSpecialMember(CXXRecordDecl *ClassDecl,
     if (InferredTarget.getValue() == CFT_Device) {
       MemberDecl->addAttr(CUDADeviceAttr::CreateImplicit(Context));
     } else if (InferredTarget.getValue() == CFT_Host) {
-      MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
+      //MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
     } else {
       MemberDecl->addAttr(CUDADeviceAttr::CreateImplicit(Context));
-      MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
+      //MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
     }
   } else {
     // If no target was inferred, mark this member as __host__ __device__;
     // it's the least restrictive option that can be invoked from any target.
     MemberDecl->addAttr(CUDADeviceAttr::CreateImplicit(Context));
-    MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
+    //MemberDecl->addAttr(CUDAHostAttr::CreateImplicit(Context));
   }
 
   return false;
@@ -543,8 +534,8 @@ void Sema::maybeAddCUDAHostDeviceAttrs(FunctionDecl *NewD,
   assert(getLangOpts().CUDA && "Should only be called during CUDA compilation");
 
   if (ForceCUDAHostDeviceDepth > 0) {
-    if (!NewD->hasAttr<CUDAHostAttr>())
-      NewD->addAttr(CUDAHostAttr::CreateImplicit(Context));
+    //if (!NewD->hasAttr<CUDAHostAttr>())
+    //  NewD->addAttr(CUDAHostAttr::CreateImplicit(Context));
     if (!NewD->hasAttr<CUDADeviceAttr>())
       NewD->addAttr(CUDADeviceAttr::CreateImplicit(Context));
     return;
@@ -552,7 +543,7 @@ void Sema::maybeAddCUDAHostDeviceAttrs(FunctionDecl *NewD,
 
   if (!getLangOpts().CUDAHostDeviceConstexpr || !NewD->isConstexpr() ||
       NewD->isVariadic() || NewD->hasAttr<CUDAHostAttr>() ||
-      NewD->hasAttr<CUDADeviceAttr>() || NewD->hasAttr<CUDAGlobalAttr>())
+      NewD->hasAttr<CUDADeviceAttr>() || NewD->hasAttr<ComputeKernelAttr>())
     return;
 
   // Is D a __device__ function with the same signature as NewD, ignoring CUDA
@@ -583,7 +574,7 @@ void Sema::maybeAddCUDAHostDeviceAttrs(FunctionDecl *NewD,
     return;
   }
 
-  NewD->addAttr(CUDAHostAttr::CreateImplicit(Context));
+  //NewD->addAttr(CUDAHostAttr::CreateImplicit(Context));
   NewD->addAttr(CUDADeviceAttr::CreateImplicit(Context));
 }
 
@@ -908,7 +899,7 @@ void Sema::CUDASetLambdaAttrs(CXXMethodDecl *Method) {
     Method->addAttr(CUDADeviceAttr::CreateImplicit(Context));
   } else if (Target == CFT_HostDevice) {
     Method->addAttr(CUDADeviceAttr::CreateImplicit(Context));
-    Method->addAttr(CUDAHostAttr::CreateImplicit(Context));
+    //Method->addAttr(CUDAHostAttr::CreateImplicit(Context));
   }
 }
 
@@ -954,7 +945,7 @@ static void copyAttrIfPresent(Sema &S, FunctionDecl *FD,
 void Sema::inheritCUDATargetAttrs(FunctionDecl *FD,
                                   const FunctionTemplateDecl &TD) {
   const FunctionDecl &TemplateFD = *TD.getTemplatedDecl();
-  copyAttrIfPresent<CUDAGlobalAttr>(*this, FD, TemplateFD);
+  copyAttrIfPresent<ComputeKernelAttr>(*this, FD, TemplateFD);
   copyAttrIfPresent<CUDAHostAttr>(*this, FD, TemplateFD);
   copyAttrIfPresent<CUDADeviceAttr>(*this, FD, TemplateFD);
 }
diff --git a/lib/Sema/SemaCast.cpp b/lib/Sema/SemaCast.cpp
index 0b4645e11c..53aea1ebb2 100644
--- a/lib/Sema/SemaCast.cpp
+++ b/lib/Sema/SemaCast.cpp
@@ -616,7 +616,7 @@ CastsAwayConstness(Sema &Self, QualType SrcType, QualType DestType,
           *CastAwayQualifiers = SrcCvrQuals - DestCvrQuals;
 
         // If we removed a cvr-qualifier, this is casting away 'constness'.
-        if (!DestCvrQuals.compatiblyIncludes(SrcCvrQuals)) {
+        if (!DestCvrQuals.compatiblyIncludes(SrcCvrQuals, false)) {
           if (TheOffendingSrcType)
             *TheOffendingSrcType = PrevUnwrappedSrcType;
           if (TheOffendingDestType)
@@ -1048,6 +1048,7 @@ void CastOperation::CheckStaticCast() {
 }
 
 static bool IsAddressSpaceConversion(QualType SrcType, QualType DestType) {
+#if 0 // we don't want this
   auto *SrcPtrType = SrcType->getAs<PointerType>();
   if (!SrcPtrType)
     return false;
@@ -1056,6 +1057,9 @@ static bool IsAddressSpaceConversion(QualType SrcType, QualType DestType) {
     return false;
   return SrcPtrType->getPointeeType().getAddressSpace() !=
          DestPtrType->getPointeeType().getAddressSpace();
+#else
+  return false;
+#endif
 }
 
 /// TryStaticCast - Check if a static cast can be performed, and do so if
@@ -2651,6 +2655,12 @@ void CastOperation::CheckCStyleCast() {
       SrcExpr = ExprError();
       return;
     }
+    if (SrcExpr.get()->getType()->isHalfType()) {
+      Self.Diag(SrcExpr.get()->getBeginLoc(), diag::err_opencl_cast_from_half)
+        << SrcType << SrcExpr.get()->getSourceRange();
+      SrcExpr = ExprError();
+      return;
+    }
   }
 
   // ARC imposes extra restrictions on casts.
diff --git a/lib/Sema/SemaChecking.cpp b/lib/Sema/SemaChecking.cpp
index 46cac25eed..7f058c1d87 100644
--- a/lib/Sema/SemaChecking.cpp
+++ b/lib/Sema/SemaChecking.cpp
@@ -631,9 +631,11 @@ static bool SemaOpenCLBuiltinEnqueueKernel(Sema &S, CallExpr *TheCall) {
   return true;
 }
 
-/// Returns OpenCL access qual.
-static OpenCLAccessAttr *getOpenCLArgAccess(const Decl *D) {
-    return D->getAttr<OpenCLAccessAttr>();
+/// Returns libfloor (OpenCL/Metal/Vulkan) access qual.
+static ImageAccessAttr *getImageArgAccess(const Decl *D) {
+  if (D->hasAttr<ImageAccessAttr>())
+    return D->getAttr<ImageAccessAttr>();
+  return nullptr;
 }
 
 /// Returns true if pipe element type is different from the pointer.
@@ -645,8 +647,8 @@ static bool checkOpenCLPipeArg(Sema &S, CallExpr *Call) {
         << Call->getDirectCallee() << Arg0->getSourceRange();
     return true;
   }
-  OpenCLAccessAttr *AccessQual =
-      getOpenCLArgAccess(cast<DeclRefExpr>(Arg0)->getDecl());
+  ImageAccessAttr *AccessQual =
+      getImageArgAccess(cast<DeclRefExpr>(Arg0)->getDecl());
   // Validates the access qualifier is compatible with the call.
   // OpenCL v2.0 s6.13.16 - The access qualifiers for pipe should only be
   // read_only and write_only, and assumed to be read_only if no qualifier is
@@ -1553,6 +1555,42 @@ static QualType getNeonEltType(NeonTypeFlags Flags, ASTContext &Context,
   llvm_unreachable("Invalid NeonTypeFlag!");
 }
 
+static void checkAccessModifier(Sema &S, ImageAccessAttr* Actual,
+                                ImageAccessAttr* Expected, QualType Ty,
+                                SourceLocation Loc, SourceRange Range) {
+  // We allow two types of conversions:
+  // a) anything -> unkown
+  // b) unkown -> read_only
+  if (!Expected || (!Actual && Expected->isReadOnly()))
+    return;
+
+  if (Actual->getSemanticSpelling() == Expected->getSemanticSpelling())
+    return;
+
+  if (Ty->isImageType()) {
+    if (Actual->isReadWrite() || Expected->isReadWrite())
+      return;
+
+    // We assume that the type declaration has some access qualifier, since it
+    // is mandatory. Not doing so should result a syntax error.
+    S.Diag(Loc, diag::err_mismatch_access_qualifiers) <<
+          Actual << Expected << Range;
+    return;
+  }
+
+  if (Ty->isPipeType()) {
+    // Pipe qualifier defaults to read_only.
+    if((!Actual && Expected->isReadOnly()))
+      return;
+
+    // Since read_write is illegal for pipes, we need strict equality.
+    S.Diag(Loc, diag::err_mismatch_access_qualifiers) <<
+          Actual << Expected << Range;
+    return;
+  }
+}
+
+
 bool Sema::CheckNeonBuiltinFunctionCall(unsigned BuiltinID, CallExpr *TheCall) {
   llvm::APSInt Result;
   uint64_t mask = 0;
@@ -4188,6 +4226,47 @@ void Sema::checkCall(NamedDecl *FDecl, const FunctionProtoType *Proto,
 
   if (FD)
     diagnoseArgDependentDiagnoseIfAttrs(FD, ThisArg, Args, Loc);
+
+  // We don't treat variadic functions, since we can't match the access modifier
+  // in the function declaration.
+  if (!getLangOpts().OpenCL || VariadicDoesNotApply != CallType)
+    return;
+
+  if (!FDecl || !isa<FunctionDecl>(FDecl))
+    return;
+
+  const FunctionDecl *FnDecl = cast<FunctionDecl>(FDecl);
+
+  // Check if overloadble built-in function with floating point arguments takes
+  // integer values.
+  if (FnDecl->hasAttr<OverloadableAttr>()) {
+    for (unsigned Idx = 0; Idx < Args.size(); Idx++) {
+      const Expr *Arg = Args[Idx];
+      const ImplicitCastExpr *ICE = dyn_cast<ImplicitCastExpr>(Arg);
+      if (!ICE || ICE->getCastKind() != CK_IntegralToFloating)
+        continue;
+      Diag(Loc, diag::warn_ocl_bultin_potential_ambiguity) << Range;
+    }
+  }
+
+  // This may indicate that this is a builtin function call, which will be
+  // treated by another part of Sema. (e.g., PipeBiCallSema).
+  if (FnDecl->getNumParams() != Args.size())
+    return;
+
+  // Check whether access attribute are respected.
+  for (unsigned Idx = 0; Idx < Args.size(); Idx++) {
+    const Expr *Arg = Args[Idx];
+    ImageAccessAttr* Expected = getImageArgAccess(FnDecl->getParamDecl(Idx));
+    ImageAccessAttr* Actual = nullptr;
+
+    if (const DeclRefExpr *RefArg = dyn_cast<DeclRefExpr>(Arg->IgnoreImpCasts()))
+      Actual = getImageArgAccess(RefArg->getDecl());
+
+    // Checking that the expected access modifier and the actual one match.
+    checkAccessModifier(*this, Actual, Expected, Arg->getType(),
+                        Arg->getExprLoc(), Range);
+  }
 }
 
 /// CheckConstructorCall - Check a constructor call for correctness and safety
@@ -4243,6 +4322,18 @@ bool Sema::CheckFunctionCall(FunctionDecl *FDecl, CallExpr *TheCall,
   if (getLangOpts().ObjC)
     DiagnoseCStringFormatDirectiveInCFAPI(*this, FDecl, Args, NumArgs);
 
+  // OpenCL 2.0 Sec. 6.6 prohibits images with 'read_write' qualifier to read
+  // using a sampler.
+  // FIXME: this code is buggy - there should be additional check that TheCall
+  // is OpenCL built-in function call.
+  //if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+  //  if (checkOpenCLRead(TheCall)) {
+  //    Diag(TheCall->getBeginLoc(), diag::err_read_write_with_samplers) <<
+  //    TheCall->getSourceRange();
+  //    return true;
+  //  }
+  //}
+
   unsigned CMId = FDecl->getMemoryFunctionKind();
   if (CMId == 0)
     return false;
diff --git a/lib/Sema/SemaDecl.cpp b/lib/Sema/SemaDecl.cpp
index 6dab332f4f..d699404b60 100644
--- a/lib/Sema/SemaDecl.cpp
+++ b/lib/Sema/SemaDecl.cpp
@@ -2466,7 +2466,7 @@ static bool mergeDeclAttribute(Sema &S, NamedDecl *D,
                                       AttrSpellingListIndex);
   else if (S.getLangOpts().CUDA && isa<FunctionDecl>(D) &&
            (isa<CUDAHostAttr>(Attr) || isa<CUDADeviceAttr>(Attr) ||
-            isa<CUDAGlobalAttr>(Attr))) {
+            isa<ComputeKernelAttr>(Attr))) {
     // CUDA target attributes are part of function signature for
     // overloading purposes and must not be merged.
     return false;
@@ -2603,6 +2603,12 @@ static void checkNewAttributesAfterDef(Sema &S, Decl *New, const Decl *Old) {
       }
     }
 
+    if (isa<CUDADeviceAttr>(NewAttribute)) {
+      // since we're always compiling device code, but the device attr might not always be present (yet), allow this
+      ++I;
+      continue;
+    }
+
     S.Diag(NewAttribute->getLocation(),
            diag::warn_attribute_precede_definition);
     S.Diag(Def->getLocation(), diag::note_previous_definition);
@@ -3194,8 +3200,10 @@ bool Sema::MergeFunctionDecl(FunctionDecl *New, NamedDecl *&OldD,
     AdjustedType = Context.adjustFunctionType(AdjustedType, NewTypeInfo);
 
     QualType AdjustedQT = QualType(AdjustedType, 0);
+#if 0 // we don't want this
     LangAS AS = Old->getType().getAddressSpace();
     AdjustedQT = Context.getAddrSpaceQualType(AdjustedQT, AS);
+#endif
 
     New->setType(AdjustedQT);
     NewQType = Context.getCanonicalType(New->getType());
@@ -4397,6 +4405,10 @@ Sema::ParsedFreeStandingDeclSpec(Scope *S, AccessSpecifier AS, DeclSpec &DS,
   //   names into the program, or shall redeclare a name introduced by a
   //   previous declaration.
   if (!DeclaresAnything) {
+    if (getLangOpts().OpenCL) {
+      Diag(DS.getBeginLoc(), diag::err_no_declarators) << DS.getSourceRange();
+      return 0;
+    }
     // In C, we allow this as a (popular) extension / bug. Don't bother
     // producing further diagnostics for redundant qualifiers after this.
     Diag(DS.getBeginLoc(), diag::ext_no_declarators) << DS.getSourceRange();
@@ -6307,7 +6319,7 @@ NamedDecl *Sema::ActOnVariableDeclarator(
     // The event type cannot be used to declare a program scope variable.
     // OpenCL v2.0 s6.9.q:
     // The clk_event_t and reserve_id_t types cannot be declared in program scope.
-    if (NULL == S->getParent()) {
+    if (nullptr == S->getParent()) {
       if (R->isReserveIDT() || R->isClkEventT() || R->isEventT()) {
         Diag(D.getIdentifierLoc(),
              diag::err_invalid_type_for_program_scope_var) << R;
@@ -6316,10 +6328,32 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       }
     }
 
+    // OpenCL v1.2 s6.5 p5
+    // There is no generic address space name for program scope variables.
+    // All program scope variables must be declared in the __constant address space.
+    if (getLangOpts().OpenCL && !S->getParent() &&
+        LangAS::opencl_constant != R.getAddressSpace()) {
+      // One exception is the sampler_t which can be declared as "const" instead
+      // of "__constant" address space.
+      if (R->isSamplerT() && R.isConstant(Context));
+      else if (R->isOpenCLSpecificType()) {
+        Diag(D.getIdentifierLoc(), diag::err_invalid_type_for_program_scope_var)
+            << R;
+        D.setInvalidType();
+      } else if (getLangOpts().OpenCLVersion < 200) {
+          Diag(D.getIdentifierLoc(), diag::err_program_scope_variable_non_constant);
+          D.setInvalidType();
+      } else if (LangAS::opencl_global != R.getAddressSpace()) {
+        Diag(D.getIdentifierLoc(),
+               diag::err_program_scope_variable_non_constant_or_global);
+        D.setInvalidType();
+      }
+    }
+
     // OpenCL v1.0 s6.8.a.3: Pointers to functions are not allowed.
     QualType NR = R;
     while (NR->isPointerType()) {
-      if (NR->isFunctionPointerType()) {
+      if (NR->isFunctionPointerType() && !getLangOpts().CPlusPlus) {
         Diag(D.getIdentifierLoc(), diag::err_opencl_function_pointer);
         D.setInvalidType();
         break;
@@ -6392,7 +6426,7 @@ NamedDecl *Sema::ActOnVariableDeclarator(
     SC = SC_Extern;
 
   DeclContext *OriginalDC = DC;
-  bool IsLocalExternDecl = SC == SC_Extern &&
+  bool IsLocalExternDecl = (SC == SC_Extern || SC == SC_OpenCLConstantExtern) &&
                            adjustContextForLocalExternDecl(DC);
 
   if (SCSpec == DeclSpec::SCS_mutable) {
@@ -6427,6 +6461,32 @@ NamedDecl *Sema::ActOnVariableDeclarator(
     }
   }
 
+  if (getLangOpts().OpenCL) {
+    // OpenCL v1.2 s6.9.b p4:
+    // The sampler type cannot be used with the __local and __global address
+    // space qualifiers.
+    if (R->isSamplerT() && (R.getAddressSpace() == LangAS::opencl_local ||
+      R.getAddressSpace() == LangAS::opencl_global)) {
+      Diag(D.getIdentifierLoc(), diag::err_wrong_sampler_addressspace);
+    }
+    if (R.getAddressSpace() == LangAS::opencl_constant) {
+      if (SC == SC_Extern)
+        SC = SC_OpenCLConstantExtern;
+      else
+        SC = SC_OpenCLConstant;
+    }
+
+    // OpenCL 1.2 spec, p6.9 r:
+    // The event type cannot be used with the __local, __constant and __global
+    // address space qualifiers.
+    if (R->isEventT()) {
+      if (R.getAddressSpace() != LangAS::Default) {
+        Diag(D.getBeginLoc(), diag::err_event_t_addr_space_qual);
+        D.setInvalidType();
+      }
+    }
+  }
+
   bool IsMemberSpecialization = false;
   bool IsVariableTemplateSpecialization = false;
   bool IsPartialSpecialization = false;
@@ -6450,6 +6510,8 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       // This is an out-of-line definition of a static data member.
       switch (SC) {
       case SC_None:
+      case SC_OpenCLConstant:
+      case SC_OpenCLConstantExtern:
         break;
       case SC_Static:
         Diag(D.getDeclSpec().getStorageClassSpecLoc(),
@@ -6759,6 +6821,8 @@ NamedDecl *Sema::ActOnVariableDeclarator(
       case SC_Static:
       case SC_Extern:
       case SC_PrivateExtern:
+      case SC_OpenCLConstant:
+      case SC_OpenCLConstantExtern:
         break;
       }
     } else if (SC == SC_Register) {
@@ -7329,11 +7393,27 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
 
   // OpenCL v1.2 s6.8 - The static qualifier is valid only in program
   // scope.
-  if (getLangOpts().OpenCLVersion == 120 &&
-      !getOpenCLOptions().isEnabled("cl_clang_storage_class_specifiers") &&
-      NewVD->isStaticLocal()) {
-    Diag(NewVD->getLocation(), diag::err_static_function_scope);
-    NewVD->setInvalidDecl();
+  // (same for Metal, enabled for CUDA as well for compatibility)
+  if (NewVD->isStaticLocal() &&
+      ((getLangOpts().OpenCL &&
+        getLangOpts().OpenCLVersion >= 120 &&
+        !getOpenCLOptions().isEnabled("cl_clang_storage_class_specifiers")) ||
+       getLangOpts().CUDA)) {
+    // however, if it is constexpr, this can be safely put into the constant address space
+    if (NewVD->isConstexpr()) {
+      // CUDA (backend) can handle this on its own
+      if (getLangOpts().OpenCL) {
+        QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+        TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+        NewVD->setType(constant_Tinfo->getType());
+        NewVD->setTypeSourceInfo(constant_Tinfo);
+      }
+    }
+    // CUDA shared/local decls are allowed to be static, so ignore them
+    else if(!(getLangOpts().CUDA && NewVD->hasAttr<CUDASharedAttr>())) {
+      Diag(NewVD->getLocation(), diag::err_static_function_scope);
+      NewVD->setInvalidDecl();
+    }
     return;
   }
 
@@ -7359,23 +7439,46 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
         return;
       }
     }
-    // OpenCL C v1.2 s6.5 - All program scope variables must be declared in the
-    // __constant address space.
-    // OpenCL C v2.0 s6.5.1 - Variables defined at program scope and static
-    // variables inside a function can also be declared in the global
-    // address space.
-    // OpenCL C++ v1.0 s2.5 inherits rule from OpenCL C v2.0 and allows local
-    // address space additionally.
-    // FIXME: Add local AS for OpenCL C++.
-    if (NewVD->isFileVarDecl() || NewVD->isStaticLocal() ||
-        NewVD->hasExternalStorage()) {
-      if (!T->isSamplerT() &&
+    if (NewVD->isFileVarDecl() /*|| NewVD->isStaticLocal() ||
+        NewVD->hasExternalStorage()*/) {
+      if (!T->isSamplerT()) {
+        // if the variable doesn't have an address space, but is a global static const variable,
+        // automatically add the constant address space
+        if ((T.getAddressSpace() == LangAS::Default || T.getAddressSpace() == LangAS::opencl_private) &&
+            (NewVD->isStaticDataMember() || NewVD->hasGlobalStorage()) &&
+            T.isConstQualified()) {
+          QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+          TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+          NewVD->setType(constant_Tinfo->getType());
+          NewVD->setTypeSourceInfo(constant_Tinfo);
+        } else {
+          int Scope = NewVD->isStaticLocal() | NewVD->hasExternalStorage() << 1;
+          if (!(T.getAddressSpace() == LangAS::opencl_constant ||
+                (T.getAddressSpace() == LangAS::opencl_global &&
+                 getLangOpts().OpenCLVersion >= 200))) {
+            if (getLangOpts().OpenCLVersion >= 200)
+              Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
+                  << Scope << "global or constant";
+            else
+              Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
+                  << Scope << "constant";
+            NewVD->setInvalidDecl();
+            return;
+          }
+        }
+      }
+    } else {
+      // TODO: does this need automatic "constant" handling?
+
+      // OpenCL v2.0 s6.5.1 - Variables defined at program scope and static
+      // variables inside a function can also be declared in the global
+      // address space.
+      int Scope = NewVD->isStaticLocal() | NewVD->hasExternalStorage() << 1;
+      if (NewVD->isStaticLocal() &&
           !(T.getAddressSpace() == LangAS::opencl_constant ||
             (T.getAddressSpace() == LangAS::opencl_global &&
-             (getLangOpts().OpenCLVersion == 200 ||
-              getLangOpts().OpenCLCPlusPlus)))) {
-        int Scope = NewVD->isStaticLocal() | NewVD->hasExternalStorage() << 1;
-        if (getLangOpts().OpenCLVersion == 200 || getLangOpts().OpenCLCPlusPlus)
+             getLangOpts().OpenCLVersion >= 200))) {
+        if (getLangOpts().OpenCLVersion >= 200)
           Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space)
               << Scope << "global or constant";
         else
@@ -7384,19 +7487,14 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
         NewVD->setInvalidDecl();
         return;
       }
-    } else {
-      if (T.getAddressSpace() == LangAS::opencl_global) {
-        Diag(NewVD->getLocation(), diag::err_opencl_function_variable)
-            << 1 /*is any function*/ << "global";
-        NewVD->setInvalidDecl();
-        return;
-      }
+
+      // OpenCL v1.1 s6.5.2 and s6.5.3 no local or constant variables
+      // in functions.
+#if 0 // everything gets inlined, so there is no need for this
       if (T.getAddressSpace() == LangAS::opencl_constant ||
           T.getAddressSpace() == LangAS::opencl_local) {
         FunctionDecl *FD = getCurFunctionDecl();
-        // OpenCL v1.1 s6.5.2 and s6.5.3: no local or constant variables
-        // in functions.
-        if (FD && !FD->hasAttr<OpenCLKernelAttr>()) {
+        if (FD && !FD->hasAttr<ComputeKernelAttr>()) {
           if (T.getAddressSpace() == LangAS::opencl_constant)
             Diag(NewVD->getLocation(), diag::err_opencl_function_variable)
                 << 0 /*non-kernel only*/ << "constant";
@@ -7408,14 +7506,14 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
         }
         // OpenCL v2.0 s6.5.2 and s6.5.3: local and constant variables must be
         // in the outermost scope of a kernel function.
-        if (FD && FD->hasAttr<OpenCLKernelAttr>()) {
+        if (FD && FD->hasAttr<ComputeKernelAttr>()) {
           if (!getCurScope()->isFunctionScope()) {
             if (T.getAddressSpace() == LangAS::opencl_constant)
               Diag(NewVD->getLocation(), diag::err_opencl_addrspace_scope)
-                  << "constant";
+                  << Scope << "constant";
             else
               Diag(NewVD->getLocation(), diag::err_opencl_addrspace_scope)
-                  << "local";
+                  << Scope << "local";
             NewVD->setInvalidDecl();
             return;
           }
@@ -7426,6 +7524,7 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
         NewVD->setInvalidDecl();
         return;
       }
+#endif
     }
   }
 
@@ -7521,6 +7620,24 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
     NewVD->setInvalidDecl();
     return;
   }
+
+  // OpenCL 2.0: Enforce block 6.12.5: block's prototype cannot be variadic.
+  if (getLangOpts().OpenCL && LangOpts.OpenCLVersion >= 200 && T->isBlockPointerType()) {
+    const BlockPointerType *BlkTy = T->getAs<BlockPointerType>();
+    assert(BlkTy && "Not a block pointer.");
+
+    const FunctionProtoType *FTy =
+      BlkTy->getPointeeType()->getAs<FunctionProtoType>();
+    assert(FTy && "Not a function prototype.");
+
+    if (FTy->isVariadic()) {
+      Diag(NewVD->getLocation(), diag::err_block_proto_variadic) << T
+      << NewVD->getSourceRange();
+      NewVD->setInvalidDecl();
+      return;
+    }
+
+  }
 }
 
 /// Perform semantic checking on a newly-created variable
@@ -8066,16 +8183,16 @@ static bool isOpenCLSizeDependentType(ASTContext &C, QualType Ty) {
   return false;
 }
 
-static OpenCLParamType getOpenCLKernelParameterType(Sema &S, QualType PT) {
+static OpenCLParamType getOpenCLKernelParameterType(Sema &S, QualType PT, const bool is_metal) {
   if (PT->isPointerType()) {
     QualType PointeeType = PT->getPointeeType();
     if (PointeeType->isPointerType())
       return PtrPtrKernelParam;
-    if (PointeeType.getAddressSpace() == LangAS::opencl_generic ||
-        PointeeType.getAddressSpace() == LangAS::opencl_private ||
-        PointeeType.getAddressSpace() == LangAS::Default)
-      return InvalidAddrSpacePtrKernelParam;
-    return PtrKernelParam;
+
+    auto addrSpace = PointeeType.getAddressSpace();
+    return (addrSpace != LangAS::opencl_global &&
+            addrSpace != LangAS::opencl_constant &&
+            addrSpace != LangAS::opencl_local) ? InvalidAddrSpacePtrKernelParam : PtrKernelParam;
   }
 
   // OpenCL v1.2 s6.9.k:
@@ -8095,7 +8212,13 @@ static OpenCLParamType getOpenCLKernelParameterType(Sema &S, QualType PT) {
   // OpenCL extension spec v1.2 s9.5:
   // This extension adds support for half scalar and vector types as built-in
   // types that can be used for arithmetic operations, conversions etc.
-  if (!S.getOpenCLOptions().isEnabled("cl_khr_fp16") && PT->isHalfType())
+  if (!S.getOpenCLOptions().isEnabled("cl_khr_fp16") && PT->isHalfType() && !is_metal)
+    return InvalidKernelParam;
+
+  if (PT->isEventT())
+    return InvalidKernelParam;
+
+  if (PT->isReserveIDT())
     return InvalidKernelParam;
 
   if (PT->isRecordType())
@@ -8107,7 +8230,7 @@ static OpenCLParamType getOpenCLKernelParameterType(Sema &S, QualType PT) {
     // Call ourself to check an underlying type of an array. Since the
     // getPointeeOrArrayElementType returns an innermost type which is not an
     // array, this recursive call only happens once.
-    return getOpenCLKernelParameterType(S, QualType(UnderlyingTy, 0));
+    return getOpenCLKernelParameterType(S, QualType(UnderlyingTy, 0), is_metal);
   }
 
   return ValidKernelParam;
@@ -8117,7 +8240,8 @@ static void checkIsValidOpenCLKernelParameter(
   Sema &S,
   Declarator &D,
   ParmVarDecl *Param,
-  llvm::SmallPtrSetImpl<const Type *> &ValidTypes) {
+  llvm::SmallPtrSetImpl<const Type *> &ValidTypes,
+  const bool is_metal) {
   QualType PT = Param->getType();
 
   // Cache the valid types we encounter to avoid rechecking structs that are
@@ -8125,7 +8249,7 @@ static void checkIsValidOpenCLKernelParameter(
   if (ValidTypes.count(PT.getTypePtr()))
     return;
 
-  switch (getOpenCLKernelParameterType(S, PT)) {
+  switch (getOpenCLKernelParameterType(S, PT, is_metal)) {
   case PtrPtrKernelParam:
     // OpenCL v1.2 s6.9.a:
     // A kernel function argument cannot be declared as a
@@ -8210,6 +8334,8 @@ static void checkIsValidOpenCLKernelParameter(
       continue;
     }
 
+    // TODO: this should also check base classes
+
     // Adds everything except the original parameter declaration (which is not a
     // field itself) to the history stack.
     const RecordDecl *RD;
@@ -8231,13 +8357,17 @@ static void checkIsValidOpenCLKernelParameter(
     // Add a null marker so we know when we've gone back up a level
     VisitStack.push_back(nullptr);
 
+    // if this is an aggregate of images, all is well
+    if (RD->getTypeForDecl()->isAggregateImageType())
+      continue;
+
     for (const auto *FD : RD->fields()) {
       QualType QT = FD->getType();
 
       if (ValidTypes.count(QT.getTypePtr()))
         continue;
 
-      OpenCLParamType ParamType = getOpenCLKernelParameterType(S, QT);
+      OpenCLParamType ParamType = getOpenCLKernelParameterType(S, QT, is_metal);
       if (ParamType == ValidKernelParam)
         continue;
 
@@ -8802,6 +8932,7 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
   // Handle attributes.
   ProcessDeclAttributes(S, NewFD, D);
 
+#if 0 // nope
   if (getLangOpts().OpenCL) {
     // OpenCL v1.1 s6.5: Using an address space qualifier in a function return
     // type declaration will generate a compilation error.
@@ -8812,6 +8943,7 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
       NewFD->setInvalidDecl();
     }
   }
+#endif
 
   if (!getLangOpts().CPlusPlus) {
     // Perform semantic checking on the function declaration.
@@ -9158,7 +9290,7 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
     // -fcuda-allow-variadic-functions.
     if (!getLangOpts().CUDAAllowVariadicFunctions && NewFD->isVariadic() &&
         (NewFD->hasAttr<CUDADeviceAttr>() ||
-         NewFD->hasAttr<CUDAGlobalAttr>()) &&
+         NewFD->hasAttr<ComputeKernelAttr>()) &&
         !(II && II->isStr("printf") && NewFD->isExternC() &&
           !D.isFunctionDefinition())) {
       Diag(NewFD->getLocation(), diag::err_variadic_device_fn);
@@ -9178,15 +9310,8 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
       CompleteMemberSpecialization(NewFD, Previous);
   }
 
-  if (NewFD->hasAttr<OpenCLKernelAttr>()) {
-    // OpenCL v1.2 s6.8 static is invalid for kernel functions.
-    if ((getLangOpts().OpenCLVersion >= 120)
-        && (SC == SC_Static)) {
-      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
-      D.setInvalidType();
-    }
-
-    // OpenCL v1.2, s6.9 -- Kernels can only have return type void.
+  if (NewFD->hasAttr<ComputeKernelAttr>()) {
+    // Kernels can only have return type void.
     if (!NewFD->getReturnType()->isVoidType()) {
       SourceRange RTRange = NewFD->getReturnTypeSourceRange();
       Diag(D.getIdentifierLoc(), diag::err_expected_kernel_void_return_type)
@@ -9194,10 +9319,23 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
                                 : FixItHint());
       D.setInvalidType();
     }
+  }
 
-    llvm::SmallPtrSet<const Type *, 16> ValidTypes;
-    for (auto Param : NewFD->parameters())
-      checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes);
+  if(NewFD->hasAttr<ComputeKernelAttr>() ||
+     NewFD->hasAttr<GraphicsVertexShaderAttr>() ||
+     NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    // static is invalid for kernel/vertex/fragment functions.
+    if (SC == SC_Static) {
+      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
+      D.setInvalidType();
+    }
+
+    // only check this for opencl/metal/vulkan
+    if (getLangOpts().OpenCL) {
+      llvm::SmallPtrSet<const Type *, 16> ValidTypes;
+      for (auto Param : NewFD->parameters())
+        checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes, getLangOpts().Metal);
+    }
   }
   for (const ParmVarDecl *Param : NewFD->parameters()) {
     QualType PT = Param->getType();
@@ -10225,7 +10363,10 @@ bool Sema::CheckFunctionDeclaration(Scope *S, FunctionDecl *NewFD,
     // the function returns a UDT (class, struct, or union type) that is not C
     // compatible, and if it does, warn the user.
     // But, issue any diagnostic on the first declaration only.
-    if (Previous.empty() && NewFD->isExternC()) {
+    if (Previous.empty() && NewFD->isExternC() &&
+        // ignore this for vertex/fragment shaders
+        !NewFD->hasAttr<GraphicsVertexShaderAttr>() &&
+        !NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
       QualType R = NewFD->getReturnType();
       if (R->isIncompleteType() && !R->isVoidType())
         Diag(NewFD->getLocation(), diag::warn_return_value_udt_incomplete)
@@ -10305,9 +10446,10 @@ void Sema::CheckMain(FunctionDecl* FD, const DeclSpec& DS) {
     FD->setConstexpr(false);
   }
 
-  if (getLangOpts().OpenCL) {
+  // TODO: this doesn't seem necessary?
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
     Diag(FD->getLocation(), diag::err_opencl_no_main)
-        << FD->hasAttr<OpenCLKernelAttr>();
+        << FD->hasAttr<ComputeKernelAttr>();
     FD->setInvalidDecl();
     return;
   }
@@ -11221,11 +11363,12 @@ void Sema::AddInitializerToDecl(Decl *RealDecl, Expr *Init, bool DirectInit) {
     if (VDecl->isInvalidDecl()) {
       // do nothing
 
+#if 0 // we don't want this
     // OpenCL v1.2 s6.5.3: __constant locals must be constant-initialized.
     // This is true even in OpenCL C++.
     } else if (VDecl->getType().getAddressSpace() == LangAS::opencl_constant) {
       CheckForConstantInitializer(Init, DclT);
-
+#endif
     // Otherwise, C++ does not restrict the initializer.
     } else if (getLangOpts().CPlusPlus) {
       // do nothing
@@ -11485,7 +11628,7 @@ void Sema::ActOnUninitializedDecl(Decl *RealDecl) {
     // be initialized.
     if (!Var->isInvalidDecl() &&
         Var->getType().getAddressSpace() == LangAS::opencl_constant &&
-        Var->getStorageClass() != SC_Extern && !Var->getInit()) {
+        Var->getStorageClass() != SC_OpenCLConstantExtern && !Var->getInit()) {
       Diag(Var->getLocation(), diag::err_opencl_constant_no_init);
       Var->setInvalidDecl();
       return;
@@ -11697,6 +11840,9 @@ void Sema::ActOnCXXForRangeDecl(Decl *D) {
   case SC_Register:
     Error = 4;
     break;
+  case SC_OpenCLConstant:
+  case SC_OpenCLConstantExtern:
+    llvm_unreachable("Unexpected storage class");
   }
   if (Error != -1) {
     Diag(VD->getOuterLocStart(), diag::err_for_range_storage_class)
@@ -12062,6 +12208,7 @@ void Sema::FinalizeDeclaration(Decl *ThisDecl) {
   if (VD->isStaticLocal()) {
     CheckStaticLocalForDllExport(VD);
 
+#if 0 // nope
     if (dyn_cast_or_null<FunctionDecl>(VD->getParentFunctionOrMethod())) {
       // CUDA 8.0 E.3.9.4: Within the body of a __device__ or __global__
       // function, only __shared__ variables or variables without any device
@@ -12083,8 +12230,10 @@ void Sema::FinalizeDeclaration(Decl *ThisDecl) {
           VD->setInvalidDecl();
       }();
     }
+#endif
   }
 
+#if 0 // again: nope, also incomplete
   // Perform check for initializers of device-side global variables.
   // CUDA allows empty constructors as initializers (see E.2.3.1, CUDA
   // 7.5). We must also apply the same checks to all __shared__
@@ -12092,6 +12241,7 @@ void Sema::FinalizeDeclaration(Decl *ThisDecl) {
   // constant initializers for __constant__ and __device__ variables.
   if (getLangOpts().CUDA)
     checkAllowedCUDAInitializer(VD);
+#endif
 
   // Grab the dllimport or dllexport attribute off of the VarDecl.
   const InheritableAttr *DLLAttr = getDLLAttr(VD);
@@ -12583,12 +12733,19 @@ ParmVarDecl *Sema::CheckParameter(DeclContext *DC, SourceLocation StartLoc,
   if (T.getAddressSpace() != LangAS::Default &&
       // OpenCL allows function arguments declared to be an array of a type
       // to be qualified with an address space.
-      !(getLangOpts().OpenCL &&
+      !((getLangOpts().OpenCL || getLangOpts().CUDA) &&
         (T->isArrayType() || T.getAddressSpace() == LangAS::opencl_private))) {
     Diag(NameLoc, diag::err_arg_with_address_space);
     New->setInvalidDecl();
   }
 
+  // Passing pointer to image is invalid in OpenCL.
+  if (getLangOpts().OpenCL && T->isPointerType() &&
+      T->getPointeeType()->isImageType()) {
+    Diag(NameLoc, diag::err_opencl_pointer_to_image);
+    New->setInvalidDecl();
+  }
+
   return New;
 }
 
@@ -12628,6 +12785,28 @@ void Sema::ActOnFinishKNRParamDeclarations(Scope *S, Declarator &D,
   }
 }
 
+static void AggregateTypeCompleter(Sema& S, const CXXRecordDecl* decl) {
+	if(decl == nullptr) return;
+	
+	// make sure decl is complete
+	S.RequireCompleteType(decl->getBeginLoc(), QualType(decl->getTypeForDecl(), 0),
+						  diag::err_typecheck_decl_incomplete_type);
+	
+	// must have definition
+	if(!decl->hasDefinition()) return;
+	
+	// iterate over / recurse into all bases, and complete all their fields
+	for(const auto& base : decl->bases()) {
+		AggregateTypeCompleter(S, base.getType()->getAsCXXRecordDecl());
+	}
+	
+	// iterate over and complete all fields
+	for(const auto& field : decl->fields()) {
+		S.RequireCompleteType(field->getBeginLoc(), field->getType(),
+							  diag::err_typecheck_decl_incomplete_type);
+	}
+}
+
 Decl *
 Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Declarator &D,
                               MultiTemplateParamsArg TemplateParameterLists,
@@ -12675,8 +12854,10 @@ static bool ShouldWarnAboutMissingPrototype(const FunctionDecl *FD,
   if (FD->isFunctionTemplateSpecialization())
     return false;
 
-  // Don't warn for OpenCL kernels.
-  if (FD->hasAttr<OpenCLKernelAttr>())
+  // Don't warn for compute kernels, or vertex/fragment shaders.
+  if (FD->hasAttr<ComputeKernelAttr>() ||
+      FD->hasAttr<GraphicsVertexShaderAttr>() ||
+      FD->hasAttr<GraphicsFragmentShaderAttr>())
     return false;
 
   // Don't warn on explicitly deleted functions.
@@ -12966,6 +13147,31 @@ Decl *Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Decl *D,
     }
   }
 
+  // for kernel and shader functions: make sure that function parameter types are complete,
+  // including pointer/pointee types that must always be complete as well, since their sizes
+  // and (possibly) structure need to be known later on
+  if(FD->hasAttr<ComputeKernelAttr>() ||
+     FD->hasAttr<GraphicsVertexShaderAttr>() ||
+     FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    for (const auto& Param : FD->parameters()) {
+      const auto param_type = Param->getType();
+      const CXXRecordDecl* cxx_rdecl = nullptr;
+      if(param_type->isPointerType()) {
+        const auto pointee_type = param_type->getPointeeType();
+        RequireCompleteType(Param->getLocation(), pointee_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = pointee_type->getAsCXXRecordDecl();
+      } else {
+        RequireCompleteType(Param->getLocation(), param_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = param_type->getAsCXXRecordDecl();
+      }
+
+      // if this is an aggregate, ensure that all contained types are also complete
+      AggregateTypeCompleter(*this, cxx_rdecl);
+    }
+  }
+
   // Introduce our parameters into the function scope
   for (auto Param : FD->parameters()) {
     Param->setOwningFunction(FD);
@@ -13628,8 +13834,8 @@ void Sema::AddKnownFunctionAttributes(FunctionDecl *FD) {
       if (getLangOpts().CUDAIsDevice !=
           Context.BuiltinInfo.isAuxBuiltinID(BuiltinID))
         FD->addAttr(CUDADeviceAttr::CreateImplicit(Context, FD->getLocation()));
-      else
-        FD->addAttr(CUDAHostAttr::CreateImplicit(Context, FD->getLocation()));
+      //else
+      //  FD->addAttr(CUDAHostAttr::CreateImplicit(Context, FD->getLocation()));
     }
   }
 
@@ -15347,14 +15553,15 @@ FieldDecl *Sema::CheckFieldDecl(DeclarationName Name, QualType T,
   if (LangOpts.OpenCL) {
     // OpenCL v1.2 s6.9b,r & OpenCL v2.0 s6.12.5 - The following types cannot be
     // used as structure or union field: image, sampler, event or block types.
-    if (T->isEventT() || T->isImageType() || T->isSamplerT() ||
+    // NOTE: image types are allowed and necessary part of aggregate images
+    if (T->isEventT() || /*T->isImageType() ||*/ T->isSamplerT() ||
         T->isBlockPointerType()) {
       Diag(Loc, diag::err_opencl_type_struct_or_union_field) << T;
       Record->setInvalidDecl();
       InvalidDecl = true;
     }
     // OpenCL v1.2 s6.9.c: bitfields are not supported.
-    if (BitWidth) {
+    if (BitWidth && getLangOpts().OpenCL && !getLangOpts().CPlusPlus) {
       Diag(Loc, diag::err_opencl_bitfields);
       InvalidDecl = true;
     }
diff --git a/lib/Sema/SemaDeclAttr.cpp b/lib/Sema/SemaDeclAttr.cpp
index 78374b8089..21414215f4 100644
--- a/lib/Sema/SemaDeclAttr.cpp
+++ b/lib/Sema/SemaDeclAttr.cpp
@@ -86,8 +86,11 @@ static bool hasFunctionProto(const Decl *D) {
 /// parameters. It is an error to call this on a K&R function (use
 /// hasFunctionProto first).
 static unsigned getFunctionOrMethodNumParams(const Decl *D) {
-  if (const FunctionType *FnTy = D->getFunctionType())
+  if (const FunctionType *FnTy = D->getFunctionType()) {
+    if (hasFunctionProto(D))
     return cast<FunctionProtoType>(FnTy)->getNumParams();
+    else return 0;
+  }
   if (const auto *BD = dyn_cast<BlockDecl>(D))
     return BD->getNumParams();
   return cast<ObjCMethodDecl>(D)->param_size();
@@ -2648,6 +2651,116 @@ static void handleVisibilityAttr(Sema &S, Decl *D, const ParsedAttr &AL,
     D->addAttr(newAttr);
 }
 
+static void handleFloorImageDataTypeAttr(Sema &S, Decl *D, const ParsedAttr &Attr) {
+  if (!Attr.hasParsedType()) {
+    S.Diag(Attr.getLoc(), diag::err_attribute_wrong_number_arguments)
+      << Attr.getName() << 1;
+    return;
+  }
+
+  TypeSourceInfo *ParmTSI = nullptr;
+  S.GetTypeFromParser(Attr.getTypeArg(), &ParmTSI);
+  D->addAttr(::new (S.Context) FloorImageDataTypeAttr(Attr.getLoc(), S.Context, ParmTSI,
+                                                      Attr.getAttributeSpellingListIndex()));
+}
+
+static void handleGraphicsFBOColorLocationAttr(Sema &S, Decl *D, const ParsedAttr &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+  S.AddGraphicsFBOColorLocationAttr(Attr.getRange(), D, Attr.getArgAsExpr(0),
+                                    Attr.getAttributeSpellingListIndex());
+}
+
+void Sema::AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E, unsigned SpellingListIndex) {
+  GraphicsFBOColorLocationAttr TmpAttr(AttrRange, Context, E, SpellingListIndex);
+  SourceLocation AttrLoc = AttrRange.getBegin();
+
+  QualType T;
+  if (ValueDecl *VD = dyn_cast<ValueDecl>(D))
+    T = VD->getType();
+  else {
+    Diag(AttrLoc, diag::err_attribute_argument_type) <<
+      &TmpAttr << AANT_ArgumentIntegerConstant;
+    return;
+  }
+
+  // TODO: check usage
+
+  if (!E->isValueDependent()) {
+    // TODO: might want to use/check isPotentialConstantExprUnevaluated
+
+    llvm::APSInt ColorLoc(32);
+    ExprResult ICE
+      = VerifyIntegerConstantExpression(E, &ColorLoc,
+          diag::err_expr_not_ice, /*AllowFold*/ true);
+    if (ICE.isInvalid())
+      return;
+
+    // check for < 0 location
+    if (ColorLoc.isNegative()) {
+      unsigned diagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "%0");
+      Diags.Report(AttrRange.getBegin(), diagID) << "location must not be negative!";
+      return;
+    }
+
+    auto loc_attr = ::new (Context) GraphicsFBOColorLocationAttr(AttrRange, Context, ICE.get(), SpellingListIndex);
+    loc_attr->setEvalLocation((unsigned int)ColorLoc.getZExtValue());
+    D->addAttr(loc_attr);
+    return;
+  }
+
+  // Save dependent expressions in the AST to be instantiated.
+  D->addAttr(::new (Context) GraphicsFBOColorLocationAttr(TmpAttr));
+  return;
+}
+
+static void handleGraphicsFBODepthTypeAttr(Sema &S, Decl *D, const ParsedAttr &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+
+  GraphicsFBODepthTypeAttr::DepthQualifierType type;
+  if (Attr.isArgIdent(0)) {
+    IdentifierLoc *Ident = Attr.getArgAsIdent(0);
+    StringRef TypeString = Ident->Ident->getName();
+
+    if (!GraphicsFBODepthTypeAttr::ConvertStrToDepthQualifierType(TypeString, type)) {
+      S.Diag(Ident->Loc, diag::warn_attribute_type_not_supported)
+        << Attr.getName() << TypeString;
+      return;
+    }
+  }
+  else {
+    S.Diag(Attr.getLoc(), diag::err_attribute_argument_type) <<
+      Attr.getName() << AANT_ArgumentIdentifier;
+    return;
+  }
+
+  D->addAttr(::new (S.Context)
+             GraphicsFBODepthTypeAttr(Attr.getRange(), S.Context, type,
+                                      Attr.getAttributeSpellingListIndex()));
+}
+
+static void handleRangeAttr(Sema &S, Decl *D, const ParsedAttr &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 2)) return;
+
+  llvm::APSInt lower_bound(64), upper_bound(64);
+  ExprResult lower_res
+    = S.VerifyIntegerConstantExpression(Attr.getArgAsExpr(0), &lower_bound,
+        diag::err_expr_not_ice, /*AllowFold*/ true);
+  ExprResult upper_res
+    = S.VerifyIntegerConstantExpression(Attr.getArgAsExpr(1), &upper_bound,
+        diag::err_expr_not_ice, /*AllowFold*/ true);
+  if (lower_res.isInvalid() || upper_res.isInvalid()) return;
+
+  if ((lower_bound.isUnsigned() && lower_bound.getZExtValue() > upper_bound.getZExtValue()) ||
+	  (!lower_bound.isUnsigned() && lower_bound.getExtValue() > upper_bound.getExtValue())) {
+    unsigned diagID = S.getDiagnostics().getCustomDiagID(DiagnosticsEngine::Error, "%0");
+    S.Diag(Attr.getRange().getBegin(), diagID) << "lower bound must be lower than the upper bound";
+    return;
+  }
+
+  D->addAttr(::new (S.Context) RetRangeAttr(Attr.getRange(), S.Context, lower_res.get(), upper_res.get(),
+                                            Attr.getAttributeSpellingListIndex()));
+}
+
 static void handleObjCMethodFamilyAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
   const auto *M = cast<ObjCMethodDecl>(D);
   if (!AL.isArgIdent(0)) {
@@ -4174,68 +4287,6 @@ static void handleOptimizeNoneAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
     D->addAttr(Optnone);
 }
 
-static void handleConstantAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
-  if (checkAttrMutualExclusion<CUDASharedAttr>(S, D, AL))
-    return;
-  const auto *VD = cast<VarDecl>(D);
-  if (!VD->hasGlobalStorage()) {
-    S.Diag(AL.getLoc(), diag::err_cuda_nonglobal_constant);
-    return;
-  }
-  D->addAttr(::new (S.Context) CUDAConstantAttr(
-      AL.getRange(), S.Context, AL.getAttributeSpellingListIndex()));
-}
-
-static void handleSharedAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
-  if (checkAttrMutualExclusion<CUDAConstantAttr>(S, D, AL))
-    return;
-  const auto *VD = cast<VarDecl>(D);
-  // extern __shared__ is only allowed on arrays with no length (e.g.
-  // "int x[]").
-  if (!S.getLangOpts().GPURelocatableDeviceCode && VD->hasExternalStorage() &&
-      !isa<IncompleteArrayType>(VD->getType())) {
-    S.Diag(AL.getLoc(), diag::err_cuda_extern_shared) << VD;
-    return;
-  }
-  if (S.getLangOpts().CUDA && VD->hasLocalStorage() &&
-      S.CUDADiagIfHostCode(AL.getLoc(), diag::err_cuda_host_shared)
-          << S.CurrentCUDATarget())
-    return;
-  D->addAttr(::new (S.Context) CUDASharedAttr(
-      AL.getRange(), S.Context, AL.getAttributeSpellingListIndex()));
-}
-
-static void handleGlobalAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
-  if (checkAttrMutualExclusion<CUDADeviceAttr>(S, D, AL) ||
-      checkAttrMutualExclusion<CUDAHostAttr>(S, D, AL)) {
-    return;
-  }
-  const auto *FD = cast<FunctionDecl>(D);
-  if (!FD->getReturnType()->isVoidType()) {
-    SourceRange RTRange = FD->getReturnTypeSourceRange();
-    S.Diag(FD->getTypeSpecStartLoc(), diag::err_kern_type_not_void_return)
-        << FD->getType()
-        << (RTRange.isValid() ? FixItHint::CreateReplacement(RTRange, "void")
-                              : FixItHint());
-    return;
-  }
-  if (const auto *Method = dyn_cast<CXXMethodDecl>(FD)) {
-    if (Method->isInstance()) {
-      S.Diag(Method->getBeginLoc(), diag::err_kern_is_nonstatic_method)
-          << Method;
-      return;
-    }
-    S.Diag(Method->getBeginLoc(), diag::warn_kern_is_method) << Method;
-  }
-  // Only warn for "inline" when compiling for host, to cut down on noise.
-  if (FD->isInlineSpecified() && !S.getLangOpts().CUDAIsDevice)
-    S.Diag(FD->getBeginLoc(), diag::warn_kern_is_inline) << FD;
-
-  D->addAttr(::new (S.Context)
-              CUDAGlobalAttr(AL.getRange(), S.Context,
-                             AL.getAttributeSpellingListIndex()));
-}
-
 static void handleGNUInlineAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
   const auto *Fn = cast<FunctionDecl>(D);
   if (!Fn->isInlineSpecified()) {
@@ -4454,6 +4505,9 @@ bool Sema::CheckCallingConvAttr(const ParsedAttr &Attrs, CallingConv &CC,
   case ParsedAttr::AT_PreserveAll:
     CC = CC_PreserveAll;
     break;
+  case ParsedAttr::AT_GraphicsVertexShader: CC = CC_FloorVertex; break;
+  case ParsedAttr::AT_GraphicsFragmentShader: CC = CC_FloorFragment; break;
+  case ParsedAttr::AT_ComputeKernel: CC = CC_FloorKernel; break;
   default: llvm_unreachable("unexpected attribute kind");
   }
 
@@ -5977,7 +6031,7 @@ static void handleInternalLinkageAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
 }
 
 static void handleOpenCLNoSVMAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
-  if (S.LangOpts.OpenCLVersion != 200)
+  if (S.LangOpts.OpenCLVersion < 200)
     S.Diag(AL.getLoc(), diag::err_attribute_requires_opencl_version)
         << AL << "2.0" << 0;
   else
@@ -6028,45 +6082,6 @@ static bool handleCommonAttributeFeatures(Sema &S, Decl *D,
   return false;
 }
 
-static void handleOpenCLAccessAttr(Sema &S, Decl *D, const ParsedAttr &AL) {
-  if (D->isInvalidDecl())
-    return;
-
-  // Check if there is only one access qualifier.
-  if (D->hasAttr<OpenCLAccessAttr>()) {
-    if (D->getAttr<OpenCLAccessAttr>()->getSemanticSpelling() ==
-        AL.getSemanticSpelling()) {
-      S.Diag(AL.getLoc(), diag::warn_duplicate_declspec)
-          << AL.getName()->getName() << AL.getRange();
-    } else {
-      S.Diag(AL.getLoc(), diag::err_opencl_multiple_access_qualifiers)
-          << D->getSourceRange();
-      D->setInvalidDecl(true);
-      return;
-    }
-  }
-
-  // OpenCL v2.0 s6.6 - read_write can be used for image types to specify that an
-  // image object can be read and written.
-  // OpenCL v2.0 s6.13.6 - A kernel cannot read from and write to the same pipe
-  // object. Using the read_write (or __read_write) qualifier with the pipe
-  // qualifier is a compilation error.
-  if (const auto *PDecl = dyn_cast<ParmVarDecl>(D)) {
-    const Type *DeclTy = PDecl->getType().getCanonicalType().getTypePtr();
-    if (AL.getName()->getName().find("read_write") != StringRef::npos) {
-      if (S.getLangOpts().OpenCLVersion < 200 || DeclTy->isPipeType()) {
-        S.Diag(AL.getLoc(), diag::err_opencl_invalid_read_write)
-            << AL << PDecl->getType() << DeclTy->isImageType();
-        D->setInvalidDecl(true);
-        return;
-      }
-    }
-  }
-
-  D->addAttr(::new (S.Context) OpenCLAccessAttr(
-      AL.getRange(), S.Context, AL.getAttributeSpellingListIndex()));
-}
-
 static void handleDestroyAttr(Sema &S, Decl *D, const ParsedAttr &A) {
   if (!cast<VarDecl>(D)->hasGlobalStorage()) {
     S.Diag(D->getLocation(), diag::err_destroy_attr_on_non_static_var)
@@ -6222,7 +6237,7 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
     handleCommonAttr(S, D, AL);
     break;
   case ParsedAttr::AT_CUDAConstant:
-    handleConstantAttr(S, D, AL);
+    handleSimpleAttributeWithExclusions<CUDAConstantAttr, CUDASharedAttr>(S, D, AL);
     break;
   case ParsedAttr::AT_PassObjectSize:
     handlePassObjectSizeAttr(S, D, AL);
@@ -6272,15 +6287,11 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case ParsedAttr::AT_FormatArg:
     handleFormatArgAttr(S, D, AL);
     break;
-  case ParsedAttr::AT_CUDAGlobal:
-    handleGlobalAttr(S, D, AL);
-    break;
   case ParsedAttr::AT_CUDADevice:
-    handleSimpleAttributeWithExclusions<CUDADeviceAttr, CUDAGlobalAttr>(S, D,
-                                                                        AL);
+    handleSimpleAttributeWithExclusions<CUDADeviceAttr, ComputeKernelAttr>(S, D, AL);
     break;
   case ParsedAttr::AT_CUDAHost:
-    handleSimpleAttributeWithExclusions<CUDAHostAttr, CUDAGlobalAttr>(S, D, AL);
+    handleSimpleAttributeWithExclusions<CUDAHostAttr, ComputeKernelAttr>(S, D, AL);
     break;
   case ParsedAttr::AT_GNUInline:
     handleGNUInlineAttr(S, D, AL);
@@ -6352,7 +6363,7 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
     handleSimpleAttribute<NoThrowAttr>(S, D, AL);
     break;
   case ParsedAttr::AT_CUDAShared:
-    handleSharedAttr(S, D, AL);
+    handleSimpleAttributeWithExclusions<CUDASharedAttr, CUDAConstantAttr>(S, D, AL);
     break;
   case ParsedAttr::AT_VecReturn:
     handleVecReturnAttr(S, D, AL);
@@ -6539,6 +6550,42 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case ParsedAttr::AT_Pure:
     handleSimpleAttribute<PureAttr>(S, D, AL);
     break;
+  case ParsedAttr::AT_ComputeKernel:
+    handleSimpleAttribute<ComputeKernelAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsVertexShader:
+    handleSimpleAttribute<GraphicsVertexShaderAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsFragmentShader:
+    handleSimpleAttribute<GraphicsFragmentShaderAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_RetRange:
+    handleRangeAttr(S, D, AL);
+    break;
+  case ParsedAttr::AT_ImageAccess:
+    handleSimpleAttribute<ImageAccessAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_FloorImageDataType:
+    handleFloorImageDataTypeAttr(S, D, AL);
+    break;
+  case ParsedAttr::AT_VectorCompat:
+    handleSimpleAttribute<VectorCompatAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsFBOColorLocation:
+    handleGraphicsFBOColorLocationAttr(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsFBODepthType:
+    handleGraphicsFBODepthTypeAttr(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsVertexPosition:
+    handleSimpleAttribute<GraphicsVertexPositionAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsPointSize:
+    handleSimpleAttribute<GraphicsPointSizeAttr>(S, D, AL);
+    break;
+  case ParsedAttr::AT_GraphicsStageInput:
+    handleSimpleAttribute<GraphicsStageInputAttr>(S, D, AL);
+    break;
   case ParsedAttr::AT_Cleanup:
     handleCleanupAttr(S, D, AL);
     break;
@@ -6581,12 +6628,6 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case ParsedAttr::AT_Suppress:
     handleSuppressAttr(S, D, AL);
     break;
-  case ParsedAttr::AT_OpenCLKernel:
-    handleSimpleAttribute<OpenCLKernelAttr>(S, D, AL);
-    break;
-  case ParsedAttr::AT_OpenCLAccess:
-    handleOpenCLAccessAttr(S, D, AL);
-    break;
   case ParsedAttr::AT_OpenCLNoSVM:
     handleOpenCLNoSVMAttr(S, D, AL);
     break;
@@ -6799,7 +6840,7 @@ void Sema::ProcessDeclAttributeList(Scope *S, Decl *D,
   // good to have a way to specify "these attributes must appear as a group",
   // for these. Additionally, it would be good to have a way to specify "these
   // attribute must never appear as a group" for attributes like cold and hot.
-  if (!D->hasAttr<OpenCLKernelAttr>()) {
+  if (!D->hasAttr<ComputeKernelAttr>()) {
     // These attributes cannot be applied to a non-kernel function.
     if (const auto *A = D->getAttr<ReqdWorkGroupSizeAttr>()) {
       // FIXME: This emits a different error message than
@@ -6815,7 +6856,7 @@ void Sema::ProcessDeclAttributeList(Scope *S, Decl *D,
     } else if (const auto *A = D->getAttr<OpenCLIntelReqdSubGroupSizeAttr>()) {
       Diag(D->getLocation(), diag::err_opencl_kernel_attr) << A;
       D->setInvalidDecl();
-    } else if (!D->hasAttr<CUDAGlobalAttr>()) {
+    } else if (!D->hasAttr<ComputeKernelAttr>()) {
       if (const auto *A = D->getAttr<AMDGPUFlatWorkGroupSizeAttr>()) {
         Diag(D->getLocation(), diag::err_attribute_wrong_decl_type)
             << A << ExpectedKernelFunction;
diff --git a/lib/Sema/SemaExpr.cpp b/lib/Sema/SemaExpr.cpp
index 4ba0fb12e7..bdd61ca81b 100644
--- a/lib/Sema/SemaExpr.cpp
+++ b/lib/Sema/SemaExpr.cpp
@@ -46,6 +46,7 @@
 #include "clang/Sema/SemaInternal.h"
 #include "clang/Sema/Template.h"
 #include "llvm/Support/ConvertUTF.h"
+#include <sstream>
 using namespace clang;
 using namespace sema;
 
@@ -90,6 +91,96 @@ static void DiagnoseUnusedOfDecl(Sema &S, NamedDecl *D, SourceLocation Loc) {
   }
 }
 
+// \brief Preform dynamic type checking on the actual arguments passed to the
+// call.
+static bool CheckEnqueueKernel(const CallExpr *TheCall, ArrayRef<Expr*> Args,
+                               Sema &S) {
+  // The index of the block paramater in overload I.
+  #define BLOCK_INDEX_I   3U
+  // The index of the block paramater in overload II.
+  #define BLOCK_INDEX_II  6U
+
+  // Minimum number of arguments in overload I.
+  #define MIN_NUM_ARGS_I  5U
+  // Minimum number of arguments in overload II.
+  #define MIN_NUM_ARGS_II 8U
+
+  QualType BlkTy;
+
+  // There are two overloads of the function which receives blocks, we need
+  // to figure if the call is one of them.
+  const unsigned NumArgs = Args.size();
+  unsigned BlkIdx = 0;
+
+  if (NumArgs >= MIN_NUM_ARGS_I) {
+    QualType ArgTy = Args[BLOCK_INDEX_I]->getType();
+
+    if (ArgTy->isBlockPointerType()) {
+      BlkTy = ArgTy->getPointeeType();
+      BlkIdx = BLOCK_INDEX_I;
+    }
+    else if (NumArgs >= MIN_NUM_ARGS_II) {
+      ArgTy = Args[BLOCK_INDEX_II]->getType();
+      if (ArgTy->isBlockPointerType()) {
+        BlkTy = ArgTy->getPointeeType();
+        BlkIdx = BLOCK_INDEX_II;
+      }
+    }
+  }
+
+  if (BlkTy.isNull())
+    return false;
+
+  bool Invalid = false;
+
+  // Making sure that if the type is a pointer, it is in local AS.
+  const FunctionProtoType *BlkProto = BlkTy->getAs<FunctionProtoType>();
+  for (unsigned i = 0; i<BlkProto->getNumParams(); i++) {
+    QualType ParmTy = BlkProto->getParamType(i);
+    if (!ParmTy->isPointerType() ||
+        ParmTy->getPointeeType().getAddressSpace() != LangAS::opencl_local) {
+      S.Diag(Args[BlkIdx]->getBeginLoc(), diag::err_invalid_block_as_parameter)
+             << BlkTy << TheCall->getSourceRange();
+      Invalid = true;
+    }
+  }
+
+  // Making sure that all variadic arguments are of type unsigned int.
+  unsigned VariadicIdx = ((FunctionDecl*)TheCall->getCalleeDecl())->
+           getMinRequiredArguments();
+
+  // Making sure that the number of local arg sizes corresponds the number of
+  // pointers in the block.
+  unsigned NumLocalSizes = NumArgs - VariadicIdx +1;
+  if (BlkProto->getNumParams() != NumLocalSizes) {
+    S.Diag(Args[BlkIdx]->getBeginLoc(),
+           diag::err_enqueue_kernel_num_args_mismatch) <<
+    TheCall->getSourceRange();
+    Invalid = true;
+  }
+
+ for (unsigned i=(VariadicIdx-1); i<NumArgs; i++) {
+    const Expr *Arg = Args[i];
+    const BuiltinType *BITy = Arg->getType().getCanonicalType()->
+                              getAs<BuiltinType>();
+    if (BITy && (BITy->getKind() == BuiltinType::UInt ||
+                 BITy->getKind() == BuiltinType::ULong ||
+                 BITy->getKind() == BuiltinType::UInt128 ||
+                 BITy->getKind() == BuiltinType::ULongLong)){
+         //at va positions natively accept UInt type
+          //and accept U types to be interpreted as 32bit sizes of local mem
+          continue;
+      }
+      else {
+          S.Diag(Arg->getBeginLoc(), diag::err_variadic_enqueue_kernel) <<
+          TheCall->getSourceRange();
+          Invalid = true;
+      }
+  }
+
+  return Invalid;
+}
+
 /// Emit a note explaining that this function is deleted.
 void Sema::NoteDeletedFunction(FunctionDecl *Decl) {
   assert(Decl->isDeleted());
@@ -440,6 +531,14 @@ ExprResult Sema::DefaultFunctionArrayConversion(Expr *E, bool Diagnose) {
   assert(!Ty.isNull() && "DefaultFunctionArrayConversion - missing type");
 
   if (Ty->isFunctionType()) {
+    // If we are here, we are not calling a function but taking
+    // its address (which is not allowed in OpenCL v1.0 s6.8.a.3).
+    if (getLangOpts().OpenCL && !LangOpts.CPlusPlus) {
+      if (Diagnose)
+        Diag(E->getExprLoc(), diag::err_opencl_taking_function_address);
+      return ExprError();
+    }
+
     if (auto *DRE = dyn_cast<DeclRefExpr>(E->IgnoreParenCasts()))
       if (auto *FD = dyn_cast<FunctionDecl>(DRE->getDecl()))
         if (!checkAddressOfFunctionIsAvailable(FD, Diagnose, E->getExprLoc()))
@@ -717,6 +816,35 @@ ExprResult Sema::UsualUnaryConversions(Expr *E) {
   return E;
 }
 
+// Find out which conversion function to call for a vector with the given
+// element type.
+//
+// TODO: unused?
+/*static std::string vec_conversion_function_for_type(BuiltinType::Kind elem_type)
+{
+    switch (elem_type)
+    {
+        case BuiltinType::Float:
+            return "convert_double";
+        case BuiltinType::Char_S:
+        case BuiltinType::SChar:
+        case BuiltinType::Short:
+            return "convert_int";
+        case BuiltinType::Char_U:
+        case BuiltinType::UChar:
+        case BuiltinType::UShort:
+            return "convert_uint";
+        default:
+            // We won't get here because the call to this function will happen
+            // only if elem_type->isPromotableIntegerType(), which apart
+            // from the above types includes bool, and vectors of bools don't
+            // currently exist in OpenCL
+            //
+            assert(0 && "Invalid vector type in conversion");
+            return "";
+    }
+}*/
+
 /// DefaultArgumentPromotion (C99 6.5.2.2p6). Used for function calls that
 /// do not have a prototype. Arguments that have type float or __fp16
 /// are promoted to double. All other argument types are converted by
@@ -3432,14 +3560,9 @@ ExprResult Sema::ActOnNumericConstant(const Token &Tok, Scope *UDLScope) {
                                               Tok.getLocation(), scale);
   } else if (Literal.isFloatingLiteral()) {
     QualType Ty;
-    if (Literal.isHalf){
-      if (getOpenCLOptions().isEnabled("cl_khr_fp16"))
+    if (Literal.isHalf)
         Ty = Context.HalfTy;
-      else {
-        Diag(Tok.getLocation(), diag::err_half_const_requires_fp16);
-        return ExprError();
-      }
-    } else if (Literal.isFloat)
+    else if (Literal.isFloat)
       Ty = Context.FloatTy;
     else if (Literal.isLong)
       Ty = Context.LongDoubleTy;
@@ -3646,8 +3769,8 @@ static bool CheckExtensionTraitOperandType(Sema &S, QualType T,
   // Allow sizeof(void)/alignof(void) as an extension, unless in OpenCL where
   // this is an error (OpenCL v1.1 s6.3.k)
   if (T->isVoidType()) {
-    unsigned DiagID = S.LangOpts.OpenCL ? diag::err_opencl_sizeof_alignof_type
-                                        : diag::ext_sizeof_alignof_void_type;
+    unsigned DiagID = S.LangOpts.OpenCL && !S.LangOpts.CPlusPlus ?
+      diag::err_opencl_sizeof_alignof_type : diag::ext_sizeof_alignof_void_type;
     S.Diag(Loc, DiagID) << TraitKind << ArgRange;
     return false;
   }
@@ -4493,6 +4616,7 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
                                       Expr *Idx, SourceLocation RLoc) {
   Expr *LHSExp = Base;
   Expr *RHSExp = Idx;
+  bool LHSIsPointerType = false;
 
   ExprValueKind VK = VK_LValue;
   ExprObjectKind OK = OK_Ordinary;
@@ -4535,6 +4659,7 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
     BaseExpr = LHSExp;
     IndexExpr = RHSExp;
     ResultType = PTy->getPointeeType();
+    LHSIsPointerType = true;
   } else if (const ObjCObjectPointerType *PTy =
                LHSTy->getAs<ObjCObjectPointerType>()) {
     BaseExpr = LHSExp;
@@ -4647,6 +4772,13 @@ Sema::CreateBuiltinArraySubscriptExpr(Expr *Base, SourceLocation LLoc,
                           diag::err_subscript_incomplete_type, BaseExpr))
     return ExprError();
 
+  if (getLangOpts().OpenCL && ResultType->isHalfType() && !LHSIsPointerType &&
+      !getOpenCLOptions().isEnabled("cl_khr_fp16")) {
+    Diag(BaseExpr->getBeginLoc(), diag::err_opencl_subscript) << ResultType <<
+    BaseExpr->getType() << BaseExpr->getSourceRange();
+    return ExprError();
+  }
+
   assert(VK == VK_RValue || LangOpts.CPlusPlus ||
          !ResultType.isCForbiddenLValueType());
 
@@ -5702,7 +5834,7 @@ ExprResult Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
   if (getLangOpts().CUDA) {
     if (Config) {
       // CUDA: Kernel calls must be to global functions
-      if (FDecl && !FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && !FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc,diag::err_kern_call_not_global_function)
             << FDecl << Fn->getSourceRange());
 
@@ -5712,12 +5844,17 @@ ExprResult Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
             << Fn->getType() << Fn->getSourceRange());
     } else {
       // CUDA: Calls to global functions must be configured
-      if (FDecl && FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc, diag::err_global_call_not_config)
             << FDecl << Fn->getSourceRange());
     }
   }
 
+  if (LangOpts.OpenCL && LangOpts.OpenCLVersion >= 200)
+    if (FDecl && FDecl->getName() == "enqueue_kernel")
+      if(CheckEnqueueKernel(TheCall, Args, *this))
+        return ExprError();
+
   // Check for a valid return type
   if (CheckCallReturnType(FuncT->getReturnType(), Fn->getBeginLoc(), TheCall,
                           FDecl))
@@ -8451,6 +8588,9 @@ static bool tryVectorConvertAndSplat(Sema &S, ExprResult *scalar,
     scalarCast = CK_IntegralCast;
   } else if (vectorEltTy->isRealFloatingType()) {
     if (scalarTy->isRealFloatingType()) {
+      // OpenCL V2.0 6.2.6.p2:
+      // An error shall occur if any scalar operand type has greater rank
+      // than the type of the vector element.
       if (S.getLangOpts().OpenCL &&
           S.Context.getFloatingTypeOrder(vectorEltTy, scalarTy) < 0) {
         DiagID = diag::err_opencl_scalar_type_rank_greater_than_vector_type;
@@ -10684,6 +10824,18 @@ QualType Sema::CheckCompareOperands(ExprResult &LHS, ExprResult &RHS,
     }
   }
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    if (LHSIsNull && RHSType->isQueueT()) {
+      LHS = ImpCastExprToType(LHS.get(), RHSType, CK_NullToPointer);
+      return computeResultTy();
+    }
+
+    if (LHSType->isQueueT() && RHSIsNull) {
+      RHS = ImpCastExprToType(RHS.get(), LHSType, CK_NullToPointer);
+      return computeResultTy();
+    }
+  }
+
   return InvalidOperands(Loc, LHS, RHS);
 }
 
@@ -11788,6 +11940,12 @@ QualType Sema::CheckAddressOfOperand(ExprResult &OrigOp, SourceLocation OpLoc) {
     }
   }
 
+  // OpenCL v1.0 s6.8.a.3: Pointers to functions are not allowed.
+  if (LangOpts.OpenCL && !LangOpts.CPlusPlus && op->getType()->isFunctionType()) {
+    Diag(op->getExprLoc(), diag::err_opencl_taking_function_address);
+    return QualType();
+  }
+
   if (getLangOpts().C99) {
     // Implement C99-only parts of addressof rules.
     if (UnaryOperator* uOp = dyn_cast<UnaryOperator>(op)) {
@@ -11945,6 +12103,14 @@ QualType Sema::CheckAddressOfOperand(ExprResult &OrigOp, SourceLocation OpLoc) {
 
   CheckAddressOfPackedMember(op);
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    const QualType Ty = OrigOp.get()->getType();
+    if (Ty->isBlockPointerType()) {
+      Diag(OpLoc, diag::err_typecheck_unary_expr) << Ty << op->getSourceRange();
+      return QualType();
+    }
+  }
+
   return Context.getPointerType(op->getType());
 }
 
@@ -11985,9 +12151,17 @@ static QualType CheckIndirectionOperand(Sema &S, Expr *Op, ExprValueKind &VK,
                                      Op->getSourceRange());
   }
 
-  if (const PointerType *PT = OpTy->getAs<PointerType>())
-  {
+  if (const PointerType *PT = OpTy->getAs<PointerType>()) {
     Result = PT->getPointeeType();
+    // OpenCL v1.2 s6.1.1.1 p2:
+    // The half data type can only be used to declare a pointer to a buffer that
+    // contains half values
+    if (S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200 &&
+        Result->isBlockPointerType()) {
+      S.Diag(OpLoc, diag::err_opencl_dereferencing) << OpTy
+                                                    << Op->getSourceRange();
+      return QualType();
+    }
   }
   else if (const ObjCObjectPointerType *OPT =
              OpTy->getAs<ObjCObjectPointerType>())
@@ -12268,6 +12442,22 @@ ExprResult Sema::CreateBuiltinBinOp(SourceLocation OpLoc,
     RHSExpr = Init.get();
   }
 
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    QualType LHSTy = LHSExpr->getType(), RHSTy = RHSExpr->getType();
+    // OpenCL 2.0 Section 6.13.11.1 allows atomic varibles to be initialized by
+    // the ATOMIC_VAR_INIT macro.
+    if (LHSTy->isAtomicType() || RHSTy->isAtomicType()) {
+      SourceRange SR(LHSExpr->getBeginLoc(), RHSExpr->getEndLoc());
+      if (BO_Assign == Opc)
+        Diag(OpLoc, diag::err_atomic_init_constant) << SR;
+      else {
+        Diag(OpLoc, diag::err_typecheck_invalid_operands) << LHSTy.getAsString()
+        << RHSTy.getAsString() << SR;
+      }
+      return ExprError();
+    }
+  }
+
   ExprResult LHS = LHSExpr, RHS = RHSExpr;
   QualType ResultTy;     // Result type of the binary operator.
   // The following two variables are used for compound assignment operators
@@ -12862,6 +13052,18 @@ static bool isOverflowingIntegerType(ASTContext &Ctx, QualType T) {
 ExprResult Sema::CreateBuiltinUnaryOp(SourceLocation OpLoc,
                                       UnaryOperatorKind Opc,
                                       Expr *InputExpr) {
+
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200) {
+    QualType Ty = InputExpr->getType();
+
+    // The only legal unary operation for atomics is '&'.
+    if (Opc != UO_AddrOf && Ty->isAtomicType()) {
+        Diag(OpLoc, diag::err_typecheck_unary_expr) << Ty.getAsString() <<
+        InputExpr->getSourceRange();
+        return ExprError();
+    }
+  }
+
   ExprResult Input = InputExpr;
   ExprValueKind VK = VK_RValue;
   ExprObjectKind OK = OK_Ordinary;
@@ -15009,7 +15211,11 @@ static bool captureInBlock(BlockScopeInfo *BSI, VarDecl *Var,
 
   const bool HasBlocksAttr = Var->hasAttr<BlocksAttr>();
   if (HasBlocksAttr || CaptureType->isReferenceType() ||
-      (S.getLangOpts().OpenMP && S.isOpenMPCapturedDecl(Var))) {
+      (S.getLangOpts().OpenMP && S.isOpenMPCapturedDecl(Var)) ||
+      // This is a unique behavior for OpenCL 2.0, since array capturing is
+      // allowed.
+      (S.getLangOpts().OpenCL && S.getLangOpts().OpenCLVersion >= 200 &&
+       CaptureType->isArrayType())) {
     // Block capture by reference does not change the capture or
     // declaration reference types.
     ByRef = true;
diff --git a/lib/Sema/SemaExprCXX.cpp b/lib/Sema/SemaExprCXX.cpp
index 2b054c4b0f..90a5f990a7 100644
--- a/lib/Sema/SemaExprCXX.cpp
+++ b/lib/Sema/SemaExprCXX.cpp
@@ -2205,7 +2205,8 @@ bool Sema::CheckAllocatedType(QualType AllocType, SourceLocation Loc,
     return Diag(Loc, diag::err_variably_modified_new_type)
              << AllocType;
   else if (AllocType.getAddressSpace() != LangAS::Default &&
-           !getLangOpts().OpenCLCPlusPlus)
+           !getLangOpts().OpenCLCPlusPlus &&
+           !(getLangOpts().OpenCL && getLangOpts().CPlusPlus))
     return Diag(Loc, diag::err_address_space_qualified_new)
       << AllocType.getUnqualifiedType()
       << AllocType.getQualifiers().getAddressSpaceAttributePrintValue();
@@ -2839,7 +2840,9 @@ void Sema::DeclareGlobalAllocationFunction(DeclarationName Name,
   else {
     // Host and device get their own declaration so each can be
     // defined or re-declared independently.
+    if (!LangOpts.CUDAIsDevice) { // don't define if device-only
     CreateAllocationFunctionDecl(CUDAHostAttr::CreateImplicit(Context));
+    }
     CreateAllocationFunctionDecl(CUDADeviceAttr::CreateImplicit(Context));
   }
 }
@@ -3301,7 +3304,8 @@ Sema::ActOnCXXDelete(SourceLocation StartLoc, bool UseGlobal,
     QualType PointeeElem = Context.getBaseElementType(Pointee);
 
     if (Pointee.getAddressSpace() != LangAS::Default &&
-        !getLangOpts().OpenCLCPlusPlus)
+        !getLangOpts().OpenCLCPlusPlus &&
+        !(getLangOpts().OpenCL && getLangOpts().CPlusPlus))
       return Diag(Ex.get()->getBeginLoc(),
                   diag::err_address_space_qualified_delete)
              << Pointee.getUnqualifiedType()
@@ -4236,12 +4240,23 @@ Sema::PerformImplicitConversion(Expr *From, QualType ToType,
   }
 
   case ICK_Zero_Event_Conversion:
-  case ICK_Zero_Queue_Conversion:
     From = ImpCastExprToType(From, ToType,
                              CK_ZeroToOCLOpaqueType,
                              From->getValueKind()).get();
     break;
 
+  case ICK_Zero_Queue_Conversion:
+    From = ImpCastExprToType(From, ToType,
+                             CK_ZeroToOCLQueue,
+                             From->getValueKind()).get();
+    break;
+
+  case ICK_Int_Sampler_Conversion:
+    From = ImpCastExprToType(From, ToType,
+                             CK_IntToOCLSampler,
+                             From->getValueKind()).get();
+    break;
+
   case ICK_Lvalue_To_Rvalue:
   case ICK_Array_To_Pointer:
   case ICK_Function_To_Pointer:
@@ -4271,6 +4286,7 @@ Sema::PerformImplicitConversion(Expr *From, QualType ToType,
   case ICK_Qualification: {
     // The qualification keeps the category of the inner expression, unless the
     // target type isn't a reference.
+#if 0 // we don't want this
     ExprValueKind VK =
         ToType->isReferenceType() ? From->getValueKind() : VK_RValue;
 
@@ -4289,6 +4305,12 @@ Sema::PerformImplicitConversion(Expr *From, QualType ToType,
     From = ImpCastExprToType(From, ToType.getNonLValueExprType(Context), CK, VK,
                              /*BasePath=*/nullptr, CCK)
                .get();
+#else // old behavior
+    ExprValueKind VK = ToType->isReferenceType() ?
+                                  From->getValueKind() : VK_RValue;
+    From = ImpCastExprToType(From, ToType.getNonLValueExprType(Context),
+                             CK_NoOp, VK, /*BasePath=*/nullptr, CCK).get();
+#endif
 
     if (SCS.DeprecatedStringLiteralToCharPtr &&
         !getLangOpts().WritableStrings) {
diff --git a/lib/Sema/SemaExprMember.cpp b/lib/Sema/SemaExprMember.cpp
index b2b21ba9ee..5a2cd66cbf 100644
--- a/lib/Sema/SemaExprMember.cpp
+++ b/lib/Sema/SemaExprMember.cpp
@@ -375,6 +375,7 @@ CheckExtVectorComponent(Sema &S, QualType baseType, ExprValueKind &VK,
     if (HexSwizzle)
       compStr++;
 
+    // TODO: add SPIR pass to scalarize all non-{1,2,3,4,8,16} vector uses
     while (*compStr) {
       if (!vecType->isAccessorWithinNumElements(*compStr++, HexSwizzle)) {
         S.Diag(OpLoc, diag::err_ext_vector_component_exceeds_length)
@@ -1776,7 +1777,8 @@ Sema::BuildFieldReferenceExpr(Expr *BaseExpr, bool IsArrow,
     Qualifiers MemberQuals =
         Context.getCanonicalType(MemberType).getQualifiers();
 
-    assert(!MemberQuals.hasAddressSpace());
+    // this should very well be possible
+    //assert(!MemberQuals.hasAddressSpace());
 
     Qualifiers Combined = BaseQuals + MemberQuals;
     if (Combined != MemberQuals)
diff --git a/lib/Sema/SemaInit.cpp b/lib/Sema/SemaInit.cpp
index c2f14229d8..4d1635350c 100644
--- a/lib/Sema/SemaInit.cpp
+++ b/lib/Sema/SemaInit.cpp
@@ -1288,7 +1288,8 @@ void InitListChecker::CheckSubElementType(const InitializedEntity &Entity,
     }
 
     // Fall through for subaggregate initialization
-  } else if (ElemType->isScalarType() || ElemType->isAtomicType()) {
+  } else if (ElemType->isScalarType() || ElemType->isAtomicType() ||
+             (SemaRef.getLangOpts().OpenCLVersion >= 200 && ElemType->isExecType())) {
     // FIXME: Need to handle atomic aggregate types with implicit init lists.
     return CheckScalarType(Entity, IList, ElemType, Index,
                            StructuredList, StructuredIndex);
@@ -3266,6 +3267,8 @@ void InitializationSequence::Step::Destroy() {
   case SK_StdInitializerListConstructorCall:
   case SK_OCLSamplerInit:
   case SK_OCLZeroOpaqueType:
+  case SK_OCLZeroEvent:
+  case SK_OCLZeroQueue:
     break;
 
   case SK_ConversionSequence:
@@ -3558,6 +3561,13 @@ void InitializationSequence::AddOCLZeroOpaqueTypeStep(QualType T) {
   Steps.push_back(S);
 }
 
+void InitializationSequence::AddOCLZeroQueueStep(QualType T) {
+  Step S;
+  S.Kind = SK_OCLZeroQueue;
+  S.Type = T;
+  Steps.push_back(S);
+}
+
 void InitializationSequence::RewrapReferenceInitList(QualType T,
                                                      InitListExpr *Syntactic) {
   assert(Syntactic->getNumInits() == 1 &&
@@ -4690,6 +4700,7 @@ static void TryReferenceInitializationCore(Sema &S,
   //         where "cv1 T1" is reference-compatible with "cv3 T3",
   //
   // DR1287 removes the "implicitly" here.
+  bool isOpenCLASRef = false;
   if (T2->isRecordType()) {
     if (RefRelationship == Sema::Ref_Incompatible) {
       ConvOvlResult = TryRefInitWithConversionFunction(
@@ -4710,8 +4721,15 @@ static void TryReferenceInitializationCore(Sema &S,
       return;
     }
 
-    Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
-    return;
+    if(S.getLangOpts().OpenCL &&
+       ((cv1T1.getAddressSpace() == LangAS::Default && cv2T2.getAddressSpace() != LangAS::Default) ||
+        (cv1T1.getAddressSpace() != LangAS::Default && cv2T2.getAddressSpace() == LangAS::Default))) {
+      isOpenCLASRef = true;
+    }
+    if(!isOpenCLASRef) {
+      Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
+      return;
+    }
   }
 
   //      - Otherwise, a temporary of type "cv1 T1" is created and initialized
@@ -5303,6 +5321,20 @@ static bool TryOCLZeroOpaqueTypeInitialization(Sema &S,
   return false;
 }
 
+static bool TryOCLZeroQueueInitialization(Sema &S,
+                                          InitializationSequence &Sequence,
+                                          QualType DestType,
+                                          Expr *Initializer) {
+  if (!S.getLangOpts().OpenCL || S.getLangOpts().OpenCLVersion < 200 ||
+      !DestType->isQueueT() ||
+      !Initializer->isIntegerConstantExpr(S.getASTContext()) ||
+      (Initializer->EvaluateKnownConstInt(S.getASTContext()) != 0))
+    return false;
+
+  Sequence.AddOCLZeroQueueStep(DestType);
+  return true;
+}
+
 InitializationSequence::InitializationSequence(Sema &S,
                                                const InitializedEntity &Entity,
                                                const InitializationKind &Kind,
@@ -5571,13 +5603,21 @@ void InitializationSequence::InitializeFrom(Sema &S,
         tryObjCWritebackConversion(S, *this, Entity, Initializer)) {
       return;
     }
+  }
 
+  // need to try these when using C++ with OpenCL
+  if (!S.getLangOpts().CPlusPlus || S.getLangOpts().OpenCL) {
     if (TryOCLSamplerInitialization(S, *this, DestType, Initializer))
       return;
 
     if (TryOCLZeroOpaqueTypeInitialization(S, *this, DestType, Initializer))
       return;
 
+    if (TryOCLZeroQueueInitialization(S, *this, DestType, Initializer))
+      return;
+  }
+
+  if (!S.getLangOpts().CPlusPlus) {
     // Handle initialization in C
     AddCAssignmentStep(DestType);
     MaybeProduceObjCObject(S, *this, Entity);
@@ -7264,9 +7304,13 @@ ExprResult Sema::TemporaryMaterializationConversion(Expr *E) {
 ExprResult Sema::PerformQualificationConversion(Expr *E, QualType Ty,
                                                 ExprValueKind VK,
                                                 CheckedConversionKind CCK) {
+#if 0 // we don't want this
   CastKind CK = (Ty.getAddressSpace() != E->getType().getAddressSpace())
                     ? CK_AddressSpaceConversion
                     : CK_NoOp;
+#else
+	CastKind CK = CK_NoOp;
+#endif
   return ImpCastExprToType(E, Ty, CK, VK, /*BasePath=*/nullptr, CCK);
 }
 
@@ -7424,7 +7468,9 @@ ExprResult InitializationSequence::Perform(Sema &S,
   case SK_ProduceObjCObject:
   case SK_StdInitializerList:
   case SK_OCLSamplerInit:
-  case SK_OCLZeroOpaqueType: {
+  case SK_OCLZeroOpaqueType:
+  case SK_OCLZeroEvent:
+  case SK_OCLZeroQueue: {
     assert(Args.size() == 1);
     CurInit = Args[0];
     if (!CurInit.get()) return ExprError();
@@ -7530,7 +7576,10 @@ ExprResult InitializationSequence::Perform(Sema &S,
 
     case SK_BindReferenceToTemporary: {
       // Make sure the "temporary" is actually an rvalue.
-      assert(CurInit.get()->isRValue() && "not a temporary");
+      // TODO: fix this!
+      //if(CurInit.get()->getType()) {
+      //assert(CurInit.get()->isRValue() && "not a temporary");
+      //}
 
       // Check exception specifications
       if (S.CheckExceptionSpecCompatibility(CurInit.get(), DestType))
@@ -8093,6 +8142,7 @@ ExprResult InitializationSequence::Perform(Sema &S,
                                       CK_IntToOCLSampler);
       break;
     }
+    case SK_OCLZeroEvent:
     case SK_OCLZeroOpaqueType: {
       assert((Step->Type->isEventT() || Step->Type->isQueueT() ||
               Step->Type->isOCLIntelSubgroupAVCType()) &&
@@ -8103,6 +8153,15 @@ ExprResult InitializationSequence::Perform(Sema &S,
                                     CurInit.get()->getValueKind());
       break;
     }
+    case SK_OCLZeroQueue: {
+      assert(Step->Type->isQueueT() &&
+             "Event initialization on non queue type.");
+
+      CurInit = S.ImpCastExprToType(CurInit.get(), Step->Type,
+                                    CK_ZeroToOCLQueue,
+                                    CurInit.get()->getValueKind());
+      break;
+    }
     }
   }
 
@@ -8983,9 +9042,14 @@ void InitializationSequence::dump(raw_ostream &OS) const {
       OS << "OpenCL sampler_t from integer constant";
       break;
 
+    case SK_OCLZeroEvent:
     case SK_OCLZeroOpaqueType:
       OS << "OpenCL opaque type from zero";
       break;
+
+    case SK_OCLZeroQueue:
+      OS << "OpenCL queue_t from zero";
+      break;
     }
 
     OS << " [" << S->Type.getAsString() << ']';
diff --git a/lib/Sema/SemaLookup.cpp b/lib/Sema/SemaLookup.cpp
index a8a3651c5d..7a4f209fa4 100644
--- a/lib/Sema/SemaLookup.cpp
+++ b/lib/Sema/SemaLookup.cpp
@@ -693,6 +693,12 @@ static bool LookupBuiltin(Sema &S, LookupResult &R) {
       if (unsigned BuiltinID = II->getBuiltinID()) {
         // In C++ and OpenCL (spec v1.2 s6.9.f), we don't have any predefined
         // library functions like 'malloc'. Instead, we'll just error.
+        // OpenCL v1.2 s6.9.f:
+        // The library functions defined in the C99 standard headers assert.h,
+        // ctype.h, complex.h, errno.h, fenv.h, float.h, inttypes.h, limits.h,
+        // locale.h, setjmp.h, signal.h, stdarg.h, stdio.h, stdlib.h, string.h,
+        // tgmath.h, time.h, wchar.h and wctype.h are not available and cannot
+        // be included by a program.
         if ((S.getLangOpts().CPlusPlus || S.getLangOpts().OpenCL) &&
             S.Context.BuiltinInfo.isPredefinedLibFunction(BuiltinID))
           return false;
diff --git a/lib/Sema/SemaOverload.cpp b/lib/Sema/SemaOverload.cpp
index 4c7d61d79e..7012787f77 100644
--- a/lib/Sema/SemaOverload.cpp
+++ b/lib/Sema/SemaOverload.cpp
@@ -23,6 +23,7 @@
 #include "clang/Basic/DiagnosticOptions.h"
 #include "clang/Basic/PartialDiagnostic.h"
 #include "clang/Basic/TargetInfo.h"
+#include "clang/Lex/Preprocessor.h"
 #include "clang/Sema/Initialization.h"
 #include "clang/Sema/Lookup.h"
 #include "clang/Sema/SemaInternal.h"
@@ -136,9 +137,9 @@ ImplicitConversionRank clang::GetConversionRank(ImplicitConversionKind Kind) {
     ICR_Conversion,
     ICR_Conversion,
     ICR_Writeback_Conversion,
-    ICR_Exact_Match, // NOTE(gbiv): This may not be completely right --
-                     // it was omitted by the patch that added
-                     // ICK_Zero_Event_Conversion
+    ICR_Conversion,
+    ICR_Conversion,
+    ICR_Conversion,
     ICR_C_Conversion,
     ICR_C_Conversion_Extension
   };
@@ -173,7 +174,9 @@ static const char* GetImplicitConversionName(ImplicitConversionKind Kind) {
     "Block Pointer conversion",
     "Transparent Union Conversion",
     "Writeback conversion",
-    "OpenCL Zero Event Conversion",
+    "OpenCL Zero Event conversion",
+    "OpenCL Zero Queue Conversion",
+    "OpenCL Integer-to-Sampler conversion",
     "C specific type conversion",
     "Incompatible pointer conversion"
   };
@@ -1841,6 +1844,10 @@ static bool IsStandardConversion(Sema &S, Expr* From, QualType ToType,
              (From->EvaluateKnownConstInt(S.getASTContext()) == 0)) {
     SCS.Second = ICK_Zero_Queue_Conversion;
     FromType = ToType;
+  } else if (ToType->isSamplerT() &&
+             From->isIntegerConstantExpr(S.getASTContext())) {
+    SCS.Second = ICK_Int_Sampler_Conversion;
+    FromType = ToType;
   } else {
     // No second conversion required.
     SCS.Second = ICK_Identity;
@@ -3138,7 +3145,8 @@ Sema::IsQualificationConversion(QualType FromType, QualType ToType,
 
     //   -- for every j > 0, if const is in cv 1,j then const is in cv
     //      2,j, and similarly for volatile.
-    if (!CStyle && !ToQuals.compatiblyIncludes(FromQuals))
+    // NOTE: we want to have hard address space checking here if both types do have an actual address space, but we do allow casting to/from default adress space
+    if (!CStyle && !ToQuals.compatiblyIncludes(FromQuals, true /* check AS */, true /* allow default <-> other AS cast */))
       return false;
 
     //   -- if the cv 1,j and cv 2,j are different, then const is in
@@ -3155,12 +3163,14 @@ Sema::IsQualificationConversion(QualType FromType, QualType ToType,
 
   // Allows address space promotion by language rules implemented in
   // Type::Qualifiers::isAddressSpaceSupersetOf.
+#if 0 // we don't want this
   Qualifiers FromQuals = FromType.getQualifiers();
   Qualifiers ToQuals = ToType.getQualifiers();
   if (!ToQuals.isAddressSpaceSupersetOf(FromQuals) &&
       !FromQuals.isAddressSpaceSupersetOf(ToQuals)) {
     return false;
   }
+#endif
 
   // We are left with FromType and ToType being the pointee types
   // after unwrapping the original FromType and ToType the same number
@@ -4351,7 +4361,7 @@ Sema::CompareReferenceRelationship(SourceLocation Loc,
   T1Quals.removeUnaligned();
   T2Quals.removeUnaligned();
 
-  if (T1Quals.compatiblyIncludes(T2Quals))
+  if (T1Quals.compatiblyIncludes(T2Quals, !getASTContext().getLangOpts().OpenCL))
     return Ref_Compatible;
   else
     return Ref_Related;
@@ -4680,7 +4690,7 @@ TryReferenceInit(Sema &S, Expr *Init, QualType DeclType,
     // MS compiler ignores __unaligned qualifier for references; do the same.
     T1Quals.removeUnaligned();
     T2Quals.removeUnaligned();
-    if (!T1Quals.compatiblyIncludes(T2Quals))
+    if (!T1Quals.compatiblyIncludes(T2Quals, !S.getLangOpts().OpenCL))
       return ICS;
   }
 
@@ -5258,10 +5268,12 @@ Sema::PerformObjectArgumentInitialization(Expr *From,
   }
 
   if (!Context.hasSameType(From->getType(), DestType)) {
+#if 0 // we don't want this
     if (From->getType().getAddressSpace() != DestType.getAddressSpace())
       From = ImpCastExprToType(From, DestType, CK_AddressSpaceConversion,
                              From->getValueKind()).get();
     else
+#endif
       From = ImpCastExprToType(From, DestType, CK_NoOp,
                              From->getValueKind()).get();
   }
@@ -5311,6 +5323,7 @@ static bool CheckConvertedConstantConversions(Sema &S,
   case ICK_Integral_Promotion:
   case ICK_Integral_Conversion: // Narrowing conversions are checked elsewhere.
   case ICK_Zero_Queue_Conversion:
+  case ICK_Int_Sampler_Conversion:
     return true;
 
   case ICK_Boolean_Conversion:
@@ -6097,6 +6110,41 @@ void Sema::AddOverloadCandidate(FunctionDecl *Function,
     return;
   }
 
+  // OpenCL
+  // A candidate function that uses extentions that are not enabled or
+  // supported is not viable.
+  bool hasHalf = getOpenCLOptions().isEnabled("cl_khr_fp16") &&
+                 PP.getSupportedPragmas().isEnabled("cl_khr_fp16");
+  bool hasDouble = PP.getSupportedPragmas().isEnabled("cl_khr_fp64");
+
+  if (getLangOpts().OpenCL) {
+    if (!hasHalf && Function->getReturnType()->isHalfType()) {
+      Candidate.Viable = false;
+      Candidate.FailureKind = ovl_fail_bad_target;
+      return;
+    }
+    if (!hasDouble && Function->getReturnType()->isDoubleType()) {
+      Candidate.Viable = false;
+      Candidate.FailureKind = ovl_fail_bad_target;
+      return;
+    }
+    for (FunctionDecl::param_iterator PI = Function->param_begin(),
+         PE = Function->param_end(); PI != PE; ++PI) {
+      ParmVarDecl *Param = *PI;
+      QualType PT = Param->getType();
+      if (!hasHalf && PT->isHalfType()) {
+        Candidate.Viable = false;
+        Candidate.FailureKind = ovl_fail_bad_target;
+        return;
+      }
+      if (!hasDouble && PT->isDoubleType()) {
+        Candidate.Viable = false;
+        Candidate.FailureKind = ovl_fail_bad_target;
+        return;
+      }
+    }
+  }
+
   // (CUDA B.1): Check for invalid calls between targets.
   if (getLangOpts().CUDA)
     if (const FunctionDecl *Caller = dyn_cast<FunctionDecl>(CurContext))
diff --git a/lib/Sema/SemaStmtAttr.cpp b/lib/Sema/SemaStmtAttr.cpp
index 353cd60c4a..fdf7cbbdda 100644
--- a/lib/Sema/SemaStmtAttr.cpp
+++ b/lib/Sema/SemaStmtAttr.cpp
@@ -119,7 +119,7 @@ static Attr *handleLoopHintAttr(Sema &S, Stmt *St, const ParsedAttr &A,
     } else {
       // #pragma unroll
       Option = LoopHintAttr::Unroll;
-      State = LoopHintAttr::Enable;
+      State = LoopHintAttr::Full;
     }
   } else if (PragmaNoUnrollAndJam) {
     // #pragma nounroll_and_jam
diff --git a/lib/Sema/SemaTemplateDeduction.cpp b/lib/Sema/SemaTemplateDeduction.cpp
index 155d842c58..4ab89a80c1 100644
--- a/lib/Sema/SemaTemplateDeduction.cpp
+++ b/lib/Sema/SemaTemplateDeduction.cpp
@@ -3213,7 +3213,7 @@ CheckOriginalCallArgDeduction(Sema &S, TemplateDeductionInfo &Info,
 
     if (AQuals == DeducedAQuals) {
       // Qualifiers match; there's nothing to do.
-    } else if (!DeducedAQuals.compatiblyIncludes(AQuals)) {
+    } else if (!DeducedAQuals.compatiblyIncludes(AQuals, !S.getLangOpts().OpenCL)) {
       return Failed();
     } else {
       // Qualifiers are compatible, so have the argument type adopt the
diff --git a/lib/Sema/SemaTemplateInstantiateDecl.cpp b/lib/Sema/SemaTemplateInstantiateDecl.cpp
index 31353e45ba..b4489e6849 100644
--- a/lib/Sema/SemaTemplateInstantiateDecl.cpp
+++ b/lib/Sema/SemaTemplateInstantiateDecl.cpp
@@ -379,6 +379,30 @@ attrToRetainOwnershipKind(const Attr *A) {
   }
 }
 
+static void instantiateDependentFloorImageDataTypeAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const FloorImageDataTypeAttr *A, const Decl *Tmpl, Decl *New) {
+  TypeSourceInfo *Result = S.SubstType(A->getImageDataTypeLoc(), TemplateArgs,
+                                       A->getLocation(), DeclarationName());
+  if (Result) {
+    FloorImageDataTypeAttr *new_attr = new (S.getASTContext())
+        FloorImageDataTypeAttr(A->getLocation(), S.getASTContext(), Result,
+                               A->getSpellingListIndex());
+    New->addAttr(new_attr);
+  }
+}
+
+static void instantiateDependentGraphicsFBOColorLocationAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const GraphicsFBOColorLocationAttr *A, const Decl *Tmpl, Decl *New) {
+  // TODO: check Tmpl with isPotentialConstantExprUnevaluated?
+  EnterExpressionEvaluationContext Unevaluated(S, Sema::ExpressionEvaluationContext::ConstantEvaluated);
+  ExprResult Result = S.SubstExpr(A->getColorLocation(), TemplateArgs);
+  if (!Result.isInvalid())
+    S.AddGraphicsFBOColorLocationAttr(A->getLocation(), New, Result.getAs<Expr>(),
+                                      A->getSpellingListIndex());
+}
+
 void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
                             const Decl *Tmpl, Decl *New,
                             LateInstantiatedAttrVec *LateAttrs,
@@ -461,6 +485,18 @@ void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
       continue;
     }
 
+    const FloorImageDataTypeAttr *ImgType = dyn_cast<FloorImageDataTypeAttr>(TmplAttr);
+    if (ImgType && ImgType->getImageDataType()->isDependentType()) {
+      instantiateDependentFloorImageDataTypeAttr(*this, TemplateArgs, ImgType, Tmpl, New);
+      continue;
+    }
+
+    const GraphicsFBOColorLocationAttr *ColorLoc = dyn_cast<GraphicsFBOColorLocationAttr>(TmplAttr);
+    if (ColorLoc) {
+      instantiateDependentGraphicsFBOColorLocationAttr(*this, TemplateArgs, ColorLoc, Tmpl, New);
+      continue;
+    }
+
     assert(!TmplAttr->isPackExpansion());
     if (TmplAttr->isLateParsed() && LateAttrs) {
       // Late parsed attributes must be instantiated and attached after the
diff --git a/lib/Sema/SemaTemplateVariadic.cpp b/lib/Sema/SemaTemplateVariadic.cpp
index 3338cec5eb..7dda77fa6b 100644
--- a/lib/Sema/SemaTemplateVariadic.cpp
+++ b/lib/Sema/SemaTemplateVariadic.cpp
@@ -862,9 +862,14 @@ bool Sema::containsUnexpandedParameterPacks(Declarator &D) {
   case TST_auto:
   case TST_auto_type:
   case TST_decltype_auto:
+  case TST_unknown_anytype:
 #define GENERIC_IMAGE_TYPE(ImgType, Id) case TST_##ImgType##_t:
 #include "clang/Basic/OpenCLImageTypes.def"
-  case TST_unknown_anytype:
+  case TST_sampler_t:
+  case TST_event_t:
+  case TST_queue_t:
+  case TST_clk_event_t:
+  case TST_reserve_id_t:
   case TST_error:
     break;
   }
diff --git a/lib/Sema/SemaType.cpp b/lib/Sema/SemaType.cpp
index bd4a0e1407..65d85ad70d 100644
--- a/lib/Sema/SemaType.cpp
+++ b/lib/Sema/SemaType.cpp
@@ -20,6 +20,7 @@
 #include "clang/AST/DeclObjC.h"
 #include "clang/AST/DeclTemplate.h"
 #include "clang/AST/Expr.h"
+#include "clang/AST/Type.h"
 #include "clang/AST/TypeLoc.h"
 #include "clang/AST/TypeLocVisitor.h"
 #include "clang/Basic/PartialDiagnostic.h"
@@ -122,13 +123,17 @@ static void diagnoseBadTypeAttribute(Sema &S, const ParsedAttr &attr,
   case ParsedAttr::AT_Pcs:                                                     \
   case ParsedAttr::AT_IntelOclBicc:                                            \
   case ParsedAttr::AT_PreserveMost:                                            \
-  case ParsedAttr::AT_PreserveAll
+  case ParsedAttr::AT_PreserveAll:                                             \
+  case ParsedAttr::AT_ComputeKernel:                                           \
+  case ParsedAttr::AT_GraphicsVertexShader:                                    \
+  case ParsedAttr::AT_GraphicsFragmentShader
 
 // Function type attributes.
 #define FUNCTION_TYPE_ATTRS_CASELIST                                           \
   case ParsedAttr::AT_NSReturnsRetained:                                       \
   case ParsedAttr::AT_NoReturn:                                                \
   case ParsedAttr::AT_Regparm:                                                 \
+  case ParsedAttr::AT_RetRange:                                                \
   case ParsedAttr::AT_AnyX86NoCallerSavedRegisters:                            \
   case ParsedAttr::AT_AnyX86NoCfCheck:                                         \
     CALLING_CONV_ATTRS_CASELIST
@@ -325,7 +330,8 @@ enum TypeAttrLocation {
 };
 
 static void processTypeAttrs(TypeProcessingState &state, QualType &type,
-                             TypeAttrLocation TAL, ParsedAttributesView &attrs);
+                             TypeAttrLocation TAL, ParsedAttributesView &attrs,
+                             Declarator &D);
 
 static bool handleFunctionTypeAttr(TypeProcessingState &state, ParsedAttr &attr,
                                    QualType &type);
@@ -1218,12 +1224,12 @@ TypeResult Sema::actOnObjCTypeArgsAndProtocolQualifiers(
   return CreateParsedType(Result, ResultTInfo);
 }
 
-static OpenCLAccessAttr::Spelling
+static ImageAccessAttr::Spelling
 getImageAccess(const ParsedAttributesView &Attrs) {
   for (const ParsedAttr &AL : Attrs)
-    if (AL.getKind() == ParsedAttr::AT_OpenCLAccess)
-      return static_cast<OpenCLAccessAttr::Spelling>(AL.getSemanticSpelling());
-  return OpenCLAccessAttr::Keyword_read_only;
+    if (AL.getKind() == ParsedAttr::AT_ImageAccess)
+      return static_cast<ImageAccessAttr::Spelling>(AL.getSemanticSpelling());
+  return ImageAccessAttr::GNU_image_read_only;
 }
 
 /// Convert the specified declspec to the appropriate type
@@ -1343,6 +1349,9 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
         S.Diag(DeclLoc, diag::err_missing_actual_pipe_type)
           << DS.getSourceRange();
         declarator.setInvalidType(true);
+      } else if (S.getLangOpts().OpenCL) {
+        S.Diag(DeclLoc, diag::err_opencl_missing_type_specifier)
+          << DS.getSourceRange();
       } else {
         S.Diag(DeclLoc, diag::ext_missing_type_specifier)
           << DS.getSourceRange();
@@ -1583,20 +1592,41 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
     }
     break;
 
+  case DeclSpec::TST_sampler_t:
+    Result = Context.OCLSamplerTy;
+    break;
+
+  case DeclSpec::TST_event_t:
+    Result = Context.OCLEventTy;
+    break;
+  case DeclSpec::TST_queue_t:
+    Result = Context.OCLQueueTy;
+    break;
+  case DeclSpec::TST_clk_event_t:
+    Result = Context.OCLClkEventTy;
+    break;
+  case DeclSpec::TST_reserve_id_t:
+    Result = Context.OCLReserveIDTy;
+    break;
+
 #define GENERIC_IMAGE_TYPE(ImgType, Id)                                        \
-  case DeclSpec::TST_##ImgType##_t:                                            \
+  case DeclSpec::TST_##ImgType##_t: {                                          \
     switch (getImageAccess(DS.getAttributes())) {                              \
-    case OpenCLAccessAttr::Keyword_write_only:                                 \
-      Result = Context.Id##WOTy;                                               \
+    case ImageAccessAttr::GNU_image_write_only:                                \
+    case ImageAccessAttr::CXX11_image_write_only:                              \
+      Result = Context.Id##Ty;                                                 \
       break;                                                                   \
-    case OpenCLAccessAttr::Keyword_read_write:                                 \
-      Result = Context.Id##RWTy;                                               \
+    case ImageAccessAttr::GNU_image_read_write:                                \
+    case ImageAccessAttr::CXX11_image_read_write:                              \
+      Result = Context.Id##Ty;                                                 \
       break;                                                                   \
-    case OpenCLAccessAttr::Keyword_read_only:                                  \
-      Result = Context.Id##ROTy;                                               \
+    case ImageAccessAttr::GNU_image_read_only:                                 \
+    case ImageAccessAttr::CXX11_image_read_only:                               \
+      Result = Context.Id##Ty;                                                 \
       break;                                                                   \
     }                                                                          \
-    break;
+    break;                                                                     \
+  }
 #include "clang/Basic/OpenCLImageTypes.def"
 
   case DeclSpec::TST_error:
@@ -1648,7 +1678,7 @@ static QualType ConvertDeclSpecToType(TypeProcessingState &state) {
   // attributes are pushed around.
   // pipe attributes will be handled later ( at GetFullTypeForDeclarator )
   if (!DS.isTypeSpecPipe())
-    processTypeAttrs(state, Result, TAL_DeclSpec, DS.getAttributes());
+    processTypeAttrs(state, Result, TAL_DeclSpec, DS.getAttributes(), declarator);
 
   // Apply const/volatile/restrict qualifiers to T.
   if (unsigned TypeQuals = DS.getTypeQualifiers()) {
@@ -1946,7 +1976,7 @@ QualType Sema::BuildPointerType(QualType T,
     return QualType();
   }
 
-  if (T->isFunctionType() && getLangOpts().OpenCL) {
+  if (T->isFunctionType() && getLangOpts().OpenCL && !getLangOpts().CPlusPlus) {
     Diag(Loc, diag::err_opencl_function_pointer);
     return QualType();
   }
@@ -2030,7 +2060,9 @@ QualType Sema::BuildReferenceType(QualType T, bool SpelledAsLValue,
 ///
 /// \param T The type to which we'll be building a Pipe.
 ///
-/// \param Loc We do not use it for now.
+/// \param Loc The location of the entity whose type involves this
+/// pointer type or, if there is no such entity, the location of the
+/// type that will have pointer type.
 ///
 /// \returns A suitable pipe type, if there are no errors. Otherwise, returns a
 /// NULL type.
@@ -2288,10 +2320,20 @@ QualType Sema::BuildArrayType(QualType T, ArrayType::ArraySizeModifier ASM,
     const QualType ArrType = Context.getBaseElementType(T);
     if (ArrType->isBlockPointerType() || ArrType->isPipeType() ||
         ArrType->isSamplerT() || ArrType->isImageType()) {
+      // allow C array of images for Vulkan and Metal
+      if (!((getLangOpts().Vulkan || getLangOpts().Metal) && ArrType->isImageType())) {
       Diag(Loc, diag::err_opencl_invalid_type_array) << ArrType;
       return QualType();
     }
   }
+  }
+
+  QualType ElemTy = Context.getBaseElementType(T);
+  if (getLangOpts().OpenCL && getLangOpts().OpenCLVersion >= 200 &&
+      ElemTy->isBlockPointerType()) {
+    Diag(Loc, diag::err_invalid_block_array);
+    return QualType();
+  }
 
   return T;
 }
@@ -2406,7 +2448,7 @@ bool Sema::CheckFunctionReturnType(QualType T, SourceLocation Loc) {
   }
 
   // Functions cannot return half FP.
-  if (T->isHalfType() && !getLangOpts().HalfArgsAndReturns) {
+  if (T->isHalfType() && !getLangOpts().HalfArgsAndReturns && !LangOpts.OpenCL && !LangOpts.CUDA) {
     Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 1 <<
       FixItHint::CreateInsertion(Loc, "*");
     return true;
@@ -2493,7 +2535,7 @@ QualType Sema::BuildFunctionType(QualType T,
     if (ParamType->isVoidType()) {
       Diag(Loc, diag::err_param_with_void_type);
       Invalid = true;
-    } else if (ParamType->isHalfType() && !getLangOpts().HalfArgsAndReturns) {
+    } else if (ParamType->isHalfType() && !getLangOpts().HalfArgsAndReturns && !LangOpts.OpenCL && !LangOpts.CUDA) {
       // Disallow half FP arguments.
       Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 0 <<
         FixItHint::CreateInsertion(Loc, "*");
@@ -2866,7 +2908,7 @@ static QualType GetDeclSpecTypeForDeclarator(TypeProcessingState &state,
     // "void" instead.
     T = SemaRef.Context.VoidTy;
     processTypeAttrs(state, T, TAL_DeclSpec,
-                     D.getMutableDeclSpec().getAttributes());
+                     D.getMutableDeclSpec().getAttributes(), D);
     break;
 
   case UnqualifiedIdKind::IK_DeductionGuideName:
@@ -3438,14 +3480,22 @@ static CallingConv getCCForDeclaratorChunk(
   CallingConv CC = S.Context.getDefaultCallingConvention(FTI.isVariadic,
                                                          IsCXXInstanceMethod);
 
-  // Attribute AT_OpenCLKernel affects the calling convention for SPIR
-  // and AMDGPU targets, hence it cannot be treated as a calling
-  // convention attribute. This is the simplest place to infer
-  // calling convention for OpenCL kernels.
-  if (S.getLangOpts().OpenCL) {
+  // Attributes AT_ComputeKernel, AT_GraphicsVertexShader, AT_GraphicsFragmentShader
+  // affect the calling convention only on SPIR, AIR and CUDA targets, hence they cannot
+  // be treated as calling convention attributes. This is the simplest place to infer
+  // "floor_kernel"/"floor_vertex"/"floor_fragment".
+  if (CC == CC_FloorFunction) {
     for (const ParsedAttr &AL : D.getDeclSpec().getAttributes()) {
-      if (AL.getKind() == ParsedAttr::AT_OpenCLKernel) {
-        CC = CC_OpenCLKernel;
+      if (AL.getKind() == ParsedAttr::AT_ComputeKernel) {
+        CC = CC_FloorKernel;
+        break;
+      }
+      if (AL.getKind() == ParsedAttr::AT_GraphicsVertexShader) {
+        CC = CC_FloorVertex;
+        break;
+      }
+      if (AL.getKind() == ParsedAttr::AT_GraphicsFragmentShader) {
+        CC = CC_FloorFragment;
         break;
       }
     }
@@ -4540,7 +4590,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
                 << T << 0 /*pointer hint*/;
             D.setInvalidType(true);
           }
-        } else if (!S.getLangOpts().HalfArgsAndReturns) {
+        } else if (!S.getLangOpts().HalfArgsAndReturns && !S.getLangOpts().CUDA) {
           S.Diag(D.getIdentifierLoc(),
             diag::err_parameters_retval_cannot_have_fp16_type) << 1;
           D.setInvalidType(true);
@@ -4559,6 +4609,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
         // OpenCL doesn't support variadic functions and blocks
         // (s6.9.e and s6.12.5 OpenCL v2.0) except for printf.
         // We also allow here any toolchain reserved identifiers.
+#if 0 // nope
         if (FTI.isVariadic &&
             !(D.getIdentifier() &&
               ((D.getIdentifier()->getName() == "printf" &&
@@ -4567,6 +4618,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
           S.Diag(D.getIdentifierLoc(), diag::err_opencl_variadic_function);
           D.setInvalidType(true);
         }
+#endif
       }
 
       // Methods cannot return interface types. All ObjC objects are
@@ -4751,7 +4803,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
                 D.setInvalidType();
                 Param->setInvalidDecl();
               }
-            } else if (!S.getLangOpts().HalfArgsAndReturns) {
+            } else if (!S.getLangOpts().HalfArgsAndReturns && !S.getLangOpts().CUDA) {
               S.Diag(Param->getLocation(),
                 diag::err_parameters_retval_cannot_have_fp16_type) << 0;
               D.setInvalidType();
@@ -4909,7 +4961,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
     case DeclaratorChunk::Pipe: {
       T = S.BuildReadPipeType(T, DeclType.Loc);
       processTypeAttrs(state, T, TAL_DeclSpec,
-                       D.getMutableDeclSpec().getAttributes());
+                       D.getMutableDeclSpec().getAttributes(), D);
       break;
     }
     }
@@ -4920,7 +4972,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
     }
 
     // See if there are any attributes on this declarator chunk.
-    processTypeAttrs(state, T, TAL_DeclChunk, DeclType.getAttrs());
+    processTypeAttrs(state, T, TAL_DeclChunk, DeclType.getAttrs(), D);
 
     if (DeclType.Kind != DeclaratorChunk::Paren) {
       if (ExpectNoDerefChunk) {
@@ -5062,7 +5114,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
   }
 
   // Apply any undistributed attributes from the declarator.
-  processTypeAttrs(state, T, TAL_DeclName, D.getAttributes());
+  processTypeAttrs(state, T, TAL_DeclName, D.getAttributes(), D);
 
   // Diagnose any ignored type attributes.
   state.diagnoseIgnoredTypeAttrs(T);
@@ -5885,18 +5937,20 @@ static void HandleAddressSpaceTypeAttribute(QualType &Type,
   } else {
     // The keyword-based type attributes imply which address space to use.
     switch (Attr.getKind()) {
-    case ParsedAttr::AT_OpenCLGlobalAddressSpace:
+    case ParsedAttr::AT_GlobalAddressSpace:
       ASIdx = LangAS::opencl_global; break;
-    case ParsedAttr::AT_OpenCLLocalAddressSpace:
+    case ParsedAttr::AT_LocalAddressSpace:
       ASIdx = LangAS::opencl_local; break;
-    case ParsedAttr::AT_OpenCLConstantAddressSpace:
+    case ParsedAttr::AT_ConstantAddressSpace:
       ASIdx = LangAS::opencl_constant; break;
-    case ParsedAttr::AT_OpenCLGenericAddressSpace:
+    case ParsedAttr::AT_GenericAddressSpace:
       ASIdx = LangAS::opencl_generic; break;
-    case ParsedAttr::AT_OpenCLPrivateAddressSpace:
+    case ParsedAttr::AT_PrivateAddressSpace:
       ASIdx = LangAS::opencl_private; break;
     default:
-      llvm_unreachable("Invalid address space");
+      //llvm_unreachable("Invalid address space");
+      assert(Attr.getKind() == ParsedAttr::AT_PrivateAddressSpace);
+      ASIdx = LangAS::opencl_private; break;
     }
 
     // If this type is already address space qualified with a different
@@ -6727,6 +6781,12 @@ static Attr *getCCTypeAttr(ASTContext &Ctx, ParsedAttr &Attr) {
     return createSimpleAttr<PreserveMostAttr>(Ctx, Attr);
   case ParsedAttr::AT_PreserveAll:
     return createSimpleAttr<PreserveAllAttr>(Ctx, Attr);
+  case ParsedAttr::AT_GraphicsVertexShader:
+    return createSimpleAttr<GraphicsVertexShaderAttr>(Ctx, Attr);
+  case ParsedAttr::AT_GraphicsFragmentShader:
+    return createSimpleAttr<GraphicsFragmentShaderAttr>(Ctx, Attr);
+  case ParsedAttr::AT_ComputeKernel:
+    return createSimpleAttr<ComputeKernelAttr>(Ctx, Attr);
   }
   llvm_unreachable("unexpected attribute kind!");
 }
@@ -7143,62 +7203,6 @@ static void HandleNeonVectorTypeAttr(QualType &CurType, const ParsedAttr &Attr,
   CurType = S.Context.getVectorType(CurType, numElts, VecKind);
 }
 
-/// Handle OpenCL Access Qualifier Attribute.
-static void HandleOpenCLAccessAttr(QualType &CurType, const ParsedAttr &Attr,
-                                   Sema &S) {
-  // OpenCL v2.0 s6.6 - Access qualifier can be used only for image and pipe type.
-  if (!(CurType->isImageType() || CurType->isPipeType())) {
-    S.Diag(Attr.getLoc(), diag::err_opencl_invalid_access_qualifier);
-    Attr.setInvalid();
-    return;
-  }
-
-  if (const TypedefType* TypedefTy = CurType->getAs<TypedefType>()) {
-    QualType BaseTy = TypedefTy->desugar();
-
-    std::string PrevAccessQual;
-    if (BaseTy->isPipeType()) {
-      if (TypedefTy->getDecl()->hasAttr<OpenCLAccessAttr>()) {
-        OpenCLAccessAttr *Attr =
-            TypedefTy->getDecl()->getAttr<OpenCLAccessAttr>();
-        PrevAccessQual = Attr->getSpelling();
-      } else {
-        PrevAccessQual = "read_only";
-      }
-    } else if (const BuiltinType* ImgType = BaseTy->getAs<BuiltinType>()) {
-
-      switch (ImgType->getKind()) {
-        #define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \
-      case BuiltinType::Id:                                          \
-        PrevAccessQual = #Access;                                    \
-        break;
-        #include "clang/Basic/OpenCLImageTypes.def"
-      default:
-        llvm_unreachable("Unable to find corresponding image type.");
-      }
-    } else {
-      llvm_unreachable("unexpected type");
-    }
-    StringRef AttrName = Attr.getName()->getName();
-    if (PrevAccessQual == AttrName.ltrim("_")) {
-      // Duplicated qualifiers
-      S.Diag(Attr.getLoc(), diag::warn_duplicate_declspec)
-         << AttrName << Attr.getRange();
-    } else {
-      // Contradicting qualifiers
-      S.Diag(Attr.getLoc(), diag::err_opencl_multiple_access_qualifiers);
-    }
-
-    S.Diag(TypedefTy->getDecl()->getBeginLoc(),
-           diag::note_opencl_typedef_access_qualifier) << PrevAccessQual;
-  } else if (CurType->isPipeType()) {
-    if (Attr.getSemanticSpelling() == OpenCLAccessAttr::Keyword_write_only) {
-      QualType ElemType = CurType->getAs<PipeType>()->getElementType();
-      CurType = S.Context.getWritePipeType(ElemType);
-    }
-  }
-}
-
 static void deduceOpenCLImplicitAddrSpace(TypeProcessingState &State,
                                           QualType &T, TypeAttrLocation TAL) {
   Declarator &D = State.getDeclarator();
@@ -7254,13 +7258,16 @@ static void deduceOpenCLImplicitAddrSpace(TypeProcessingState &State,
     return;
 
   LangAS ImpAddr = LangAS::Default;
+  // NOTE: disabled due to it being _very_ incompatible to other backends right now
+#if 0 // we don't want automatic address space deduction
   // Put OpenCL automatic variable in private address space.
   // OpenCL v1.2 s6.5:
   // The default address space name for arguments to a function in a
   // program, or local variables of a function is __private. All function
   // arguments shall be in the __private address space.
   if (State.getSema().getLangOpts().OpenCLVersion <= 120 &&
-      !State.getSema().getLangOpts().OpenCLCPlusPlus) {
+      !State.getSema().getLangOpts().OpenCLCPlusPlus &&
+      !State.getSema().getLangOpts().CPlusPlus) {
     ImpAddr = LangAS::opencl_private;
   } else {
     // If address space is not set, OpenCL 2.0 defines non private default
@@ -7282,13 +7289,19 @@ static void deduceOpenCLImplicitAddrSpace(TypeProcessingState &State,
       } else {
         if (D.getDeclSpec().getStorageClassSpec() == DeclSpec::SCS_static ||
             D.getDeclSpec().getStorageClassSpec() == DeclSpec::SCS_extern) {
-          ImpAddr = LangAS::opencl_global;
+			if (D.getDeclSpec().isConstexprSpecified() ||
+				T.isConstQualified()) {
+				ImpAddr = LangAS::opencl_constant;
+			} else {
+				ImpAddr = LangAS::opencl_global;
+			}
         } else {
           ImpAddr = LangAS::opencl_private;
         }
       }
     }
   }
+#endif
   T = State.getSema().Context.getAddrSpaceQualType(T, ImpAddr);
 }
 
@@ -7307,7 +7320,8 @@ static void HandleLifetimeBoundAttr(TypeProcessingState &State,
 
 static void processTypeAttrs(TypeProcessingState &state, QualType &type,
                              TypeAttrLocation TAL,
-                             ParsedAttributesView &attrs) {
+                             ParsedAttributesView &attrs,
+                             Declarator &D) {
   // Scan through and apply attributes to this type where it makes sense.  Some
   // attributes (such as __address_space__, __vector_size__, etc) apply to the
   // type, but others can be present in the type specifiers even though they
@@ -7376,11 +7390,11 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
       // it it breaks large amounts of Linux software.
       attr.setUsedAsTypeAttr();
       break;
-    case ParsedAttr::AT_OpenCLPrivateAddressSpace:
-    case ParsedAttr::AT_OpenCLGlobalAddressSpace:
-    case ParsedAttr::AT_OpenCLLocalAddressSpace:
-    case ParsedAttr::AT_OpenCLConstantAddressSpace:
-    case ParsedAttr::AT_OpenCLGenericAddressSpace:
+    case ParsedAttr::AT_PrivateAddressSpace:
+    case ParsedAttr::AT_GlobalAddressSpace:
+    case ParsedAttr::AT_LocalAddressSpace:
+    case ParsedAttr::AT_ConstantAddressSpace:
+    case ParsedAttr::AT_GenericAddressSpace:
     case ParsedAttr::AT_AddressSpace:
       HandleAddressSpaceTypeAttribute(type, attr, state);
       attr.setUsedAsTypeAttr();
@@ -7408,8 +7422,28 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
                                VectorType::NeonPolyVector);
       attr.setUsedAsTypeAttr();
       break;
-    case ParsedAttr::AT_OpenCLAccess:
-      HandleOpenCLAccessAttr(type, attr, state.getSema());
+    case ParsedAttr::AT_ImageAccess:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_FloorImageDataType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_VectorCompat:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_GraphicsFBOColorLocation:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_GraphicsFBODepthType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_GraphicsVertexPosition:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_GraphicsPointSize:
+      attr.setUsedAsTypeAttr();
+      break;
+    case ParsedAttr::AT_GraphicsStageInput:
       attr.setUsedAsTypeAttr();
       break;
     case ParsedAttr::AT_LifetimeBound:
diff --git a/lib/Sema/TreeTransform.h b/lib/Sema/TreeTransform.h
index 3f4b21eb55..45c38fd4ad 100644
--- a/lib/Sema/TreeTransform.h
+++ b/lib/Sema/TreeTransform.h
@@ -4275,8 +4275,10 @@ QualType TreeTransform<Derived>::RebuildQualifiedType(QualType T,
   //   [When] adding cv-qualifications on top of the function type [...] the
   //   cv-qualifiers are ignored.
   if (T->isFunctionType()) {
+#if 0 // we don't want this
     T = SemaRef.getASTContext().getAddrSpaceQualType(T,
                                                      Quals.getAddressSpace());
+#endif
     return T;
   }
 
@@ -5299,11 +5301,13 @@ QualType TreeTransform<Derived>::TransformFunctionProtoType(
       return QualType();
 
     // Return type can not be qualified with an address space.
+#if 0 // we don't want this
     if (ResultType.getAddressSpace() != LangAS::Default) {
       SemaRef.Diag(TL.getReturnLoc().getBeginLoc(),
                    diag::err_attribute_address_function_type);
       return QualType();
     }
+#endif
 
     if (getDerived().TransformFunctionTypeParams(
             TL.getBeginLoc(), TL.getParams(),
diff --git a/lib/Serialization/ASTReaderDecl.cpp b/lib/Serialization/ASTReaderDecl.cpp
index 8c1710f660..9f82251ca3 100644
--- a/lib/Serialization/ASTReaderDecl.cpp
+++ b/lib/Serialization/ASTReaderDecl.cpp
@@ -1370,8 +1370,8 @@ ASTDeclReader::RedeclarableResult ASTDeclReader::VisitVarDeclImpl(VarDecl *VD) {
   VD->setCachedLinkage(VarLinkage);
 
   // Reconstruct the one piece of the IdentifierNamespace that we need.
-  if (VD->getStorageClass() == SC_Extern && VarLinkage != NoLinkage &&
-      VD->getLexicalDeclContext()->isFunctionOrMethod())
+  if ((VD->getStorageClass() == SC_Extern || VD->getStorageClass() == SC_OpenCLConstantExtern) &&
+      VarLinkage != NoLinkage && VD->getLexicalDeclContext()->isFunctionOrMethod())
     VD->setLocalExternDecl();
 
   if (uint64_t Val = Record.readInt()) {
diff --git a/lib/StaticAnalyzer/Core/ExprEngineC.cpp b/lib/StaticAnalyzer/Core/ExprEngineC.cpp
index 7d47cf4f33..b7ab42aedf 100644
--- a/lib/StaticAnalyzer/Core/ExprEngineC.cpp
+++ b/lib/StaticAnalyzer/Core/ExprEngineC.cpp
@@ -413,6 +413,8 @@ void ExprEngine::VisitCast(const CastExpr *CastE, const Expr *Ex,
       case CK_AnyPointerToBlockPointerCast:
       case CK_ObjCObjectLValueCast:
       case CK_ZeroToOCLOpaqueType:
+      case CK_ZeroToOCLEvent:
+      case CK_ZeroToOCLQueue:
       case CK_IntToOCLSampler:
       case CK_LValueBitCast:
       case CK_FixedPointCast:
diff --git a/tools/driver/cc1_main.cpp b/tools/driver/cc1_main.cpp
index 7d21c6a671..57dd0bd1f6 100644
--- a/tools/driver/cc1_main.cpp
+++ b/tools/driver/cc1_main.cpp
@@ -18,6 +18,7 @@
 #include "clang/Config/config.h"
 #include "clang/Driver/DriverDiagnostic.h"
 #include "clang/Driver/Options.h"
+#include "clang/Lex/PreprocessorOptions.h"
 #include "clang/Frontend/CompilerInstance.h"
 #include "clang/Frontend/CompilerInvocation.h"
 #include "clang/Frontend/FrontendDiagnostic.h"
@@ -176,6 +177,30 @@ int cc1_main(ArrayRef<const char *> Argv, const char *Argv0, void *MainAddr) {
   PCHOps->registerWriter(llvm::make_unique<ObjectFilePCHContainerWriter>());
   PCHOps->registerReader(llvm::make_unique<ObjectFilePCHContainerReader>());
 
+  // Enable OpenCL supported pragmas by default.
+  OpenCLOptions &SP = Clang->getPreprocessorOpts().SupportedPragmas;
+  SP.enable("cl_khr_3d_image_writes");
+  SP.enable("cl_khr_byte_addressable_store");
+  SP.enable("cl_khr_depth_images");
+  SP.enable("cl_khr_d3d10_sharing");
+  SP.enable("cl_khr_fp16");
+  SP.enable("cl_khr_fp64");
+  SP.enable("cl_khr_gl_event");
+  SP.enable("cl_khr_gl_msaa_sharing");
+  SP.enable("cl_khr_gl_sharing");
+  SP.enable("cl_khr_int64_base_atomics");
+  SP.enable("cl_khr_int64_extended_atomics");
+  SP.enable("cl_khr_global_int32_base_atomics");
+  SP.enable("cl_khr_global_int32_extended_atomics");
+  SP.enable("cl_khr_local_int32_base_atomics");
+  SP.enable("cl_khr_local_int32_extended_atomics");
+  SP.enable("cl_khr_subgroups");
+  SP.enable("cl_khr_mipmap_image");
+  SP.enable("cl_khr_mipmap_image_writes");
+  SP.enable("cl_intel_subgroups");
+
+  SP.enable("cl_clang_storage_class_specifiers");
+
   // Initialize targets first, so that --version shows registered targets.
   llvm::InitializeAllTargets();
   llvm::InitializeAllTargetMCs();
diff --git a/tools/libclang/CIndex.cpp b/tools/libclang/CIndex.cpp
index ca8b4baf6c..351eb22832 100644
--- a/tools/libclang/CIndex.cpp
+++ b/tools/libclang/CIndex.cpp
@@ -5280,11 +5280,11 @@ CXString clang_getCursorKindSpelling(enum CXCursorKind Kind) {
   case CXCursor_NoDuplicateAttr:
     return cxstring::createRef("attribute(noduplicate)");
   case CXCursor_CUDAConstantAttr:
-    return cxstring::createRef("attribute(constant)");
+    return cxstring::createRef("attribute(constant_cuda)");
   case CXCursor_CUDADeviceAttr:
     return cxstring::createRef("attribute(device)");
-  case CXCursor_CUDAGlobalAttr:
-    return cxstring::createRef("attribute(global)");
+  case CXCursor_ComputeKernelAttr:
+    return cxstring::createRef("attribute(compute_kernel)");
   case CXCursor_CUDAHostAttr:
     return cxstring::createRef("attribute(host)");
   case CXCursor_CUDASharedAttr:
@@ -7972,6 +7972,8 @@ enum CX_StorageClass clang_Cursor_getStorageClass(CXCursor C) {
   }
   switch (sc) {
   case SC_None:
+  case SC_OpenCLConstant: // unsupported in here
+  case SC_OpenCLConstantExtern: // unsupported in here
     return CX_SC_None;
   case SC_Extern:
     return CX_SC_Extern;
diff --git a/tools/libclang/CXCursor.cpp b/tools/libclang/CXCursor.cpp
index b8c2529169..d831d9c700 100644
--- a/tools/libclang/CXCursor.cpp
+++ b/tools/libclang/CXCursor.cpp
@@ -55,7 +55,7 @@ static CXCursorKind GetCursorKind(const Attr *A) {
     case attr::NoDuplicate: return CXCursor_NoDuplicateAttr;
     case attr::CUDAConstant: return CXCursor_CUDAConstantAttr;
     case attr::CUDADevice: return CXCursor_CUDADeviceAttr;
-    case attr::CUDAGlobal: return CXCursor_CUDAGlobalAttr;
+    case attr::ComputeKernel: return CXCursor_ComputeKernelAttr;
     case attr::CUDAHost: return CXCursor_CUDAHostAttr;
     case attr::CUDAShared: return CXCursor_CUDASharedAttr;
     case attr::Visibility: return CXCursor_VisibilityAttr;
diff --git a/tools/libclang/CXType.cpp b/tools/libclang/CXType.cpp
index b511046fe6..431ff51290 100644
--- a/tools/libclang/CXType.cpp
+++ b/tools/libclang/CXType.cpp
@@ -657,11 +657,13 @@ CXCallingConv clang_getFunctionTypeCallingConv(CXType X) {
       TCALLINGCONV(AAPCS);
       TCALLINGCONV(AAPCS_VFP);
       TCALLINGCONV(IntelOclBicc);
+      TCALLINGCONV(FloorFunction);
+      TCALLINGCONV(FloorKernel);
+      TCALLINGCONV(FloorVertex);
+      TCALLINGCONV(FloorFragment);
       TCALLINGCONV(Swift);
       TCALLINGCONV(PreserveMost);
       TCALLINGCONV(PreserveAll);
-    case CC_SpirFunction: return CXCallingConv_Unexposed;
-    case CC_OpenCLKernel: return CXCallingConv_Unexposed;
       break;
     }
 #undef TCALLINGCONV
