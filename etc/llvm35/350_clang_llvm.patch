diff --git a/include/llvm/ADT/Triple.h b/include/llvm/ADT/Triple.h
index b96f114..0ac3249 100644
--- a/include/llvm/ADT/Triple.h
+++ b/include/llvm/ADT/Triple.h
@@ -77,6 +77,7 @@ public:
     amdil,      // amdil: amd IL
     spir,       // SPIR: standard portable IR for OpenCL 32-bit version
     spir64,     // SPIR: standard portable IR for OpenCL 64-bit version
+    air64,      // AIR: Apple IR, used for Metal, always 64-bit
     kalimba     // Kalimba: generic kalimba
   };
   enum SubArchType {
diff --git a/include/llvm/CodeGen/AsmPrinter.h b/include/llvm/CodeGen/AsmPrinter.h
index de14c1a..80fc6bc 100644
--- a/include/llvm/CodeGen/AsmPrinter.h
+++ b/include/llvm/CodeGen/AsmPrinter.h
@@ -232,7 +232,7 @@ public:
   /// requested, it will override the alignment request if required for
   /// correctness.
   ///
-  void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const;
+  virtual void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const;
 
   /// This method prints the label for the specified MachineBasicBlock, an
   /// alignment (if present) and a comment describing it if appropriate.
@@ -500,7 +500,7 @@ private:
   void EmitVisibility(MCSymbol *Sym, unsigned Visibility,
                       bool IsDefinition = true) const;
 
-  void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const;
+  virtual void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const;
 
   void EmitJumpTableEntry(const MachineJumpTableInfo *MJTI,
                           const MachineBasicBlock *MBB, unsigned uid) const;
diff --git a/include/llvm/IR/DerivedTypes.h b/include/llvm/IR/DerivedTypes.h
index ff15087..0e9430c 100644
--- a/include/llvm/IR/DerivedTypes.h
+++ b/include/llvm/IR/DerivedTypes.h
@@ -194,7 +194,8 @@ class StructType : public CompositeType {
     SCDB_HasBody = 1,
     SCDB_Packed = 2,
     SCDB_IsLiteral = 4,
-    SCDB_IsSized = 8
+    SCDB_IsSized = 8,
+    SCDB_IsMetalReturnType = 16
   };
 
   /// SymbolTableEntry - For a named struct that actually has a name, this is a
@@ -248,6 +249,15 @@ public:
   /// specified yet.  These prints as 'opaque' in .ll files.
   bool isOpaque() const { return (getSubclassData() & SCDB_HasBody) == 0; }
 
+  /// isMetalReturnType - Return true if this type is used as a metal vertex/fragment
+  /// shader return type.
+  bool isMetalReturnType() const { return (getSubclassData() & SCDB_IsMetalReturnType) != 0; }
+
+  /// setMetalReturnType - Flags this type as a metal return type.
+  void setMetalReturnType() {
+    setSubclassData(getSubclassData() | SCDB_IsMetalReturnType);
+  }
+
   /// isSized - Return true if this is a sized type.
   bool isSized(SmallPtrSet<const Type*, 4> *Visited = nullptr) const;
   
diff --git a/include/llvm/IR/Metadata.h b/include/llvm/IR/Metadata.h
index 7a0ca88..4b27374 100644
--- a/include/llvm/IR/Metadata.h
+++ b/include/llvm/IR/Metadata.h
@@ -30,7 +30,8 @@ template<typename ValueSubClass, typename ItemParentClass>
 
 
 enum LLVMConstants : uint32_t {
-  DEBUG_METADATA_VERSION = 1  // Current debug info version number.
+  DEBUG_METADATA_VERSION = 1,  // Current debug info version number.
+  IOS_METAL_DEBUG_METADATA_VERSION = 360203
 };
 
 //===----------------------------------------------------------------------===//
diff --git a/include/llvm/InitializePasses.h b/include/llvm/InitializePasses.h
index 02f4259..37570c8 100644
--- a/include/llvm/InitializePasses.h
+++ b/include/llvm/InitializePasses.h
@@ -64,6 +64,14 @@ void initializeTarget(PassRegistry&);
 
 void initializeAAEvalPass(PassRegistry&);
 void initializeAddDiscriminatorsPass(PassRegistry&);
+void initializeAddressSpaceFixPass(PassRegistry&);
+void initializeCUDAImagePass(PassRegistry&);
+void initializeCUDAFinalPass(PassRegistry&);
+void initializeMetalFirstPass(PassRegistry&);
+void initializeMetalFinalPass(PassRegistry&);
+void initializeMetalImagePass(PassRegistry&);
+void initializeSPIRFinalPass(PassRegistry&);
+void initializeSPIRImagePass(PassRegistry&);
 void initializeADCEPass(PassRegistry&);
 void initializeAliasAnalysisAnalysisGroup(PassRegistry&);
 void initializeAliasAnalysisCounterPass(PassRegistry&);
@@ -117,6 +125,7 @@ void initializeDominanceFrontierPass(PassRegistry&);
 void initializeDominatorTreeWrapperPassPass(PassRegistry&);
 void initializeEarlyIfConverterPass(PassRegistry&);
 void initializeEdgeBundlesPass(PassRegistry&);
+void initializeEverythingInlinerPass(PassRegistry&);
 void initializeExpandPostRAPass(PassRegistry&);
 void initializeGCOVProfilerPass(PassRegistry&);
 void initializeAddressSanitizerPass(PassRegistry&);
diff --git a/include/llvm/LinkAllPasses.h b/include/llvm/LinkAllPasses.h
index e06560c..19d9e6c 100644
--- a/include/llvm/LinkAllPasses.h
+++ b/include/llvm/LinkAllPasses.h
@@ -48,6 +48,14 @@ namespace {
         return;
 
       (void) llvm::createAAEvalPass();
+      (void) llvm::createAddressSpaceFixPass();
+      (void) llvm::createCUDAImagePass();
+      (void) llvm::createCUDAFinalPass();
+      (void) llvm::createMetalFirstPass(false);
+      (void) llvm::createMetalFinalPass(false);
+      (void) llvm::createMetalImagePass();
+      (void) llvm::createSPIRFinalPass();
+      (void) llvm::createSPIRImagePass();
       (void) llvm::createAggressiveDCEPass();
       (void) llvm::createAliasAnalysisCounterPass();
       (void) llvm::createAliasDebugger();
@@ -77,6 +85,7 @@ namespace {
       (void) llvm::createGCOVProfilerPass();
       (void) llvm::createFunctionInliningPass();
       (void) llvm::createAlwaysInlinerPass();
+      (void) llvm::createEverythingInlinerPass();
       (void) llvm::createGlobalDCEPass();
       (void) llvm::createGlobalOptimizerPass();
       (void) llvm::createGlobalsModRefPass();
diff --git a/include/llvm/Transforms/IPO.h b/include/llvm/Transforms/IPO.h
index ce1a7d6..0511a23 100644
--- a/include/llvm/Transforms/IPO.h
+++ b/include/llvm/Transforms/IPO.h
@@ -98,6 +98,12 @@ Pass *createAlwaysInlinerPass();
 Pass *createAlwaysInlinerPass(bool InsertLifetime);
 
 //===----------------------------------------------------------------------===//
+/// createEverythingInlinerPass - Return a new pass object that inlines
+/// everything, unless it was marked "noinline".
+Pass *createEverythingInlinerPass();
+Pass *createEverythingInlinerPass(bool InsertLifetime);
+
+//===----------------------------------------------------------------------===//
 /// createPruneEHPass - Return a new pass object which transforms invoke
 /// instructions into calls, if the callee can _not_ unwind the stack.
 ///
@@ -177,6 +183,7 @@ ModulePass *createStripDeadPrototypesPass();
 /// and marks them with the nocapture attribute.
 ///
 Pass *createFunctionAttrsPass();
+extern char &FunctionAttrsID;
 
 //===----------------------------------------------------------------------===//
 /// createMergeFunctionsPass - This pass discovers identical functions and
diff --git a/include/llvm/Transforms/IPO/PassManagerBuilder.h b/include/llvm/Transforms/IPO/PassManagerBuilder.h
index 50877d0..4af3890 100644
--- a/include/llvm/Transforms/IPO/PassManagerBuilder.h
+++ b/include/llvm/Transforms/IPO/PassManagerBuilder.h
@@ -118,6 +118,14 @@ public:
   bool LoopVectorize;
   bool RerollLoops;
   bool LoadCombine;
+  bool EnableAddressSpaceFix;
+  bool EnableCUDAPasses;
+  bool EnableMetalPasses;
+  bool EnableMetalIntelWorkarounds;
+  bool EnableSPIRPasses;
+
+  // can't rely on clang header here, so just use a uint32_t
+  unsigned int floor_image_capabilities { 0 };
 
 private:
   /// ExtensionList - This is list of all of the extensions that are registered.
diff --git a/include/llvm/Transforms/Scalar.h b/include/llvm/Transforms/Scalar.h
index 413134e..9221f55 100644
--- a/include/llvm/Transforms/Scalar.h
+++ b/include/llvm/Transforms/Scalar.h
@@ -30,6 +30,55 @@ class TargetMachine;
 
 //===----------------------------------------------------------------------===//
 //
+// AddressSpaceFix - This pass fixes (intentionally) broken uses of addrspace
+// pointers that should be non-addrspace pointers.
+//
+FunctionPass *createAddressSpaceFixPass();
+
+//===----------------------------------------------------------------------===//
+//
+// CUDAImage - This pass applies CUDA-specific floor image transformations.
+//
+FunctionPass *createCUDAImagePass(const uint32_t image_capabilities = 0);
+
+//===----------------------------------------------------------------------===//
+//
+// CUDAFinal - final pass, making CUDA related IR changes.
+//
+FunctionPass *createCUDAFinalPass();
+
+//===----------------------------------------------------------------------===//
+//
+// MetalFirst - This pass fixes Metal/AIR issues.
+//
+FunctionPass *createMetalFirstPass(const bool enable_intel_workarounds = false);
+
+//===----------------------------------------------------------------------===//
+//
+// MetalFinal - This pass fixes Metal/AIR issues.
+//
+FunctionPass *createMetalFinalPass(const bool enable_intel_workarounds = false);
+
+//===----------------------------------------------------------------------===//
+//
+// MetalImage - This pass applies Metal-specific floor image transformations.
+//
+FunctionPass *createMetalImagePass(const uint32_t image_capabilities = 0);
+
+//===----------------------------------------------------------------------===//
+//
+// SPIRFinal - This pass fixes LLVM IR to be SPIR-compliant.
+//
+FunctionPass *createSPIRFinalPass();
+
+//===----------------------------------------------------------------------===//
+//
+// SPIRImage - This pass applies SPIR-specific floor image transformations.
+//
+FunctionPass *createSPIRImagePass(const uint32_t image_capabilities = 0);
+
+//===----------------------------------------------------------------------===//
+//
 // ConstantPropagation - A worklist driven constant propagation pass
 //
 FunctionPass *createConstantPropagationPass();
diff --git a/include/llvm/Transforms/Scalar/FloorImage.h b/include/llvm/Transforms/Scalar/FloorImage.h
new file mode 100644
index 0000000..eadf6d5
--- /dev/null
+++ b/include/llvm/Transforms/Scalar/FloorImage.h
@@ -0,0 +1,361 @@
+//===-- FloorImage.h - base class for image transformations------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This header file and class define and implement the base class for all
+// image transformations (CUDA and opaque, as used for Metal and OpenCL).
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_TRANSFORMS_SCALAR_FLOORIMAGE_H
+#define LLVM_TRANSFORMS_SCALAR_FLOORIMAGE_H
+
+#include <algorithm>
+#include <cstdarg>
+#include <cstdint>
+#include <memory>
+#include <string>
+#include <array>
+
+#include "llvm/Pass.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+
+// condensed version of the COMPUTE_IMAGE_TYPE defined by floor
+enum class COMPUTE_IMAGE_TYPE : uint32_t {
+	//! invalid/uninitialized
+	NONE					= (0u),
+	
+	//////////////////////////////////////////
+	// -> image flags and types
+	//! upper 14-bit (18-31): type flags
+	__FLAG_MASK				= (0xFFFC0000u),
+	__FLAG_SHIFT			= (18u),
+	//! base type: image is an array (aka has layers)
+	FLAG_ARRAY				= (1u << (__FLAG_SHIFT + 0u)),
+	//! base type: image is a buffer object
+	FLAG_BUFFER				= (1u << (__FLAG_SHIFT + 1u)),
+	//! base type: image uses mutli-sampling (consists of multiple samples)
+	FLAG_MSAA				= (1u << (__FLAG_SHIFT + 2u)),
+	//! base type: image is a cube map
+	FLAG_CUBE				= (1u << (__FLAG_SHIFT + 3u)),
+	//! base type: image is a depth image
+	FLAG_DEPTH				= (1u << (__FLAG_SHIFT + 4u)),
+	//! base type: image is a stencil image
+	FLAG_STENCIL			= (1u << (__FLAG_SHIFT + 5u)),
+	//! base type: image is a renderbuffer
+	//! NOTE: only applicable when using opengl sharing or metal
+	FLAG_RENDERBUFFER		= (1u << (__FLAG_SHIFT + 6u)),
+	//! optional type: image uses mip-mapping, i.e. has multiple LODs
+	FLAG_MIPMAPPED			= (1u << (__FLAG_SHIFT + 7u)),
+	//! optional type: image uses a fixed channel count
+	//! NOTE: only used internally, serves no purpose on the user-side
+	FLAG_FIXED_CHANNELS		= (1u << (__FLAG_SHIFT + 8u)),
+	//! optional type: image doesn't need a sampler (i.e. only point/nearest/pixel sampled)
+	//! NOTE: on some platforms this might provide better performance and/or less overhead
+	FLAG_NO_SAMPLER			= (1u << (__FLAG_SHIFT + 9u)),
+	//! optional type: image uses gather sampling (aka tld4/fetch4)
+	FLAG_GATHER				= (1u << (__FLAG_SHIFT + 10u)),
+	//! optional type: when using integer storage formats, the data is normalized in [0, 1]
+	FLAG_NORMALIZED			= (1u << (__FLAG_SHIFT + 11u)),
+	//! optional type: image data is stored in (partial) reverse order (e.g. BGRA instead of RGBA)
+	FLAG_REVERSE			= (1u << (__FLAG_SHIFT + 12u)),
+	//! optional type: image data contains sRGB data
+	FLAG_SRGB				= (1u << (__FLAG_SHIFT + 13u)),
+	
+	//! bits 16-17: dimensionality
+	//! NOTE: cube maps and arrays use the dimensionality of their underlying image data
+	//!       -> 2D for cube maps, 2D for 2D arrays, 1D for 1D arrays
+	__DIM_MASK				= (0x00030000u),
+	__DIM_SHIFT				= (16u),
+	DIM_1D					= (1u << __DIM_SHIFT),
+	DIM_2D					= (2u << __DIM_SHIFT),
+	DIM_3D					= (3u << __DIM_SHIFT),
+	
+	//! bits 14-15: channel count
+	__CHANNELS_MASK			= (0x0000C000u),
+	__CHANNELS_SHIFT		= (14u),
+	CHANNELS_1				= (0u << __CHANNELS_SHIFT),
+	CHANNELS_2				= (1u << __CHANNELS_SHIFT),
+	CHANNELS_3				= (2u << __CHANNELS_SHIFT),
+	CHANNELS_4				= (3u << __CHANNELS_SHIFT),
+	//! channel convenience aliases
+	R 						= CHANNELS_1,
+	RG 						= CHANNELS_2,
+	RGB 					= CHANNELS_3,
+	RGBA					= CHANNELS_4,
+	
+	//! bits 12-13: storage data type
+	__DATA_TYPE_MASK		= (0x00003000u),
+	__DATA_TYPE_SHIFT		= (12u),
+	INT						= (1u << __DATA_TYPE_SHIFT),
+	UINT					= (2u << __DATA_TYPE_SHIFT),
+	FLOAT					= (3u << __DATA_TYPE_SHIFT),
+	
+	//! bits 10-11: access qualifier
+	__ACCESS_MASK			= (0x00000C00u),
+	__ACCESS_SHIFT			= (10u),
+	//! image is read-only (exluding host operations)
+	READ					= (1u << __ACCESS_SHIFT),
+	//! image is write-only (exluding host operations)
+	WRITE					= (2u << __ACCESS_SHIFT),
+	//! image is read-write
+	//! NOTE: also applies if neither is set
+	READ_WRITE				= (READ | WRITE),
+	
+	//! bits 6-9: compressed formats
+	__COMPRESSION_MASK		= (0x000003C0),
+	__COMPRESSION_SHIFT		= (6u),
+	//! image data is not compressed
+	UNCOMPRESSED			= (0u << __COMPRESSION_SHIFT),
+	//! S3TC/DXTn
+	BC1						= (1u << __COMPRESSION_SHIFT),
+	BC2						= (2u << __COMPRESSION_SHIFT),
+	BC3						= (3u << __COMPRESSION_SHIFT),
+	//! RGTC1/RGTC2
+	RGTC					= (4u << __COMPRESSION_SHIFT),
+	BC4						= RGTC,
+	BC5						= RGTC,
+	//! BPTC/BPTC_FLOAT
+	BPTC					= (5u << __COMPRESSION_SHIFT),
+	BC6H					= BPTC,
+	BC7						= BPTC,
+	//! PVRTC
+	PVRTC					= (6u << __COMPRESSION_SHIFT),
+	//! PVRTC2
+	PVRTC2					= (7u << __COMPRESSION_SHIFT),
+	//! EAC/ETC1
+	EAC						= (8u << __COMPRESSION_SHIFT),
+	ETC1					= EAC,
+	//! ETC2
+	ETC2					= (9u << __COMPRESSION_SHIFT),
+	//! ASTC
+	ASTC					= (10u << __COMPRESSION_SHIFT),
+	
+	//! bits 0-5: formats
+	//! NOTE: unless specified otherwise, a format is usable with any channel count
+	//! NOTE: not all backends support all formats (for portability, stick to 8-bit/16-bit/32-bit)
+	__FORMAT_MASK			= (0x0000003Fu),
+	//! 1 bit per channel
+	FORMAT_1				= (1u),
+	//! 2 bits per channel
+	FORMAT_2				= (2u),
+	//! 3 channel format: 3-bit/3-bit/2-bit
+	FORMAT_3_3_2			= (3u),
+	//! 4 bits per channel or YUV444
+	FORMAT_4				= (4u),
+	//! YUV420
+	FORMAT_4_2_0			= (5u),
+	//! YUV411
+	FORMAT_4_1_1			= (6u),
+	//! YUV422
+	FORMAT_4_2_2			= (7u),
+	//! 3 channel format: 5-bit/5-bit/5-bit
+	FORMAT_5_5_5			= (8u),
+	//! 4 channel format: 5-bit/5-bit/5-bit/1-bit
+	FORMAT_5_5_5_1			= (9u),
+	//! 3 channel format: 5-bit/6-bit/5-bit
+	FORMAT_5_6_5			= (10u),
+	//! 8 bits per channel
+	FORMAT_8				= (11u),
+	//! 3 channel format: 9-bit/9-bit/9-bit (5-bit exp)
+	FORMAT_9_9_9_5			= (12u),
+	//! 3 channel format: 10-bit/10-bit/10-bit
+	FORMAT_10				= (13u),
+	//! 4 channel format: 10-bit/10-bit/10-bit/2-bit
+	FORMAT_10_10_10_2		= (14u),
+	//! 3 channel format: 11-bit/11-bit/10-bit
+	FORMAT_11_11_10			= (15u),
+	//! 3 channel format: 12-bit/12-bit/12-bit
+	FORMAT_12_12_12			= (16u),
+	//! 4 channel format: 12-bit/12-bit/12-bit/12-bit
+	FORMAT_12_12_12_12		= (17u),
+	//! 16 bits per channel
+	FORMAT_16				= (18u),
+	//! 1 channel format: 24-bit
+	FORMAT_24				= (19u),
+	//! 2 channel format: 24-bit/8-bit
+	FORMAT_24_8				= (20u),
+	//! 32 bits per channel
+	FORMAT_32				= (21u),
+	//! 2 channel format: 32-bit/8-bit
+	FORMAT_32_8				= (22u),
+	//! 64 bits per channel
+	FORMAT_64				= (23u),
+	__FORMAT_MAX			= FORMAT_64,
+	
+	//////////////////////////////////////////
+	// -> base image types
+	//! 1D image
+	IMAGE_1D				= DIM_1D,
+	//! array of 1D images
+	IMAGE_1D_ARRAY			= DIM_1D | FLAG_ARRAY,
+	//! 1D image buffer (special format on some platforms)
+	IMAGE_1D_BUFFER			= DIM_1D | FLAG_BUFFER,
+	
+	//! 2D image
+	IMAGE_2D				= DIM_2D,
+	//! array of 2D images
+	IMAGE_2D_ARRAY			= DIM_2D | FLAG_ARRAY,
+	//! multi-sampled 2D image
+	IMAGE_2D_MSAA			= DIM_2D | FLAG_MSAA,
+	//! array of multi-sampled 2D images
+	IMAGE_2D_MSAA_ARRAY		= DIM_2D | FLAG_MSAA | FLAG_ARRAY,
+	
+	//! cube map image
+	IMAGE_CUBE				= DIM_2D | FLAG_CUBE,
+	//! array of cube map images
+	IMAGE_CUBE_ARRAY		= DIM_2D | FLAG_CUBE | FLAG_ARRAY,
+	
+	//! 2D depth image
+	IMAGE_DEPTH				= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D,
+	//! combined 2D depth + stencil image
+	IMAGE_DEPTH_STENCIL		= FLAG_DEPTH | CHANNELS_2 | IMAGE_2D | FLAG_STENCIL,
+	//! array of 2D depth images
+	IMAGE_DEPTH_ARRAY		= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_ARRAY,
+	//! depth cube map image
+	IMAGE_DEPTH_CUBE		= FLAG_DEPTH | CHANNELS_1 | IMAGE_CUBE,
+	//! array of depth cube map images
+	IMAGE_DEPTH_CUBE_ARRAY	= FLAG_DEPTH | CHANNELS_1 | IMAGE_CUBE | FLAG_ARRAY,
+	//! multi-sampled 2D depth image
+	IMAGE_DEPTH_MSAA		= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_MSAA,
+	//! array of multi-sampled 2D depth images
+	IMAGE_DEPTH_MSAA_ARRAY	= FLAG_DEPTH | CHANNELS_1 | IMAGE_2D_MSAA_ARRAY,
+	
+	//! 3D image
+	IMAGE_3D				= DIM_3D,
+	
+	//
+	BASE_TYPE_MASK			= (__DIM_MASK |
+							   FLAG_ARRAY | FLAG_BUFFER | FLAG_CUBE | FLAG_DEPTH | FLAG_MSAA | FLAG_STENCIL),
+	
+};
+__attribute__((always_inline, used)) static constexpr COMPUTE_IMAGE_TYPE operator|(const COMPUTE_IMAGE_TYPE& e0,
+																				   const COMPUTE_IMAGE_TYPE& e1) {
+	return (COMPUTE_IMAGE_TYPE)((typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e0 |
+								(typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e1);
+}
+__attribute__((always_inline, used)) static constexpr COMPUTE_IMAGE_TYPE operator&(const COMPUTE_IMAGE_TYPE& e0,
+																			 const COMPUTE_IMAGE_TYPE& e1) {
+	return (COMPUTE_IMAGE_TYPE)((typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e0 &
+								(typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type)e1);
+}
+template <COMPUTE_IMAGE_TYPE flag, typename int_type = typename std::underlying_type<COMPUTE_IMAGE_TYPE>::type>
+__attribute__((always_inline, used)) static constexpr bool has_flag(const COMPUTE_IMAGE_TYPE& enum_object) {
+	return ((int_type(flag) & int_type(enum_object)) == int_type(flag));
+}
+
+// compare function used by depth compare reads
+enum class COMPARE_FUNCTION : uint32_t {
+	NONE				= 0u,
+	LESS_OR_EQUAL		= 1u,
+	GREATER_OR_EQUAL	= 2u,
+	LESS				= 3u,
+	GREATER				= 4u,
+	EQUAL				= 5u,
+	NOT_EQUAL			= 6u,
+	ALWAYS				= 7u,
+	NEVER				= 8u,
+	__MAX_COMPARE_FUNCTION
+};
+
+// device image capabilities
+enum class IMAGE_CAPABILITY : uint32_t {
+	NONE					= (0u),
+	BASIC					= (1u << 0u),
+	DEPTH_READ				= (1u << 1u),
+	DEPTH_WRITE				= (1u << 2u),
+	MSAA_READ				= (1u << 3u),
+	MSAA_WRITE				= (1u << 4u),
+	CUBE_READ				= (1u << 5u),
+	CUBE_WRITE				= (1u << 6u),
+	MIPMAP_READ				= (1u << 7u),
+	MIPMAP_WRITE			= (1u << 8u),
+	OFFSET_READ				= (1u << 9u),
+	OFFSET_WRITE			= (1u << 10u),
+};
+template <IMAGE_CAPABILITY flag, typename int_type = typename std::underlying_type<IMAGE_CAPABILITY>::type>
+__attribute__((always_inline, used)) static constexpr bool has_flag(const IMAGE_CAPABILITY& enum_object) {
+	return ((int_type(flag) & int_type(enum_object)) == int_type(flag));
+}
+
+namespace llvm {
+	struct FloorImageBasePass : public FunctionPass, InstVisitor<FloorImageBasePass> {
+		friend class InstVisitor<FloorImageBasePass>;
+		
+		enum class IMAGE_TYPE_ID {
+			CUDA,
+			OPAQUE
+		};
+		
+		explicit FloorImageBasePass(char &ID,
+									const IMAGE_TYPE_ID& image_type_id,
+									const uint32_t& image_capabilities);
+		
+		bool runOnFunction(Function &F) override;
+		
+		using InstVisitor<FloorImageBasePass>::visit;
+		void visit(Instruction& I);
+		void visitCallSite(CallSite CS);
+		
+		void handle_image(CallSite& CS, const StringRef& func_name);
+		
+		virtual void handle_read_image(Instruction& I,
+									   const StringRef& func_name,
+									   llvm::Value* img_handle_arg,
+									   const COMPUTE_IMAGE_TYPE& image_type,
+									   llvm::ConstantInt* sampler_arg,
+									   llvm::Value* coord_arg,
+									   llvm::Value* layer_arg,
+									   llvm::Value* sample_arg,
+									   llvm::Value* offset_arg,
+									   const SmallVector<llvm::Value*, 3>& offset_elems,
+									   const bool is_offset,
+									   llvm::Value* lod_or_bias_arg,
+									   const bool is_lod_or_bias, // true: lod, false: bias
+									   llvm::Value* dpdx_arg,
+									   llvm::Value* dpdy_arg,
+									   const bool is_gradient,
+									   const COMPARE_FUNCTION& compare_function,
+									   llvm::Value* compare_value_arg,
+									   const bool is_compare) = 0;
+		
+		virtual void handle_write_image(Instruction& I,
+										const StringRef& func_name,
+										llvm::Value* img_handle_arg,
+										const COMPUTE_IMAGE_TYPE& image_type,
+										const COMPUTE_IMAGE_TYPE& format_type,
+										const COMPUTE_IMAGE_TYPE& data_type,
+										const bool& is_normalized,
+										const uint32_t& image_channel_count,
+										llvm::Value* coord_arg,
+										llvm::Value* layer_arg,
+										llvm::Value* data_arg) = 0;
+		
+	protected:
+		const IMAGE_TYPE_ID image_type_id;
+		const char* image_read_prefix;
+		const char* image_write_prefix;
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		std::shared_ptr<IRBuilder<>> builder;
+		bool was_modified { false };
+		IMAGE_CAPABILITY image_capabilities { IMAGE_CAPABILITY::NONE };
+		
+		llvm::AttributeSet nounwind_readnone_attr;
+		llvm::AttributeSet nounwind_attr;
+		
+	};
+}
+
+#endif
diff --git a/lib/AsmParser/LLParser.cpp b/lib/AsmParser/LLParser.cpp
index ac6e0e5..9e922f8 100644
--- a/lib/AsmParser/LLParser.cpp
+++ b/lib/AsmParser/LLParser.cpp
@@ -2644,10 +2644,10 @@ bool LLParser::ParseValID(ValID &ID, PerFunctionState *PFS) {
         ParseType(DestTy) ||
         ParseToken(lltok::rparen, "expected ')' at end of constantexpr cast"))
       return true;
-    if (!CastInst::castIsValid((Instruction::CastOps)Opc, SrcVal, DestTy))
+    /*if (!CastInst::castIsValid((Instruction::CastOps)Opc, SrcVal, DestTy))
       return Error(ID.Loc, "invalid cast opcode for cast from '" +
                    getTypeString(SrcVal->getType()) + "' to '" +
-                   getTypeString(DestTy) + "'");
+                   getTypeString(DestTy) + "'");*/
     ID.ConstantVal = ConstantExpr::getCast((Instruction::CastOps)Opc,
                                                  SrcVal, DestTy);
     ID.Kind = ValID::t_Constant;
@@ -3971,12 +3971,12 @@ bool LLParser::ParseCast(Instruction *&Inst, PerFunctionState &PFS,
       ParseType(DestTy))
     return true;
 
-  if (!CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy)) {
+  /*if (!CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy)) {
     CastInst::castIsValid((Instruction::CastOps)Opc, Op, DestTy);
     return Error(Loc, "invalid cast opcode for cast from '" +
                  getTypeString(Op->getType()) + "' to '" +
                  getTypeString(DestTy) + "'");
-  }
+  }*/
   Inst = CastInst::Create((Instruction::CastOps)Opc, Op, DestTy);
   return false;
 }
diff --git a/lib/IR/AsmWriter.cpp b/lib/IR/AsmWriter.cpp
index a7499bc..90ec2a3 100644
--- a/lib/IR/AsmWriter.cpp
+++ b/lib/IR/AsmWriter.cpp
@@ -19,6 +19,7 @@
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/SmallString.h"
 #include "llvm/ADT/StringExtras.h"
+#include "llvm/ADT/Triple.h"
 #include "llvm/IR/AssemblyAnnotationWriter.h"
 #include "llvm/IR/CFG.h"
 #include "llvm/IR/CallingConv.h"
@@ -1469,12 +1470,21 @@ void AssemblyWriter::printGlobal(const GlobalVariable *GV) {
   PrintVisibility(GV->getVisibility(), Out);
   PrintDLLStorageClass(GV->getDLLStorageClass(), Out);
   PrintThreadLocalModel(GV->getThreadLocalMode(), Out);
-  if (GV->hasUnnamedAddr())
+
+  // metal/air requires unnamed_addr to come after addrspace
+  // -> only add it here for anyone else
+  const bool is_air64 = (llvm::Triple(TheModule->getTargetTriple()).getArch() == Triple::air64);
+  if (GV->hasUnnamedAddr() && !is_air64)
     Out << "unnamed_addr ";
 
   if (unsigned AddressSpace = GV->getType()->getAddressSpace())
     Out << "addrspace(" << AddressSpace << ") ";
   if (GV->isExternallyInitialized()) Out << "externally_initialized ";
+
+  // insert after the addrspace for metal/air
+  if (GV->hasUnnamedAddr() && is_air64)
+    Out << "unnamed_addr ";
+
   Out << (GV->isConstant() ? "constant " : "global ");
   TypePrinter.print(GV->getType()->getElementType(), Out);
 
diff --git a/lib/IR/AutoUpgrade.cpp b/lib/IR/AutoUpgrade.cpp
index 459bd88..ac77437 100644
--- a/lib/IR/AutoUpgrade.cpp
+++ b/lib/IR/AutoUpgrade.cpp
@@ -567,7 +567,8 @@ Value *llvm::UpgradeBitCastExpr(unsigned Opc, Constant *C, Type *DestTy) {
 /// info. Return true if module is modified.
 bool llvm::UpgradeDebugInfo(Module &M) {
   unsigned Version = getDebugMetadataVersionFromModule(M);
-  if (Version == DEBUG_METADATA_VERSION)
+  if (Version == DEBUG_METADATA_VERSION ||
+      Version == IOS_METAL_DEBUG_METADATA_VERSION)
     return false;
 
   bool RetCode = StripDebugInfo(M);
diff --git a/lib/IR/Constants.cpp b/lib/IR/Constants.cpp
index 7557886..a9f4def 100644
--- a/lib/IR/Constants.cpp
+++ b/lib/IR/Constants.cpp
@@ -1509,7 +1509,8 @@ Constant *ConstantExpr::getCast(unsigned oc, Constant *C, Type *Ty) {
   Instruction::CastOps opc = Instruction::CastOps(oc);
   assert(Instruction::isCast(opc) && "opcode out of range");
   assert(C && Ty && "Null arguments to getCast");
-  assert(CastInst::castIsValid(opc, C, Ty) && "Invalid constantexpr cast!");
+  // TODO: fix this!
+  //assert(CastInst::castIsValid(opc, C, Ty) && "Invalid constantexpr cast!");
 
   switch (opc) {
   default:
@@ -1734,8 +1735,9 @@ Constant *ConstantExpr::getIntToPtr(Constant *C, Type *DstTy) {
 }
 
 Constant *ConstantExpr::getBitCast(Constant *C, Type *DstTy) {
-  assert(CastInst::castIsValid(Instruction::BitCast, C, DstTy) &&
-         "Invalid constantexpr bitcast!");
+  // TODO: fix this! fails in AddAppleCLKernelAnnotation
+  //assert(CastInst::castIsValid(Instruction::BitCast, C, DstTy) &&
+  //     "Invalid constantexpr bitcast!");
 
   // It is common to ask for a bitcast of a value to its own type, handle this
   // speedily.
diff --git a/lib/IR/DataLayout.cpp b/lib/IR/DataLayout.cpp
index dea05fb..e343af4 100644
--- a/lib/IR/DataLayout.cpp
+++ b/lib/IR/DataLayout.cpp
@@ -71,6 +71,19 @@ StructLayout::StructLayout(StructType *ST, const DataLayout &DL) {
   // and all array elements would be aligned correctly.
   if ((StructSize & (StructAlignment-1)) != 0)
     StructSize = DataLayout::RoundUpAlignment(StructSize, StructAlignment);
+
+  // fix up metal return types (densely pack vector types)
+  if (ST->isMetalReturnType()) {
+    uint64_t offset_fix = 0;
+    for (uint32_t i = 0; i < NumElements; ++i) {
+      MemberOffsets[i] -= offset_fix;
+
+      const auto type = ST->getElementType(i);
+      if (type->isVectorTy()) {
+        offset_fix += DL.getABITypeAlignment(type) - DL.getTypeStoreSize(type);
+      }
+    }
+  }
 }
 
 
diff --git a/lib/IR/Instructions.cpp b/lib/IR/Instructions.cpp
index 9553252..5047ab2 100644
--- a/lib/IR/Instructions.cpp
+++ b/lib/IR/Instructions.cpp
@@ -275,11 +275,13 @@ void CallInst::init(Value *Func, ArrayRef<Value *> Args, const Twine &NameStr) {
           (FTy->isVarArg() && Args.size() > FTy->getNumParams())) &&
          "Calling a function with bad signature!");
 
+#if 0 // TODO: disabled for now, need to ignore address space mismatches
   for (unsigned i = 0; i != Args.size(); ++i)
     assert((i >= FTy->getNumParams() || 
             FTy->getParamType(i) == Args[i]->getType()) &&
            "Calling a function with a bad signature!");
 #endif
+#endif
 
   std::copy(Args.begin(), Args.end(), op_begin());
   setName(NameStr);
diff --git a/lib/IR/Verifier.cpp b/lib/IR/Verifier.cpp
index 9cf911b..8d61d2b 100644
--- a/lib/IR/Verifier.cpp
+++ b/lib/IR/Verifier.cpp
@@ -1542,10 +1542,17 @@ void Verifier::VerifyCallSite(CallSite CS) {
             "Incorrect number of arguments passed to called function!", I);
 
   // Verify that all arguments to the call match the function type.
-  for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i)
-    Assert3(CS.getArgument(i)->getType() == FTy->getParamType(i),
+  // Note that address space mismatches will be fixed later.
+  for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+    Assert3(CS.getArgument(i)->getType() == FTy->getParamType(i) ||
+            (CS.getArgument(i)->getType()->isPointerTy() &&
+             FTy->getParamType(i)->isPointerTy() &&
+             PointerType::get(cast<PointerType>(CS.getArgument(i)->getType())->getElementType(),
+                              FTy->getParamType(i)->getPointerAddressSpace()) ==
+             FTy->getParamType(i)),
             "Call parameter type does not match function signature!",
             CS.getArgument(i), FTy->getParamType(i), I);
+  }
 
   AttributeSet Attrs = CS.getAttributes();
 
diff --git a/lib/Support/Triple.cpp b/lib/Support/Triple.cpp
index 714d9e8..18e01ff 100644
--- a/lib/Support/Triple.cpp
+++ b/lib/Support/Triple.cpp
@@ -50,6 +50,7 @@ const char *Triple::getArchTypeName(ArchType Kind) {
   case amdil:       return "amdil";
   case spir:        return "spir";
   case spir64:      return "spir64";
+  case air64:       return "air64";
   case kalimba:     return "kalimba";
   }
 
@@ -101,6 +102,7 @@ const char *Triple::getArchTypePrefix(ArchType Kind) {
   case amdil:       return "amdil";
   case spir:        return "spir";
   case spir64:      return "spir";
+  case air64:       return "air64";
   case kalimba:     return "kalimba";
   }
 }
@@ -211,6 +213,7 @@ Triple::ArchType Triple::getArchTypeForLLVMName(StringRef Name) {
     .Case("amdil", amdil)
     .Case("spir", spir)
     .Case("spir64", spir64)
+    .Case("air64", air64)
     .Case("kalimba", kalimba)
     .Default(UnknownArch);
 }
@@ -241,6 +244,7 @@ const char *Triple::getArchNameForAssembler() {
     .Case("amdil", "amdil")
     .Case("spir", "spir")
     .Case("spir64", "spir64")
+    .Case("air64", "air64")
     .Default(nullptr);
 }
 
@@ -285,6 +289,7 @@ static Triple::ArchType parseArch(StringRef ArchName) {
     .Case("amdil", Triple::amdil)
     .Case("spir", Triple::spir)
     .Case("spir64", Triple::spir64)
+    .Case("air64", Triple::air64)
     .Case("kalimba", Triple::kalimba)
     .Default(Triple::UnknownArch);
 }
@@ -848,6 +853,7 @@ static unsigned getArchPointerBitWidth(llvm::Triple::ArchType Arch) {
   case llvm::Triple::systemz:
   case llvm::Triple::x86_64:
   case llvm::Triple::spir64:
+  case llvm::Triple::air64:
     return 64;
   }
   llvm_unreachable("Invalid architecture value");
@@ -876,6 +882,7 @@ Triple Triple::get32BitArchVariant() const {
   case Triple::msp430:
   case Triple::systemz:
   case Triple::ppc64le:
+  case Triple::air64:
     T.setArch(UnknownArch);
     break;
 
@@ -933,6 +940,7 @@ Triple Triple::get64BitArchVariant() const {
   case Triple::aarch64:
   case Triple::aarch64_be:
   case Triple::spir64:
+  case Triple::air64:
   case Triple::mips64:
   case Triple::mips64el:
   case Triple::nvptx64:
diff --git a/lib/Target/NVPTX/NVPTX.td b/lib/Target/NVPTX/NVPTX.td
index 93fabf6..e12ada6 100644
--- a/lib/Target/NVPTX/NVPTX.td
+++ b/lib/Target/NVPTX/NVPTX.td
@@ -26,16 +26,37 @@ include "NVPTXInstrInfo.td"
 //===----------------------------------------------------------------------===//
 
 // SM Versions
+// Fermi
 def SM20 : SubtargetFeature<"sm_20", "SmVersion", "20",
                             "Target SM 2.0">;
 def SM21 : SubtargetFeature<"sm_21", "SmVersion", "21",
                             "Target SM 2.1">;
+// Kepler
 def SM30 : SubtargetFeature<"sm_30", "SmVersion", "30",
                             "Target SM 3.0">;
+def SM32 : SubtargetFeature<"sm_32", "SmVersion", "32",
+                            "Target SM 3.2">;
 def SM35 : SubtargetFeature<"sm_35", "SmVersion", "35",
                             "Target SM 3.5">;
+def SM37 : SubtargetFeature<"sm_37", "SmVersion", "37",
+                            "Target SM 3.7">;
+// Kepler
 def SM50 : SubtargetFeature<"sm_50", "SmVersion", "50",
                             "Target SM 5.0">;
+def SM52 : SubtargetFeature<"sm_52", "SmVersion", "52",
+                            "Target SM 5.2">;
+def SM53 : SubtargetFeature<"sm_53", "SmVersion", "53",
+                            "Target SM 5.3">;
+// Pascal
+def SM60 : SubtargetFeature<"sm_60", "SmVersion", "60",
+                            "Target SM 6.0">;
+def SM61 : SubtargetFeature<"sm_61", "SmVersion", "61",
+                            "Target SM 6.1">;
+def SM62 : SubtargetFeature<"sm_62", "SmVersion", "62",
+                            "Target SM 6.2">;
+// Volta
+def SM70 : SubtargetFeature<"sm_70", "SmVersion", "70",
+                            "Target SM 7.0">;
 
 // PTX Versions
 def PTX30 : SubtargetFeature<"ptx30", "PTXVersion", "30",
@@ -46,6 +67,14 @@ def PTX32 : SubtargetFeature<"ptx32", "PTXVersion", "32",
                              "Use PTX version 3.2">;
 def PTX40 : SubtargetFeature<"ptx40", "PTXVersion", "40",
                              "Use PTX version 4.0">;
+def PTX41 : SubtargetFeature<"ptx41", "PTXVersion", "41",
+                             "Use PTX version 4.1">;
+def PTX42 : SubtargetFeature<"ptx42", "PTXVersion", "42",
+                             "Use PTX version 4.2">;
+def PTX43 : SubtargetFeature<"ptx43", "PTXVersion", "43",
+                             "Use PTX version 4.3">;
+def PTX50 : SubtargetFeature<"ptx50", "PTXVersion", "50",
+                             "Use PTX version 5.0">;
 
 //===----------------------------------------------------------------------===//
 // NVPTX supported processors.
@@ -57,8 +86,16 @@ class Proc<string Name, list<SubtargetFeature> Features>
 def : Proc<"sm_20", [SM20]>;
 def : Proc<"sm_21", [SM21]>;
 def : Proc<"sm_30", [SM30]>;
+def : Proc<"sm_32", [SM32, PTX40]>;
 def : Proc<"sm_35", [SM35]>;
-def : Proc<"sm_50", [SM50]>;
+def : Proc<"sm_37", [SM37, PTX41]>;
+def : Proc<"sm_50", [SM50, PTX40]>;
+def : Proc<"sm_52", [SM52, PTX41]>;
+def : Proc<"sm_53", [SM53, PTX42]>;
+def : Proc<"sm_60", [SM60, PTX50]>;
+def : Proc<"sm_61", [SM61, PTX50]>;
+def : Proc<"sm_62", [SM62, PTX50]>;
+def : Proc<"sm_70", [SM70, PTX50]>;
 
 
 def NVPTXInstrInfo : InstrInfo {
diff --git a/lib/Target/NVPTX/NVPTXAsmPrinter.h b/lib/Target/NVPTX/NVPTXAsmPrinter.h
index a9f9bdd..bf44862 100644
--- a/lib/Target/NVPTX/NVPTXAsmPrinter.h
+++ b/lib/Target/NVPTX/NVPTXAsmPrinter.h
@@ -202,6 +202,12 @@ private:
   void EmitFunctionBodyEnd() override;
   void emitImplicitDef(const MachineInstr *MI) const override;
 
+  /// superfluous function header fix: nop these three functions
+  void EmitGlobalVariable(const GlobalVariable *GV) override {}
+  void EmitLinkage(const GlobalValue *GV, MCSymbol *GVSym) const override {}
+  void EmitAlignment(unsigned NumBits, const GlobalObject *GO = nullptr) const override {}
+  ///
+
   void EmitInstruction(const MachineInstr *) override;
   void lowerToMCInst(const MachineInstr *MI, MCInst &OutMI);
   bool lowerOperand(const MachineOperand &MO, MCOperand &MCOp);
diff --git a/lib/Target/NVPTX/NVPTXISelLowering.cpp b/lib/Target/NVPTX/NVPTXISelLowering.cpp
index d76b20a..a444f10 100644
--- a/lib/Target/NVPTX/NVPTXISelLowering.cpp
+++ b/lib/Target/NVPTX/NVPTXISelLowering.cpp
@@ -205,7 +205,15 @@ NVPTXTargetLowering::NVPTXTargetLowering(NVPTXTargetMachine &TM)
   // Turn FP extload into load/fextend
   setLoadExtAction(ISD::EXTLOAD, MVT::f16, Expand);
   setLoadExtAction(ISD::EXTLOAD, MVT::f32, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::f64, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v2f16, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v2f32, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v2f64, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v4f16, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v4f32, Expand);
+  setLoadExtAction(ISD::EXTLOAD, MVT::v4f64, Expand);
   // Turn FP truncstore into trunc + store.
+  // FIXME: vector types should also be expanded
   setTruncStoreAction(MVT::f32, MVT::f16, Expand);
   setTruncStoreAction(MVT::f64, MVT::f16, Expand);
   setTruncStoreAction(MVT::f64, MVT::f32, Expand);
diff --git a/lib/Target/NVPTX/NVPTXInstrInfo.td b/lib/Target/NVPTX/NVPTXInstrInfo.td
index 9900b8c..4879b84 100644
--- a/lib/Target/NVPTX/NVPTXInstrInfo.td
+++ b/lib/Target/NVPTX/NVPTXInstrInfo.td
@@ -1659,12 +1659,12 @@ multiclass FSET_FORMAT<PatFrag OpNode, PatLeaf Mode, PatLeaf ModeFTZ> {
             (SET_f64ir fpimm:$a, Float64Regs:$b, Mode)>;
 }
 
-defm FSetGT : FSET_FORMAT<setogt, CmpGT, CmpGT_FTZ>;
-defm FSetLT : FSET_FORMAT<setolt, CmpLT, CmpLT_FTZ>;
-defm FSetGE : FSET_FORMAT<setoge, CmpGE, CmpGE_FTZ>;
-defm FSetLE : FSET_FORMAT<setole, CmpLE, CmpLE_FTZ>;
-defm FSetEQ : FSET_FORMAT<setoeq, CmpEQ, CmpEQ_FTZ>;
-defm FSetNE : FSET_FORMAT<setone, CmpNE, CmpNE_FTZ>;
+defm FSetOGT : FSET_FORMAT<setogt, CmpGT, CmpGT_FTZ>;
+defm FSetOLT : FSET_FORMAT<setolt, CmpLT, CmpLT_FTZ>;
+defm FSetOGE : FSET_FORMAT<setoge, CmpGE, CmpGE_FTZ>;
+defm FSetOLE : FSET_FORMAT<setole, CmpLE, CmpLE_FTZ>;
+defm FSetOEQ : FSET_FORMAT<setoeq, CmpEQ, CmpEQ_FTZ>;
+defm FSetONE : FSET_FORMAT<setone, CmpNE, CmpNE_FTZ>;
 
 defm FSetUGT : FSET_FORMAT<setugt, CmpGTU, CmpGTU_FTZ>;
 defm FSetULT : FSET_FORMAT<setult, CmpLTU, CmpLTU_FTZ>;
@@ -1673,6 +1673,13 @@ defm FSetULE : FSET_FORMAT<setule, CmpLEU, CmpLEU_FTZ>;
 defm FSetUEQ : FSET_FORMAT<setueq, CmpEQU, CmpEQU_FTZ>;
 defm FSetUNE : FSET_FORMAT<setune, CmpNEU, CmpNEU_FTZ>;
 
+defm FSetGT : FSET_FORMAT<setgt, CmpGT, CmpGT_FTZ>;
+defm FSetLT : FSET_FORMAT<setlt, CmpLT, CmpLT_FTZ>;
+defm FSetGE : FSET_FORMAT<setge, CmpGE, CmpGE_FTZ>;
+defm FSetLE : FSET_FORMAT<setle, CmpLE, CmpLE_FTZ>;
+defm FSetEQ : FSET_FORMAT<seteq, CmpEQ, CmpEQ_FTZ>;
+defm FSetNE : FSET_FORMAT<setne, CmpNE, CmpNE_FTZ>;
+
 defm FSetNUM : FSET_FORMAT<seto, CmpNUM, CmpNUM_FTZ>;
 defm FSetNAN : FSET_FORMAT<setuo, CmpNAN, CmpNAN_FTZ>;
 
diff --git a/lib/Target/NVPTX/NVPTXSubtarget.cpp b/lib/Target/NVPTX/NVPTXSubtarget.cpp
index d5cded2..2e0ca79 100644
--- a/lib/Target/NVPTX/NVPTXSubtarget.cpp
+++ b/lib/Target/NVPTX/NVPTXSubtarget.cpp
@@ -45,9 +45,9 @@ NVPTXSubtarget &NVPTXSubtarget::initializeSubtargetDependencies(StringRef CPU,
 
   ParseSubtargetFeatures(TargetName, FS);
 
-  // Set default to PTX 3.2 (CUDA 5.5)
+  // Set default to PTX 4.0
   if (PTXVersion == 0) {
-    PTXVersion = 32;
+    PTXVersion = 40;
   }
 
   return *this;
diff --git a/lib/Transforms/IPO/CMakeLists.txt b/lib/Transforms/IPO/CMakeLists.txt
index 90c1c33..3c64ad0 100644
--- a/lib/Transforms/IPO/CMakeLists.txt
+++ b/lib/Transforms/IPO/CMakeLists.txt
@@ -10,6 +10,7 @@ add_llvm_library(LLVMipo
   IPConstantPropagation.cpp
   IPO.cpp
   InlineAlways.cpp
+  InlineEverything.cpp
   InlineSimple.cpp
   Inliner.cpp
   Internalize.cpp
diff --git a/lib/Transforms/IPO/FunctionAttrs.cpp b/lib/Transforms/IPO/FunctionAttrs.cpp
index 8174df9..21a73ba 100644
--- a/lib/Transforms/IPO/FunctionAttrs.cpp
+++ b/lib/Transforms/IPO/FunctionAttrs.cpp
@@ -135,6 +135,7 @@ namespace {
 }
 
 char FunctionAttrs::ID = 0;
+char &llvm::FunctionAttrsID = FunctionAttrs::ID;
 INITIALIZE_PASS_BEGIN(FunctionAttrs, "functionattrs",
                 "Deduce function attributes", false, false)
 INITIALIZE_AG_DEPENDENCY(AliasAnalysis)
diff --git a/lib/Transforms/IPO/GlobalOpt.cpp b/lib/Transforms/IPO/GlobalOpt.cpp
index c1d0d3b..3d4303a 100644
--- a/lib/Transforms/IPO/GlobalOpt.cpp
+++ b/lib/Transforms/IPO/GlobalOpt.cpp
@@ -20,6 +20,7 @@
 #include "llvm/ADT/SmallSet.h"
 #include "llvm/ADT/SmallVector.h"
 #include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/Triple.h"
 #include "llvm/Analysis/ConstantFolding.h"
 #include "llvm/Analysis/MemoryBuiltins.h"
 #include "llvm/IR/CallSite.h"
@@ -1869,6 +1870,17 @@ static void ChangeCalleesToFastCall(Function *F) {
   }
 }
 
+/// ChangeCalleesToSpirFunc - Walk all of the direct calls of the specified
+/// function, changing them to spir_func calling convention.
+static void ChangeCalleesToSpirFunc(Function *F) {
+  for (User *U : F->users()) {
+    if (isa<BlockAddress>(U))
+      continue;
+    CallSite CS(cast<Instruction>(U));
+    CS.setCallingConv(CallingConv::SPIR_FUNC);
+  }
+}
+
 static AttributeSet StripNest(LLVMContext &C, const AttributeSet &Attrs) {
   for (unsigned i = 0, e = Attrs.getNumSlots(); i != e; ++i) {
     unsigned Index = Attrs.getSlotIndex(i);
@@ -1903,6 +1915,7 @@ static bool isProfitableToMakeFastCC(Function *F) {
 }
 
 bool GlobalOpt::OptimizeFunctions(Module &M) {
+  const llvm::Triple triple(M.getTargetTriple());
   bool Changed = false;
   // Optimize functions.
   for (Module::iterator FI = M.begin(), E = M.end(); FI != E; ) {
@@ -1921,8 +1934,17 @@ bool GlobalOpt::OptimizeFunctions(Module &M) {
         // If this function has a calling convention worth changing, is not a
         // varargs function, and is only called directly, promote it to use the
         // Fast calling convention.
-        F->setCallingConv(CallingConv::Fast);
-        ChangeCalleesToFastCall(F);
+        // with OpenCL/SPIR: change it to spir_func instead (fastcc is invalid)
+        if ((triple.getArch() == llvm::Triple::ArchType::spir ||
+             triple.getArch() == llvm::Triple::ArchType::spir64) &&
+            triple.getVendorName().str() == "unknown") {
+          F->setCallingConv(CallingConv::SPIR_FUNC);
+          ChangeCalleesToSpirFunc(F);
+        }
+        else {
+          F->setCallingConv(CallingConv::Fast);
+          ChangeCalleesToFastCall(F);
+        }
         ++NumFastCallFns;
         Changed = true;
       }
diff --git a/lib/Transforms/IPO/IPO.cpp b/lib/Transforms/IPO/IPO.cpp
index b4d31d8..ffef3ba 100644
--- a/lib/Transforms/IPO/IPO.cpp
+++ b/lib/Transforms/IPO/IPO.cpp
@@ -31,6 +31,7 @@ void llvm::initializeIPO(PassRegistry &Registry) {
   initializeGlobalOptPass(Registry);
   initializeIPCPPass(Registry);
   initializeAlwaysInlinerPass(Registry);
+  initializeEverythingInlinerPass(Registry);
   initializeSimpleInlinerPass(Registry);
   initializeInternalizePassPass(Registry);
   initializeLoopExtractorPass(Registry);
@@ -75,6 +76,10 @@ void LLVMAddAlwaysInlinerPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(llvm::createAlwaysInlinerPass());
 }
 
+void LLVMAddEverythingInlinerPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(llvm::createEverythingInlinerPass());
+}
+
 void LLVMAddGlobalDCEPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(createGlobalDCEPass());
 }
diff --git a/lib/Transforms/IPO/InlineEverything.cpp b/lib/Transforms/IPO/InlineEverything.cpp
new file mode 100644
index 0000000..4284c6d
--- /dev/null
+++ b/lib/Transforms/IPO/InlineEverything.cpp
@@ -0,0 +1,100 @@
+//===- InlineEverything.cpp - Code to inline all functions ----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements a custom inliner that inlines everything, unless it was
+// marked "noinline".
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Transforms/IPO.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/Analysis/CallGraph.h"
+#include "llvm/Analysis/InlineCost.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/Transforms/IPO/InlinerPass.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "inline"
+
+namespace {
+
+/// \brief Inliner pass which inlines everything unless it was marked "noinline".
+class EverythingInliner : public Inliner {
+  InlineCostAnalysis *ICA;
+
+public:
+  // Use extremely high threshold (one lower then noinline).
+  EverythingInliner() : Inliner(ID, INT_MAX - 1, /*InsertLifetime*/ true),
+                        ICA(nullptr) {
+    initializeEverythingInlinerPass(*PassRegistry::getPassRegistry());
+  }
+
+  EverythingInliner(bool InsertLifetime)
+      : Inliner(ID, INT_MAX - 1, InsertLifetime), ICA(nullptr) {
+    initializeEverythingInlinerPass(*PassRegistry::getPassRegistry());
+  }
+
+  static char ID; // Pass identification, replacement for typeid
+
+  InlineCost getInlineCost(CallSite CS) override;
+
+  void getAnalysisUsage(AnalysisUsage &AU) const override;
+  bool runOnSCC(CallGraphSCC &SCC) override;
+
+  using llvm::Pass::doFinalization;
+  bool doFinalization(CallGraph &CG) override {
+    return removeDeadFunctions(CG, /*AlwaysInlineOnly=*/ false);
+  }
+};
+
+}
+
+char EverythingInliner::ID = 0;
+INITIALIZE_PASS_BEGIN(EverythingInliner, "everything-inline",
+                      "everything inliner", false, false)
+INITIALIZE_PASS_DEPENDENCY(CallGraphWrapperPass)
+INITIALIZE_PASS_DEPENDENCY(InlineCostAnalysis)
+INITIALIZE_PASS_END(EverythingInliner, "everything-inline",
+                    "everything inliner", false, false)
+
+Pass *llvm::createEverythingInlinerPass() { return new EverythingInliner(); }
+
+Pass *llvm::createEverythingInlinerPass(bool InsertLifetime) {
+  return new EverythingInliner(InsertLifetime);
+}
+
+InlineCost EverythingInliner::getInlineCost(CallSite CS) {
+  Function *Callee = CS.getCalledFunction();
+
+  if (Callee && !Callee->isDeclaration() &&
+      (CS.hasFnAttr(Attribute::NoInline) ||
+	   Callee->hasFnAttribute(Attribute::NoInline) ||
+	   !ICA->isInlineViable(*Callee))) {
+    return InlineCost::getNever();
+  }
+
+  return InlineCost::getAlways();
+}
+
+bool EverythingInliner::runOnSCC(CallGraphSCC &SCC) {
+  ICA = &getAnalysis<InlineCostAnalysis>();
+  return Inliner::runOnSCC(SCC);
+}
+
+void EverythingInliner::getAnalysisUsage(AnalysisUsage &AU) const {
+  AU.addRequired<InlineCostAnalysis>();
+  Inliner::getAnalysisUsage(AU);
+}
diff --git a/lib/Transforms/IPO/Internalize.cpp b/lib/Transforms/IPO/Internalize.cpp
index c970a1a..62f3c6a 100644
--- a/lib/Transforms/IPO/Internalize.cpp
+++ b/lib/Transforms/IPO/Internalize.cpp
@@ -23,6 +23,7 @@
 #include "llvm/ADT/SmallPtrSet.h"
 #include "llvm/ADT/Statistic.h"
 #include "llvm/Analysis/CallGraph.h"
+#include "llvm/IR/Function.h"
 #include "llvm/IR/Module.h"
 #include "llvm/Pass.h"
 #include "llvm/Support/CommandLine.h"
@@ -127,6 +128,17 @@ static bool shouldInternalize(const GlobalValue &GV,
   if (ExternalNames.count(GV.getName()))
     return false;
 
+  // is this a compute (opencl/cuda/metal) kernel or graphics function?
+  if (isa<Function>(GV)) {
+    const Function* F = dyn_cast<Function>(&GV);
+    if (F &&
+        (F->hasFnAttribute("compute_kernel") ||
+         F->hasFnAttribute("vertex_shader") ||
+         F->hasFnAttribute("fragment_shader"))) {
+      return false;
+    }
+  }
+
   return true;
 }
 
diff --git a/lib/Transforms/IPO/PassManagerBuilder.cpp b/lib/Transforms/IPO/PassManagerBuilder.cpp
index 701fb46..8c056f8 100644
--- a/lib/Transforms/IPO/PassManagerBuilder.cpp
+++ b/lib/Transforms/IPO/PassManagerBuilder.cpp
@@ -70,6 +70,11 @@ PassManagerBuilder::PassManagerBuilder() {
     LoopVectorize = RunLoopVectorization;
     RerollLoops = RunLoopRerolling;
     LoadCombine = RunLoadCombine;
+    EnableAddressSpaceFix = false;
+    EnableCUDAPasses = false;
+    EnableMetalPasses = false;
+    EnableMetalIntelWorkarounds = false;
+    EnableSPIRPasses = false;
 }
 
 PassManagerBuilder::~PassManagerBuilder() {
@@ -130,6 +135,13 @@ void PassManagerBuilder::populateFunctionPassManager(FunctionPassManager &FPM) {
 }
 
 void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {
+  // run "first" passes that should run before all else
+  // if(EnableCUDAPasses) --none
+  if(EnableMetalPasses) {
+    MPM.add(createMetalFirstPass(EnableMetalIntelWorkarounds));
+  }
+  // if(EnableSPIRPasses) --none
+
   // If all optimizations are disabled, just run the always-inline pass.
   if (OptLevel == 0) {
     if (Inliner) {
@@ -153,6 +165,18 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {
 
   addInitialAliasAnalysisPasses(MPM);
 
+  if (EnableAddressSpaceFix) {
+    // address space fixing should be run as early as possible, but it also
+    // requires readonly/nocapture/etc function and argument attributes,
+    // which in turn requires certain alias analysis to be run first
+    // -> this is the earliest point to do this
+    // NOTE: the original FunctionAttrs pass should still be run later on,
+    // because the code will have changed significantly due to optimizations
+    // and other pass changes
+    MPM.add(createFunctionAttrsPass());
+    MPM.add(createAddressSpaceFixPass());
+  }
+
   if (!DisableUnitAtATime) {
     addExtensionsToPM(EP_ModuleOptimizerEarly, MPM);
 
@@ -255,6 +279,29 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {
   // pass manager that we are specifically trying to avoid. To prevent this
   // we must insert a no-op module pass to reset the pass manager.
   MPM.add(createBarrierNoopPass());
+
+  // run image read/write function passes after inling everything,
+  // this way we can actually check each use of these functions and their arguments,
+  // with constants potentially changing/improving the behavior and allowing
+  // additional checking (like oob offsets).
+  if(EnableCUDAPasses || EnableMetalPasses || EnableSPIRPasses) {
+    if(EnableCUDAPasses) MPM.add(createCUDAImagePass(floor_image_capabilities));
+    if(EnableMetalPasses) MPM.add(createMetalImagePass(floor_image_capabilities));
+    if(EnableSPIRPasses) MPM.add(createSPIRImagePass(floor_image_capabilities));
+
+    // and cleanup afterwards, including loop and unrolling related things
+    MPM.add(createTailCallEliminationPass());
+    MPM.add(createLoopRotatePass());
+    MPM.add(createLICMPass());
+    MPM.add(createSimpleLoopUnrollPass());
+
+    MPM.add(createGVNPass());
+    MPM.add(createAggressiveDCEPass());
+    MPM.add(createCFGSimplificationPass());
+    MPM.add(createInstructionCombiningPass());
+    addExtensionsToPM(EP_Peephole, MPM);
+  }
+
   MPM.add(createLoopVectorizePass(DisableUnrollLoops, LoopVectorize));
   // FIXME: Because of #pragma vectorize enable, the passes below are always
   // inserted in the pipeline, even when the vectorizer doesn't run (ex. when
@@ -280,6 +327,20 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {
     }
   }
   addExtensionsToPM(EP_OptimizerLast, MPM);
+
+  // run CUDAFinal/MetalFinal/SPIRFinal pass at the very end, no IR should change after this point!
+  if(EnableSPIRPasses) MPM.add(createSPIRFinalPass());
+  if(EnableMetalPasses) {
+    MPM.add(createMetalFinalPass(EnableMetalIntelWorkarounds));
+
+    // cleanup
+    MPM.add(createTailCallEliminationPass());
+    MPM.add(createCFGSimplificationPass());
+    MPM.add(createInstructionCombiningPass());
+    MPM.add(createGVNPass());
+    MPM.add(createAggressiveDCEPass());
+  }
+  if(EnableCUDAPasses) MPM.add(createCUDAFinalPass());
 }
 
 void PassManagerBuilder::populateLTOPassManager(PassManagerBase &PM,
diff --git a/lib/Transforms/Scalar/AddressSpaceFix.cpp b/lib/Transforms/Scalar/AddressSpaceFix.cpp
new file mode 100644
index 0000000..a0485af
--- /dev/null
+++ b/lib/Transforms/Scalar/AddressSpaceFix.cpp
@@ -0,0 +1,258 @@
+//===- AddressSpaceFix.cpp - OpenCL/SPIR and related addrspace fixes ------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements an address space fixer for OpenCL/SPIR (and related).
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "AddressSpaceFix"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// AddressSpaceFix
+	struct AddressSpaceFix : public FunctionPass, InstVisitor<AddressSpaceFix> {
+		friend class InstVisitor<AddressSpaceFix>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		
+		AddressSpaceFix() : FunctionPass(ID) {
+			initializeAddressSpaceFixPass(*PassRegistry::getPassRegistry());
+		}
+		
+		void getAnalysisUsage(AnalysisUsage &AU) const override {
+			AU.addRequiredID(FunctionAttrsID);
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if (F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			// find first non-alloca instruction in the entry block of the function
+			// -> this will be the insert position for new alloca instructions
+			for(auto& instr : *F.begin()) {
+				if(!isa<AllocaInst>(instr)) {
+					alloca_insert = &instr;
+					break;
+				}
+			}
+			
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			if(was_modified) {
+				DBG(errs() << "!! modified function: ";)
+				DBG(errs().write_escaped(F.getName()) << '\n';)
+			}
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<AddressSpaceFix>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<AddressSpaceFix>::visit(I);
+		}
+		
+		void visitCallInst(CallInst& CI) {
+			CallSite CS { &CI };
+			PointerType* FPTy = cast<PointerType>(CS.getCalledValue()->getType());
+			FunctionType* FTy = cast<FunctionType>(FPTy->getElementType());
+			
+			for (unsigned i = 0, e = FTy->getNumParams(); i != e; ++i) {
+				// check if there is a type mismatch
+				if(CS.getArgument(i)->getType() != FTy->getParamType(i)) {
+					// both types must be pointers
+					auto arg = CS.getArgument(i);
+					auto called_arg_type = arg->getType();
+					auto expected_arg_type = FTy->getParamType(i);
+					if(!called_arg_type->isPointerTy() ||
+					   !expected_arg_type->isPointerTy()) {
+						// emit original verifier assertion (TODO: fix it there!)
+						assert(false && "#1: Call parameter type does not match function signature!");
+						continue;
+					}
+					
+					// check if the mismatch is _only_ due to the addrspace
+					auto as_ptr = cast<PointerType>(called_arg_type);
+					if(PointerType::get(as_ptr->getElementType(),
+										expected_arg_type->getPointerAddressSpace()) !=
+					   expected_arg_type) {
+						// emit original verifier assertion (TODO: fix it there!)
+						assert(false && "#2: Call parameter type does not match function signature!");
+						continue;
+					}
+					// else: yup, only addrspace mismatch
+					DBG(errs() << "#####################################################\n";)
+					DBG(errs() << "\t>> call to: "; CS.getCalledFunction()->llvm::Value::getType()->dump();)
+					DBG(errs() << "\n\t>> full: " << CS.getCalledFunction()->getName() << "\n";)
+					DBG(errs() << "\tonly addrspace mismatch!\n";)
+					DBG(errs() << "\treplacing arg #" << i << "!\n";)
+					DBG(errs() << called_arg_type->getPointerAddressSpace() << ", ";)
+					DBG(errs() << expected_arg_type->getPointerAddressSpace() << "\n";)
+					DBG(called_arg_type->dump(); errs() << ", ";)
+					DBG(expected_arg_type->dump(); errs() << "\n";)
+					DBG({
+						int err = 0;
+						const char* demangled_name = abi::__cxa_demangle(CS.getCalledFunction()->getName().data(), 0, 0, &err);
+						errs() << "\tfunc: " << (demangled_name != nullptr ? demangled_name : CS.getCalledFunction()->getName().data()) << "\n";
+						if(demangled_name != nullptr) {
+							free((void*)demangled_name);
+						}
+					})
+					
+					// abort if arg is an addrspacecast and pretend everything is fine ("someone else" is already making it fit)
+					if(isa<AddrSpaceCastInst>(arg)) {
+						DBG(errs() << "\tabort due to existing addrspacecast: " << *arg << "\n";)
+						continue;
+					}
+					
+					// the same goes for bitcasts, unless src and dst have the same address space
+					if(const auto BCI = dyn_cast_or_null<BitCastInst>(arg)) {
+						if(BCI->getSrcTy()->getPointerAddressSpace() != BCI->getDestTy()->getPointerAddressSpace()) {
+							DBG(errs() << "\tabort due to existing bitcast: " << *arg << "\n";)
+							continue;
+						}
+						// else: perform address space fix, b/c this is a simple pointer/type cast
+						DBG(errs() << "\tkeeping bitcast: " << *arg << "\n";)
+					}
+					
+					// abort if expected param address space is not 0, this is not supported (or would end in a good way ...)
+					// TODO: figure out if it would be a good idea to allow things like loading from e.g. local AS and calling a global AS function
+					if(expected_arg_type->getPointerAddressSpace() != 0) {
+						DBG(errs() << "\tabort due to expected AS not being 0\n";)
+						continue;
+					}
+					
+					// abort if current argument is in address space 0 (can't be moved to an address space)
+					if(called_arg_type->getPointerAddressSpace() == 0) {
+						DBG(errs() << "\tabort due to arg already being in AS 0\n";)
+						continue;
+					}
+					
+					// fix it:
+					//  * create a temporary object (of the element/pointee type of the address space pointer)
+					//  * load data from the address space pointer to the temp object
+					//  * replace the respective call operand/argument with a pointer to the temp object
+					//  * after the call, store data back to the address space pointer from the temp object,
+					//    unless the temp object can not or has not been written to
+					
+					// TODO: handle alignment?
+					
+					// query information that decides if a store is necessary later on
+					const bool is_constant_as = (as_ptr->getPointerAddressSpace() == 2);
+					const bool is_readonly = CS.onlyReadsMemory(i);
+					const bool is_load = isa<LoadInst>(arg);
+					
+					builder->SetInsertPoint(alloca_insert); // insert alloca at function entry
+					auto tmp = builder->CreateAlloca(as_ptr->getElementType(),
+													 // what about arrays?
+													 nullptr,
+													 // give it a nice name
+													 "asfixtmp");
+					
+					builder->SetInsertPoint(&CI); // insert load before call
+					builder->CreateStore(builder->CreateLoad(arg), tmp);
+					
+					CS.setArgument(i, tmp);
+					
+					// don't emit stores for const pointers or constant address space pointers
+					if(!is_constant_as && !is_readonly && !is_load) {
+						builder->SetInsertPoint(CI.getNextNode()); // insert store after call
+						builder->CreateStore(builder->CreateLoad(tmp), arg);
+						DBG(errs() << "<< emitted write-back\n";)
+					}
+					else {
+						DBG(errs() << "<< discarded write-back";)
+						if(is_constant_as) {
+							DBG(errs() << ": constant address space";)
+						}
+						else if(is_readonly) {
+							DBG(errs() << ": readonly arg";)
+						}
+						else if(is_load) {
+							DBG(errs() << ": load instruction";)
+						}
+						DBG(errs() << ", " << is_constant_as << ", " << is_readonly << ", " << is_load << "\n";)
+					}
+
+					// done, signal that the function was modified
+					was_modified = true;
+				}
+			}
+		}
+	};
+}
+
+char AddressSpaceFix::ID = 0;
+INITIALIZE_PASS_BEGIN(AddressSpaceFix, "AddressSpaceFix", "AddressSpaceFix Pass", false, false)
+INITIALIZE_PASS_DEPENDENCY(FunctionAttrs)
+INITIALIZE_PASS_END(AddressSpaceFix, "AddressSpaceFix", "AddressSpaceFix Pass", false, false)
+
+FunctionPass *llvm::createAddressSpaceFixPass() {
+	return new AddressSpaceFix();
+}
diff --git a/lib/Transforms/Scalar/CMakeLists.txt b/lib/Transforms/Scalar/CMakeLists.txt
index 261ddda..88976b0 100644
--- a/lib/Transforms/Scalar/CMakeLists.txt
+++ b/lib/Transforms/Scalar/CMakeLists.txt
@@ -1,4 +1,12 @@
 add_llvm_library(LLVMScalarOpts
+  AddressSpaceFix.cpp
+  CUDAImage.cpp
+  CUDAFinal.cpp
+  MetalFinal.cpp
+  SPIRFinal.cpp
+  FloorImage.cpp
+  MetalImage.cpp
+  SPIRImage.cpp
   ADCE.cpp
   ConstantHoisting.cpp
   ConstantProp.cpp
diff --git a/lib/Transforms/Scalar/CUDAFinal.cpp b/lib/Transforms/Scalar/CUDAFinal.cpp
new file mode 100644
index 0000000..b77f9fa
--- /dev/null
+++ b/lib/Transforms/Scalar/CUDAFinal.cpp
@@ -0,0 +1,116 @@
+//===- CUDAFinal.cpp - CUDA final pass ------------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// TODO
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "CUDAFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// CUDAFinal
+	struct CUDAFinal : public FunctionPass, InstVisitor<CUDAFinal> {
+		friend class InstVisitor<CUDAFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		
+		CUDAFinal() : FunctionPass(ID) {
+			initializeCUDAFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			// if not a kernel function, return (for now)
+			if(!F.hasFnAttribute("compute_kernel")) return false;
+			
+			// reset
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			was_modified = false;
+			
+			// visit everything in this function
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<CUDAFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<CUDAFinal>::visit(I);
+		}
+		
+	};
+}
+
+char CUDAFinal::ID = 0;
+INITIALIZE_PASS_BEGIN(CUDAFinal, "CUDAFinal", "CUDAFinal Pass", false, false)
+INITIALIZE_PASS_END(CUDAFinal, "CUDAFinal", "CUDAFinal Pass", false, false)
+
+FunctionPass *llvm::createCUDAFinalPass() {
+	return new CUDAFinal();
+}
diff --git a/lib/Transforms/Scalar/CUDAImage.cpp b/lib/Transforms/Scalar/CUDAImage.cpp
new file mode 100644
index 0000000..f03cc68
--- /dev/null
+++ b/lib/Transforms/Scalar/CUDAImage.cpp
@@ -0,0 +1,566 @@
+//===- CUDAImage.cpp - CUDA-specific floor image transformations ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the CUDA-specific floor image transformations, i.e.
+// floor.cuda.<read/write function>.*
+//   -> PTX texture/surface instructions (inline asm)
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <array>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "CUDAImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// CUDAImage
+	struct CUDAImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		CUDAImage(const uint32_t image_capabilities_ = 0) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::CUDA, image_capabilities_) {
+			initializeCUDAImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 16> asm_arg_types;
+			SmallVector<llvm::Value*, 16> asm_args;
+			std::string constraints_str = "";
+			
+			// -> return data
+			std::string dtype;
+			llvm::Type* ret_type, *ret_vec_type;
+			if(func_name == "floor.cuda.read_image.float") {
+				dtype = "f32";
+				constraints_str = "=f,=f,=f,=f";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx),
+					llvm::Type::getFloatTy(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name == "floor.cuda.read_image.int") {
+				dtype = "s32";
+				constraints_str = "=r,=r,=r,=r";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name == "floor.cuda.read_image.uint") {
+				dtype = "u32";
+				constraints_str = "=r,=r,=r,=r";
+				ret_type = llvm::StructType::get(*ctx, std::vector<llvm::Type*> {{
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx),
+					llvm::Type::getInt32Ty(*ctx)
+				}});
+				ret_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			constraints_str += ",l"; // u64 tex handle
+			asm_arg_types.push_back(llvm::Type::getInt64Ty(*ctx));
+			asm_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom; // .1d, .2d, .3d, .a1d, .a2d, .cube, .acube, .2dms, .a2dms
+			bool is_array = false, is_msaa = false, is_cube = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "a1d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "a2d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "2dms"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:		geom = "a2dms"; is_array = true; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "acube"; is_cube = true; is_array = true; break;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			const auto coord_dim = coord_vec_type->getVectorNumElements();
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(is_msaa && !coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			
+			// TODO: add s/w support for reading cube maps with integer coords (u, v, face, *layer)
+			if(is_cube && !coord_type->isFloatTy()) {
+				ctx->emitError(&I, "coordinate type must be float for cube images");
+				return;
+			}
+			
+			std::string ctype = (coord_type->isFloatTy() ? "f32" : "s32");
+			std::string coords_placeholders;
+			const std::string coord_type_str = (coord_type->isFloatTy() ? "f" : "r");
+			uint32_t asm_arg_idx = 5;
+			if(is_msaa) {
+				asm_arg_types.push_back(sample_arg->getType());
+				asm_args.push_back(sample_arg);
+				constraints_str += ",r";
+				coords_placeholders += " $";
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			if(is_array) {
+				asm_arg_types.push_back(layer_arg->getType());
+				asm_args.push_back(layer_arg);
+				constraints_str += ",r";
+				coords_placeholders += (!is_msaa ? " $" : ", $");
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				asm_arg_types.push_back(coord_type);
+				asm_args.push_back(builder->CreateExtractElement(coord_arg, builder->getInt32(i)));
+				constraints_str += "," + coord_type_str;
+				coords_placeholders += (i == 0 && asm_arg_idx == 5 ? " $" : ", $");
+				coords_placeholders += std::to_string(asm_arg_idx++);
+			}
+			
+			// append (ignored) 0 coordinate if #coordinates == 3
+			if((coord_dim + (is_msaa ? 1 : 0) + (is_array ? 1 : 0)) == 3) {
+				coords_placeholders += (coord_type->isFloatTy() ? ", 0.0" : ", 0");
+			}
+			
+			// -> lod
+			std::string mipmap_prefix = "";
+			std::string lod_str = "";
+			if(is_lod_or_bias) {
+				mipmap_prefix = "level.";
+				lod_str = ", ";
+				// NOTE: lod type must match coord elem type, cast if necessary
+				if(const auto const_lod = dyn_cast_or_null<ConstantInt>(lod_or_bias_arg)) {
+					if(coord_type->isIntegerTy()) {
+						lod_str += std::to_string(const_lod->getSExtValue());
+					}
+					else {
+						// convert to float
+						lod_str += std::to_string((float)const_lod->getSExtValue());
+					}
+				}
+				else if(const auto const_lod = dyn_cast_or_null<ConstantFP>(lod_or_bias_arg)) {
+					if(coord_type->isFloatTy()) {
+						lod_str += std::to_string(const_lod->getValueAPF().convertToFloat());
+					}
+					else {
+						// convert to int
+						lod_str += std::to_string((int32_t)round(const_lod->getValueAPF().convertToFloat()));
+					}
+				}
+				else {
+					asm_arg_types.push_back(coord_type);
+					if(coord_type == lod_or_bias_arg->getType()) {
+						asm_args.push_back(lod_or_bias_arg);
+					}
+					else {
+						// convert to appropriate type
+						asm_args.push_back(coord_type->isIntegerTy() ?
+										   builder->CreateFPToSI(lod_or_bias_arg, coord_type) :
+										   builder->CreateSIToFP(lod_or_bias_arg, coord_type));
+					}
+					lod_str += "$" + std::to_string(asm_arg_idx++);
+					constraints_str += (coord_type->isIntegerTy() ? ",r" : ",f");
+				}
+			}
+			
+			// -> gradient
+			std::string gradient_str = "";
+			if(is_gradient) {
+				mipmap_prefix = "grad.";
+				
+				// dpdx
+				gradient_str += ", { ";
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					asm_arg_types.push_back(builder->getFloatTy());
+					asm_args.push_back(builder->CreateExtractElement(dpdx_arg, builder->getInt32(i)));
+					gradient_str += (i == 0 ? "$" : ", $") + std::to_string(asm_arg_idx++);
+					constraints_str += ",f";
+				}
+				if(coord_dim == 3) gradient_str += ", 0.0";
+				
+				// dpdy
+				gradient_str += " }, { ";
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					asm_arg_types.push_back(builder->getFloatTy());
+					asm_args.push_back(builder->CreateExtractElement(dpdy_arg, builder->getInt32(i)));
+					gradient_str += (i == 0 ? "$" : ", $") + std::to_string(asm_arg_idx++);
+					constraints_str += ",f";
+				}
+				if(coord_dim == 3) gradient_str += ", 0.0";
+				gradient_str += " }";
+			}
+			
+			// -> offset
+			std::string offset_str = "";
+			if(is_offset) {
+				for(uint32_t i = 0; i < coord_dim; ++i) {
+					if(i != 0) offset_str += ", ";
+					if(const auto const_offset_elem = dyn_cast_or_null<ConstantInt>(offset_elems[i])) {
+						offset_str += std::to_string(const_offset_elem->getSExtValue());
+					}
+					else {
+						asm_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+						asm_args.push_back(offset_elems[i]);
+						offset_str += "$" + std::to_string(asm_arg_idx++);
+						constraints_str += ",r";
+					}
+				}
+				
+				// append ignored 0 offset
+				if(coord_dim == 3) {
+					offset_str += ", 0";
+				}
+			}
+			
+			// -> build asm string
+			std::string asm_str = "tex." + mipmap_prefix + geom + ".v4." + dtype + "." + ctype;
+			asm_str += " { $0, $1, $2, $3 },";
+			asm_str += " [$4, {" + coords_placeholders + " }]";
+			if(is_lod_or_bias) {
+				asm_str += lod_str;
+			}
+			if(is_gradient) {
+				asm_str += gradient_str;
+			}
+			if(is_offset) {
+				asm_str += ", { " + offset_str + " }";
+			}
+			asm_str += ";";
+			
+			const auto asm_func_type = FunctionType::get(ret_type, asm_arg_types, false);
+			auto asm_func = InlineAsm::get(asm_func_type, asm_str, constraints_str, false /* non-volatile */);
+			auto asm_call = builder->CreateCall(asm_func, asm_args);
+			asm_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			asm_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			//
+			llvm::Value* dst_vec = UndefValue::get(ret_vec_type);
+			for(uint32_t i = 0; i < 4; ++i) {
+				auto scalar = builder->CreateExtractValue(asm_call, i);
+				dst_vec = builder->CreateInsertElement(dst_vec, scalar, builder->getInt32(i));
+			}
+			
+			//
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 16> asm_arg_types;
+			SmallVector<llvm::Value*, 16> asm_args;
+			
+			//// more arg checking
+			
+			// check if format is supported (only for cuda image write)
+			switch(format_type) {
+				case COMPUTE_IMAGE_TYPE::FORMAT_8:
+				case COMPUTE_IMAGE_TYPE::FORMAT_16:
+				case COMPUTE_IMAGE_TYPE::FORMAT_24: // as 32-bit
+				case COMPUTE_IMAGE_TYPE::FORMAT_32:
+				case COMPUTE_IMAGE_TYPE::FORMAT_32_8: // for depth+stencil
+					break;
+				default:
+					// all else: nope
+					ctx->emitError(&I, "unsupported image format (must be 8-bit, 16-bit, 24-bit or 32-bit per channel)");
+					return;
+			}
+			
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			if(func_name != "floor.cuda.write_image.float" &&
+			   func_name != "floor.cuda.write_image.int" &&
+			   func_name != "floor.cuda.write_image.uint") {
+				return; // unknown -> ignore
+			}
+			
+			//// func replacement
+			std::string constraints_str = "l"; // u64 surf handle
+			asm_arg_types.push_back(llvm::Type::getInt64Ty(*ctx));
+			asm_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom; // .1d, .2d, .3d, .a1d, .a2d
+			bool is_array = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "a1d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "a2d"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "3d"; break;
+				// cube and msaa formats are not writable by cuda/ptx
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+					ctx->emitError(&I, "invalid image type - type is not writable");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords
+			const auto coord_dim = coord_vec_type->getVectorNumElements();
+			std::string coords_placeholders;
+			static const uint32_t coord_start_idx = 1;
+			uint32_t coord_idx = 0;
+			size_t x_coord_idx = 0;
+			if(is_array) {
+				asm_arg_types.push_back(layer_arg->getType());
+				asm_args.push_back(layer_arg);
+				constraints_str += ",r";
+				coords_placeholders += " $";
+				coords_placeholders += std::to_string(coord_idx++);
+			}
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				asm_arg_types.push_back(coord_type);
+				auto coord_elem = builder->CreateExtractElement(coord_arg, builder->getInt32(i));
+				if(i == 0) {
+					x_coord_idx = asm_args.size();
+				}
+				asm_args.push_back(coord_elem);
+				constraints_str += ",r";
+				coords_placeholders += (coord_idx == 0 ? " $" : ", $");
+				coords_placeholders += std::to_string(coord_start_idx + coord_idx++);
+			}
+			
+			// append (ignored) 0 coordinate if #coordinates == 3
+			if((coord_dim + (is_array ? 1 : 0)) == 3) {
+				coords_placeholders += ", 0";
+			}
+			
+			// -> data
+			const auto write_channel_count = (image_channel_count == 3 ? 4 : image_channel_count);
+			std::array<llvm::Value*, 4> data_args {{
+				builder->CreateExtractElement(data_arg, builder->getInt32(0)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(1)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(2)),
+				builder->CreateExtractElement(data_arg, builder->getInt32(3))
+			}};
+			
+			std::string dtype, rtype;
+			const bool is_signed_int = ((data_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK) == COMPUTE_IMAGE_TYPE::INT);
+			const bool is_float = ((data_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK) == COMPUTE_IMAGE_TYPE::FLOAT);
+			if(is_normalized) {
+				// need to normalize 32-bit float -> 8-bit or 16-bit unsigned/signed int
+				if(format_type != COMPUTE_IMAGE_TYPE::FORMAT_8 && format_type != COMPUTE_IMAGE_TYPE::FORMAT_16) {
+					ctx->emitError(&I, "invalid normalized write format (expected 8-bit or 16-bit dst format");
+					return;
+				}
+				
+				bool is_8_bit = true;
+				if(format_type == COMPUTE_IMAGE_TYPE::FORMAT_8) {
+					dtype = "b8";
+				}
+				else {
+					dtype = "b16";
+					is_8_bit = false;
+				}
+				rtype = "h"; // can't go lower than 16-bit
+				
+				for(uint32_t i = 0; i < write_channel_count; ++i) {
+					data_args[i] = builder->CreateFMul(data_args[i],
+													   ConstantFP::get(builder->getFloatTy(),
+																	   is_signed_int ?
+																	   (is_8_bit ? 127.0 : 32767.0) :
+																	   (is_8_bit ? 255.0 : 65535.0)));
+					data_args[i] = builder->CreateFPToUI(data_args[i],
+														 is_8_bit ? builder->getInt8Ty() : builder->getInt16Ty());
+				}
+			}
+			else {
+				switch(format_type) {
+					case COMPUTE_IMAGE_TYPE::FORMAT_8:
+						dtype = "b8";
+						rtype = "h"; // can't go lower than 16-bit
+						break;
+					case COMPUTE_IMAGE_TYPE::FORMAT_16:
+						dtype = "b16";
+						rtype = (is_float ? "f" : "h");
+						break;
+					case COMPUTE_IMAGE_TYPE::FORMAT_24:
+					case COMPUTE_IMAGE_TYPE::FORMAT_32_8:
+					case COMPUTE_IMAGE_TYPE::FORMAT_32:
+						dtype = "b32";
+						rtype = (is_float ? "f" : "r");
+						break;
+					default:
+						ctx->emitError(&I, "invalid write format");
+						return;
+				}
+				
+				// need to trunc 32-bit data to 16-bit (for 8-bit/16-bit int/uint writes)
+				if(rtype == "h") {
+					for(uint32_t i = 0; i < write_channel_count; ++i) {
+						builder->CreateTrunc(data_args[i], builder->getInt16Ty());
+					}
+				}
+			}
+			
+			// we know the written binary data size now -> update x coordinate offset
+			asm_args[x_coord_idx] = builder->CreateMul(asm_args[x_coord_idx],
+													   builder->getInt32(write_channel_count *
+																		 (dtype == "b16" ? 2 :
+																		  (dtype == "b32" ? 4 : 1 /* b8 */))));
+			
+			std::string data_placeholders;
+			uint32_t data_idx = coord_start_idx + coord_idx;
+			for(uint32_t i = 0; i < write_channel_count; ++i) {
+				asm_arg_types.push_back(data_args[i]->getType());
+				asm_args.push_back(data_args[i]);
+				constraints_str += "," + rtype;
+				data_placeholders += (i == 0 ? " $" : ", $");
+				data_placeholders += std::to_string(data_idx++);
+			}
+			
+			// -> build asm string
+			std::string asm_str = "sust.b." + geom + ".";
+			asm_str += (image_channel_count == 1 ? "" : (image_channel_count == 2 ? "v2." : "v4."));
+			asm_str += dtype + ".";
+			asm_str += "zero"; // ignore out-of-bounds writes (TODO: might want to trap in debug mode?)
+			
+			asm_str += " [$0, {" + coords_placeholders + " }],";
+			asm_str += " {" + data_placeholders + " };";
+			
+			const auto asm_func_type = FunctionType::get(builder->getVoidTy(), asm_arg_types, false);
+			auto asm_func = InlineAsm::get(asm_func_type, asm_str, constraints_str, true /* volatile */);
+			auto asm_call = builder->CreateCall(asm_func, asm_args);
+			asm_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			//
+			I.replaceAllUsesWith(asm_call);
+			I.eraseFromParent();
+		}
+		
+	};
+}
+
+char CUDAImage::ID = 0;
+INITIALIZE_PASS_BEGIN(CUDAImage, "CUDAImage", "CUDAImage Pass", false, false)
+INITIALIZE_PASS_END(CUDAImage, "CUDAImage", "CUDAImage Pass", false, false)
+
+FunctionPass *llvm::createCUDAImagePass(const uint32_t image_capabilities) {
+	return new CUDAImage(image_capabilities);
+}
diff --git a/lib/Transforms/Scalar/FloorImage.cpp b/lib/Transforms/Scalar/FloorImage.cpp
new file mode 100644
index 0000000..6831922
--- /dev/null
+++ b/lib/Transforms/Scalar/FloorImage.cpp
@@ -0,0 +1,379 @@
+//===- FloorImage.cpp - base class for image transformations --------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This class defines and implements the base class for all
+// image transformations (CUDA and opaque, as used for Metal and OpenCL).
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Transforms/Scalar/FloorImage.h"
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <cxxabi.h>
+using namespace llvm;
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+FloorImageBasePass::FloorImageBasePass(char &ID,
+									   const IMAGE_TYPE_ID& image_type_id_,
+									   const uint32_t& image_capabilities_)
+: FunctionPass(ID), image_type_id(image_type_id_),
+image_read_prefix(image_type_id == IMAGE_TYPE_ID::CUDA ? "floor.cuda.read_image." : "floor.opaque.read_image."),
+image_write_prefix(image_type_id == IMAGE_TYPE_ID::CUDA ? "floor.cuda.write_image." : "floor.opaque.write_image."),
+image_capabilities((IMAGE_CAPABILITY)image_capabilities_) {
+}
+
+bool FloorImageBasePass::runOnFunction(Function &F) {
+	// exit if empty function
+	if(F.empty()) return false;
+	
+	// reset
+	M = F.getParent();
+	ctx = &M->getContext();
+	func = &F;
+	builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+	was_modified = false;
+	
+	{
+		AttrBuilder attr_builder;
+		attr_builder.addAttribute(llvm::Attribute::NoUnwind);
+		attr_builder.addAttribute(llvm::Attribute::ReadNone);
+		nounwind_readnone_attr = AttributeSet::get(*ctx, ~0, attr_builder);
+	}
+	{
+		AttrBuilder attr_builder;
+		attr_builder.addAttribute(llvm::Attribute::NoUnwind);
+		nounwind_attr = AttributeSet::get(*ctx, ~0, attr_builder);
+	}
+	
+	// visit everything in this function
+	DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+	visit(F);
+	
+	return was_modified;
+}
+
+void FloorImageBasePass::visit(Instruction& I) {
+	InstVisitor<FloorImageBasePass>::visit(I);
+}
+
+void FloorImageBasePass::visitCallSite(CallSite CS) {
+	const auto func = CS.getCalledFunction();
+	if(!func) return;
+	
+	const auto full_func_name = func->getName();
+	if(full_func_name.startswith(image_read_prefix) ||
+	   full_func_name.startswith(image_write_prefix)) {
+		// strip off .(i|f)(1|2|3) from the end of the func name
+		const auto func_name = full_func_name.rsplit('.').first;
+		handle_image(CS, func_name);
+		was_modified = true;
+	}
+}
+
+void FloorImageBasePass::handle_image(CallSite& CS, const StringRef& func_name) {
+	Instruction* I = CS.getInstruction();
+	builder->SetInsertPoint(I);
+	const bool is_image_read = func_name.startswith(image_read_prefix);
+	
+	/* args for cuda and opaque read/write functions:
+	 
+	 cuda read:
+	 uint64_t tex, COMPUTE_IMAGE_TYPE type,
+	 coord_vec_type coord, uint32_t layer, uint32_t sample, offset_vec_type offset,
+	 int32_t lod_i, float lod_or_bias_f, bool is_lod, bool is_lod_float, bool is_bias,
+	 gradient_vec_type dpdx, gradient_vec_type dpdy, bool is_gradient,
+	 COMPARE_FUNCTION compare_function, float compare_value, bool is_compare
+	 
+	 cuda write:
+	 uint64_t surf, COMPUTE_IMAGE_TYPE type, coord_vec_type coord, uint32_t layer, data_vec_type data
+	 
+	 opaque read:
+	 image_t img, sampler_type smplr, COMPUTE_IMAGE_TYPE type,
+	 coord_vec_type coord, uint32_t layer, uint32_t sample, offset_vec_type offset,
+	 int32_t lod_i, float lod_or_bias_f, bool is_lod, bool is_lod_float, bool is_bias,
+	 gradient_vec_type dpdx, gradient_vec_type dpdy, bool is_gradient,
+	 COMPARE_FUNCTION compare_function, float compare_value, bool is_compare
+	 
+	 opaque write:
+	 image_t img, COMPUTE_IMAGE_TYPE type, coord_vec_type coord, uint32_t layer, data_vec_type data
+	 
+	 */
+	
+	const uint32_t read_arg_count = (image_type_id == IMAGE_TYPE_ID::CUDA ? 17 : 18);
+	const uint32_t write_arg_count = (image_type_id == IMAGE_TYPE_ID::CUDA ? 5 : 5);
+	
+	// as args are largely the same for cuda and opaque, just offset the arg num by 1 for opaque,
+	// instead of doing this individually for each arg.
+	// also: only offset for image reads, as image writes are identical.
+	const uint32_t read_args_offset = (image_type_id == IMAGE_TYPE_ID::CUDA ? 0 : 1);
+	const uint32_t write_args_offset = 0;
+	const uint32_t args_offset = (is_image_read ? read_args_offset : write_args_offset);
+	
+	// check + get arguments
+	if(is_image_read && CS.arg_size() != read_arg_count) {
+		ctx->emitError(I, func_name + ": invalid argument count (expected " + std::to_string(read_arg_count) + ")");
+		return;
+	}
+	if(!is_image_read && CS.arg_size() != write_arg_count) {
+		ctx->emitError(I, func_name + ": invalid argument count (expected " + std::to_string(write_arg_count) + ")");
+		return;
+	}
+	
+	// -> tex/surf/img handle
+	const auto img_handle_arg = CS.getArgument(0);
+	if(image_type_id == IMAGE_TYPE_ID::CUDA &&
+	   !img_handle_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image handle type (must be integer)");
+		return;
+	}
+	else if(image_type_id == IMAGE_TYPE_ID::OPAQUE) {
+		if(!img_handle_arg->getType()->isPointerTy()) {
+			ctx->emitError(I, "invalid image handle type (must be an image pointer)");
+			return;
+		}
+		// TODO: check opaque? check opencl image type?
+	}
+	
+	// -> type enum
+	const auto image_type_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(1 + args_offset));
+	if(!image_type_arg) {
+		ctx->emitError(I, "image type argument must be a constant value");
+		return;
+	}
+	if(!image_type_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image-type type (must be enum/integer)");
+		return;
+	}
+	const uint32_t image_channel_count = ((uint32_t(image_type_arg->getZExtValue()) &
+										   uint32_t(COMPUTE_IMAGE_TYPE::__CHANNELS_MASK)) >>
+										  uint32_t(COMPUTE_IMAGE_TYPE::__CHANNELS_SHIFT)) + 1u;
+	const auto full_image_type = COMPUTE_IMAGE_TYPE(image_type_arg->getZExtValue());
+	const COMPUTE_IMAGE_TYPE image_type = full_image_type & COMPUTE_IMAGE_TYPE::BASE_TYPE_MASK;
+	const COMPUTE_IMAGE_TYPE format_type = full_image_type & COMPUTE_IMAGE_TYPE::__FORMAT_MASK;
+	const COMPUTE_IMAGE_TYPE image_data_type = full_image_type & COMPUTE_IMAGE_TYPE::__DATA_TYPE_MASK;
+	const bool is_normalized = has_flag<COMPUTE_IMAGE_TYPE::FLAG_NORMALIZED>(full_image_type);
+	
+	// -> coord
+	const auto coord_arg = CS.getArgument(2 + args_offset);
+	const auto coord_arg_type = coord_arg->getType();
+	if(!(coord_arg_type->isVectorTy() && (coord_arg_type->getVectorElementType()->isFloatTy() ||
+										  coord_arg_type->getVectorElementType()->isIntegerTy()))) {
+		ctx->emitError(I, "invalid image coordinate type");
+		return;
+	}
+	const auto coord_dim = coord_arg_type->getVectorNumElements();
+	
+	// -> layer
+	const auto layer_arg = CS.getArgument(3 + args_offset);
+	if(!layer_arg->getType()->isIntegerTy()) {
+		ctx->emitError(I, "invalid image layer index type (must be integer)");
+		return;
+	}
+	
+	if(is_image_read) {
+		// -> sampler
+		llvm::ConstantInt* sampler_arg = nullptr;
+		if(image_type_id != IMAGE_TYPE_ID::CUDA) {
+			sampler_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(1));
+			if(sampler_arg == nullptr) {
+				ctx->emitError(I, "sampler must be a constant");
+				return;
+			}
+		}
+		
+		// -> sample
+		const auto sample_arg = CS.getArgument(4 + args_offset);
+		if(!sample_arg->getType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid image sample index type (must be integer)");
+			return;
+		}
+		
+		// -> offset
+		const auto offset_arg = CS.getArgument(5 + args_offset);
+		if(!offset_arg->getType()->isVectorTy() ||
+		   !offset_arg->getType()->getVectorElementType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid offset type (must be an int vector)");
+			return;
+		}
+		if(coord_dim != offset_arg->getType()->getVectorNumElements()) {
+			ctx->emitError(I, "invalid offset vector dimension: should be " + std::to_string(coord_dim));
+			return;
+		}
+		
+		SmallVector<llvm::Value*, 3> offset_elems;
+		bool is_offset = true;
+		if(const auto const_offset_arg = dyn_cast_or_null<Constant>(offset_arg)) {
+			// const 0 or undef -> no offset
+			if(const_offset_arg->isZeroValue() ||
+			   dyn_cast_or_null<UndefValue>(const_offset_arg)) {
+				is_offset = false;
+			}
+		}
+		
+		if(is_offset) {
+			for(uint32_t i = 0; i < coord_dim; ++i) {
+				auto offset_elem = builder->CreateExtractElement(offset_arg, builder->getInt32(i));
+				offset_elems.push_back(offset_elem);
+				
+				if(const auto const_offset_elem = dyn_cast_or_null<ConstantInt>(offset_elem)) {
+					// can check if within required [-8, 7]
+					const auto val = const_offset_elem->getSExtValue();
+					if(val < -8 || val > 7) {
+						ctx->emitError(I, "offset out of range (must be in [-8, 7]): " + std::to_string(val));
+					}
+				}
+			}
+		}
+		
+		// -> misc flags
+		const auto is_lod_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(8 + args_offset));
+		const auto is_lod_float_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(9 + args_offset));
+		const auto is_bias_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(10 + args_offset));
+		const auto is_gradient_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(13 + args_offset));
+		const auto is_compare_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(16 + args_offset));
+		if(!is_lod_arg) {
+			ctx->emitError(I, "is_lod is not constant");
+			return;
+		}
+		if(!is_lod_float_arg) {
+			ctx->emitError(I, "is_lod_float is not constant");
+			return;
+		}
+		if(!is_bias_arg) {
+			ctx->emitError(I, "is_bias is not constant");
+			return;
+		}
+		if(!is_gradient_arg) {
+			ctx->emitError(I, "is_gradient is not constant");
+			return;
+		}
+		if(!is_compare_arg) {
+			ctx->emitError(I, "is_compare_arg is not constant");
+			return;
+		}
+		
+		const bool is_lod = is_lod_arg->isOne();
+		const bool is_lod_float = is_lod_float_arg->isOne();
+		const bool is_bias = is_bias_arg->isOne();
+		const bool is_gradient = is_gradient_arg->isOne();
+		const bool is_compare = is_compare_arg->isOne();
+		
+		if(is_lod && is_gradient) {
+			ctx->emitError(I, "lod and gradient are mutually exclusive");
+			return;
+		}
+		
+		// -> lod and bias
+		const auto lod_or_bias_arg = CS.getArgument(args_offset + (!is_bias && !is_lod_float ? 6 : 7));
+		
+		if(!lod_or_bias_arg->getType()->isIntegerTy() &&
+		   !lod_or_bias_arg->getType()->isFloatTy()) {
+			ctx->emitError(I, "lod must either be an integer or a float");
+			return;
+		}
+		
+		// -> gradient
+		const auto dpdx_arg = CS.getArgument(11 + args_offset);
+		const auto dpdy_arg = CS.getArgument(12 + args_offset);
+		
+		if(!dpdx_arg->getType()->isVectorTy() ||
+		   !dpdy_arg->getType()->isVectorTy()) {
+			ctx->emitError(I, "dpdx and dpdy must be vector types");
+			return;
+		}
+		if(!dpdx_arg->getType()->getVectorElementType()->isFloatTy() ||
+		   !dpdy_arg->getType()->getVectorElementType()->isFloatTy()) {
+			ctx->emitError(I, "dpdx and dpdy element type must be float");
+			return;
+		}
+		
+		const auto dpdx_dim = dpdx_arg->getType()->getVectorNumElements();
+		const auto dpdy_dim = dpdy_arg->getType()->getVectorNumElements();
+		
+		if(dpdx_dim != coord_dim || dpdy_dim != coord_dim) {
+			ctx->emitError(I, "dpdx and dpdy vector dim must correspond to the coordinate dim");
+			return;
+		}
+		
+		// -> compare
+		const auto compare_function_arg = dyn_cast_or_null<ConstantInt>(CS.getArgument(14 + args_offset));
+		if(!compare_function_arg) {
+			ctx->emitError(I, "compare function arg is not constant");
+			return;
+		}
+		const COMPARE_FUNCTION compare_function = (COMPARE_FUNCTION)compare_function_arg->getZExtValue();
+		if(compare_function >= COMPARE_FUNCTION::__MAX_COMPARE_FUNCTION) {
+			ctx->emitError(I, "invalid compare function");
+			return;
+		}
+		
+		const auto compare_value_arg = CS.getArgument(15 + args_offset);
+		
+		handle_read_image(*I, func_name,
+						  img_handle_arg, image_type,
+						  sampler_arg,
+						  coord_arg, layer_arg, sample_arg,
+						  offset_arg, offset_elems, is_offset,
+						  lod_or_bias_arg, is_lod /* if false, then it's always bias */,
+						  dpdx_arg, dpdy_arg, is_gradient,
+						  compare_function, compare_value_arg, is_compare);
+	}
+	else {
+		// -> data
+		const auto data_arg = CS.getArgument(4 + args_offset);
+		const auto data_type = data_arg->getType();
+		if(!data_type->isVectorTy() ||
+		   data_type->getVectorNumElements() != 4) {
+			ctx->emitError(I, "invalid image data type (must be 4-component vector)");
+			return;
+		}
+		if(!data_type->getVectorElementType()->isFloatTy() &&
+		   !data_type->getVectorElementType()->isIntegerTy()) {
+			ctx->emitError(I, "invalid image data type (must be a float or integer vector)");
+			return;
+		}
+		
+		handle_write_image(*I, func_name,
+						   img_handle_arg,
+						   image_type, format_type, image_data_type,
+						   is_normalized, image_channel_count,
+						   coord_arg, layer_arg, data_arg);
+	}
+}
diff --git a/lib/Transforms/Scalar/MetalFinal.cpp b/lib/Transforms/Scalar/MetalFinal.cpp
new file mode 100644
index 0000000..ff5cb3f
--- /dev/null
+++ b/lib/Transforms/Scalar/MetalFinal.cpp
@@ -0,0 +1,728 @@
+//===- MetalFinal.cpp - Metal final pass ----------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file fixes certain post-codegen issues.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <unordered_map>
+#include <array>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "MetalFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+//////////////////////////////////////////
+// blatantly copied/transplanted from SROA
+namespace {
+/// \brief A custom IRBuilder inserter which prefixes all names if they are
+/// preserved.
+template <bool preserveNames = true>
+class IRBuilderPrefixedInserter :
+    public IRBuilderDefaultInserter<preserveNames> {
+  std::string Prefix;
+
+public:
+  void SetNamePrefix(const Twine &P) { Prefix = P.str(); }
+
+protected:
+  void InsertHelper(Instruction *I, const Twine &Name, BasicBlock *BB,
+                    BasicBlock::iterator InsertPt) const {
+    IRBuilderDefaultInserter<preserveNames>::InsertHelper(
+        I, Name.isTriviallyEmpty() ? Name : Prefix + Name, BB, InsertPt);
+  }
+};
+
+// Specialization for not preserving the name is trivial.
+template <>
+class IRBuilderPrefixedInserter<false> :
+    public IRBuilderDefaultInserter<false> {
+public:
+  void SetNamePrefix(const Twine &P) {}
+};
+
+#ifndef NDEBUG
+typedef llvm::IRBuilder<true, ConstantFolder,
+                        IRBuilderPrefixedInserter<true> > IRBuilderTy;
+#else
+typedef llvm::IRBuilder<false, ConstantFolder,
+                        IRBuilderPrefixedInserter<false> > IRBuilderTy;
+#endif
+}
+
+namespace {
+  /// \brief Generic recursive split emission class.
+  template <typename Derived>
+  class OpSplitter {
+  protected:
+    /// The builder used to form new instructions.
+    IRBuilderTy IRB;
+    /// The indices which to be used with insert- or extractvalue to select the
+    /// appropriate value within the aggregate.
+    SmallVector<unsigned, 4> Indices;
+    /// The indices to a GEP instruction which will move Ptr to the correct slot
+    /// within the aggregate.
+    SmallVector<Value *, 4> GEPIndices;
+    /// The base pointer of the original op, used as a base for GEPing the
+    /// split operations.
+    Value *Ptr;
+
+    /// Initialize the splitter with an insertion point, Ptr and start with a
+    /// single zero GEP index.
+    OpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : IRB(InsertionPoint), GEPIndices(1, IRB.getInt32(0)), Ptr(Ptr) {}
+
+  public:
+    /// \brief Generic recursive split emission routine.
+    ///
+    /// This method recursively splits an aggregate op (load or store) into
+    /// scalar or vector ops. It splits recursively until it hits a single value
+    /// and emits that single value operation via the template argument.
+    ///
+    /// The logic of this routine relies on GEPs and insertvalue and
+    /// extractvalue all operating with the same fundamental index list, merely
+    /// formatted differently (GEPs need actual values).
+    ///
+    /// \param Ty  The type being split recursively into smaller ops.
+    /// \param Agg The aggregate value being built up or stored, depending on
+    /// whether this is splitting a load or a store respectively.
+    void emitSplitOps(Type *Ty, Value *&Agg, const Twine &Name) {
+      if (Ty->isSingleValueType())
+        return static_cast<Derived *>(this)->emitFunc(Ty, Agg, Name);
+
+      if (ArrayType *ATy = dyn_cast<ArrayType>(Ty)) {
+        unsigned OldSize = Indices.size();
+        (void)OldSize;
+        for (unsigned Idx = 0, Size = ATy->getNumElements(); Idx != Size;
+             ++Idx) {
+          assert(Indices.size() == OldSize && "Did not return to the old size");
+          Indices.push_back(Idx);
+          GEPIndices.push_back(IRB.getInt32(Idx));
+          emitSplitOps(ATy->getElementType(), Agg, Name + "." + Twine(Idx));
+          GEPIndices.pop_back();
+          Indices.pop_back();
+        }
+        return;
+      }
+
+      if (StructType *STy = dyn_cast<StructType>(Ty)) {
+        unsigned OldSize = Indices.size();
+        (void)OldSize;
+        for (unsigned Idx = 0, Size = STy->getNumElements(); Idx != Size;
+             ++Idx) {
+          assert(Indices.size() == OldSize && "Did not return to the old size");
+          Indices.push_back(Idx);
+          GEPIndices.push_back(IRB.getInt32(Idx));
+          emitSplitOps(STy->getElementType(Idx), Agg, Name + "." + Twine(Idx));
+          GEPIndices.pop_back();
+          Indices.pop_back();
+        }
+        return;
+      }
+
+      llvm_unreachable("Only arrays and structs are aggregate loadable types");
+    }
+  };
+
+  struct LoadOpSplitter : public OpSplitter<LoadOpSplitter> {
+    LoadOpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : OpSplitter<LoadOpSplitter>(InsertionPoint, Ptr) {}
+
+    /// Emit a leaf load of a single value. This is called at the leaves of the
+    /// recursive emission to actually load values.
+    void emitFunc(Type *Ty, Value *&Agg, const Twine &Name) {
+      assert(Ty->isSingleValueType());
+      // Load the single value and insert it using the indices.
+      Value *GEP = IRB.CreateInBoundsGEP(Ptr, GEPIndices, Name + ".gep");
+      Value *Load = IRB.CreateLoad(GEP, Name + ".load");
+      Agg = IRB.CreateInsertValue(Agg, Load, Indices, Name + ".insert");
+      DEBUG(dbgs() << "          to: " << *Load << "\n");
+    }
+  };
+
+  struct StoreOpSplitter : public OpSplitter<StoreOpSplitter> {
+    StoreOpSplitter(Instruction *InsertionPoint, Value *Ptr)
+      : OpSplitter<StoreOpSplitter>(InsertionPoint, Ptr) {}
+
+    /// Emit a leaf store of a single value. This is called at the leaves of the
+    /// recursive emission to actually produce stores.
+    void emitFunc(Type *Ty, Value *&Agg, const Twine &Name) {
+      assert(Ty->isSingleValueType());
+      // Extract the single value and store it using the indices.
+      Value *Store = IRB.CreateStore(
+        IRB.CreateExtractValue(Agg, Indices, Name + ".extract"),
+        IRB.CreateInBoundsGEP(Ptr, GEPIndices, Name + ".gep"));
+      (void)Store;
+      DEBUG(dbgs() << "          to: " << *Store << "\n");
+    }
+  };
+
+}
+//////////////////////////////////////////
+
+namespace {
+	static bool metal_load_splitter(LoadInst& LI, const bool is_vs) {
+#if 1
+		if(!is_vs) return false;
+		if(!LI.getType()->isAggregateType()) return false;
+		
+		/*printf(">> replacing load: "); fflush(stdout);
+		LI.dump(); fflush(stdout); fflush(stderr);
+		printf("\n"); fflush(stdout);*/
+		
+		LoadOpSplitter Splitter(&LI, LI.getPointerOperand());
+		Value *V = UndefValue::get(LI.getType());
+		Splitter.emitSplitOps(LI.getType(), V, LI.getName() + ".mtlld");
+		LI.replaceAllUsesWith(V);
+		LI.eraseFromParent();
+		return true;
+#else
+		return false;
+#endif
+	}
+	
+	static bool metal_store_splitter(StoreInst& SI, const bool is_vs) {
+#if 1
+		if(!is_vs) return false;
+		if(!SI.getType()->isAggregateType()) return false;
+		
+		/*printf(">> replacing store: "); fflush(stdout);
+		SI.dump(); fflush(stdout); fflush(stderr);
+		printf("\n"); fflush(stdout);*/
+		
+		Value *V = SI.getValueOperand();
+		StoreOpSplitter Splitter(&SI, SI.getPointerOperand());
+		Splitter.emitSplitOps(V->getType(), V, V->getName() + ".mtlst");
+		SI.eraseFromParent();
+		return true;
+#else
+		return false;
+#endif
+	}
+	
+	// MetalFirst
+	struct MetalFirst : public FunctionPass, InstVisitor<MetalFirst> {
+		friend class InstVisitor<MetalFirst>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		const bool enable_intel_workarounds;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		
+		bool was_modified { false };
+		bool is_vertex_func { false };
+		bool is_fragment_func { false };
+		
+		MetalFirst(const bool enable_intel_workarounds_ = false) :
+		FunctionPass(ID), enable_intel_workarounds(enable_intel_workarounds_) {
+			initializeMetalFirstPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			
+			is_vertex_func = F.hasFnAttribute("vertex_shader");
+			is_fragment_func = F.hasFnAttribute("fragment_shader");
+			
+			//
+			was_modified = false;
+			//visit(F); // NOTE/TODO: disabled for now
+			
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<MetalFirst>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<MetalFirst>::visit(I);
+		}
+		
+		void visitLoadInst(LoadInst &LI) {
+			was_modified = metal_load_splitter(LI, is_vertex_func);
+		}
+		
+		void visitStoreInst(StoreInst &SI) {
+			was_modified = metal_store_splitter(SI, is_vertex_func);
+		}
+	};
+	
+	// MetalFinal
+	struct MetalFinal : public FunctionPass, InstVisitor<MetalFinal> {
+		friend class InstVisitor<MetalFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		const bool enable_intel_workarounds;
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		bool is_kernel_func { false };
+		bool is_vertex_func { false };
+		bool is_fragment_func { false };
+		
+		// added kernel function args
+		Argument* global_id { nullptr };
+		Argument* global_size { nullptr };
+		Argument* local_id { nullptr };
+		Argument* local_size { nullptr };
+		Argument* group_id { nullptr };
+		Argument* group_size { nullptr };
+		
+		// added vertex function args
+		Argument* vertex_id { nullptr };
+		
+		// added fragment function args
+		Argument* point_coord { nullptr };
+		
+		MetalFinal(const bool enable_intel_workarounds_ = false) :
+		FunctionPass(ID), enable_intel_workarounds(enable_intel_workarounds_) {
+			initializeMetalFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		template <Instruction::CastOps cast_op, typename std::enable_if<(cast_op == llvm::Instruction::FPToSI ||
+																		 cast_op == llvm::Instruction::FPToUI ||
+																		 cast_op == llvm::Instruction::SIToFP ||
+																		 cast_op == llvm::Instruction::UIToFP), int>::type = 0>
+		llvm::Value* call_conversion_func(llvm::Value* from, llvm::Type* to_type) {
+			// metal only supports conversion of a specific set of integer and float types
+			// -> find and check them
+			const auto from_type = from->getType();
+			static const std::unordered_map<llvm::Type*, const char*> type_map {
+				{ llvm::Type::getInt1Ty(*ctx), ".i1" }, // not sure about signed/unsigned conversion here
+				{ llvm::Type::getInt8Ty(*ctx), ".i8" },
+				{ llvm::Type::getInt16Ty(*ctx), ".i16" },
+				{ llvm::Type::getInt32Ty(*ctx), ".i32" },
+				{ llvm::Type::getInt64Ty(*ctx), ".i64" },
+				{ llvm::Type::getHalfTy(*ctx), "f.f16" },
+				{ llvm::Type::getFloatTy(*ctx), "f.f32" },
+				{ llvm::Type::getDoubleTy(*ctx), "f.f64" },
+			};
+			const auto from_iter = type_map.find(from_type);
+			if(from_iter == end(type_map)) {
+				DBG(errs() << "failed to find conversion function for: " << *from_type << " -> " << *to_type << "\n";)
+				return from;
+			}
+			const auto to_iter = type_map.find(to_type);
+			if(to_iter == end(type_map)) {
+				DBG(errs() << "failed to find conversion function for: " << *from_type << " -> " << *to_type << "\n";)
+				return from;
+			}
+			
+			// figure out if from/to type is signed/unsigned
+			bool from_signed = false, to_signed = false;
+			switch(cast_op) {
+				case llvm::Instruction::FPToSI: from_signed = true; to_signed = true; break;
+				case llvm::Instruction::FPToUI: from_signed = true; to_signed = false; break;
+				case llvm::Instruction::SIToFP: from_signed = true; to_signed = true; break;
+				case llvm::Instruction::UIToFP: from_signed = false; to_signed = true; break;
+				default: __builtin_unreachable();
+			}
+			
+			DBG(errs() << "converting: " << *from_type << " (" << (from_signed ? "signed" : "unsigned") << ") -> " << *to_type << "(" << (to_signed ? "signed" : "unsigned") << ")\n";)
+			
+			// for intel gpus any conversion from/to float from/to i8 or i16 needs to go through a i32 first
+			if(enable_intel_workarounds && from_iter->second[0] == 'f') {
+				if(to_iter->first == llvm::Type::getInt8Ty(*ctx) ||
+				   to_iter->first == llvm::Type::getInt16Ty(*ctx)) {
+					// convert to i32 first, then trunc from i32 to i8/i16
+					const auto to_i32_cast = call_conversion_func<cast_op>(from, llvm::Type::getInt32Ty(*ctx));
+					return builder->CreateTrunc(to_i32_cast, to_iter->first);
+				}
+			}
+			
+			// air.convert.<to_type>.<from_type>
+			std::string func_name = "air.convert.";
+			
+			if(to_iter->second[0] == '.') {
+				func_name += (to_signed ? 's' : 'u');
+			}
+			func_name += to_iter->second;
+			
+			func_name += '.';
+			if(from_iter->second[0] == '.') {
+				func_name += (from_signed ? 's' : 'u');
+			}
+			func_name += from_iter->second;
+			
+			SmallVector<llvm::Type*, 1> params(1, from_type);
+			const auto func_type = llvm::FunctionType::get(to_type, params, false);
+			return builder->CreateCall(M->getOrInsertFunction(func_name, func_type), from);
+		}
+		
+		// dummy
+		template <Instruction::CastOps cast_op, typename std::enable_if<!(cast_op == llvm::Instruction::FPToSI ||
+																		  cast_op == llvm::Instruction::FPToUI ||
+																		  cast_op == llvm::Instruction::SIToFP ||
+																		  cast_op == llvm::Instruction::UIToFP), int>::type = 0>
+		llvm::Value* call_conversion_func(llvm::Value* from, llvm::Type*) {
+			return from;
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if(F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			// add args if this is a kernel function
+			is_kernel_func = F.hasFnAttribute("compute_kernel");
+			if(is_kernel_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 3);
+				global_id = new llvm::Argument(vec_type, "__metal__global_id__", &F);
+				global_size = new llvm::Argument(vec_type, "__metal__global_size__", &F);
+				local_id = new llvm::Argument(vec_type, "__metal__local_id__", &F);
+				local_size = new llvm::Argument(vec_type, "__metal__local_size__", &F);
+				group_id = new llvm::Argument(vec_type, "__metal__group_id__", &F);
+				group_size = new llvm::Argument(vec_type, "__metal__group_size__", &F);
+			}
+			
+			// add args if this is a vertex function
+			is_vertex_func = F.hasFnAttribute("vertex_shader");
+			if(is_vertex_func) {
+				const auto uint_type = llvm::Type::getInt32Ty(*ctx);
+				vertex_id = new llvm::Argument(uint_type, "__metal__vertex_id__", &F);
+				// TODO: this should be optional / only happen on request
+				// TODO: handle instance id
+			}
+			
+			// add args if this is a fragment function
+			is_fragment_func = F.hasFnAttribute("fragment_shader");
+			if(is_fragment_func) {
+				const auto vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 2);
+				point_coord = new llvm::Argument(vec_type, "__metal__point_coord__", &F);
+			}
+			
+			// update function signature / param list
+			if(is_kernel_func || is_vertex_func || is_fragment_func) {
+				std::vector<Type*> param_types;
+				for(auto& arg : F.args()) {
+					// also kill "dereferenceable" arg attributes while we're at it (this is not supported by metal)
+					// NOTE: this only needs to be done here, b/c everything else will be inlined
+					if(F.getAttributes().hasAttribute(arg.getArgNo() + 1, Attribute::Dereferenceable)) {
+						// this is a bit complicated, we can't just remove any deref attribute, but it needs to be
+						// specific to the amount of bytes that are specified + attributes are actually stored in the
+						// function, so we need to set the correct arg number
+						AttrBuilder B;
+						B.addDereferenceableAttr(F.getAttributes().getDereferenceableBytes(arg.getArgNo() + 1));
+						arg.removeAttr(AttributeSet::get(*ctx, arg.getArgNo() + 1,  B));
+					}
+					
+					param_types.push_back(arg.getType());
+				}
+				auto new_func_type = PointerType::get(FunctionType::get(F.getReturnType(), param_types, false), 0);
+				F.mutateType(new_func_type);
+			}
+			
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			
+			// always modified
+			return was_modified || is_kernel_func || is_vertex_func || is_fragment_func;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<MetalFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<MetalFinal>::visit(I);
+		}
+		
+		//
+		void visitCallInst(CallInst &I) {
+			// if this isn't a kernel function we don't need to do anything here (yet)
+			if(!is_kernel_func && !is_vertex_func && !is_fragment_func) return;
+			
+			const auto func_name = I.getCalledFunction()->getName();
+			if(!func_name.startswith("floor.")) return;
+			
+			CallSite CS { &I };
+			builder->SetInsertPoint(&I);
+			
+			// figure out which one we need
+			Argument* id;
+			if(func_name == "floor.get_global_id.i32") {
+				id = global_id;
+			}
+			else if(func_name == "floor.get_global_size.i32") {
+				id = global_size;
+			}
+			else if(func_name == "floor.get_local_id.i32") {
+				id = local_id;
+			}
+			else if(func_name == "floor.get_local_size.i32") {
+				id = local_size;
+			}
+			else if(func_name == "floor.get_group_id.i32") {
+				id = group_id;
+			}
+			else if(func_name == "floor.get_group_size.i32") {
+				id = group_size;
+			}
+			else if(func_name == "floor.get_work_dim.i32") {
+				if(group_size == nullptr) {
+					DBG(printf("failed to get group_size arg, probably not in a kernel function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				// special case
+				// => group_size.z == 1 ? (group_size.y == 1 ? 1 : 2) : 3
+				const auto size_z = builder->CreateExtractElement(group_size, builder->getInt32(2));
+				const auto size_y = builder->CreateExtractElement(group_size, builder->getInt32(1));
+				const auto cmp_z = builder->CreateICmp(ICmpInst::ICMP_EQ, size_z, builder->getInt32(1));
+				const auto cmp_y = builder->CreateICmp(ICmpInst::ICMP_EQ, size_y, builder->getInt32(1));
+				const auto sel_x_or_y = builder->CreateSelect(cmp_y, builder->getInt32(1), builder->getInt32(2));
+				const auto sel_xy_or_z = builder->CreateSelect(cmp_z, sel_x_or_y, builder->getInt32(3));
+				I.replaceAllUsesWith(sel_xy_or_z);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.get_vertex_id.i32") {
+				if(vertex_id == nullptr) {
+					DBG(printf("failed to get vertex_id arg, probably not in a vertex function?\n"); fflush(stdout);)
+					return;
+				}
+				
+				I.replaceAllUsesWith(vertex_id);
+				I.eraseFromParent();
+				return;
+			}
+			else if(func_name == "floor.get_point_coord.float2") {
+				if(point_coord == nullptr) {
+					DBG(printf("failed to get point_coord arg, probably not in a fragment function?\n"); fflush(stdout);)
+					return;
+				}
+			
+				I.replaceAllUsesWith(point_coord);
+				I.eraseFromParent();
+				return;
+			}
+			// unknown -> ignore for now
+			else return;
+			
+			if(id == nullptr) {
+				DBG(printf("failed to get id arg, probably not in a kernel function?\n"); fflush(stdout);)
+				return;
+			}
+			
+			// replace call with vector load / elem extraction from the appropriate vector
+			I.replaceAllUsesWith(builder->CreateExtractElement(id, CS.getArgument(0)));
+			I.eraseFromParent();
+		}
+		
+		// like SPIR, Metal only supports scalar conversion ops ->
+		// * scalarize source vector
+		// * call conversion op for each scalar
+		// * reassemble a vector from the converted scalars
+		// * replace all uses of the original vector
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		bool vec_to_scalar_ops(CastInst& I) {
+			if(!I.getType()->isVectorTy()) return false;
+			
+			// start insertion before instruction
+			builder->SetInsertPoint(&I);
+			
+			// setup
+			auto src_vec = I.getOperand(0);
+			const auto src_vec_type = src_vec->getType();
+			const auto dim = src_vec_type->getVectorNumElements();
+			
+			const auto si_type = I.getDestTy();
+			const auto dst_scalar_type = si_type->getScalarType();
+			llvm::Value* dst_vec = UndefValue::get(si_type);
+			
+			// iterate over all vector components, emit a scalar instruction and insert into a new vector
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto scalar = builder->CreateExtractElement(src_vec, builder->getInt32(i));
+				llvm::Value* cast;
+				switch(cast_op) {
+					case llvm::Instruction::FPToSI:
+					case llvm::Instruction::FPToUI:
+					case llvm::Instruction::SIToFP:
+					case llvm::Instruction::UIToFP:
+						cast = call_conversion_func<cast_op>(scalar, dst_scalar_type);
+						break;
+					default:
+						cast = builder->CreateCast(cast_op, scalar, dst_scalar_type);
+						break;
+				}
+				dst_vec = builder->CreateInsertElement(dst_vec, cast, builder->getInt32(i));
+			}
+			
+			// finally, replace all uses with the new vector and remove the old vec instruction
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+			was_modified = true;
+			return true;
+		}
+		
+		// si/ui/fp -> si/ui/fp conversions require a call to an intrinsic air function (air.convert.*)
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		void scalar_conversion(CastInst& I) {
+			builder->SetInsertPoint(&I);
+			
+			// replace original conversion
+			I.replaceAllUsesWith(call_conversion_func<cast_op>(I.getOperand(0), I.getDestTy()));
+			I.eraseFromParent();
+			was_modified = true;
+		}
+		
+		void visitTruncInst(TruncInst &I) {
+			vec_to_scalar_ops<Instruction::Trunc>(I);
+		}
+		void visitZExtInst(ZExtInst &I) {
+			vec_to_scalar_ops<Instruction::ZExt>(I);
+		}
+		void visitSExtInst(SExtInst &I) {
+			vec_to_scalar_ops<Instruction::SExt>(I);
+		}
+		void visitFPTruncInst(FPTruncInst &I) {
+			vec_to_scalar_ops<Instruction::FPTrunc>(I);
+		}
+		void visitFPExtInst(FPExtInst &I) {
+			vec_to_scalar_ops<Instruction::FPExt>(I);
+		}
+		void visitFPToUIInst(FPToUIInst &I) {
+			if(!vec_to_scalar_ops<Instruction::FPToUI>(I)) {
+				scalar_conversion<Instruction::FPToUI>(I);
+			}
+		}
+		void visitFPToSIInst(FPToSIInst &I) {
+			if(!vec_to_scalar_ops<Instruction::FPToSI>(I)) {
+				scalar_conversion<Instruction::FPToSI>(I);
+			}
+		}
+		void visitUIToFPInst(UIToFPInst &I) {
+			if(!vec_to_scalar_ops<Instruction::UIToFP>(I)) {
+				scalar_conversion<Instruction::UIToFP>(I);
+			}
+		}
+		void visitSIToFPInst(SIToFPInst &I) {
+			if(!vec_to_scalar_ops<Instruction::SIToFP>(I)) {
+				scalar_conversion<Instruction::SIToFP>(I);
+			}
+		}
+		
+		// metal can only handle i32 indices
+		void visitExtractElement(ExtractElementInst& EEI) {
+			const auto idx_op = EEI.getIndexOperand();
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					EEI.setOperand(1 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				else {
+					builder->SetInsertPoint(&EEI);
+					const auto i32_index = builder->CreateIntCast(idx_op, builder->getInt32Ty(), false);
+					EEI.setOperand(1 /* idx op */, i32_index);
+				}
+				was_modified = true;
+			}
+		}
+		
+		// metal can only handle i32 indices
+		void visitInsertElement(InsertElementInst& IEI) {
+			const auto idx_op = IEI.llvm::User::getOperand(2);
+			const auto idx_type = idx_op->getType();
+			if(!idx_type->isIntegerTy(32)) {
+				if(const auto const_idx_op = dyn_cast_or_null<ConstantInt>(idx_op)) {
+					IEI.setOperand(2 /* idx op */, builder->getInt32((int32_t)const_idx_op->getValue().getZExtValue()));
+				}
+				else {
+					builder->SetInsertPoint(&IEI);
+					const auto i32_index = builder->CreateIntCast(idx_op, builder->getInt32Ty(), false);
+					IEI.setOperand(2 /* idx op */, i32_index);
+				}
+				was_modified = true;
+			}
+		}
+		
+		void visitLoadInst(LoadInst &LI) {
+			was_modified = metal_load_splitter(LI, is_vertex_func);
+		}
+		
+		void visitStoreInst(StoreInst &SI) {
+			was_modified = metal_store_splitter(SI, is_vertex_func);
+		}
+		
+	};
+}
+
+char MetalFirst::ID = 0;
+FunctionPass *llvm::createMetalFirstPass(const bool enable_intel_workarounds) {
+	return new MetalFirst(enable_intel_workarounds);
+}
+INITIALIZE_PASS_BEGIN(MetalFirst, "MetalFirst", "MetalFirst Pass", false, false)
+INITIALIZE_PASS_END(MetalFirst, "MetalFirst", "MetalFirst Pass", false, false)
+
+char MetalFinal::ID = 0;
+FunctionPass *llvm::createMetalFinalPass(const bool enable_intel_workarounds) {
+	return new MetalFinal(enable_intel_workarounds);
+}
+INITIALIZE_PASS_BEGIN(MetalFinal, "MetalFinal", "MetalFinal Pass", false, false)
+INITIALIZE_PASS_END(MetalFinal, "MetalFinal", "MetalFinal Pass", false, false)
diff --git a/lib/Transforms/Scalar/MetalImage.cpp b/lib/Transforms/Scalar/MetalImage.cpp
new file mode 100644
index 0000000..b4bd6ba
--- /dev/null
+++ b/lib/Transforms/Scalar/MetalImage.cpp
@@ -0,0 +1,505 @@
+//===- MetalImage.cpp - Metal-specific floor image transformations --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the Metal-specific floor image transformations, i.e.
+// floor.opaque.<read/write function>.* -> air.<read/write function>.*
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+using namespace llvm;
+
+#define DEBUG_TYPE "MetalImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	struct MetalImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		MetalImage(const uint32_t image_capabilities_ = 0) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::OPAQUE, image_capabilities_) {
+			initializeMetalImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 16> func_arg_types;
+			SmallVector<llvm::Value*, 16> func_args;
+			
+			// -> return data
+			std::string dtype;
+			llvm::Type* ret_type;
+			if(func_name.endswith("float")) {
+				dtype = "v4f32";
+				ret_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name.endswith("int")) {
+				dtype = "s.v4i32";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("uint")) {
+				dtype = "u.v4i32";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("half")) {
+				dtype = "v4f16";
+				ret_type = llvm::VectorType::get(llvm::Type::getHalfTy(*ctx), 4);
+			}
+			else if(func_name.endswith("short")) {
+				dtype = "s.v4i16";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt16Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("ushort")) {
+				dtype = "u.v4i16";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt16Ty(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_msaa = false, is_cube = false, is_depth = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "texture_1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "texture_1d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "texture_1d_buffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "depth_2d"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "texture_2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "depth_2d_array"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "texture_2d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:			geom = "depth_2d_ms"; is_msaa = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "texture_2d_ms"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "texture_3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:			geom = "depth_cube"; is_cube = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:	geom = "depth_cube_array"; is_cube = true; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "texture_cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "texture_cube_array"; is_cube = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coord type
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(is_msaa && !coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			if(is_cube && !coord_type->isFloatTy()) {
+				ctx->emitError(&I, "coordinate type must be float for cube images");
+				return;
+			}
+			
+			// air.read_* or air.sample_*?
+			// for msaa: always read
+			// for all else: read if int coords, sample if float coords
+			const bool is_sample_call = (!is_msaa && !coord_type->isIntegerTy());
+			
+			// img handle and sampler
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			if(is_sample_call) {
+				// only add the sampler arg if this is a sample call
+				func_arg_types.push_back(sampler_arg->getType());
+				func_args.push_back(sampler_arg);
+			}
+			
+			if(is_depth) {
+				// must always add the depth type 1 (== float)
+				func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+				func_args.push_back(builder->getInt32(1));
+				
+				// depth return type is always a float
+				ret_type = llvm::Type::getFloatTy(*ctx);
+				dtype = "f32";
+				
+				if(is_compare) {
+					if(!is_sample_call) {
+						ctx->emitError(&I, "compare must be a sample call");
+						return;
+					}
+				}
+			}
+			else {
+				if(is_compare) {
+					ctx->emitError(&I, "compare is only allowed with depth types");
+					return;
+				}
+			}
+			
+			// handle offset
+			llvm::Value* offset_coord_arg = coord_arg;
+			if(!is_sample_call && is_offset) {
+				offset_coord_arg = builder->CreateAdd(coord_arg, offset_arg);
+			}
+			
+			// -> coords: coords, sample, face, layer
+			if(coord_vec_type->getNumElements() == 1) {
+				// 1D coord, make it scalar
+				func_arg_types.push_back(coord_type);
+				func_args.push_back(builder->CreateExtractElement(offset_coord_arg, builder->getInt32(0)));
+			}
+			else {
+				// normal coord arg
+				if(!is_cube || coord_type->isFloatTy()) {
+					func_arg_types.push_back(offset_coord_arg->getType());
+					func_args.push_back(offset_coord_arg);
+				}
+				// cube with int coords
+				else {
+					// extract the face integer from the coords
+					const auto face_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(2));
+					
+					// create new int2 arg
+					llvm::Value* coord_i2_arg = UndefValue::get(llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 2));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(offset_coord_arg, builder->getInt32(0)), builder->getInt32(0));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(offset_coord_arg, builder->getInt32(1)), builder->getInt32(1));
+					
+					func_arg_types.push_back(coord_i2_arg->getType());
+					func_args.push_back(coord_i2_arg);
+					
+					func_arg_types.push_back(face_arg->getType());
+					func_args.push_back(face_arg);
+				}
+			}
+			
+			if(is_msaa) {
+				func_arg_types.push_back(sample_arg->getType());
+				func_args.push_back(sample_arg);
+			}
+			
+			if(is_array) {
+				func_arg_types.push_back(layer_arg->getType());
+				func_args.push_back(layer_arg);
+			}
+			
+			if(is_compare) {
+				func_arg_types.push_back(compare_value_arg->getType());
+				func_args.push_back(compare_value_arg);
+			}
+			
+			// -> additional args: lod, bias, gradient, offset
+			if(!is_sample_call) {
+				// -> read
+				if(!is_msaa) { // msaa is always lod 0, hence needs no arg
+					// -> lod
+					if(is_lod_or_bias) {
+						// for read, only int lods are allowed
+						if(!lod_or_bias_arg->getType()->isIntegerTy()) {
+							// convert to int
+							const auto int_lod = builder->CreateFPToSI(lod_or_bias_arg, llvm::Type::getInt32Ty(*ctx));
+							func_arg_types.push_back(int_lod->getType());
+							func_args.push_back(int_lod);
+						}
+						else {
+							func_arg_types.push_back(lod_or_bias_arg->getType());
+							func_args.push_back(lod_or_bias_arg);
+						}
+					}
+					else {
+						// if no lod is specified (bias is not allowed here), add a 0 lod
+						func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+						func_args.push_back(builder->getInt32(0));
+					}
+				}
+			}
+			else {
+				// -> sample
+				
+				// -> gradient
+				if(is_gradient) {
+					func_arg_types.push_back(dpdx_arg->getType());
+					func_args.push_back(dpdx_arg);
+					func_arg_types.push_back(dpdy_arg->getType());
+					func_args.push_back(dpdy_arg);
+				}
+				
+				// -> offset
+				if(!is_cube) { // cube allows no offset (TODO: support this through s/w?)
+					func_arg_types.push_back(llvm::Type::getInt1Ty(*ctx));
+					func_args.push_back(builder->getInt1(is_offset));
+					
+					func_arg_types.push_back(offset_arg->getType());
+					func_args.push_back(offset_arg);
+				}
+				// else: TODO
+				
+				// -> lod / bias
+				if(!is_gradient) {
+					// lod or bias?
+					func_arg_types.push_back(llvm::Type::getInt1Ty(*ctx));
+					func_args.push_back(builder->getInt1(is_lod_or_bias));
+					
+					// for sample, only float lods are allowed
+					if(!lod_or_bias_arg->getType()->isFloatTy()) {
+						// convert to float
+						const auto float_lod = builder->CreateSIToFP(lod_or_bias_arg, llvm::Type::getFloatTy(*ctx));
+						func_arg_types.push_back(float_lod->getType());
+						func_args.push_back(float_lod);
+					}
+					else {
+						func_arg_types.push_back(lod_or_bias_arg->getType());
+						func_args.push_back(lod_or_bias_arg);
+					}
+				}
+				
+			}
+			
+			// -> build read func name
+			std::string read_func_name = "air.";
+			
+			read_func_name += (is_sample_call ? "sample_" : "read_");
+			if(is_compare) read_func_name += "compare_";
+			read_func_name += geom;
+			if(is_gradient) read_func_name += "_grad";
+			
+			read_func_name += '.' + dtype;
+			
+			// create the air call
+			const auto func_type = llvm::FunctionType::get(ret_type, func_arg_types, false);
+			llvm::CallInst* read_call = builder->CreateCall(M->getOrInsertFunction(read_func_name, func_type, nounwind_readnone_attr), func_args);
+			read_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			read_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			// if this is a depth read/sample, the return type is a float -> create a float4
+			llvm::Value* read_call_result = read_call;
+			if(is_depth) {
+				read_call_result = UndefValue::get(llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4));
+				read_call_result = builder->CreateInsertElement(read_call_result, read_call, builder->getInt32(0));
+				// rest is undef/zero (and will be stripped away again anyways)
+			}
+			
+			//
+			I.replaceAllUsesWith(read_call_result);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 16> func_arg_types;
+			SmallVector<llvm::Value*, 16> func_args;
+			
+			//// more arg checking
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			std::string dtype;
+			if(func_name.endswith("float")) {
+				dtype = "v4f32";
+			}
+			else if(func_name.endswith("int")) {
+				dtype = "s.v4i32";
+			}
+			else if(func_name.endswith("uint")) {
+				dtype = "u.v4i32";
+			}
+			else if(func_name.endswith("half")) {
+				dtype = "v4f16";
+			}
+			else if(func_name.endswith("short")) {
+				dtype = "s.v4i16";
+			}
+			else if(func_name.endswith("ushort")) {
+				dtype = "u.v4i16";
+			}
+			// unknown -> ignore
+			else return;
+			
+			//// func replacement
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_cube = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "texture_1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "texture_1d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "texture_1d_buffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "texture_2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "texture_2d_array"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "texture_3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:				geom = "texture_cube"; is_cube = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:			geom = "texture_cube_array"; is_cube = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+					ctx->emitError(&I, "invalid image type - type is not writable");
+					return;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> coords: coords, face, layer
+			if(coord_vec_type->getNumElements() == 1) {
+				// 1D coord, make it scalar
+				func_arg_types.push_back(coord_type);
+				func_args.push_back(builder->CreateExtractElement(coord_arg, builder->getInt32(0)));
+			}
+			else {
+				// normal coord arg
+				if(!is_cube) {
+					func_arg_types.push_back(coord_vec_type);
+					func_args.push_back(coord_arg);
+				}
+				// cube with int coords
+				else {
+					if(coord_type->isFloatTy()) {
+						// TODO: support float as well through s/w
+						ctx->emitError(&I, "cube write coordinate must be integer");
+						return;
+					}
+					
+					// extract the face integer from the coords
+					const auto face_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(2));
+					
+					// create new int2 arg
+					llvm::Value* coord_i2_arg = UndefValue::get(llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 2));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(coord_arg, builder->getInt32(0)), builder->getInt32(0));
+					coord_i2_arg = builder->CreateInsertElement(coord_i2_arg, builder->CreateExtractElement(coord_arg, builder->getInt32(1)), builder->getInt32(1));
+					
+					func_arg_types.push_back(coord_i2_arg->getType());
+					func_args.push_back(coord_i2_arg);
+					
+					func_arg_types.push_back(face_arg->getType());
+					func_args.push_back(face_arg);
+				}
+			}
+			
+			if(is_array) {
+				func_arg_types.push_back(layer_arg->getType());
+				func_args.push_back(layer_arg);
+			}
+			
+			// -> data (also a 4-component vector)
+			func_arg_types.push_back(data_arg->getType());
+			func_args.push_back(data_arg);
+			
+			// -> lod (always 0 for now, TODO: support write lod)
+			func_arg_types.push_back(llvm::Type::getInt32Ty(*ctx));
+			func_args.push_back(builder->getInt32(0));
+			
+			// -> build write func name
+			const std::string write_func_name = "air.write_" + geom + '.' + dtype;
+			
+			// create the air call
+			const auto func_type = llvm::FunctionType::get(builder->getVoidTy(), func_arg_types, false);
+			llvm::CallInst* write_call = builder->CreateCall(M->getOrInsertFunction(write_func_name, func_type, nounwind_attr), func_args);
+			write_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			
+			//
+			I.replaceAllUsesWith(write_call);
+			I.eraseFromParent();
+		}
+		
+	};
+}
+
+char MetalImage::ID = 0;
+INITIALIZE_PASS_BEGIN(MetalImage, "MetalImage", "MetalImage Pass", false, false)
+INITIALIZE_PASS_END(MetalImage, "MetalImage", "MetalImage Pass", false, false)
+
+FunctionPass *llvm::createMetalImagePass(const uint32_t image_capabilities) {
+	return new MetalImage(image_capabilities);
+}
diff --git a/lib/Transforms/Scalar/SPIRFinal.cpp b/lib/Transforms/Scalar/SPIRFinal.cpp
new file mode 100644
index 0000000..7ce000e
--- /dev/null
+++ b/lib/Transforms/Scalar/SPIRFinal.cpp
@@ -0,0 +1,248 @@
+//===- SPIRFinal.cpp - OpenCL/SPIR fixes ----------------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file tries to fix the LLVM IR so that it is SPIR-conformant.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include <algorithm>
+#include <cstdarg>
+#include <memory>
+#include <cxxabi.h>
+using namespace llvm;
+
+#define DEBUG_TYPE "SPIRFinal"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	// SPIRFinal
+	struct SPIRFinal : public FunctionPass, InstVisitor<SPIRFinal> {
+		friend class InstVisitor<SPIRFinal>;
+		
+		static char ID; // Pass identification, replacement for typeid
+		
+		std::shared_ptr<llvm::IRBuilder<>> builder;
+		
+		Module* M { nullptr };
+		LLVMContext* ctx { nullptr };
+		Function* func { nullptr };
+		Instruction* alloca_insert { nullptr };
+		bool was_modified { false };
+		
+		SPIRFinal() : FunctionPass(ID) {
+			initializeSPIRFinalPass(*PassRegistry::getPassRegistry());
+		}
+		
+		bool runOnFunction(Function &F) override {
+			// exit if empty function
+			if (F.empty()) return false;
+			
+			//
+			M = F.getParent();
+			ctx = &M->getContext();
+			func = &F;
+			builder = std::make_shared<llvm::IRBuilder<>>(*ctx);
+			
+			// visit everything in this function
+			was_modified = false; // reset every time
+			DBG(errs() << "in func: "; errs().write_escaped(F.getName()) << '\n';)
+			visit(F);
+			if(was_modified) {
+				DBG(errs() << "!! modified function: ";)
+				DBG(errs().write_escaped(F.getName()) << '\n';)
+			}
+			return was_modified;
+		}
+		
+		// InstVisitor overrides...
+		using InstVisitor<SPIRFinal>::visit;
+		void visit(Instruction& I) {
+			InstVisitor<SPIRFinal>::visit(I);
+		}
+		
+		// SPIR only supports scalar conversion ops ->
+		// * scalarize source vector
+		// * call conversion op for each scalar
+		// * reassemble a vector from the converted scalars
+		// * replace all uses of the original vector
+		template <Instruction::CastOps cast_op>
+		__attribute__((always_inline))
+		void vec_to_scalar_ops(CastInst& I) {
+			if(!I.getType()->isVectorTy()) return;
+			
+			// start insertion before instruction
+			builder->SetInsertPoint(&I);
+			
+			// setup
+			auto* src_vec = I.getOperand(0);
+			const auto dim = src_vec->getType()->getVectorNumElements();
+			const auto si_type = I.getDestTy();
+			const auto si_scalar_type = si_type->getScalarType();
+			llvm::Value* dst_vec = UndefValue::get(si_type);
+			
+			// iterate over all vector components, emit a scalar instruction and insert into a new vector
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto scalar = builder->CreateExtractElement(src_vec, builder->getInt32(i));
+				dst_vec = builder->CreateInsertElement(dst_vec,
+													   builder->CreateCast(cast_op, scalar, si_scalar_type),
+													   builder->getInt32(i));
+			}
+			
+			// finally, replace all uses with the new vector and remove the old vec instruction
+			I.replaceAllUsesWith(dst_vec);
+			I.eraseFromParent();
+			was_modified = true;
+		}
+		
+		void visitTruncInst(TruncInst &I) {
+			vec_to_scalar_ops<Instruction::Trunc>(I);
+		}
+		void visitZExtInst(ZExtInst &I) {
+			vec_to_scalar_ops<Instruction::ZExt>(I);
+		}
+		void visitSExtInst(SExtInst &I) {
+			vec_to_scalar_ops<Instruction::SExt>(I);
+		}
+		void visitFPTruncInst(FPTruncInst &I) {
+			vec_to_scalar_ops<Instruction::FPTrunc>(I);
+		}
+		void visitFPExtInst(FPExtInst &I) {
+			vec_to_scalar_ops<Instruction::FPExt>(I);
+		}
+		void visitFPToUIInst(FPToUIInst &I) {
+			vec_to_scalar_ops<Instruction::FPToUI>(I);
+		}
+		void visitFPToSIInst(FPToSIInst &I) {
+			vec_to_scalar_ops<Instruction::FPToSI>(I);
+		}
+		void visitUIToFPInst(UIToFPInst &I) {
+			vec_to_scalar_ops<Instruction::UIToFP>(I);
+		}
+		void visitSIToFPInst(SIToFPInst &I) {
+			vec_to_scalar_ops<Instruction::SIToFP>(I);
+		}
+		
+		// SPIR doesn't support LLVM lifetime intrinsics
+		// -> simply remove them
+		// TODO: should probably kill the global decl as well
+		void visitIntrinsicInst(IntrinsicInst &I) {
+			if (I.getIntrinsicID() == Intrinsic::lifetime_start ||
+				I.getIntrinsicID() == Intrinsic::lifetime_end) {
+				I.eraseFromParent();
+				was_modified = true;
+			}
+		}
+		
+		// "ashr" instructions may not be "exact"
+		void visitAShr(BinaryOperator& O) {
+			auto* ashr = dyn_cast_or_null<PossiblyExactOperator>(&O);
+			if(ashr && ashr->isExact()) {
+				// -> replace with a non-exact version
+				builder->SetInsertPoint(&O);
+				auto* new_ashr = builder->CreateAShr(O.getOperand(0), O.getOperand(1));
+				O.replaceAllUsesWith(new_ashr);
+				O.eraseFromParent();
+				was_modified = true;
+			}
+		}
+		
+		// unsupported LLVM IR instructions - fail on these
+		void visitIndirectBrInst(IndirectBrInst &I) {
+			ctx->emitError(&I, "indirect-br instruction is not supported by SPIR");
+		}
+		void visitInvokeInst(InvokeInst &I) {
+			ctx->emitError(&I, "invoke instruction is not supported by SPIR");
+		}
+		// NOTE: unwind no longer exists
+		void visitResumeInst(ResumeInst &I) {
+			ctx->emitError(&I, "resume instruction is not supported by SPIR");
+		}
+		void visitFenceInst(FenceInst &I) {
+			ctx->emitError(&I, "fence instruction is not supported by SPIR");
+		}
+		void visitAtomicCmpXchgInst(AtomicCmpXchgInst &I) {
+			ctx->emitError(&I, "atomic-cmp-xchg instruction is not supported by SPIR - use atomic_* function calls instead!");
+		}
+		void visitAtomicRMWInst(AtomicRMWInst &I) {
+			ctx->emitError(&I, "atomic-rmv instruction is not supported by SPIR - use atomic_* function calls instead!");
+		}
+		void visitVAArgInst(VAArgInst &I) {
+			ctx->emitError(&I, "va-arg instruction is not supported by SPIR");
+		}
+		void visitLandingPadInst(LandingPadInst &I) {
+			ctx->emitError(&I, "landing-pad instruction is not supported by SPIR");
+		}
+		
+		// calls to function pointers are not allowed
+		void visitCallInst(CallInst &I) {
+			if(I.getCalledFunction() == nullptr) {
+				ctx->emitError(&I, "indirect function call / call to function pointer is not supported by SPIR");
+			}
+		}
+		
+		// atomic load/store instructions are not allowed
+		void visitLoadInst(LoadInst &I) {
+			if(I.isAtomic()) {
+				ctx->emitError(&I, "atomic-load instruction is not supported by SPIR - use atomic_* function calls instead!");
+			}
+		}
+		void visitStoreInst(StoreInst &I) {
+			if(I.isAtomic()) {
+				ctx->emitError(&I, "atomic-store instruction is not supported by SPIR - use atomic_* function calls instead!");
+			}
+		}
+	};
+}
+
+char SPIRFinal::ID = 0;
+INITIALIZE_PASS_BEGIN(SPIRFinal, "SPIRFinal", "SPIRFinal Pass", false, false)
+INITIALIZE_PASS_END(SPIRFinal, "SPIRFinal", "SPIRFinal Pass", false, false)
+
+FunctionPass *llvm::createSPIRFinalPass() {
+	return new SPIRFinal();
+}
diff --git a/lib/Transforms/Scalar/SPIRImage.cpp b/lib/Transforms/Scalar/SPIRImage.cpp
new file mode 100644
index 0000000..e7a457d
--- /dev/null
+++ b/lib/Transforms/Scalar/SPIRImage.cpp
@@ -0,0 +1,614 @@
+//===- SPIRImage.cpp - SPIR-specific floor image transformations ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This pass implements the SPIR-specific floor image transformations, i.e.
+// floor.opaque.<read/write function>.* -> spir image function call
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/ADT/Statistic.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/SetVector.h"
+#include "llvm/ADT/SmallPtrSet.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringExtras.h"
+#include "llvm/Analysis/AliasAnalysis.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/IR/CallSite.h"
+#include "llvm/IR/CallingConv.h"
+#include "llvm/IR/ConstantRange.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DebugInfo.h"
+#include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/Function.h"
+#include "llvm/IR/InlineAsm.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/InstVisitor.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Pass.h"
+#include "llvm/Support/CommandLine.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/IPO.h"
+#include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Scalar/FloorImage.h"
+using namespace llvm;
+
+#define DEBUG_TYPE "SPIRImage"
+
+#if 1
+#define DBG(x)
+#else
+#define DBG(x) x
+#endif
+
+namespace {
+	struct SPIRImage : public FloorImageBasePass {
+		static char ID; // Pass identification, replacement for typeid
+		
+		SPIRImage(const uint32_t image_capabilities_ = 0) :
+		FloorImageBasePass(ID, IMAGE_TYPE_ID::OPAQUE, image_capabilities_) {
+			initializeSPIRImagePass(*PassRegistry::getPassRegistry());
+		}
+		
+		llvm::Value* get_or_create_spir_function(const std::string& func_name,
+												 llvm::Type* ret_type,
+												 const SmallVector<llvm::Type*, 8>& func_arg_types,
+												 const bool is_readnone = false) {
+			const auto func_type = llvm::FunctionType::get(ret_type, func_arg_types, false);
+			auto func = M->getFunction(func_name);
+			if(func == nullptr) { // only do this once
+				func = dyn_cast<Function>(M->getOrInsertFunction(func_name, func_type,
+																 is_readnone ?
+																 nounwind_readnone_attr :
+																 nounwind_attr));
+				func->setCallingConv(CallingConv::SPIR_FUNC);
+			}
+			return func;
+		}
+		
+		SmallVector<llvm::Value*, 3> get_image_dim(llvm::Value* img_handle_arg,
+												   llvm::Type* coord_type,
+												   const std::string& geom) {
+			SmallVector<llvm::Value*, 3> ret;
+			
+			static const char* img_dim_funcs[] {
+				"_Z15get_image_width",
+				"_Z15get_image_height",
+				"_Z15get_image_depth"
+			};
+			
+			const auto dim = coord_type->getVectorNumElements();
+			SmallVector<llvm::Type*, 8> get_dim_arg_types;
+			SmallVector<llvm::Value*, 8> get_dim_func_args;
+			get_dim_arg_types.push_back(img_handle_arg->getType());
+			get_dim_func_args.push_back(img_handle_arg);
+			for(uint32_t i = 0; i < dim; ++i) {
+				auto get_dim_func = get_or_create_spir_function(img_dim_funcs[i] + geom,
+																builder->getInt32Ty(),
+																get_dim_arg_types);
+				llvm::CallInst* get_dim_call = builder->CreateCall(get_dim_func, get_dim_func_args);
+				get_dim_call->setDoesNotAccessMemory();
+				get_dim_call->setCallingConv(CallingConv::SPIR_FUNC);
+				ret.push_back(get_dim_call);
+			}
+			
+			return ret;
+		}
+		
+		void handle_cl_coord(Instruction& I,
+							 llvm::Value* coord_arg,
+							 llvm::Value* layer_arg,
+							 const bool is_array,
+							 const bool is_msaa,
+							 const bool must_have_int_args,
+							 std::string& cl_func_name,
+							 SmallVector<llvm::Type*, 8>& func_arg_types,
+							 SmallVector<llvm::Value*, 8>& func_args) {
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			const auto coord_dim = coord_vec_type->getNumElements();
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			const auto is_int_coord = coord_type->isIntegerTy();
+			if(is_msaa && !is_int_coord) {
+				ctx->emitError(&I, "coordinate type must be integer for msaa images");
+				return;
+			}
+			
+			if(must_have_int_args && !is_int_coord) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			// opencl only knows scalar, vector2 and vector4 coordinates -> need to create them if necessary
+			auto cl_coord_dim = coord_dim + (is_array ? 1 : 0);
+			if(cl_coord_dim == 3) cl_coord_dim = 4;
+			const auto cl_coord_scalar_type = (is_int_coord ? llvm::Type::getInt32Ty(*ctx) : llvm::Type::getFloatTy(*ctx));
+			const auto cl_coord_type = (cl_coord_dim == 1 ?
+										cl_coord_scalar_type :
+										llvm::VectorType::get(cl_coord_scalar_type, cl_coord_dim));
+			
+			// start with the specified coord arg, there are some cases where we can just use it without rebuilding
+			auto cl_coord_arg = coord_arg;
+			if(cl_coord_type != coord_vec_type) {
+				if(cl_coord_dim == 1) {
+					// just a scalar
+					cl_coord_arg = builder->CreateExtractElement(coord_arg, builder->getInt32(0));
+				}
+				else {
+					// create a new tmp coord, then copy coord elements (keep unused undef)
+					cl_coord_arg = UndefValue::get(cl_coord_type);
+					uint32_t coord_idx = 0;
+					for(; coord_idx < coord_dim; ++coord_idx) {
+						cl_coord_arg = builder->CreateInsertElement(cl_coord_arg,
+																	builder->CreateExtractElement(coord_arg,
+																								  builder->getInt32(coord_idx)),
+																	builder->getInt32(coord_idx));
+					}
+					
+					// need to pull the layer index into the coordinate, including possible int -> float conversion
+					if(is_array) {
+						auto layer = layer_arg;
+						if(!is_int_coord) {
+							// need to convert
+							layer = builder->CreateUIToFP(layer_arg, cl_coord_scalar_type);
+						}
+						cl_coord_arg = builder->CreateInsertElement(cl_coord_arg, layer, builder->getInt32(coord_idx++));
+					}
+				}
+			}
+			func_arg_types.push_back(cl_coord_arg->getType());
+			func_args.push_back(cl_coord_arg);
+			
+			if(cl_coord_dim > 1) {
+				cl_func_name += "Dv" + std::to_string(cl_coord_dim) + "_";
+			}
+			cl_func_name += (is_int_coord ? "i" : "f");
+		}
+		
+		void handle_read_image(Instruction& I,
+							   const StringRef& func_name,
+							   llvm::Value* img_handle_arg,
+							   const COMPUTE_IMAGE_TYPE& image_type,
+							   llvm::ConstantInt* sampler_arg,
+							   llvm::Value* coord_arg,
+							   llvm::Value* layer_arg,
+							   llvm::Value* sample_arg,
+							   llvm::Value* offset_arg,
+							   const SmallVector<llvm::Value*, 3>& offset_elems,
+							   const bool is_offset,
+							   llvm::Value* lod_or_bias_arg,
+							   const bool is_lod_or_bias, // true: lod, false: bias
+							   llvm::Value* dpdx_arg,
+							   llvm::Value* dpdy_arg,
+							   const bool is_gradient_,
+							   const COMPARE_FUNCTION& compare_function,
+							   llvm::Value* compare_value_arg,
+							   const bool is_compare) override {
+			SmallVector<llvm::Type*, 8> func_arg_types;
+			SmallVector<llvm::Value*, 8> func_args;
+			
+			// NOTE: opencl is rather limited when it comes to image functionality, hence not all types of image reads
+			//       are supported, though some can simply be ignored or emulated in s/w
+			
+			// TODO: add an option to disable advanced image functions and silently fallback to simple ones (at the loss of functionality)
+			
+			// get geom string / mangled name + flags
+			std::string geom;
+			bool is_array = false, is_msaa = false, is_depth = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "17ocl_image1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "16ocl_image1darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "17ocl_image1dbuffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "16ocl_image2ddepth"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "11ocl_image2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "21ocl_image2darraydepth"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "16ocl_image2darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:			geom = "20ocl_image2dmsaadepth"; is_msaa = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:				geom = "15ocl_image2dmsaa"; is_msaa = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "11ocl_image3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:	geom = "25ocl_image2darraymsaadepth"; is_msaa = true; is_depth = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:		geom = "20ocl_image2darraymsaa"; is_msaa = true; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			
+			// -> caps check
+			if(is_lod_or_bias) {
+				if(!has_flag<IMAGE_CAPABILITY::MIPMAP_READ>(image_capabilities)) {
+					ctx->emitError(&I, "lod read not supported by device");
+					return;
+				}
+				
+				// *sigh* will be supported with opencl 2.1 though
+				// -> convert int coords to float coords and swap out sampler
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					const auto coord_type = coord_arg->getType();
+					const auto coord_dim = coord_arg->getType()->getVectorNumElements();
+					const auto fp_coord_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), coord_dim);
+					
+					auto img_dims = get_image_dim(img_handle_arg, coord_type, geom);
+					
+					llvm::Value* fp_coord = UndefValue::get(fp_coord_type);
+					for(uint32_t i = 0; i < coord_dim; ++i) {
+						// fp_coord_i = float(int_coord_i) / float(img_dim_i - 1)
+						auto elem = builder->CreateExtractElement(coord_arg, builder->getInt32(i));
+						auto fp_elem = builder->CreateSIToFP(elem, builder->getFloatTy());
+						auto dim_i = builder->CreateSub(img_dims[i], builder->getInt32(1));
+						auto fp_dim_i = builder->CreateSIToFP(dim_i, builder->getFloatTy());
+						auto div = builder->CreateFDiv(fp_elem, fp_dim_i);
+						fp_coord = builder->CreateInsertElement(fp_coord, div, builder->getInt32(i));
+					}
+					coord_arg = fp_coord;
+					
+					// sampler: set NORMALIZED/CLK_NORMALIZED_COORDS_TRUE flag
+					// NOTE: PIXEL/CLK_NORMALIZED_COORDS_FALSE is 0, so we don't need to clear anything
+					sampler_arg = ConstantInt::get(sampler_arg->getType(), sampler_arg->getZExtValue() | 0x1);
+				}
+			}
+			
+			bool is_gradient = is_gradient_;
+			if(is_gradient_) {
+				if(!has_flag<IMAGE_CAPABILITY::MIPMAP_READ>(image_capabilities)) {
+					ctx->emitError(&I, "gradient read not supported by device");
+					return;
+				}
+				
+				// again, not supported (also: doesn't make much sense?)
+				// -> not going to s/w emulate this for now
+				// -> silently ignore for now
+#if 0
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					ctx->emitError(&I, "gradient read not supported with integer coordinates");
+					return;
+				}
+#else
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					is_gradient = false;
+				}
+#endif
+			}
+			
+			// -> return data and cl function name
+			// NOTE: we don't have a c++ mangling support in here, so do it manually
+			// (this is actually easy enough, since everything is very static)
+			std::string cl_func_name;
+			llvm::Type* ret_type;
+			if(func_name.endswith("float")) {
+				cl_func_name = "_Z11read_imagef";
+				ret_type = llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4);
+			}
+			else if(func_name.endswith("int")) {
+				cl_func_name = "_Z11read_imagei";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("uint")) {
+				cl_func_name = "_Z12read_imageui";
+				ret_type = llvm::VectorType::get(llvm::Type::getInt32Ty(*ctx), 4);
+			}
+			else if(func_name.endswith("half")) {
+				cl_func_name = "_Z11read_imageh";
+				ret_type = llvm::VectorType::get(llvm::Type::getHalfTy(*ctx), 4);
+			}
+			// unknown -> ignore
+			else return;
+			
+			// -> geom
+			cl_func_name += geom;
+			
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			if(is_depth) {
+				// depth return type is always a float
+				ret_type = llvm::Type::getFloatTy(*ctx);
+			}
+			
+			// except for msaa, we always have a sampler
+			if(!is_msaa) {
+				cl_func_name += "11ocl_sampler";
+				func_arg_types.push_back(sampler_arg->getType());
+				func_args.push_back(sampler_arg);
+			}
+			
+			// -> offset
+			// opencl has no offset support, so always add it
+			llvm::Value* offset_coord_arg = coord_arg;
+			if(is_offset) {
+				if(coord_arg->getType()->getVectorElementType()->isIntegerTy()) {
+					offset_coord_arg = builder->CreateAdd(coord_arg, offset_arg);
+				}
+				else {
+					// need to fallback to s/w for fp coords
+					auto coord_type = coord_arg->getType();
+					auto offset_dim = coord_type->getVectorNumElements();
+					auto img_dims = get_image_dim(img_handle_arg, coord_type, geom);
+					
+					// float_offset_i = float(offset_i) / float(dim_i)
+					llvm::Value* fp_offset = UndefValue::get(coord_type);
+					for(uint32_t i = 0; i < offset_dim; ++i) {
+						auto offset_i = builder->CreateExtractElement(offset_arg, builder->getInt32(i));
+						
+						// one offset elem is often 0
+						// -> add some special handling since the si->fp conversion and fdiv are unnecessary here
+						// (this might later also get rid of unnecessary get_image_* calls)
+						if(const auto const_offset_i = dyn_cast_or_null<ConstantInt>(offset_i)) {
+							if(const_offset_i->getSExtValue() == 0) {
+								builder->CreateInsertElement(fp_offset, ConstantFP::get(builder->getFloatTy(), 0.0),
+															 builder->getInt32(i));
+								continue;
+							}
+						}
+						
+						auto offset_i_fp = builder->CreateSIToFP(offset_i, builder->getFloatTy());
+						auto dim_i = builder->CreateSIToFP(img_dims[i], builder->getFloatTy());
+						fp_offset = builder->CreateInsertElement(fp_offset,
+																 builder->CreateFDiv(offset_i_fp, dim_i),
+																 builder->getInt32(i));
+					}
+					
+					// finally: add the compute fp offset
+					offset_coord_arg = builder->CreateFAdd(coord_arg, fp_offset);
+				}
+			}
+			
+			// -> coord
+			handle_cl_coord(I,
+							offset_coord_arg,
+							layer_arg,
+							is_array,
+							is_msaa,
+							false, // can have either int or float coords
+							cl_func_name,
+							func_arg_types,
+							func_args);
+			
+			// -> sample
+			if(is_msaa) {
+				if(!sample_arg->getType()->isIntegerTy()) {
+					ctx->emitError(&I, "msaa sample index must be integer");
+					return;
+				}
+				
+				cl_func_name += "i";
+				func_arg_types.push_back(sample_arg->getType());
+				func_args.push_back(sample_arg);
+			}
+			
+			// -> gradient
+			if(is_gradient) {
+				const auto coord_dim = coord_arg->getType()->getVectorNumElements();
+				if(coord_dim == 1) {
+					// extract scalar
+					cl_func_name += "ff";
+					func_arg_types.push_back(builder->getFloatTy());
+					func_args.push_back(builder->CreateExtractElement(dpdx_arg, builder->getInt32(0)));
+					func_arg_types.push_back(builder->getFloatTy());
+					func_args.push_back(builder->CreateExtractElement(dpdy_arg, builder->getInt32(0)));
+				}
+				else if(coord_dim == 2) {
+					// just pass-through
+					cl_func_name += "Dv2_fDv2_f";
+					func_arg_types.push_back(dpdx_arg->getType());
+					func_args.push_back(dpdx_arg);
+					func_arg_types.push_back(dpdy_arg->getType());
+					func_args.push_back(dpdy_arg);
+				}
+				else if(coord_dim == 3) {
+					// need to create a vector4
+					cl_func_name += "Dv4_fDv4_f";
+					
+					const auto grad_type = llvm::VectorType::get(builder->getFloatTy(), 4);
+					func_arg_types.push_back(grad_type);
+					func_arg_types.push_back(grad_type);
+					
+					llvm::Value* dpdx4 = UndefValue::get(grad_type);
+					llvm::Value* dpdy4 = UndefValue::get(grad_type);
+					for(uint32_t i = 0; i < 3; ++i) {
+						auto idx = builder->getInt32(i);
+						dpdx4 = builder->CreateInsertElement(dpdx4, builder->CreateExtractElement(dpdx_arg, idx), idx);
+						dpdy4 = builder->CreateInsertElement(dpdy4, builder->CreateExtractElement(dpdy_arg, idx), idx);
+					}
+					func_args.push_back(dpdx4);
+					func_args.push_back(dpdy4);
+				}
+				else llvm_unreachable("invalid coord dim");
+			}
+			
+			// -> lod
+			// NOTE: bias is never supported
+			if(is_lod_or_bias) {
+				cl_func_name += "f";
+				
+				auto lod = lod_or_bias_arg;
+				if(lod_or_bias_arg->getType()->isIntegerTy()) {
+					// only float is supported, convert it
+					lod = builder->CreateSIToFP(lod_or_bias_arg, builder->getFloatTy());
+				}
+				func_arg_types.push_back(lod->getType());
+				func_args.push_back(lod);
+			}
+			
+			// -> compare
+			if(is_compare) {
+				// TODO: emulate in s/w
+			}
+			
+			// create the opencl call
+			auto read_func = get_or_create_spir_function(cl_func_name, ret_type, func_arg_types, true);
+			llvm::CallInst* read_call = builder->CreateCall(read_func, func_args);
+			read_call->setDoesNotAccessMemory(); // all reads are readnone (can be optimized away if unused)
+			read_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			read_call->setCallingConv(CallingConv::SPIR_FUNC);
+			
+			// if this is a depth read/sample, the return type is a float -> create a float4
+			llvm::Value* read_call_result = read_call;
+			if(is_depth) {
+				read_call_result = UndefValue::get(llvm::VectorType::get(llvm::Type::getFloatTy(*ctx), 4));
+				read_call_result = builder->CreateInsertElement(read_call_result, read_call, builder->getInt32(0));
+				// rest is undef/zero (and will be stripped away again anyways)
+			}
+			
+			//
+			I.replaceAllUsesWith(read_call_result);
+			I.eraseFromParent();
+		}
+		
+		void handle_write_image(Instruction& I,
+								const StringRef& func_name,
+								llvm::Value* img_handle_arg,
+								const COMPUTE_IMAGE_TYPE& image_type,
+								const COMPUTE_IMAGE_TYPE& format_type,
+								const COMPUTE_IMAGE_TYPE& data_type,
+								const bool& is_normalized,
+								const uint32_t& image_channel_count,
+								llvm::Value* coord_arg,
+								llvm::Value* layer_arg,
+								llvm::Value* data_arg) override {
+			SmallVector<llvm::Type*, 8> func_arg_types;
+			SmallVector<llvm::Value*, 8> func_args;
+			
+			//// more arg checking
+			auto coord_vec_type = dyn_cast_or_null<VectorType>(coord_arg->getType());
+			if(!coord_vec_type) {
+				ctx->emitError(&I, "invalid image coordinate argument (cast to vector failed)");
+				return;
+			}
+			
+			const auto coord_type = coord_vec_type->getElementType();
+			if(!coord_type->isIntegerTy()) {
+				ctx->emitError(&I, "coordinate type must be integer");
+				return;
+			}
+			
+			std::string cl_func_name, dtype;
+			if(func_name.endswith("float")) {
+				cl_func_name = "_Z12write_imagef";
+				dtype = "f";
+			}
+			else if(func_name.endswith("int")) {
+				cl_func_name = "_Z12write_imagei";
+				dtype = "i";
+			}
+			else if(func_name.endswith("uint")) {
+				cl_func_name = "_Z13write_imageui";
+				dtype = "j";
+			}
+			else if(func_name.endswith("half")) {
+				cl_func_name = "_Z12write_imageh";
+				dtype = "h";
+			}
+			// unknown -> ignore
+			else return;
+			
+			//// func replacement
+			// -> geom
+			std::string geom;
+			bool is_array = false, is_depth = false;
+			switch(image_type) {
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D:					geom = "17ocl_image1d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_ARRAY:			geom = "16ocl_image1darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_1D_BUFFER:			geom = "17ocl_image1dbuffer"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_STENCIL:		geom = "16ocl_image2ddepth"; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D:					geom = "11ocl_image2d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_ARRAY:			geom = "21ocl_image2darraydepth"; is_array = true; is_depth = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_ARRAY:			geom = "16ocl_image2darray"; is_array = true; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_3D:					geom = "11ocl_image3d"; break;
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_2D_MSAA_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_DEPTH_CUBE_ARRAY:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE:
+				case COMPUTE_IMAGE_TYPE::IMAGE_CUBE_ARRAY:
+					ctx->emitError(&I, "unsupported image type");
+					return;
+				default:
+					ctx->emitError(&I, "unknown or incorrect image type");
+					return;
+			}
+			cl_func_name += geom;
+			
+			func_arg_types.push_back(img_handle_arg->getType());
+			func_args.push_back(img_handle_arg);
+			
+			// -> coord
+			handle_cl_coord(I,
+							coord_arg,
+							layer_arg,
+							is_array,
+							false, // no msaa
+							true, // must always have int coords for writes
+							cl_func_name,
+							func_arg_types,
+							func_args);
+			
+			// -> data
+			// data is always a vector4, unless we're writing depth
+			if(!is_depth) {
+				cl_func_name += "Dv4_";
+				func_arg_types.push_back(data_arg->getType());
+				func_args.push_back(data_arg);
+			}
+			else {
+				// extract and use depth elem
+				auto depth_arg = builder->CreateExtractElement(data_arg, builder->getInt32(0));
+				func_arg_types.push_back(depth_arg->getType());
+				func_args.push_back(depth_arg);
+			}
+			cl_func_name += dtype;
+			
+			// -> lod
+			// TODO
+			
+			// create the opencl call
+			auto write_func = get_or_create_spir_function(cl_func_name, builder->getVoidTy(), func_arg_types, false);
+			llvm::CallInst* write_call = builder->CreateCall(write_func, func_args);
+			write_call->setDebugLoc(I.getDebugLoc()); // keep debug loc
+			write_call->setCallingConv(CallingConv::SPIR_FUNC);
+			
+			//
+			I.replaceAllUsesWith(write_call);
+			I.eraseFromParent();
+			
+		}
+		
+	};
+}
+
+char SPIRImage::ID = 0;
+INITIALIZE_PASS_BEGIN(SPIRImage, "SPIRImage", "SPIRImage Pass", false, false)
+INITIALIZE_PASS_END(SPIRImage, "SPIRImage", "SPIRImage Pass", false, false)
+
+FunctionPass *llvm::createSPIRImagePass(const uint32_t image_capabilities) {
+	return new SPIRImage(image_capabilities);
+}
diff --git a/lib/Transforms/Scalar/Scalar.cpp b/lib/Transforms/Scalar/Scalar.cpp
index de724d4..e119f54 100644
--- a/lib/Transforms/Scalar/Scalar.cpp
+++ b/lib/Transforms/Scalar/Scalar.cpp
@@ -73,6 +73,38 @@ void LLVMInitializeScalarOpts(LLVMPassRegistryRef R) {
   initializeScalarOpts(*unwrap(R));
 }
 
+void LLVMAddAddressSpaceFixPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createAddressSpaceFixPass());
+}
+
+void LLVMAddCUDAImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createCUDAImagePass());
+}
+
+void LLVMAddCUDAFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createCUDAFinalPass());
+}
+
+void LLVMAddMetalFirstPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalFirstPass());
+}
+
+void LLVMAddMetalFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalFinalPass());
+}
+
+void LLVMAddMetalImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createMetalImagePass());
+}
+
+void LLVMAddSPIRFinalPass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createSPIRFinalPass());
+}
+
+void LLVMAddSPIRImagePass(LLVMPassManagerRef PM) {
+  unwrap(PM)->add(createSPIRImagePass());
+}
+
 void LLVMAddAggressiveDCEPass(LLVMPassManagerRef PM) {
   unwrap(PM)->add(createAggressiveDCEPass());
 }
diff --git a/tools/clang/include/clang-c/Index.h b/tools/clang/include/clang-c/Index.h
index f69f567..4fffcdb 100644
--- a/tools/clang/include/clang-c/Index.h
+++ b/tools/clang/include/clang-c/Index.h
@@ -2226,7 +2226,7 @@ enum CXCursorKind {
   CXCursor_NoDuplicateAttr               = 411,
   CXCursor_CUDAConstantAttr              = 412,
   CXCursor_CUDADeviceAttr                = 413,
-  CXCursor_CUDAGlobalAttr                = 414,
+  CXCursor_ComputeKernelAttr             = 414,
   CXCursor_CUDAHostAttr                  = 415,
   CXCursor_LastAttr                      = CXCursor_CUDAHostAttr,
 
@@ -2822,6 +2822,9 @@ enum CXCallingConv {
   CXCallingConv_IntelOclBicc = 9,
   CXCallingConv_X86_64Win64 = 10,
   CXCallingConv_X86_64SysV = 11,
+  // 12 is CXCallingConv_X86VectorCall in later clang/llvm
+  CXCallingConv_SpirFunction = 13,
+  CXCallingConv_SpirKernel = 14,
 
   CXCallingConv_Invalid = 100,
   CXCallingConv_Unexposed = 200
diff --git a/tools/clang/include/clang/AST/ASTContext.h b/tools/clang/include/clang/AST/ASTContext.h
index 8134f6b..bfcd916 100644
--- a/tools/clang/include/clang/AST/ASTContext.h
+++ b/tools/clang/include/clang/AST/ASTContext.h
@@ -789,7 +789,8 @@ public:
   CanQualType ObjCBuiltinIdTy, ObjCBuiltinClassTy, ObjCBuiltinSelTy;
   CanQualType ObjCBuiltinBoolTy;
   CanQualType OCLImage1dTy, OCLImage1dArrayTy, OCLImage1dBufferTy;
-  CanQualType OCLImage2dTy, OCLImage2dArrayTy;
+  CanQualType OCLImage2dTy, OCLImage2dArrayTy, OCLImage2dDepthTy, OCLImage2dArrayDepthTy, OCLImage2dMSAATy, OCLImage2dArrayMSAATy, OCLImage2dMSAADepthTy, OCLImage2dArrayMSAADepthTy;
+  CanQualType OCLImageCubeTy, OCLImageCubeArrayTy, OCLImageCubeDepthTy, OCLImageCubeArrayDepthTy;
   CanQualType OCLImage3dTy;
   CanQualType OCLSamplerTy, OCLEventTy;
 
diff --git a/tools/clang/include/clang/AST/BuiltinTypes.def b/tools/clang/include/clang/AST/BuiltinTypes.def
index 488cace..a815eae 100644
--- a/tools/clang/include/clang/AST/BuiltinTypes.def
+++ b/tools/clang/include/clang/AST/BuiltinTypes.def
@@ -160,6 +160,16 @@ BUILTIN_TYPE(OCLImage1dArray, OCLImage1dArrayTy)
 BUILTIN_TYPE(OCLImage1dBuffer, OCLImage1dBufferTy)
 BUILTIN_TYPE(OCLImage2d, OCLImage2dTy)
 BUILTIN_TYPE(OCLImage2dArray, OCLImage2dArrayTy)
+BUILTIN_TYPE(OCLImage2dDepth, OCLImage2dDepthTy)
+BUILTIN_TYPE(OCLImage2dArrayDepth, OCLImage2dArrayDepthTy)
+BUILTIN_TYPE(OCLImage2dMSAA, OCLImage2dMSAATy)
+BUILTIN_TYPE(OCLImage2dArrayMSAA, OCLImage2dArrayMSAATy)
+BUILTIN_TYPE(OCLImage2dMSAADepth, OCLImage2dMSAADepthTy)
+BUILTIN_TYPE(OCLImage2dArrayMSAADepth, OCLImage2dArrayMSAADepthTy)
+BUILTIN_TYPE(OCLImageCube, OCLImageCubeTy)
+BUILTIN_TYPE(OCLImageCubeArray, OCLImageCubeArrayTy)
+BUILTIN_TYPE(OCLImageCubeDepth, OCLImageCubeDepthTy)
+BUILTIN_TYPE(OCLImageCubeArrayDepth, OCLImageCubeArrayDepthTy)
 BUILTIN_TYPE(OCLImage3d, OCLImage3dTy)
 
 // OpenCL sampler_t.
diff --git a/tools/clang/include/clang/AST/Mangle.h b/tools/clang/include/clang/AST/Mangle.h
index a8d1199..41139fc 100644
--- a/tools/clang/include/clang/AST/Mangle.h
+++ b/tools/clang/include/clang/AST/Mangle.h
@@ -138,6 +138,9 @@ public:
   /// across translation units so it can be used with LTO.
   virtual void mangleTypeName(QualType T, raw_ostream &) = 0;
 
+  virtual void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) {}
+  virtual void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) {}
+
   /// @}
 };
 
diff --git a/tools/clang/include/clang/AST/Type.h b/tools/clang/include/clang/AST/Type.h
index 09862e4..eed14f2 100644
--- a/tools/clang/include/clang/AST/Type.h
+++ b/tools/clang/include/clang/AST/Type.h
@@ -403,10 +403,10 @@ public:
   /// \brief Determines if these qualifiers compatibly include another set.
   /// Generally this answers the question of whether an object with the other
   /// qualifiers can be safely used as an object with these qualifiers.
-  bool compatiblyIncludes(Qualifiers other) const {
+  bool compatiblyIncludes(Qualifiers other, bool check_as = true) const {
     return
       // Address spaces must match exactly.
-      getAddressSpace() == other.getAddressSpace() &&
+      ((check_as && getAddressSpace() == other.getAddressSpace()) || !check_as) &&
       // ObjC GC qualifiers can match, be added, or be removed, but can't be
       // changed.
       (getObjCGCAttr() == other.getObjCGCAttr() ||
@@ -1575,10 +1575,22 @@ public:
   bool isImage1dBufferT() const;                // OpenCL image1d_buffer_t
   bool isImage2dT() const;                      // OpenCL image2d_t
   bool isImage2dArrayT() const;                 // OpenCL image2d_array_t
+  bool isImage2dDepthT() const;                 // OpenCL image2d_depth_t
+  bool isImage2dArrayDepthT() const;            // OpenCL image2d_array_depth_t
+  bool isImage2dMSAAT() const;                  // OpenCL image2d_msaa_t
+  bool isImage2dArrayMSAAT() const;             // OpenCL image2d_array_msaa_t
+  bool isImage2dMSAADepthT() const;             // OpenCL image2d_msaa_depth_t
+  bool isImage2dArrayMSAADepthT() const;        // OpenCL image2d_array_msaa_depth_t
+  bool isImageCubeT() const;                    // (not) OpenCL imagecube_t
+  bool isImageCubeArrayT() const;               // (not) OpenCL imagecube_array_t
+  bool isImageCubeDepthT() const;               // (not) OpenCL imagecube_depth_t
+  bool isImageCubeArrayDepthT() const;          // (not) OpenCL imagecube_array_depth_t
   bool isImage3dT() const;                      // OpenCL image3d_t
 
   bool isImageType() const;                     // Any OpenCL image type
 
+  bool isAggregateImageType() const;            // struct/class containing only image*_t members
+
   bool isSamplerT() const;                      // OpenCL sampler_t
   bool isEventT() const;                        // OpenCL event_t
 
@@ -4803,7 +4815,7 @@ inline FunctionType::ExtInfo getFunctionExtInfo(QualType t) {
 inline bool QualType::isMoreQualifiedThan(QualType other) const {
   Qualifiers myQuals = getQualifiers();
   Qualifiers otherQuals = other.getQualifiers();
-  return (myQuals != otherQuals && myQuals.compatiblyIncludes(otherQuals));
+  return (myQuals != otherQuals && myQuals.compatiblyIncludes(otherQuals, false));
 }
 
 /// isAtLeastAsQualifiedAs - Determine whether this type is at last
@@ -4811,7 +4823,7 @@ inline bool QualType::isMoreQualifiedThan(QualType other) const {
 /// int" is at least as qualified as "const int", "volatile int",
 /// "int", and "const volatile int".
 inline bool QualType::isAtLeastAsQualifiedAs(QualType other) const {
-  return getQualifiers().compatiblyIncludes(other.getQualifiers());
+  return getQualifiers().compatiblyIncludes(other.getQualifiers(), false);
 }
 
 /// getNonReferenceType - If Type is a reference type (e.g., const
@@ -5008,6 +5020,46 @@ inline bool Type::isImage2dArrayT() const {
   return isSpecificBuiltinType(BuiltinType::OCLImage2dArray);
 }
 
+inline bool Type::isImage2dDepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dDepth);
+}
+
+inline bool Type::isImage2dArrayDepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dArrayDepth);
+}
+
+inline bool Type::isImage2dMSAAT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dMSAA);
+}
+
+inline bool Type::isImage2dArrayMSAAT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dArrayMSAA);
+}
+
+inline bool Type::isImage2dMSAADepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dMSAADepth);
+}
+
+inline bool Type::isImage2dArrayMSAADepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImage2dArrayMSAADepth);
+}
+
+inline bool Type::isImageCubeT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImageCube);
+}
+
+inline bool Type::isImageCubeArrayT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImageCubeArray);
+}
+
+inline bool Type::isImageCubeDepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImageCubeDepth);
+}
+
+inline bool Type::isImageCubeArrayDepthT() const {
+  return isSpecificBuiltinType(BuiltinType::OCLImageCubeArrayDepth);
+}
+
 inline bool Type::isImage3dT() const {
   return isSpecificBuiltinType(BuiltinType::OCLImage3d);
 }
@@ -5023,11 +5075,16 @@ inline bool Type::isEventT() const {
 inline bool Type::isImageType() const {
   return isImage3dT() ||
          isImage2dT() || isImage2dArrayT() ||
+         isImage2dDepthT() || isImage2dArrayDepthT() ||
+         isImage2dMSAAT() || isImage2dArrayMSAAT() ||
+         isImage2dMSAADepthT() || isImage2dArrayMSAADepthT() ||
+         isImageCubeT() || isImageCubeArrayT() ||
+         isImageCubeDepthT() || isImageCubeArrayDepthT() ||
          isImage1dT() || isImage1dArrayT() || isImage1dBufferT();
 }
 
 inline bool Type::isOpenCLSpecificType() const {
-  return isSamplerT() || isEventT() || isImageType();
+  return isSamplerT() || isEventT() || isImageType() || isAggregateImageType();
 }
 
 inline bool Type::isTemplateTypeParmType() const {
diff --git a/tools/clang/include/clang/Basic/Attr.td b/tools/clang/include/clang/Basic/Attr.td
index 704a375..1348b67 100644
--- a/tools/clang/include/clang/Basic/Attr.td
+++ b/tools/clang/include/clang/Basic/Attr.td
@@ -354,6 +354,25 @@ def Aligned : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
+def AlignValue : Attr {
+  let Spellings = [
+    // Unfortunately, this is semantically an assertion, not a
+    // directive (something else must ensure the alignment), so
+    // aligned_value is a probably a better name. We might want
+    // to add an aligned_value spelling in the future (and a
+    // corresponding C++ attribute), but this can be done later
+    // once we decide if we also want them to have
+    // slightly-different semantics than Intel's align_value.
+    GNU<"align_value">
+    // Intel's compiler on Windows also supports:
+    // , Declspec<"align_value">
+  ];
+  let Args = [ExprArgument<"Alignment">];
+  let Subjects = SubjectList<[Var, TypedefName], WarnDiag,
+                             "ExpectedVariableOrTypedef">;
+  let Documentation = [AlignValueDocs];
+}
+
 def AlignMac68k : InheritableAttr {
   // This attribute has no spellings as it is only ever created implicitly.
   let Spellings = [];
@@ -513,13 +532,6 @@ def Constructor : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAConstant : InheritableAttr {
-  let Spellings = [GNU<"constant">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDADevice : InheritableAttr {
   let Spellings = [GNU<"device">];
   let Subjects = SubjectList<[Function, Var]>;
@@ -527,13 +539,6 @@ def CUDADevice : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAGlobal : InheritableAttr {
-  let Spellings = [GNU<"global">];
-  let Subjects = SubjectList<[Function]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def CUDAHost : InheritableAttr {
   let Spellings = [GNU<"host">];
   let Subjects = SubjectList<[Function]>;
@@ -553,13 +558,6 @@ def CUDALaunchBounds : InheritableAttr {
   let Documentation = [Undocumented];
 }
 
-def CUDAShared : InheritableAttr {
-  let Spellings = [GNU<"shared">];
-  let Subjects = SubjectList<[Var]>;
-  let LangOpts = [CUDA];
-  let Documentation = [Undocumented];
-}
-
 def C11NoReturn : InheritableAttr {
   let Spellings = [Keyword<"_Noreturn">];
   let Subjects = SubjectList<[Function], ErrorDiag>;
@@ -573,45 +571,129 @@ def CXX11NoReturn : InheritableAttr {
   let Documentation = [CXX11NoReturnDocs];
 }
 
-def OpenCLKernel : InheritableAttr {
-  let Spellings = [Keyword<"__kernel">, Keyword<"kernel">];
+def ComputeKernel : InheritableAttr {
+  let Spellings = [GNU<"compute_kernel">, CXX11<"","compute_kernel">];
+  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def GraphicsVertexShader : InheritableAttr {
+  let Spellings = [GNU<"vertex_shader">, CXX11<"","vertex_shader">];
+  let Subjects = SubjectList<[Function], ErrorDiag>;
+  let Documentation = [Undocumented];
+}
+
+def GraphicsFragmentShader : InheritableAttr {
+  let Spellings = [GNU<"fragment_shader">, CXX11<"","fragment_shader">];
   let Subjects = SubjectList<[Function], ErrorDiag>;
   let Documentation = [Undocumented];
 }
 
 // This attribute is both a type attribute, and a declaration attribute (for
 // parameter variables).
-def OpenCLImageAccess : Attr {
-  let Spellings = [Keyword<"__read_only">, Keyword<"read_only">,
-                   Keyword<"__write_only">, Keyword<"write_only">,
-                   Keyword<"__read_write">, Keyword<"read_write">];
-  let Subjects = SubjectList<[ParmVar], ErrorDiag>;
-  let Accessors = [Accessor<"isReadOnly", [Keyword<"__read_only">,
-                                           Keyword<"read_only">]>,
-                   Accessor<"isReadWrite", [Keyword<"__read_write">,
-                                            Keyword<"read_write">]>,
-                   Accessor<"isWriteOnly", [Keyword<"__write_only">,
-                                            Keyword<"write_only">]>];
+def ImageAccess : Attr {
+  let Spellings = [GNU<"image_read_only">, CXX11<"","image_read_only">,
+                   GNU<"image_write_only">, CXX11<"","image_write_only">,
+                   GNU<"image_read_write">, CXX11<"","image_read_write">];
+  let Accessors = [Accessor<"isReadOnly", [GNU<"image_read_only">,
+										   CXX11<"","image_read_only">]>,
+                   Accessor<"isReadWrite", [GNU<"image_read_write">,
+											CXX11<"","image_read_write">]>,
+                   Accessor<"isWriteOnly", [GNU<"image_write_only">,
+											CXX11<"","image_write_only">]>];
+  let Documentation = [Undocumented];
+}
+
+def PrivateAddressSpace : TypeAttr {
+  let Spellings = [GNU<"private_as">, CXX11<"","private_as">];
+  let Documentation = [Undocumented];
+}
+
+def GlobalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"global_as">, CXX11<"","global_as">];
   let Documentation = [Undocumented];
 }
 
-def OpenCLPrivateAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__private">, Keyword<"private">];
+def LocalAddressSpace : TypeAttr {
+  let Spellings = [GNU<"local_as">, CXX11<"","local_as">];
   let Documentation = [Undocumented];
 }
 
-def OpenCLGlobalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__global">, Keyword<"global">];
+def ConstantAddressSpace : TypeAttr {
+  let Spellings = [GNU<"constant_as">, CXX11<"","constant_as">];
   let Documentation = [Undocumented];
 }
 
-def OpenCLLocalAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__local">, Keyword<"local">];
+// CUDA address space attrs are not type attrs, so they need to be handled specially
+def CUDAShared : InheritableAttr {
+  let Spellings = [GNU<"local_cuda">, CXX11<"","local_cuda">];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def CUDAConstant : InheritableAttr {
+  let Spellings = [GNU<"constant_cuda">, CXX11<"","constant_cuda">];
+  let Subjects = SubjectList<[Var]>;
+  let LangOpts = [CUDA];
+  let Documentation = [Undocumented];
+}
+
+def FloorImageDataType : InheritableAttr {
+  let Spellings = [GNU<"floor_image">, CXX11<"","floor_image">];
+  let Args = [TypeArgument<"ImageDataType">];
+  let TemplateDependent = 1;
+  let Documentation = [Undocumented];
+}
+
+// on aggregate types this signals that they can be converted/coerced to the corresponding clang/llvm vector type
+def VectorCompat : InheritableAttr {
+  let Spellings = [GNU<"vector_compat">, CXX11<"","vector_compat">];
+  let Documentation = [Undocumented];
+}
+
+// fbo color output location
+def GraphicsFBOColorLocation : InheritableAttr {
+  let Spellings = [GNU<"color">, CXX11<"","color">];
+  let Args = [ExprArgument<"ColorLocation">];
+  let TemplateDependent = 1;
+  let AdditionalMembers = [{
+  unsigned int eval_location = 0;
+  unsigned int getEvalLocation() const {
+    return eval_location;
+  }
+  void setEvalLocation(unsigned int loc) {
+    eval_location = loc;
+  }
+  }];
   let Documentation = [Undocumented];
 }
 
-def OpenCLConstantAddressSpace : TypeAttr {
-  let Spellings = [Keyword<"__constant">, Keyword<"constant">];
+// fbo explicit writable depth with depth type
+def GraphicsFBODepthType : InheritableAttr {
+  let Spellings = [GNU<"depth">, CXX11<"","depth">];
+  let Args = [EnumArgument<"DepthQualifier", "DepthQualifierType",
+                           ["any", "greater", "less"],
+                           ["FBODepthTypeAny", "FBODepthTypeGreater", "FBODepthTypeLess"]>];
+  let Documentation = [Undocumented];
+}
+
+// vertex output position (used in vertex output structs)
+def GraphicsVertexPosition : InheritableAttr {
+  let Spellings = [GNU<"position">, CXX11<"","position">];
+  let Documentation = [Undocumented];
+}
+
+// vertex/point output size (used in vertex output structs)
+def GraphicsPointSize : InheritableAttr {
+  let Spellings = [GNU<"point_size">, CXX11<"","point_size">];
+  let Documentation = [Undocumented];
+}
+
+// stage input (just fragment shader input right now)
+def GraphicsStageInput : Attr {
+  let Spellings = [GNU<"stage_input">, CXX11<"","stage_input">];
+  let Subjects = SubjectList<[ParmVar], ErrorDiag>;
   let Documentation = [Undocumented];
 }
 
diff --git a/tools/clang/include/clang/Basic/AttrDocs.td b/tools/clang/include/clang/Basic/AttrDocs.td
index e6d6a33..3e7bdc1 100644
--- a/tools/clang/include/clang/Basic/AttrDocs.td
+++ b/tools/clang/include/clang/Basic/AttrDocs.td
@@ -987,6 +987,26 @@ Clang implements two kinds of checks with this attribute.
   }];
 }
 
+def AlignValueDocs : Documentation {
+  let Category = DocCatType;
+  let Content = [{
+The align_value attribute can be added to the typedef of a pointer type or the
+declaration of a variable of pointer or reference type. It specifies that the
+pointer will point to, or the reference will bind to, only objects with at
+least the provided alignment. This alignment value must be some positive power
+of 2.
+
+   .. code-block:: c
+
+     typedef double * aligned_double_ptr __attribute__((align_value(64)));
+     void foo(double & x  __attribute__((align_value(128)),
+              aligned_double_ptr y) { ... }
+
+If the pointer value does not have the specified alignment at runtime, the
+behavior of the program is undefined.
+  }];
+}
+
 def MSInheritanceDocs : Documentation {
   let Category = DocCatType;
   let Heading = "__single_inhertiance, __multiple_inheritance, __virtual_inheritance";
diff --git a/tools/clang/include/clang/Basic/Builtins.def b/tools/clang/include/clang/Basic/Builtins.def
index e705382..1137d0c 100644
--- a/tools/clang/include/clang/Basic/Builtins.def
+++ b/tools/clang/include/clang/Basic/Builtins.def
@@ -117,9 +117,11 @@ BUILTIN(__builtin_frexpl, "LdLdi*", "Fn")
 BUILTIN(__builtin_huge_val, "d", "nc")
 BUILTIN(__builtin_huge_valf, "f", "nc")
 BUILTIN(__builtin_huge_vall, "Ld", "nc")
+BUILTIN(__builtin_huge_valh, "h", "nc")
 BUILTIN(__builtin_inf  , "d"   , "nc")
 BUILTIN(__builtin_inff , "f"   , "nc")
 BUILTIN(__builtin_infl , "Ld"  , "nc")
+BUILTIN(__builtin_infh , "h"   , "nc")
 BUILTIN(__builtin_labs , "LiLi"  , "Fnc")
 BUILTIN(__builtin_llabs, "LLiLLi", "Fnc")
 BUILTIN(__builtin_ldexp , "ddi"  , "Fnc")
@@ -131,9 +133,11 @@ BUILTIN(__builtin_modfl, "LdLdLd*", "Fn")
 BUILTIN(__builtin_nan,  "dcC*" , "ncF")
 BUILTIN(__builtin_nanf, "fcC*" , "ncF")
 BUILTIN(__builtin_nanl, "LdcC*", "ncF")
+BUILTIN(__builtin_nanh, "hcC*" , "ncF")
 BUILTIN(__builtin_nans,  "dcC*" , "ncF")
 BUILTIN(__builtin_nansf, "fcC*" , "ncF")
 BUILTIN(__builtin_nansl, "LdcC*", "ncF")
+BUILTIN(__builtin_nansh, "hcC*" , "ncF")
 BUILTIN(__builtin_powi , "ddi"  , "Fnc")
 BUILTIN(__builtin_powif, "ffi"  , "Fnc")
 BUILTIN(__builtin_powil, "LdLdi", "Fnc")
diff --git a/tools/clang/include/clang/Basic/DiagnosticSemaKinds.td b/tools/clang/include/clang/Basic/DiagnosticSemaKinds.td
index 1665a45..3778e80 100644
--- a/tools/clang/include/clang/Basic/DiagnosticSemaKinds.td
+++ b/tools/clang/include/clang/Basic/DiagnosticSemaKinds.td
@@ -1897,8 +1897,12 @@ def err_attribute_bad_neon_vector_size : Error<
   "Neon vector size must be 64 or 128 bits">;
 def err_attribute_unsupported : Error<
   "%0 attribute is not supported for this target">;
+// The err_*_attribute_argument_not_int are seperate because they're used by
+// VerifyIntegerConstantExpression.
 def err_aligned_attribute_argument_not_int : Error<
   "'aligned' attribute requires integer constant">;
+def err_align_value_attribute_argument_not_int : Error<
+  "'align_value' attribute requires integer constant">;
 def err_alignas_attribute_wrong_decl_type : Error<
   "%0 attribute cannot be applied to a %select{function parameter|"
   "variable with 'register' storage class|'catch' variable|bit-field}1">;
@@ -1934,6 +1938,9 @@ def err_attribute_pointers_only : Error<warn_attribute_pointers_only.Text>;
 def warn_attribute_return_pointers_only : Warning<
   "%0 attribute only applies to return values that are pointers">,
   InGroup<IgnoredAttributes>;
+def warn_attribute_pointer_or_reference_only : Warning<
+  "%0 attribute only applies to a pointer or reference (%1 is invalid)">,
+  InGroup<IgnoredAttributes>;
 def err_attribute_no_member_pointers : Error<
   "%0 attribute cannot be used with pointers to members">;
 def err_attribute_invalid_implicit_this_argument : Error<
@@ -2054,6 +2061,9 @@ def err_no_accessor_for_property : Error<
 def error_cannot_find_suitable_accessor : Error<
   "cannot find suitable %select{getter|setter}0 for property %1">;
 
+def err_alignment_not_power_of_two : Error<
+  "requested alignment is not a power of 2">;
+
 def err_attribute_aligned_not_power_of_two : Error<
   "requested alignment is not a power of 2">;
 def err_attribute_aligned_too_great : Error<
@@ -2166,7 +2176,7 @@ def warn_attribute_wrong_decl_type : Warning<
   "functions, methods and blocks|functions, methods, and classes|"
   "functions, methods, and parameters|classes|variables|methods|"
   "variables, functions and labels|fields and global variables|structs|"
-  "variables, functions and tag types|thread-local variables|"
+  "variables and typedefs|thread-local variables|"
   "variables and fields|variables, data members and tag types|"
   "types and namespaces|Objective-C interfaces|methods and properties|"
   "struct or union|struct, union or class|types|"
diff --git a/tools/clang/include/clang/Basic/LangOptions.def b/tools/clang/include/clang/Basic/LangOptions.def
index a297a4c..5085091 100644
--- a/tools/clang/include/clang/Basic/LangOptions.def
+++ b/tools/clang/include/clang/Basic/LangOptions.def
@@ -124,6 +124,7 @@ ENUM_LANGOPT(MSPointerToMemberRepresentationMethod, PragmaMSPointersToMembersKin
 LANGOPT(ShortEnums        , 1, 0, "short enum types")
 
 LANGOPT(OpenCL            , 1, 0, "OpenCL")
+LANGOPT(Metal             , 1, 0, "Metal")
 LANGOPT(OpenCLVersion     , 32, 0, "OpenCL version")
 LANGOPT(NativeHalfType    , 1, 0, "Native half type support")
 LANGOPT(CUDA              , 1, 0, "CUDA")
diff --git a/tools/clang/include/clang/Basic/LangOptions.h b/tools/clang/include/clang/Basic/LangOptions.h
index 9bffc7c..470cf81 100644
--- a/tools/clang/include/clang/Basic/LangOptions.h
+++ b/tools/clang/include/clang/Basic/LangOptions.h
@@ -20,6 +20,7 @@
 #include "clang/Basic/ObjCRuntime.h"
 #include "clang/Basic/Visibility.h"
 #include <string>
+#include <array>
 
 namespace clang {
 
@@ -74,6 +75,8 @@ public:
 
   enum AddrSpaceMapMangling { ASMM_Target, ASMM_On, ASMM_Off };
 
+  unsigned int floor_image_capabilities { 0 };
+
 public:
   clang::ObjCRuntime ObjCRuntime;
 
diff --git a/tools/clang/include/clang/Basic/Specifiers.h b/tools/clang/include/clang/Basic/Specifiers.h
index f895673..78084dc 100644
--- a/tools/clang/include/clang/Basic/Specifiers.h
+++ b/tools/clang/include/clang/Basic/Specifiers.h
@@ -209,7 +209,9 @@ namespace clang {
     CC_AAPCS,       // __attribute__((pcs("aapcs")))
     CC_AAPCS_VFP,   // __attribute__((pcs("aapcs-vfp")))
     CC_PnaclCall,   // __attribute__((pnaclcall))
-    CC_IntelOclBicc // __attribute__((intel_ocl_bicc))
+    CC_IntelOclBicc,// __attribute__((intel_ocl_bicc))
+    CC_SpirFunction,// default for OpenCL functions on SPIR target
+    CC_SpirKernel   // inferred for OpenCL kernels on SPIR target
   };
 
   /// \brief Checks whether the given calling convention is callee-cleanup.
@@ -219,6 +221,8 @@ namespace clang {
     case CC_X86FastCall:
     case CC_X86ThisCall:
     case CC_X86Pascal:
+    case CC_SpirFunction:
+    case CC_SpirKernel:
       return true;
     default:
       return false;
diff --git a/tools/clang/include/clang/Basic/TokenKinds.def b/tools/clang/include/clang/Basic/TokenKinds.def
index 5d08833..c53d8b2 100644
--- a/tools/clang/include/clang/Basic/TokenKinds.def
+++ b/tools/clang/include/clang/Basic/TokenKinds.def
@@ -460,28 +460,9 @@ KEYWORD(__thiscall                  , KEYALL)
 KEYWORD(__forceinline               , KEYMS)
 KEYWORD(__unaligned                 , KEYMS)
 
-// OpenCL address space qualifiers
-KEYWORD(__global                    , KEYOPENCL)
-KEYWORD(__local                     , KEYOPENCL)
-KEYWORD(__constant                  , KEYOPENCL)
-KEYWORD(__private                   , KEYOPENCL)
-ALIAS("global", __global            , KEYOPENCL)
-ALIAS("local", __local              , KEYOPENCL)
-ALIAS("constant", __constant        , KEYOPENCL)
-ALIAS("private", __private          , KEYOPENCL)
-// OpenCL function qualifiers
-KEYWORD(__kernel                    , KEYOPENCL)
-ALIAS("kernel", __kernel            , KEYOPENCL)
-// OpenCL access qualifiers
-KEYWORD(__read_only                 , KEYOPENCL)
-KEYWORD(__write_only                , KEYOPENCL)
-KEYWORD(__read_write                , KEYOPENCL)
-ALIAS("read_only", __read_only      , KEYOPENCL)
-ALIAS("write_only", __write_only    , KEYOPENCL)
-ALIAS("read_write", __read_write    , KEYOPENCL)
 // OpenCL builtins
-KEYWORD(__builtin_astype            , KEYOPENCL)
-KEYWORD(vec_step                    , KEYOPENCL|KEYALTIVEC)
+KEYWORD(__builtin_astype            , KEYCXX|KEYOPENCL)
+KEYWORD(vec_step                    , KEYCXX|KEYOPENCL|KEYALTIVEC)
 
 // Borland Extensions.
 KEYWORD(__pascal                    , KEYALL)
diff --git a/tools/clang/include/clang/Driver/CC1Options.td b/tools/clang/include/clang/Driver/CC1Options.td
index d25560c..17d9a7a 100644
--- a/tools/clang/include/clang/Driver/CC1Options.td
+++ b/tools/clang/include/clang/Driver/CC1Options.td
@@ -550,6 +550,13 @@ def detailed_preprocessing_record : Flag<["-"], "detailed-preprocessing-record">
   HelpText<"include a detailed record of preprocessing actions">;
 
 //===----------------------------------------------------------------------===//
+// libfloor Options (applying to OpenCL, CUDA and Metal)
+//===----------------------------------------------------------------------===//
+
+def floor_image_capabilities : Joined<["-"], "floor-image-capabilities=">,
+  HelpText<"image read and write capabilities">;
+
+//===----------------------------------------------------------------------===//
 // OpenCL Options
 //===----------------------------------------------------------------------===//
 
@@ -577,6 +584,19 @@ def cl_std_EQ : Joined<["-"], "cl-std=">,
 def fcuda_is_device : Flag<["-"], "fcuda-is-device">,
   HelpText<"Generate code for CUDA device">;
 
+//===----------------------------------------------------------------------===//
+// AIR/Metal Options
+//===----------------------------------------------------------------------===//
+
+def metal_intel_workarounds : Flag<["-"], "metal-intel-workarounds">,
+  HelpText<"Enable Intel GPU specific fixes and workarounds">;
+
+//===----------------------------------------------------------------------===//
+// AppleCL/OpenCL Options
+//===----------------------------------------------------------------------===//
+def applecl_kernel_info : Flag<["-"], "applecl-kernel-info">,
+  HelpText<"AppleCL/OpenCL only. Generate general AppleCL and kernel argument metadata.">;
+
 } // let Flags = [CC1Option]
 
 
diff --git a/tools/clang/include/clang/Driver/Types.def b/tools/clang/include/clang/Driver/Types.def
index 3209679..2df0e4b 100644
--- a/tools/clang/include/clang/Driver/Types.def
+++ b/tools/clang/include/clang/Driver/Types.def
@@ -42,6 +42,7 @@
 TYPE("cpp-output",               PP_C,         INVALID,         "i",     "u")
 TYPE("c",                        C,            PP_C,            "c",     "u")
 TYPE("cl",                       CL,           PP_C,            "cl",    "u")
+TYPE("metal",                    METAL,        PP_CXX,          "cpp",   "u")
 TYPE("cuda",                     CUDA,         PP_CXX,          "cpp",   "u")
 TYPE("objective-c-cpp-output",   PP_ObjC,      INVALID,         "mi",    "u")
 TYPE("objc-cpp-output",          PP_ObjC_Alias, INVALID,        "mi",    "u")
@@ -56,6 +57,7 @@ TYPE("objective-c++",            ObjCXX,       PP_ObjCXX,       "mm",    "u")
 TYPE("c-header-cpp-output",      PP_CHeader,   INVALID,         "i",     "p")
 TYPE("c-header",                 CHeader,      PP_CHeader,      nullptr, "pu")
 TYPE("cl-header",                CLHeader,     PP_CHeader,      nullptr, "pu")
+TYPE("metal-header",             MetalHeader,  PP_CXXHeader,    nullptr, "pu")
 TYPE("objective-c-header-cpp-output", PP_ObjCHeader, INVALID,   "mi",    "p")
 TYPE("objective-c-header",       ObjCHeader,   PP_ObjCHeader,   nullptr, "pu")
 TYPE("c++-header-cpp-output",    PP_CXXHeader, INVALID,         "ii",    "p")
diff --git a/tools/clang/include/clang/Frontend/CodeGenOptions.def b/tools/clang/include/clang/Frontend/CodeGenOptions.def
index 1d92efe..3db3307 100644
--- a/tools/clang/include/clang/Frontend/CodeGenOptions.def
+++ b/tools/clang/include/clang/Frontend/CodeGenOptions.def
@@ -56,6 +56,8 @@ CODEGENOPT(EmitDeclMetadata  , 1, 0) ///< Emit special metadata indicating what
 CODEGENOPT(EmitGcovArcs      , 1, 0) ///< Emit coverage data files, aka. GCDA.
 CODEGENOPT(EmitGcovNotes     , 1, 0) ///< Emit coverage "notes" files, aka GCNO.
 CODEGENOPT(EmitOpenCLArgMetadata , 1, 0) ///< Emit OpenCL kernel arg metadata.
+CODEGENOPT(EmitAppleCLMetadata , 1, 0) ///< Emit AppleCL kernel info and arg metadata.
+CODEGENOPT(MetalIntelWorkarounds , 1, 0) ///< Enable Intel GPU specific fixes and workarounds.
 /// \brief FP_CONTRACT mode (on/off/fast).
 ENUM_CODEGENOPT(FPContractMode, FPContractModeKind, 2, FPC_On)
 CODEGENOPT(ForbidGuardVariables , 1, 0) ///< Issue errors if C++ guard variables
diff --git a/tools/clang/include/clang/Frontend/FrontendOptions.h b/tools/clang/include/clang/Frontend/FrontendOptions.h
index e87da8d..2efddfb 100644
--- a/tools/clang/include/clang/Frontend/FrontendOptions.h
+++ b/tools/clang/include/clang/Frontend/FrontendOptions.h
@@ -70,6 +70,7 @@ enum InputKind {
   IK_PreprocessedObjC,
   IK_PreprocessedObjCXX,
   IK_OpenCL,
+  IK_Metal,
   IK_CUDA,
   IK_AST,
   IK_LLVM_IR
diff --git a/tools/clang/include/clang/Frontend/LangStandards.def b/tools/clang/include/clang/Frontend/LangStandards.def
index 90a27b5..ef31cc5 100644
--- a/tools/clang/include/clang/Frontend/LangStandards.def
+++ b/tools/clang/include/clang/Frontend/LangStandards.def
@@ -134,17 +134,27 @@ LANGSTANDARD(gnucxx1z, "gnu++1z",
 // OpenCL
 LANGSTANDARD(opencl, "cl",
              "OpenCL 1.0",
-             LineComment | C99 | Digraphs | HexFloat)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus1y |
+             Digraphs | GNUMode)
 LANGSTANDARD(opencl11, "CL1.1",
              "OpenCL 1.1",
-             LineComment | C99 | Digraphs | HexFloat)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus1y |
+             Digraphs | GNUMode)
 LANGSTANDARD(opencl12, "CL1.2",
              "OpenCL 1.2",
-             LineComment | C99 | Digraphs | HexFloat)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus1y |
+             Digraphs | GNUMode)
+
+// Metal
+LANGSTANDARD(metal11, "metal1.1",
+             "Metal 1.1",
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus1y |
+             Digraphs | GNUMode)
 
 // CUDA
 LANGSTANDARD(cuda, "cuda",
              "NVIDIA CUDA(tm)",
-             LineComment | CPlusPlus | Digraphs)
+             LineComment | CPlusPlus | CPlusPlus11 | CPlusPlus1y |
+             Digraphs | GNUMode)
 
 #undef LANGSTANDARD
diff --git a/tools/clang/include/clang/Sema/AttributeList.h b/tools/clang/include/clang/Sema/AttributeList.h
index c21c19f..a37f138 100644
--- a/tools/clang/include/clang/Sema/AttributeList.h
+++ b/tools/clang/include/clang/Sema/AttributeList.h
@@ -826,7 +826,7 @@ enum AttributeDeclKind {
   ExpectedVariableFunctionOrLabel,
   ExpectedFieldOrGlobalVar,
   ExpectedStruct,
-  ExpectedVariableFunctionOrTag,
+  ExpectedVariableOrTypedef,
   ExpectedTLSVar,
   ExpectedVariableOrField,
   ExpectedVariableFieldOrTag,
diff --git a/tools/clang/include/clang/Sema/Sema.h b/tools/clang/include/clang/Sema/Sema.h
index e254afd..c34d2b3 100644
--- a/tools/clang/include/clang/Sema/Sema.h
+++ b/tools/clang/include/clang/Sema/Sema.h
@@ -7283,6 +7283,15 @@ public:
   void AddAlignedAttr(SourceRange AttrRange, Decl *D, TypeSourceInfo *T,
                       unsigned SpellingListIndex, bool IsPackExpansion);
 
+  /// AddAlignValueAttr - Adds an align_value attribute to a particular
+  /// declaration.
+  void AddAlignValueAttr(SourceRange AttrRange, Decl *D, Expr *E,
+                         unsigned SpellingListIndex);
+
+  /// Adds a color(location) attribute to a particular declaration.
+  void AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E,
+                                       unsigned SpellingListIndex);
+
   // OpenMP directives and clauses.
 private:
   void *VarDataSharingAttributesStack;
diff --git a/tools/clang/include/clang/Serialization/ASTBitCodes.h b/tools/clang/include/clang/Serialization/ASTBitCodes.h
index 7ae1977..a5ced4e 100644
--- a/tools/clang/include/clang/Serialization/ASTBitCodes.h
+++ b/tools/clang/include/clang/Serialization/ASTBitCodes.h
@@ -744,6 +744,17 @@ namespace clang {
       PREDEF_TYPE_IMAGE2D_ID    = 41,
       /// \brief OpenCL 2d image array type.
       PREDEF_TYPE_IMAGE2D_ARR_ID = 42,
+      PREDEF_TYPE_IMAGE2D_DEPTH_ID = 46,
+      PREDEF_TYPE_IMAGE2D_ARR_DEPTH_ID = 47,
+      PREDEF_TYPE_IMAGE2D_MSAA_ID = 48,
+      PREDEF_TYPE_IMAGE2D_ARR_MSAA_ID = 49,
+      PREDEF_TYPE_IMAGE2D_MSAA_DEPTH_ID = 50,
+      PREDEF_TYPE_IMAGE2D_ARR_MSAA_DEPTH_ID = 51,
+      /// \brief not currently supported by OpenCL, but by other backends
+      PREDEF_TYPE_IMAGECUBE_ID = 52,
+      PREDEF_TYPE_IMAGECUBE_ARR_ID = 53,
+      PREDEF_TYPE_IMAGECUBE_DEPTH_ID = 54,
+      PREDEF_TYPE_IMAGECUBE_ARR_DEPTH_ID = 55,
       /// \brief OpenCL 3d image type.
       PREDEF_TYPE_IMAGE3D_ID    = 43,
       /// \brief OpenCL event type.
diff --git a/tools/clang/lib/AST/ASTContext.cpp b/tools/clang/lib/AST/ASTContext.cpp
index bccdae9..80a9618 100644
--- a/tools/clang/lib/AST/ASTContext.cpp
+++ b/tools/clang/lib/AST/ASTContext.cpp
@@ -1030,6 +1030,16 @@ void ASTContext::InitBuiltinTypes(const TargetInfo &Target) {
     InitBuiltinType(OCLImage1dBufferTy, BuiltinType::OCLImage1dBuffer);
     InitBuiltinType(OCLImage2dTy, BuiltinType::OCLImage2d);
     InitBuiltinType(OCLImage2dArrayTy, BuiltinType::OCLImage2dArray);
+    InitBuiltinType(OCLImage2dDepthTy, BuiltinType::OCLImage2dDepth);
+    InitBuiltinType(OCLImage2dArrayDepthTy, BuiltinType::OCLImage2dArrayDepth);
+    InitBuiltinType(OCLImage2dMSAATy, BuiltinType::OCLImage2dMSAA);
+    InitBuiltinType(OCLImage2dArrayMSAATy, BuiltinType::OCLImage2dArrayMSAA);
+    InitBuiltinType(OCLImage2dMSAADepthTy, BuiltinType::OCLImage2dMSAADepth);
+    InitBuiltinType(OCLImage2dArrayMSAADepthTy, BuiltinType::OCLImage2dArrayMSAADepth);
+    InitBuiltinType(OCLImageCubeTy, BuiltinType::OCLImageCube);
+    InitBuiltinType(OCLImageCubeArrayTy, BuiltinType::OCLImageCubeArray);
+    InitBuiltinType(OCLImageCubeDepthTy, BuiltinType::OCLImageCubeDepth);
+    InitBuiltinType(OCLImageCubeArrayDepthTy, BuiltinType::OCLImageCubeArrayDepth);
     InitBuiltinType(OCLImage3dTy, BuiltinType::OCLImage3d);
 
     InitBuiltinType(OCLSamplerTy, BuiltinType::OCLSampler);
@@ -1596,6 +1606,16 @@ ASTContext::getTypeInfoImpl(const Type *T) const {
     case BuiltinType::OCLImage1dBuffer:
     case BuiltinType::OCLImage2d:
     case BuiltinType::OCLImage2dArray:
+    case BuiltinType::OCLImage2dDepth:
+    case BuiltinType::OCLImage2dArrayDepth:
+    case BuiltinType::OCLImage2dMSAA:
+    case BuiltinType::OCLImage2dArrayMSAA:
+    case BuiltinType::OCLImage2dMSAADepth:
+    case BuiltinType::OCLImage2dArrayMSAADepth:
+    case BuiltinType::OCLImageCube:
+    case BuiltinType::OCLImageCubeArray:
+    case BuiltinType::OCLImageCubeDepth:
+    case BuiltinType::OCLImageCubeArrayDepth:
     case BuiltinType::OCLImage3d:
       // Currently these types are pointers to opaque types.
       Width = Target->getPointerWidth(0);
@@ -5154,6 +5174,16 @@ static char getObjCEncodingForPrimitiveKind(const ASTContext *C,
     case BuiltinType::OCLImage1dBuffer:
     case BuiltinType::OCLImage2d:
     case BuiltinType::OCLImage2dArray:
+    case BuiltinType::OCLImage2dDepth:
+    case BuiltinType::OCLImage2dArrayDepth:
+    case BuiltinType::OCLImage2dMSAA:
+    case BuiltinType::OCLImage2dArrayMSAA:
+    case BuiltinType::OCLImage2dMSAADepth:
+    case BuiltinType::OCLImage2dArrayMSAADepth:
+    case BuiltinType::OCLImageCube:
+    case BuiltinType::OCLImageCubeArray:
+    case BuiltinType::OCLImageCubeDepth:
+    case BuiltinType::OCLImageCubeArrayDepth:
     case BuiltinType::OCLImage3d:
     case BuiltinType::OCLEvent:
     case BuiltinType::OCLSampler:
@@ -7973,7 +8003,9 @@ CallingConv ASTContext::getDefaultCallingConvention(bool IsVariadic,
   if (IsCXXMethod)
     return ABI->getDefaultMethodCallConv(IsVariadic);
 
-  return (LangOpts.MRTD && !IsVariadic) ? CC_X86StdCall : CC_C;
+  if (LangOpts.MRTD && !IsVariadic) return CC_X86StdCall;
+
+  return Target->getDefaultCallingConv(TargetInfo::CCMT_Unknown);
 }
 
 bool ASTContext::isNearlyEmpty(const CXXRecordDecl *RD) const {
diff --git a/tools/clang/lib/AST/ExprConstant.cpp b/tools/clang/lib/AST/ExprConstant.cpp
index 7d7ca99..4f4b1a0 100644
--- a/tools/clang/lib/AST/ExprConstant.cpp
+++ b/tools/clang/lib/AST/ExprConstant.cpp
@@ -835,7 +835,8 @@ CallStackFrame::~CallStackFrame() {
 APValue &CallStackFrame::createTemporary(const void *Key,
                                          bool IsLifetimeExtended) {
   APValue &Result = Temporaries[Key];
-  assert(Result.isUninit() && "temporary created multiple times");
+  // TODO: fix this!
+  //assert(Result.isUninit() && "temporary created multiple times");
   Info.CleanupStack.push_back(Cleanup(&Result, IsLifetimeExtended));
   return Result;
 }
@@ -3588,6 +3589,22 @@ static bool CheckConstexprFunction(EvalInfo &Info, SourceLocation CallLoc,
   return false;
 }
 
+/// Determine if a class has any fields that might need to be copied by a
+/// trivial copy or move operation.
+static bool hasFields(const CXXRecordDecl *RD) {
+  if (!RD || RD->isEmpty())
+    return false;
+  for (auto *FD : RD->fields()) {
+    if (FD->isUnnamedBitfield())
+      continue;
+    return true;
+  }
+  for (auto &Base : RD->bases())
+    if (hasFields(Base.getType()->getAsCXXRecordDecl()))
+      return true;
+  return false;
+}
+
 namespace {
 typedef SmallVector<APValue, 8> ArgVector;
 }
@@ -3626,8 +3643,13 @@ static bool HandleFunctionCall(SourceLocation CallLoc,
   // For a trivial copy or move assignment, perform an APValue copy. This is
   // essential for unions, where the operations performed by the assignment
   // operator cannot be represented as statements.
+  //
+  // Skip this for non-union classes with no fields; in that case, the defaulted
+  // copy/move does not actually read the object.
   const CXXMethodDecl *MD = dyn_cast<CXXMethodDecl>(Callee);
-  if (MD && MD->isDefaulted() && MD->isTrivial()) {
+  if (MD && MD->isDefaulted() &&
+      (MD->getParent()->isUnion() ||
+       (MD->isTrivial() && hasFields(MD->getParent())))) {
     assert(This &&
            (MD->isCopyAssignmentOperator() || MD->isMoveAssignmentOperator()));
     LValue RHS;
@@ -3684,11 +3706,16 @@ static bool HandleConstructorCall(SourceLocation CallLoc, const LValue &This,
   }
 
   // For a trivial copy or move constructor, perform an APValue copy. This is
-  // essential for unions, where the operations performed by the constructor
-  // cannot be represented by ctor-initializers.
-  if (Definition->isDefaulted() &&
-      ((Definition->isCopyConstructor() && Definition->isTrivial()) ||
-       (Definition->isMoveConstructor() && Definition->isTrivial()))) {
+  // essential for unions (or classes with anonymous union members), where the
+  // operations performed by the constructor cannot be represented by
+  // ctor-initializers.
+  //
+  // Skip this for empty non-union classes; we should not perform an
+  // lvalue-to-rvalue conversion on them because their copy constructor does not
+  // actually read them.
+  if (Definition->isDefaulted() && Definition->isCopyOrMoveConstructor() &&
+      (Definition->getParent()->isUnion() ||
+       (Definition->isTrivial() && hasFields(Definition->getParent())))) {
     LValue RHS;
     RHS.setFrom(Info.Ctx, ArgValues[0]);
     return handleLValueToRValueConversion(Info, Args[0], Args[0]->getType(),
@@ -4733,6 +4760,7 @@ bool PointerExprEvaluator::VisitCastExpr(const CastExpr* E) {
   case CK_CPointerToObjCPointerCast:
   case CK_BlockPointerToObjCPointerCast:
   case CK_AnyPointerToBlockPointerCast:
+  case CK_AddressSpaceConversion:
     if (!Visit(SubExpr))
       return false;
     // Bitcasts to cv void* are static_casts, not reinterpret_casts, so are
@@ -7372,9 +7400,11 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_huge_val:
   case Builtin::BI__builtin_huge_valf:
   case Builtin::BI__builtin_huge_vall:
+  case Builtin::BI__builtin_huge_valh:
   case Builtin::BI__builtin_inf:
   case Builtin::BI__builtin_inff:
-  case Builtin::BI__builtin_infl: {
+  case Builtin::BI__builtin_infl:
+  case Builtin::BI__builtin_infh: {
     const llvm::fltSemantics &Sem =
       Info.Ctx.getFloatTypeSemantics(E->getType());
     Result = llvm::APFloat::getInf(Sem);
@@ -7384,6 +7414,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nans:
   case Builtin::BI__builtin_nansf:
   case Builtin::BI__builtin_nansl:
+  case Builtin::BI__builtin_nansh:
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
                                true, Result))
       return Error(E);
@@ -7392,6 +7423,7 @@ bool FloatExprEvaluator::VisitCallExpr(const CallExpr *E) {
   case Builtin::BI__builtin_nan:
   case Builtin::BI__builtin_nanf:
   case Builtin::BI__builtin_nanl:
+  case Builtin::BI__builtin_nanh:
     // If this is __builtin_nan() turn this into a nan, otherwise we
     // can't constant fold it.
     if (!TryEvaluateBuiltinNaN(Info.Ctx, E->getType(), E->getArg(0),
diff --git a/tools/clang/lib/AST/ItaniumMangle.cpp b/tools/clang/lib/AST/ItaniumMangle.cpp
index 977d6fc..a21fbe5 100644
--- a/tools/clang/lib/AST/ItaniumMangle.cpp
+++ b/tools/clang/lib/AST/ItaniumMangle.cpp
@@ -160,6 +160,9 @@ public:
 
   void mangleStringLiteral(const StringLiteral *, raw_ostream &) override;
 
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &) override;
+  void mangleMetalGeneric(const std::string& name, QualType Ty, const CXXRecordDecl* RD, raw_ostream &) override;
+
   bool getNextDiscriminator(const NamedDecl *ND, unsigned &disc) {
     // Lambda closure types are already numbered.
     if (isLambda(ND))
@@ -292,6 +295,7 @@ public:
   void mangleName(const NamedDecl *ND);
   void mangleType(QualType T);
   void mangleNameOrStandardSubstitution(const NamedDecl *ND);
+  void mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD);
   
 private:
 
@@ -1919,7 +1923,39 @@ void CXXNameMangler::mangleNameOrStandardSubstitution(const NamedDecl *ND) {
     mangleName(ND);
 }
 
+void CXXNameMangler::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD) {
+	const DeclContext *DC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(D));
+	const DeclContext *PDC = IgnoreLinkageSpecDecls(getEffectiveDeclContext(RD));
+	
+	if(const auto II = D->getIdentifier()) {
+		// TODO: need actual parent field entry for all nested types
+		if(DC->getParent()->Equals(PDC)) {
+			mangleSourceName(II);
+		}
+	}
+	
+	// top level: mangle directly (without enclosing record decl / PDC)
+	// all else: mangle nested type as well
+	if(!DC->getParent()->Equals(PDC)) {
+		if (GetLocalClassDecl(D)) {
+			mangleLocalName(D);
+		}
+		else {
+			mangleNestedName(D, DC);
+		}
+	}
+	mangleType(D->getType());
+}
+
 void CXXNameMangler::mangleType(const BuiltinType *T) {
+  // helper function to discern between spir and applecl name mangling depending on the triple vendor
+  static const auto mangle_opencl_name = [](const ASTContext& ast_ctx, const char* spir_name, const char* applecl_name) {
+    if(ast_ctx.getTargetInfo().getTriple().getVendorName().str() == "applecl") {
+      return applecl_name;
+    }
+    return spir_name;
+  };
+
   //  <type>         ::= <builtin-type>
   //  <builtin-type> ::= v  # void
   //                 ::= w  # wchar_t
@@ -1984,14 +2020,24 @@ void CXXNameMangler::mangleType(const BuiltinType *T) {
   case BuiltinType::ObjCId: Out << "11objc_object"; break;
   case BuiltinType::ObjCClass: Out << "10objc_class"; break;
   case BuiltinType::ObjCSel: Out << "13objc_selector"; break;
-  case BuiltinType::OCLImage1d: Out << "11ocl_image1d"; break;
-  case BuiltinType::OCLImage1dArray: Out << "16ocl_image1darray"; break;
-  case BuiltinType::OCLImage1dBuffer: Out << "17ocl_image1dbuffer"; break;
-  case BuiltinType::OCLImage2d: Out << "11ocl_image2d"; break;
-  case BuiltinType::OCLImage2dArray: Out << "16ocl_image2darray"; break;
-  case BuiltinType::OCLImage3d: Out << "11ocl_image3d"; break;
-  case BuiltinType::OCLSampler: Out << "11ocl_sampler"; break;
-  case BuiltinType::OCLEvent: Out << "9ocl_event"; break;
+  case BuiltinType::OCLImage1d: Out << mangle_opencl_name(getASTContext(), "11ocl_image1d", "PU3AS110_image1d_t"); break;
+  case BuiltinType::OCLImage1dArray: Out << mangle_opencl_name(getASTContext(), "16ocl_image1darray", "PU3AS116_image1d_array_t"); break;
+  case BuiltinType::OCLImage1dBuffer: Out << mangle_opencl_name(getASTContext(), "17ocl_image1dbuffer", "PU3AS117_image1d_buffer_t"); break;
+  case BuiltinType::OCLImage2d: Out << mangle_opencl_name(getASTContext(), "11ocl_image2d", "PU3AS110_image2d_t"); break;
+  case BuiltinType::OCLImage2dArray: Out << mangle_opencl_name(getASTContext(), "16ocl_image2darray", "PU3AS116_image2d_array_t"); break;
+  case BuiltinType::OCLImage2dDepth: Out << mangle_opencl_name(getASTContext(), "16ocl_image2ddepth", "PU3AS116_image2d_depth_t"); break;
+  case BuiltinType::OCLImage2dArrayDepth: Out << mangle_opencl_name(getASTContext(), "21ocl_image2darraydepth", "PU3AS122_image2d_array_depth_t"); break;
+  case BuiltinType::OCLImage2dMSAA: Out << mangle_opencl_name(getASTContext(), "15ocl_image2dmsaa", "PU3AS115_image2d_msaa_t"); break;
+  case BuiltinType::OCLImage2dArrayMSAA: Out << mangle_opencl_name(getASTContext(), "20ocl_image2darraymsaa", "PU3AS121_image2d_array_msaa_t"); break;
+  case BuiltinType::OCLImage2dMSAADepth: Out << mangle_opencl_name(getASTContext(), "20ocl_image2dmsaadepth", "PU3AS121_image2d_msaa_depth_t"); break;
+  case BuiltinType::OCLImage2dArrayMSAADepth: Out << mangle_opencl_name(getASTContext(), "25ocl_image2darraymsaadepth", "PU3AS127_image2d_array_msaa_depth_t"); break;
+  case BuiltinType::OCLImageCube: Out << mangle_opencl_name(getASTContext(), "13ocl_imagecube", "PU3AS112_imagecube_t"); break;
+  case BuiltinType::OCLImageCubeArray: Out << mangle_opencl_name(getASTContext(), "18ocl_imagecubearray", "PU3AS117_imagecubearray_t"); break;
+  case BuiltinType::OCLImageCubeDepth: Out << mangle_opencl_name(getASTContext(), "18ocl_imagecubedepth", "PU3AS117_imagecubedepth_t"); break;
+  case BuiltinType::OCLImageCubeArrayDepth: Out << mangle_opencl_name(getASTContext(), "23ocl_imagecubearraydepth", "PU3AS122_imagecubearraydepth_t"); break;
+  case BuiltinType::OCLImage3d: Out << mangle_opencl_name(getASTContext(), "11ocl_image3d", "PU3AS110_image3d_t"); break;
+  case BuiltinType::OCLSampler: Out << mangle_opencl_name(getASTContext(), "11ocl_sampler", "uSampler"); break;
+  case BuiltinType::OCLEvent: Out << mangle_opencl_name(getASTContext(), "9ocl_event", "i"); break;
   }
 }
 
@@ -3847,6 +3893,26 @@ void ItaniumMangleContextImpl::mangleStringLiteral(const StringLiteral *, raw_os
   llvm_unreachable("Can't mangle string literals");
 }
 
+void ItaniumMangleContextImpl::mangleMetalFieldName(const FieldDecl *D, const CXXRecordDecl* RD, raw_ostream &Out) {
+	assert(isa<FieldDecl>(D) &&
+		   "Invalid mangleName() call, argument is not a field decl!");
+	
+	PrettyStackTraceDecl CrashInfo(D, SourceLocation(),
+								   getASTContext().getSourceManager(),
+								   "Mangling declaration");
+	
+	CXXNameMangler Mangler(*this, Out, D);
+	Mangler.mangleMetalFieldName(D, RD);
+}
+
+void ItaniumMangleContextImpl::mangleMetalGeneric(const std::string& name, QualType Ty,
+												  const CXXRecordDecl* RD, raw_ostream &Out) {
+	CXXNameMangler Mangler(*this, Out, nullptr);
+	Out << name.size();
+	Out << name;
+	Mangler.mangleType(Ty);
+}
+
 ItaniumMangleContext *
 ItaniumMangleContext::create(ASTContext &Context, DiagnosticsEngine &Diags) {
   return new ItaniumMangleContextImpl(Context, Diags);
diff --git a/tools/clang/lib/AST/MicrosoftMangle.cpp b/tools/clang/lib/AST/MicrosoftMangle.cpp
index e6a6d09..267b1c0 100644
--- a/tools/clang/lib/AST/MicrosoftMangle.cpp
+++ b/tools/clang/lib/AST/MicrosoftMangle.cpp
@@ -1492,6 +1492,16 @@ void MicrosoftCXXNameMangler::mangleType(const BuiltinType *T,
   case BuiltinType::OCLImage1dBuffer: Out << "PAUocl_image1dbuffer@@"; break;
   case BuiltinType::OCLImage2d: Out << "PAUocl_image2d@@"; break;
   case BuiltinType::OCLImage2dArray: Out << "PAUocl_image2darray@@"; break;
+  case BuiltinType::OCLImage2dDepth: Out << "PAUocl_image2ddepth@@"; break;
+  case BuiltinType::OCLImage2dArrayDepth: Out << "PAUocl_image2darraydepth@@"; break;
+  case BuiltinType::OCLImage2dMSAA: Out << "PAUocl_image2dmsaa@@"; break;
+  case BuiltinType::OCLImage2dArrayMSAA: Out << "PAUocl_image2darraymsaa@@"; break;
+  case BuiltinType::OCLImage2dMSAADepth: Out << "PAUocl_image2dmsaadepth@@"; break;
+  case BuiltinType::OCLImage2dArrayMSAADepth: Out << "PAUocl_image2darraymsaadepth@@"; break;
+  case BuiltinType::OCLImageCube: Out << "PAUocl_imagecube@@"; break;
+  case BuiltinType::OCLImageCubeArray: Out << "PAUocl_imagecubearray@@"; break;
+  case BuiltinType::OCLImageCubeDepth: Out << "PAUocl_imagecubedepth@@"; break;
+  case BuiltinType::OCLImageCubeArrayDepth: Out << "PAUocl_imagecubearraydepth@@"; break;
   case BuiltinType::OCLImage3d: Out << "PAUocl_image3d@@"; break;
   case BuiltinType::OCLSampler: Out << "PAUocl_sampler@@"; break;
   case BuiltinType::OCLEvent: Out << "PAUocl_event@@"; break;
diff --git a/tools/clang/lib/AST/NSAPI.cpp b/tools/clang/lib/AST/NSAPI.cpp
index 986b3b5..3f8aad8 100644
--- a/tools/clang/lib/AST/NSAPI.cpp
+++ b/tools/clang/lib/AST/NSAPI.cpp
@@ -349,6 +349,16 @@ NSAPI::getNSNumberFactoryMethodKind(QualType T) const {
   case BuiltinType::OCLImage1dBuffer:
   case BuiltinType::OCLImage2d:
   case BuiltinType::OCLImage2dArray:
+  case BuiltinType::OCLImage2dDepth:
+  case BuiltinType::OCLImage2dArrayDepth:
+  case BuiltinType::OCLImage2dMSAA:
+  case BuiltinType::OCLImage2dArrayMSAA:
+  case BuiltinType::OCLImage2dMSAADepth:
+  case BuiltinType::OCLImage2dArrayMSAADepth:
+  case BuiltinType::OCLImageCube:
+  case BuiltinType::OCLImageCubeArray:
+  case BuiltinType::OCLImageCubeDepth:
+  case BuiltinType::OCLImageCubeArrayDepth:
   case BuiltinType::OCLImage3d:
   case BuiltinType::OCLSampler:
   case BuiltinType::OCLEvent:
diff --git a/tools/clang/lib/AST/Type.cpp b/tools/clang/lib/AST/Type.cpp
index 1677874..fb31818 100644
--- a/tools/clang/lib/AST/Type.cpp
+++ b/tools/clang/lib/AST/Type.cpp
@@ -1546,6 +1546,16 @@ StringRef BuiltinType::getName(const PrintingPolicy &Policy) const {
   case OCLImage1dBuffer:  return "image1d_buffer_t";
   case OCLImage2d:        return "image2d_t";
   case OCLImage2dArray:   return "image2d_array_t";
+  case OCLImage2dDepth:   return "image2d_depth_t";
+  case OCLImage2dArrayDepth: return "image2d_array_depth_t";
+  case OCLImage2dMSAA:    return "image2d_msaa_t";
+  case OCLImage2dArrayMSAA: return "image2d_array_msaa_t";
+  case OCLImage2dMSAADepth: return "image2d_msaa_depth_t";
+  case OCLImage2dArrayMSAADepth: return "image2d_array_msaa_depth_t";
+  case OCLImageCube:      return "imagecube_t";
+  case OCLImageCubeArray: return "imagecube_array_t";
+  case OCLImageCubeDepth: return "imagecube_depth_t";
+  case OCLImageCubeArrayDepth: return "imagecube_array_depth_t";
   case OCLImage3d:        return "image3d_t";
   case OCLSampler:        return "sampler_t";
   case OCLEvent:          return "event_t";
@@ -1583,6 +1593,8 @@ StringRef FunctionType::getNameForCallConv(CallingConv CC) {
   case CC_AAPCS_VFP: return "aapcs-vfp";
   case CC_PnaclCall: return "pnaclcall";
   case CC_IntelOclBicc: return "intel_ocl_bicc";
+  case CC_SpirFunction: return "spir_function";
+  case CC_SpirKernel: return "spir_kernel";
   }
 
   llvm_unreachable("Invalid calling convention.");
@@ -2469,3 +2481,43 @@ QualType::DestructionKind QualType::isDestructedTypeImpl(QualType type) {
 CXXRecordDecl *MemberPointerType::getMostRecentCXXRecordDecl() const {
   return getClass()->getAsCXXRecordDecl()->getMostRecentDecl();
 }
+
+static std::pair<bool, bool> isAggregateImageTypeRecurse(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return { false, false };
+	
+	// union is not allowed
+	if(decl->isUnion()) return { false, false };
+	
+	// must have definition
+	if(!decl->hasDefinition()) return { false, false };
+	
+	// iterate over all fields/members and check if all are image types
+	bool has_any_image = false;
+	for(const auto& field : decl->fields()) {
+		if(!field->getType()->isImageType()) {
+			return { false, false };
+		}
+		has_any_image = true;
+	}
+	
+	// iterate over / recurse into all bases, check if they only consist of image types
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = isAggregateImageTypeRecurse(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.first) {
+			return { false, false };
+		}
+		has_any_image |= base_ret.second;
+	}
+	
+	// all passed
+	return { true, has_any_image };
+}
+
+bool Type::isAggregateImageType() const {
+  // must be struct or class, union is not allowed
+  if(!isStructureOrClassType()) return false;
+
+  // check class/struct itself + all inherited base classes/structs
+  const auto valid_and_has_image = isAggregateImageTypeRecurse(getAsCXXRecordDecl());
+  return valid_and_has_image.first && valid_and_has_image.second;
+}
diff --git a/tools/clang/lib/AST/TypeLoc.cpp b/tools/clang/lib/AST/TypeLoc.cpp
index 208d695..3fca2c9 100644
--- a/tools/clang/lib/AST/TypeLoc.cpp
+++ b/tools/clang/lib/AST/TypeLoc.cpp
@@ -296,6 +296,16 @@ TypeSpecifierType BuiltinTypeLoc::getWrittenTypeSpec() const {
   case BuiltinType::OCLImage1dBuffer:
   case BuiltinType::OCLImage2d:
   case BuiltinType::OCLImage2dArray:
+  case BuiltinType::OCLImage2dDepth:
+  case BuiltinType::OCLImage2dArrayDepth:
+  case BuiltinType::OCLImage2dMSAA:
+  case BuiltinType::OCLImage2dArrayMSAA:
+  case BuiltinType::OCLImage2dMSAADepth:
+  case BuiltinType::OCLImage2dArrayMSAADepth:
+  case BuiltinType::OCLImageCube:
+  case BuiltinType::OCLImageCubeArray:
+  case BuiltinType::OCLImageCubeDepth:
+  case BuiltinType::OCLImageCubeArrayDepth:
   case BuiltinType::OCLImage3d:
   case BuiltinType::OCLSampler:
   case BuiltinType::OCLEvent:
diff --git a/tools/clang/lib/AST/TypePrinter.cpp b/tools/clang/lib/AST/TypePrinter.cpp
index 061473e..9de3dad 100644
--- a/tools/clang/lib/AST/TypePrinter.cpp
+++ b/tools/clang/lib/AST/TypePrinter.cpp
@@ -694,6 +694,12 @@ void TypePrinter::printFunctionProtoAfter(const FunctionProtoType *T,
     case CC_X86_64SysV:
       OS << " __attribute__((sysv_abi))";
       break;
+    case CC_SpirFunction:
+      OS << "spir_function";
+      break;
+    case CC_SpirKernel:
+      OS << "spir_kernel";
+      break;
     }
   }
 
diff --git a/tools/clang/lib/Basic/Targets.cpp b/tools/clang/lib/Basic/Targets.cpp
index 075f905..230850f 100644
--- a/tools/clang/lib/Basic/Targets.cpp
+++ b/tools/clang/lib/Basic/Targets.cpp
@@ -1361,6 +1361,7 @@ namespace {
       // Define available target features
       // These must be defined in sorted order!
       NoAsmVariants = true;
+      UserLabelPrefix = "";
     }
     void getTargetDefines(const LangOptions &Opts,
                           MacroBuilder &Builder) const override {
@@ -1394,6 +1395,7 @@ namespace {
       case 'l':
       case 'f':
       case 'd':
+      case 'b':
         Info.setAllowsRegister();
         return true;
       }
@@ -1411,7 +1413,16 @@ namespace {
         .Case("sm_20", true)
         .Case("sm_21", true)
         .Case("sm_30", true)
+        .Case("sm_32", true)
         .Case("sm_35", true)
+        .Case("sm_37", true)
+        .Case("sm_50", true)
+        .Case("sm_52", true)
+        .Case("sm_53", true)
+        .Case("sm_60", true)
+        .Case("sm_61", true)
+        .Case("sm_62", true)
+        .Case("sm_70", true)
         .Default(false);
 
       return Valid;
@@ -5872,12 +5883,11 @@ namespace {
     0     // cuda_shared
   };
   class SPIRTargetInfo : public TargetInfo {
+  private:
+    // true for spir-unknown-* and spir64-unknown-* (-> false for AppleCL and AIR/Metal)
+    const bool is_pure_spir;
   public:
-    SPIRTargetInfo(const llvm::Triple &Triple) : TargetInfo(Triple) {
-      assert(getTriple().getOS() == llvm::Triple::UnknownOS &&
-        "SPIR target must use unknown OS");
-      assert(getTriple().getEnvironment() == llvm::Triple::UnknownEnvironment &&
-        "SPIR target must use unknown environment type");
+    SPIRTargetInfo(const llvm::Triple &Triple) : TargetInfo(Triple), is_pure_spir(Triple.getVendorName().str() == "unknown") {
       BigEndian = false;
       TLSSupported = false;
       LongWidth = LongAlign = 64;
@@ -5886,6 +5896,7 @@ namespace {
       // Define available target features
       // These must be defined in sorted order!
       NoAsmVariants = true;
+      UserLabelPrefix = "";
     }
     void getTargetDefines(const LangOptions &Opts,
                           MacroBuilder &Builder) const override {
@@ -5911,6 +5922,16 @@ namespace {
     BuiltinVaListKind getBuiltinVaListKind() const override {
       return TargetInfo::VoidPtrBuiltinVaList;
     }
+
+    CallingConvCheckResult checkCallingConvention(CallingConv CC) const override {
+      if (!is_pure_spir) return CCCR_OK;
+      return (CC == CC_SpirFunction ||
+              CC == CC_SpirKernel) ? CCCR_OK : CCCR_Warning;
+    }
+
+    CallingConv getDefaultCallingConv(CallingConvMethodType MT) const override {
+      return (is_pure_spir ? CC_SpirFunction : CC_C);
+    }
   };
 
 
@@ -5944,6 +5965,26 @@ namespace {
       DefineStd(Builder, "SPIR64", Opts);
     }
   };
+
+  class AIR64TargetInfo : public SPIRTargetInfo {
+  public:
+    AIR64TargetInfo(const llvm::Triple &Triple) : SPIRTargetInfo(Triple) {
+      PointerWidth = PointerAlign = 64;
+      SizeType     = TargetInfo::UnsignedLong;
+      PtrDiffType = IntPtrType = TargetInfo::SignedLong;
+      if(Triple.getOS() == llvm::Triple::IOS) {
+        DescriptionString = "e-i64:64-f80:128-v16:16-v24:32-v32:32-v48:64-"
+                            "v96:128-v192:256-v256:256-v512:512-v1024:1024-n8:16:32";
+      }
+      else { // os x, or default
+        DescriptionString = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-f80:128:128-v16:16:16-v24:32:32-v32:32:32-v48:64:64-v64:64:64-v96:128:128-v128:128:128-v192:256:256-v256:256:256-v512:512:512-v1024:1024:1024-f80:128:128-n8:16:32";
+      }
+    }
+    void getTargetDefines(const LangOptions &Opts,
+                          MacroBuilder &Builder) const override {
+      DefineStd(Builder, "AIR64", Opts);
+    }
+  };
 }
 
 namespace {
@@ -6369,18 +6410,12 @@ static TargetInfo *AllocateTarget(const llvm::Triple &Triple) {
       return new X86_64TargetInfo(Triple);
     }
 
-    case llvm::Triple::spir: {
-      if (Triple.getOS() != llvm::Triple::UnknownOS ||
-          Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-        return nullptr;
-      return new SPIR32TargetInfo(Triple);
-    }
-    case llvm::Triple::spir64: {
-      if (Triple.getOS() != llvm::Triple::UnknownOS ||
-          Triple.getEnvironment() != llvm::Triple::UnknownEnvironment)
-        return nullptr;
-      return new SPIR64TargetInfo(Triple);
-    }
+  case llvm::Triple::spir:
+    return new SPIR32TargetInfo(Triple);
+  case llvm::Triple::spir64:
+    return new SPIR64TargetInfo(Triple);
+  case llvm::Triple::air64:
+    return new AIR64TargetInfo(Triple);
   }
 }
 
diff --git a/tools/clang/lib/CodeGen/BackendUtil.cpp b/tools/clang/lib/CodeGen/BackendUtil.cpp
index cec48f3..b50e897 100644
--- a/tools/clang/lib/CodeGen/BackendUtil.cpp
+++ b/tools/clang/lib/CodeGen/BackendUtil.cpp
@@ -240,6 +240,28 @@ void EmitAssemblyHelper::CreatePasses() {
   PMBuilder.DisableUnrollLoops = !CodeGenOpts.UnrollLoops;
   PMBuilder.RerollLoops = CodeGenOpts.RerollLoops;
 
+  PMBuilder.floor_image_capabilities = LangOpts.floor_image_capabilities;
+
+  PMBuilder.EnableAddressSpaceFix = LangOpts.OpenCL;
+  if(PMBuilder.EnableAddressSpaceFix && OptLevel == 0) {
+    unsigned DiagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "compiling OpenCL or Metal with"
+											" -O0 is not possible!");
+    Diags.Report(DiagID);
+    return;
+  }
+
+  // only enable this for CUDA
+  PMBuilder.EnableCUDAPasses = LangOpts.CUDA;
+
+  // only enable this for Metal/AIR
+  PMBuilder.EnableMetalPasses = LangOpts.Metal;
+  PMBuilder.EnableMetalIntelWorkarounds = CodeGenOpts.MetalIntelWorkarounds;
+
+  // only enable this for OpenCL/SPIR (don't want this for AppleCL or Metal)
+  PMBuilder.EnableSPIRPasses = (LangOpts.OpenCL &&
+                                (Triple(TheModule->getTargetTriple()).getArch() == Triple::spir64) &&
+                                (Triple(TheModule->getTargetTriple()).getVendorName().str() == "unknown"));
+
   PMBuilder.addExtension(PassManagerBuilder::EP_EarlyAsPossible,
                          addAddDiscriminatorsPass);
 
@@ -301,8 +323,13 @@ void EmitAssemblyHelper::CreatePasses() {
   switch (Inlining) {
   case CodeGenOptions::NoInlining: break;
   case CodeGenOptions::NormalInlining: {
-    PMBuilder.Inliner =
-        createFunctionInliningPass(OptLevel, CodeGenOpts.OptimizeSize);
+    // always inline everything for metal/cuda/opencl, otherwise we run into trouble when fixing the IR
+    if (LangOpts.Metal || LangOpts.CUDA || LangOpts.OpenCL) {
+      PMBuilder.Inliner = createEverythingInlinerPass();
+    }
+    else {
+      PMBuilder.Inliner = createFunctionInliningPass(OptLevel, CodeGenOpts.OptimizeSize);
+    }
     break;
   }
   case CodeGenOptions::OnlyAlwaysInlining:
@@ -326,6 +353,10 @@ void EmitAssemblyHelper::CreatePasses() {
   if (CodeGenOpts.VerifyModule)
     MPM->add(createDebugInfoVerifierPass());
 
+  if (LangOpts.OpenCL || LangOpts.CUDA) {
+    MPM->add(createInternalizePass());
+  }
+
   if (!CodeGenOpts.DisableGCov &&
       (CodeGenOpts.EmitGcovArcs || CodeGenOpts.EmitGcovNotes)) {
     // Not using 'GCOVOptions::getDefault' allows us to avoid exiting if
diff --git a/tools/clang/lib/CodeGen/CGCall.cpp b/tools/clang/lib/CodeGen/CGCall.cpp
index 17c3354..cc2c088 100644
--- a/tools/clang/lib/CodeGen/CGCall.cpp
+++ b/tools/clang/lib/CodeGen/CGCall.cpp
@@ -47,6 +47,8 @@ static unsigned ClangCallConvToLLVMCallConv(CallingConv CC) {
   case CC_AAPCS: return llvm::CallingConv::ARM_AAPCS;
   case CC_AAPCS_VFP: return llvm::CallingConv::ARM_AAPCS_VFP;
   case CC_IntelOclBicc: return llvm::CallingConv::Intel_OCL_BI;
+  case CC_SpirFunction: return llvm::CallingConv::SPIR_FUNC;
+  case CC_SpirKernel: return llvm::CallingConv::SPIR_KERNEL;
   // TODO: add support for CC_X86Pascal to llvm
   }
 }
@@ -562,7 +564,11 @@ void CodeGenTypes::GetExpandedTypes(QualType type,
     const RecordDecl *RD = RT->getDecl();
     assert(!RD->hasFlexibleArrayMember() &&
            "Cannot expand structure with flexible array.");
-    if (RD->isUnion()) {
+
+    const auto cxx_rdecl = RT->getAsCXXRecordDecl();
+    if (cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+      GetExpandedTypes(get_compat_vector_type(cxx_rdecl), expandedTypes);
+    } else if (RD->isUnion()) {
       // Unions can be here only in degenerative cases - all the fields are same
       // after flattening. Thus we have to use the "largest" field.
       const FieldDecl *LargestFD = nullptr;
@@ -579,6 +585,12 @@ void CodeGenTypes::GetExpandedTypes(QualType type,
       }
       if (LargestFD)
         GetExpandedTypes(LargestFD->getType(), expandedTypes);
+    } else if (type->isAggregateImageType() ||
+               CGM.getLangOpts().Metal) {
+      const auto fields = get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+      for(const auto& field : fields) {
+        expandedTypes.push_back(ConvertType(field.type));
+      }
     } else {
       for (const auto *I : RD->fields()) {
         assert(!I->isBitField() &&
@@ -610,7 +622,12 @@ CodeGenFunction::ExpandTypeFromArgs(QualType Ty, LValue LV,
     }
   } else if (const RecordType *RT = Ty->getAs<RecordType>()) {
     RecordDecl *RD = RT->getDecl();
-    if (RD->isUnion()) {
+    const auto cxx_rdecl = RT->getAsCXXRecordDecl();
+    if (cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+      const auto vec_type = getTypes().get_compat_vector_type(cxx_rdecl);
+      LValue VecLV = MakeAddrLValue(LV.getAddress(), vec_type);
+      AI = ExpandTypeFromArgs(vec_type, VecLV, AI);
+    } else if (RD->isUnion()) {
       // Unions can be here only in degenerative cases - all the fields are same
       // after flattening. Thus we have to use the "largest" field.
       const FieldDecl *LargestFD = nullptr;
@@ -630,6 +647,22 @@ CodeGenFunction::ExpandTypeFromArgs(QualType Ty, LValue LV,
         LValue SubLV = EmitLValueForField(LV, LargestFD);
         AI = ExpandTypeFromArgs(LargestFD->getType(), SubLV, AI);
       }
+    } else if(Ty->isAggregateImageType() ||
+              CGM.getLangOpts().Metal) {
+      for (const auto& base : cxx_rdecl->bases()) {
+        // TODO: should use the base offset:
+        // getContext().getASTRecordLayout(cxx_decl).getBaseClassOffset(base.getType()->getAsCXXRecordDecl());
+        llvm::Value* addr = Builder.CreateConstGEP2_32(LV.getAddress(), 0, 0);
+        LValue BaseLV = MakeAddrLValue(addr, base.getType());
+        AI = ExpandTypeFromArgs(base.getType(), BaseLV, AI);
+      }
+
+      const auto fields = getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl, false, true);
+      for(const auto& field : fields) {
+        // TODO: arrays -> these have no FD
+        LValue SubLV = EmitLValueForField(LV, field.field_decl);
+        AI = ExpandTypeFromArgs(SubLV.getType(), SubLV, AI);
+      }
     } else {
       for (const auto *FD : RD->fields()) {
         QualType FT = FD->getType();
@@ -1527,6 +1560,25 @@ void CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,
                                                   AI->getArgNo() + 1,
                                                   llvm::Attribute::NonNull));
           }
+
+          const auto *AVAttr = PVD->getAttr<AlignValueAttr>();
+          if (!AVAttr)
+            if (const auto *TOTy = dyn_cast<TypedefType>(OTy))
+              AVAttr = TOTy->getDecl()->getAttr<AlignValueAttr>();
+          if (AVAttr) {
+            llvm::Value *AlignmentValue =
+              EmitScalarExpr(AVAttr->getAlignment());
+            llvm::ConstantInt *AlignmentCI =
+              cast<llvm::ConstantInt>(AlignmentValue);
+            unsigned Alignment =
+              std::min((unsigned) AlignmentCI->getZExtValue(),
+                       +llvm::Value::MaximumAlignment);
+
+            llvm::AttrBuilder Attrs;
+            Attrs.addAlignmentAttr(Alignment);
+            AI->addAttr(llvm::AttributeSet::get(getLLVMContext(),
+                                                AI->getArgNo() + 1, Attrs));
+          }
         }
 
         if (Arg->getType().isRestrictQualified())
@@ -2573,9 +2625,12 @@ CodeGenFunction::EmitCallOrInvoke(llvm::Value *Callee,
 }
 
 static void checkArgMatches(llvm::Value *Elt, unsigned &ArgNo,
-                            llvm::FunctionType *FTy) {
-  if (ArgNo < FTy->getNumParams())
-    assert(Elt->getType() == FTy->getParamType(ArgNo));
+                            llvm::FunctionType *FTy, bool ignore_type = false) {
+  if (ArgNo < FTy->getNumParams()) {
+    if(!ignore_type) {
+      assert(Elt->getType() == FTy->getParamType(ArgNo));
+    }
+  }
   else
     assert(FTy->isVarArg());
   ++ArgNo;
@@ -2598,7 +2653,14 @@ void CodeGenFunction::ExpandTypeToArgs(QualType Ty, RValue RV,
     assert(RV.isAggregate() && "Unexpected rvalue during struct expansion");
     LValue LV = MakeAddrLValue(RV.getAggregateAddr(), Ty);
 
-    if (RD->isUnion()) {
+    const auto cxx_rdecl = Ty->getAsCXXRecordDecl();
+    if (cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+      const auto vec_type = getTypes().get_compat_vector_type(cxx_rdecl);
+      const auto llvm_vec_type = getTypes().ConvertType(vec_type);
+      auto vec_ptr = Builder.CreateBitCast(RV.getAggregateAddr(),
+                                           llvm::PointerType::get(llvm_vec_type, Ty.getAddressSpace()));
+      Args.push_back(Builder.CreateLoad(vec_ptr));
+    } else if (RD->isUnion()) {
       const FieldDecl *LargestFD = nullptr;
       CharUnits UnionSize = CharUnits::Zero();
 
@@ -2615,6 +2677,18 @@ void CodeGenFunction::ExpandTypeToArgs(QualType Ty, RValue RV,
         RValue FldRV = EmitRValueForField(LV, LargestFD, SourceLocation());
         ExpandTypeToArgs(LargestFD->getType(), FldRV, Args, IRFuncTy);
       }
+    } else if(Ty->isAggregateImageType() ||
+              CGM.getLangOpts().Metal) {
+      for (const auto& base : cxx_rdecl->bases()) {
+        ExpandTypeToArgs(base.getType(), RV, Args, IRFuncTy);
+      }
+
+      const auto fields = getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl, false, true);
+      for(const auto& field : fields) {
+        // TODO: arrays -> these have no FD
+        RValue FldRV = EmitRValueForField(LV, field.field_decl, SourceLocation());
+        ExpandTypeToArgs(field.field_decl->getType(), FldRV, Args, IRFuncTy);
+      }
     } else {
       for (const auto *FD : RD->fields()) {
         RValue FldRV = EmitRValueForField(LV, FD, SourceLocation());
@@ -2832,12 +2906,20 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
         
         // If the argument doesn't match, perform a bitcast to coerce it.  This
         // can happen due to trivial type mismatches.
+        bool ignore_type_check = false;
         if (IRArgNo < IRFuncTy->getNumParams() &&
-            V->getType() != IRFuncTy->getParamType(IRArgNo))
-          V = Builder.CreateBitCast(V, IRFuncTy->getParamType(IRArgNo));
+            V->getType() != IRFuncTy->getParamType(IRArgNo)) {
+          const auto src_as = V->getType()->getPointerAddressSpace();
+          auto param_type = IRFuncTy->getParamType(IRArgNo);
+          if(src_as > 0 && src_as != param_type->getPointerAddressSpace()) {
+            param_type = llvm::PointerType::get(cast<llvm::PointerType>(param_type->getScalarType())->getElementType(), src_as);
+            ignore_type_check = true;
+          }
+          V = Builder.CreateBitCast(V, param_type);
+        }
         Args.push_back(V);
         
-        checkArgMatches(V, IRArgNo, IRFuncTy);
+        checkArgMatches(V, IRArgNo, IRFuncTy, ignore_type_check);
         break;
       }
 
@@ -3078,6 +3160,13 @@ RValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,
           DestPtr = CreateMemTemp(RetTy, "agg.tmp");
           DestIsVolatile = false;
         }
+		
+        // handle [[vector_compat]] stores from an aggregate to a vector type
+        if(DestPtr->getType()->getPointerElementType()->isVectorTy()) {
+          CreateCoercedStore(CI, DestPtr, DestIsVolatile, *this);
+          return RValue::get(DestPtr);
+        }
+
         BuildAggStore(*this, CI, DestPtr, DestIsVolatile, false);
         return RValue::getAggregate(DestPtr);
       }
diff --git a/tools/clang/lib/CodeGen/CGClass.cpp b/tools/clang/lib/CodeGen/CGClass.cpp
index 9427de1..cd0626d 100644
--- a/tools/clang/lib/CodeGen/CGClass.cpp
+++ b/tools/clang/lib/CodeGen/CGClass.cpp
@@ -172,9 +172,16 @@ CodeGenFunction::GetAddressOfBaseClass(llvm::Value *Value,
     VBase = nullptr; // we no longer have a virtual step
   }
 
-  // Get the base pointer type.
-  llvm::Type *BasePtrTy = 
-    ConvertType((PathEnd[-1])->getType())->getPointerTo();
+  // Get the base pointer type, and keep the Values address space if it has one
+  const auto val_type = Value->getType();
+  unsigned val_as = 0;
+  if(val_type != nullptr &&
+     val_type->isPointerTy() &&
+     val_type->getPointerAddressSpace() != 0) {
+      val_as = val_type->getPointerAddressSpace();
+  }
+  llvm::Type *BasePtrTy =
+    ConvertType((PathEnd[-1])->getType())->getPointerTo(val_as);
 
   // If the static offset is zero and we don't have a virtual step,
   // just do a bitcast; null checks are unnecessary.
diff --git a/tools/clang/lib/CodeGen/CGDebugInfo.cpp b/tools/clang/lib/CodeGen/CGDebugInfo.cpp
index 048c8f8..71783c8 100644
--- a/tools/clang/lib/CodeGen/CGDebugInfo.cpp
+++ b/tools/clang/lib/CodeGen/CGDebugInfo.cpp
@@ -452,6 +452,36 @@ llvm::DIType CGDebugInfo::CreateType(const BuiltinType *BT) {
   case BuiltinType::OCLImage2dArray:
     return getOrCreateStructPtrType("opencl_image2d_array_t",
                                     OCLImage2dArrayDITy);
+  case BuiltinType::OCLImage2dDepth:
+    return getOrCreateStructPtrType("opencl_image2d_depth_t",
+                                    OCLImage2dDepthDITy);
+  case BuiltinType::OCLImage2dArrayDepth:
+    return getOrCreateStructPtrType("opencl_image2d_array_depth_t",
+                                    OCLImage2dArrayDepthDITy);
+  case BuiltinType::OCLImage2dMSAA:
+    return getOrCreateStructPtrType("opencl_image2d_msaa_t",
+                                    OCLImage2dMSAADITy);
+  case BuiltinType::OCLImage2dArrayMSAA:
+    return getOrCreateStructPtrType("opencl_image2d_array_msaa_t",
+                                    OCLImage2dArrayMSAADITy);
+  case BuiltinType::OCLImage2dMSAADepth:
+    return getOrCreateStructPtrType("opencl_image2d_msaa_depth_t",
+                                    OCLImage2dMSAADepthDITy);
+  case BuiltinType::OCLImage2dArrayMSAADepth:
+    return getOrCreateStructPtrType("opencl_image2d_array_msaa_depth_t",
+                                    OCLImage2dArrayMSAADepthDITy);
+  case BuiltinType::OCLImageCube:
+    return getOrCreateStructPtrType("opencl_imagecube_t",
+                                    OCLImageCubeDITy);
+  case BuiltinType::OCLImageCubeArray:
+    return getOrCreateStructPtrType("opencl_imagecube_array_t",
+                                    OCLImageCubeDITy);
+  case BuiltinType::OCLImageCubeDepth:
+    return getOrCreateStructPtrType("opencl_imagecube_depth_t",
+                                    OCLImageCubeDITy);
+  case BuiltinType::OCLImageCubeArrayDepth:
+    return getOrCreateStructPtrType("opencl_imagecube_array_depth_t",
+                                    OCLImageCubeDITy);
   case BuiltinType::OCLImage3d:
     return getOrCreateStructPtrType("opencl_image3d_t",
                                     OCLImage3dDITy);
diff --git a/tools/clang/lib/CodeGen/CGDebugInfo.h b/tools/clang/lib/CodeGen/CGDebugInfo.h
index fc3f434..217f1d4 100644
--- a/tools/clang/lib/CodeGen/CGDebugInfo.h
+++ b/tools/clang/lib/CodeGen/CGDebugInfo.h
@@ -59,7 +59,8 @@ class CGDebugInfo {
   llvm::DICompositeType ObjTy;
   llvm::DIType SelTy;
   llvm::DIType OCLImage1dDITy, OCLImage1dArrayDITy, OCLImage1dBufferDITy;
-  llvm::DIType OCLImage2dDITy, OCLImage2dArrayDITy;
+  llvm::DIType OCLImage2dDITy, OCLImage2dArrayDITy, OCLImage2dDepthDITy, OCLImage2dArrayDepthDITy, OCLImage2dMSAADITy, OCLImage2dArrayMSAADITy, OCLImage2dMSAADepthDITy, OCLImage2dArrayMSAADepthDITy;
+  llvm::DIType OCLImageCubeDITy, OCLImageCubeArrayDITy, OCLImageCubeDepthDITy, OCLImageCubeArrayDepthDITy;
   llvm::DIType OCLImage3dDITy;
   llvm::DIType OCLEventDITy;
   llvm::DIType BlockLiteralGeneric;
diff --git a/tools/clang/lib/CodeGen/CGDecl.cpp b/tools/clang/lib/CodeGen/CGDecl.cpp
index 91f8041..2c68378 100644
--- a/tools/clang/lib/CodeGen/CGDecl.cpp
+++ b/tools/clang/lib/CodeGen/CGDecl.cpp
@@ -150,8 +150,12 @@ static std::string GetStaticDeclName(CodeGenFunction &CGF, const VarDecl &D,
                                      const char *Separator) {
   CodeGenModule &CGM = CGF.CGM;
 
-  if (CGF.getLangOpts().CPlusPlus)
+  // don't cxx mangle OpenCL "local" variables (affects SPIR and AppleCL - Metal/AIR use cxx mangling)
+  if (CGF.getLangOpts().CPlusPlus &&
+      !(D.getStorageClass() == SC_OpenCLWorkGroupLocal &&
+        CGM.getContext().getLangOpts().OpenCL && !CGM.getContext().getLangOpts().Metal)) {
     return CGM.getMangledName(&D).str();
+  }
 
   StringRef ContextName;
   if (!CGF.CurFuncDecl) {
diff --git a/tools/clang/lib/CodeGen/CGExpr.cpp b/tools/clang/lib/CodeGen/CGExpr.cpp
index 512b323..0bacf88 100644
--- a/tools/clang/lib/CodeGen/CGExpr.cpp
+++ b/tools/clang/lib/CodeGen/CGExpr.cpp
@@ -2538,28 +2538,36 @@ LValue CodeGenFunction::EmitLValueForLambdaField(const FieldDecl *Field) {
 
 LValue CodeGenFunction::EmitLValueForField(LValue base,
                                            const FieldDecl *field) {
+  llvm::Value *addr = base.getAddress();
+  llvm::Type* elem_type = addr->getType()->getPointerElementType();
+  const RecordDecl *rec = field->getParent();
+  const CGRecordLayout &RL = CGM.getTypes().getCGRecordLayout(rec, elem_type);
+
   if (field->isBitField()) {
-    const CGRecordLayout &RL =
-      CGM.getTypes().getCGRecordLayout(field->getParent());
     const CGBitFieldInfo &Info = RL.getBitFieldInfo(field);
-    llvm::Value *Addr = base.getAddress();
     unsigned Idx = RL.getLLVMFieldNo(field);
     if (Idx != 0)
       // For structs, we GEP to the field that the record layout suggests.
-      Addr = Builder.CreateStructGEP(Addr, Idx, field->getName());
+      addr = Builder.CreateStructGEP(addr, Idx, field->getName());
     // Get the access type.
-    llvm::Type *PtrTy = llvm::Type::getIntNPtrTy(
+    llvm::PointerType *PtrTy = llvm::Type::getIntNPtrTy(
       getLLVMContext(), Info.StorageSize,
       CGM.getContext().getTargetAddressSpace(base.getType()));
-    if (Addr->getType() != PtrTy)
-      Addr = Builder.CreateBitCast(Addr, PtrTy);
+    // target address space handling above is apparently insufficient,
+    // so fix up the address space manually
+    if(PtrTy->getPointerAddressSpace() != addr->getType()->getPointerAddressSpace()) {
+      PtrTy = llvm::PointerType::get(PtrTy->getElementType(),
+                                     addr->getType()->getPointerAddressSpace());
+    }
+
+    if (addr->getType() != PtrTy)
+      addr = Builder.CreateBitCast(addr, PtrTy);
 
     QualType fieldType =
       field->getType().withCVRQualifiers(base.getVRQualifiers());
-    return LValue::MakeBitfield(Addr, Info, fieldType, base.getAlignment());
+    return LValue::MakeBitfield(addr, Info, fieldType, base.getAlignment());
   }
 
-  const RecordDecl *rec = field->getParent();
   QualType type = field->getType();
   CharUnits alignment = getContext().getDeclAlign(field);
 
@@ -2570,7 +2578,6 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
 
   bool mayAlias = rec->hasAttr<MayAliasAttr>();
 
-  llvm::Value *addr = base.getAddress();
   unsigned cvr = base.getVRQualifiers();
   bool TBAAPath = CGM.getCodeGenOpts().StructPathTBAA;
   if (rec->isUnion()) {
@@ -2580,7 +2587,7 @@ LValue CodeGenFunction::EmitLValueForField(LValue base,
     TBAAPath = false;
   } else {
     // For structs, we GEP to the field that the record layout suggests.
-    unsigned idx = CGM.getTypes().getCGRecordLayout(rec).getLLVMFieldNo(field);
+    unsigned idx = RL.getLLVMFieldNo(field);
     addr = Builder.CreateStructGEP(addr, idx, field->getName());
 
     // If this is a reference field, load the reference right now.
@@ -2657,8 +2664,9 @@ CodeGenFunction::EmitLValueForFieldInitialization(LValue Base,
   if (!FieldType->isReferenceType())
     return EmitLValueForField(Base, Field);
 
+  llvm::Type* elem_type = Base.getAddress()->getType()->getPointerElementType();
   const CGRecordLayout &RL =
-    CGM.getTypes().getCGRecordLayout(Field->getParent());
+    CGM.getTypes().getCGRecordLayout(Field->getParent(), elem_type);
   unsigned idx = RL.getLLVMFieldNo(Field);
   llvm::Value *V = Builder.CreateStructGEP(Base.getAddress(), idx);
   assert(!FieldType.getObjCGCAttr() && "fields cannot have GC attrs");
diff --git a/tools/clang/lib/CodeGen/CGExprAgg.cpp b/tools/clang/lib/CodeGen/CGExprAgg.cpp
index 4cf94c0..53f4bb5 100644
--- a/tools/clang/lib/CodeGen/CGExprAgg.cpp
+++ b/tools/clang/lib/CodeGen/CGExprAgg.cpp
@@ -1405,12 +1405,13 @@ void CodeGenFunction::EmitAggregateCopy(llvm::Value *DestPtr,
   if (getLangOpts().CPlusPlus) {
     if (const RecordType *RT = Ty->getAs<RecordType>()) {
       CXXRecordDecl *Record = cast<CXXRecordDecl>(RT->getDecl());
-      assert((Record->hasTrivialCopyConstructor() || 
+	  // TODO: fix this!
+      /*assert((Record->hasTrivialCopyConstructor() ||
               Record->hasTrivialCopyAssignment() ||
               Record->hasTrivialMoveConstructor() ||
               Record->hasTrivialMoveAssignment()) &&
              "Trying to aggregate-copy a type without a trivial copy/move "
-             "constructor or assignment operator");
+             "constructor or assignment operator");*/
       // Ignore empty classes in C++.
       if (Record->isEmpty())
         return;
diff --git a/tools/clang/lib/CodeGen/CGExprCXX.cpp b/tools/clang/lib/CodeGen/CGExprCXX.cpp
index 7aacee4..5c002e0 100644
--- a/tools/clang/lib/CodeGen/CGExprCXX.cpp
+++ b/tools/clang/lib/CodeGen/CGExprCXX.cpp
@@ -24,6 +24,8 @@
 using namespace clang;
 using namespace CodeGen;
 
+// TODO: fix other This uses?
+
 RValue CodeGenFunction::EmitCXXMemberCall(const CXXMethodDecl *MD,
                                           SourceLocation CallLoc,
                                           llvm::Value *Callee,
@@ -46,7 +48,8 @@ RValue CodeGenFunction::EmitCXXMemberCall(const CXXMethodDecl *MD,
   CallArgList Args;
 
   // Push the this ptr.
-  Args.add(RValue::get(This), MD->getThisType(getContext()));
+  auto this_type = getContext().getAddrSpaceQualType(MD->getThisType(getContext()), This->getType()->getPointerAddressSpace());
+  Args.add(RValue::get(This), this_type);
 
   // If there is an implicit parameter (e.g. VTT), emit it.
   if (ImplicitParam) {
diff --git a/tools/clang/lib/CodeGen/CGOpenCLRuntime.cpp b/tools/clang/lib/CodeGen/CGOpenCLRuntime.cpp
index 079ef72..ba16e2c 100644
--- a/tools/clang/lib/CodeGen/CGOpenCLRuntime.cpp
+++ b/tools/clang/lib/CodeGen/CGOpenCLRuntime.cpp
@@ -36,32 +36,138 @@ llvm::Type *CGOpenCLRuntime::convertOpenCLSpecificType(const Type *T) {
   llvm::LLVMContext& Ctx = CGM.getLLVMContext();
   uint32_t ImgAddrSpc =
     CGM.getContext().getTargetAddressSpace(LangAS::opencl_global);
-  switch (cast<BuiltinType>(T)->getKind()) {
-  default: 
-    llvm_unreachable("Unexpected opencl builtin type!");
-    return nullptr;
-  case BuiltinType::OCLImage1d:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image1d_t"), ImgAddrSpc);
-  case BuiltinType::OCLImage1dArray:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image1d_array_t"), ImgAddrSpc);
-  case BuiltinType::OCLImage1dBuffer:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image1d_buffer_t"), ImgAddrSpc);
-  case BuiltinType::OCLImage2d:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image2d_t"), ImgAddrSpc);
-  case BuiltinType::OCLImage2dArray:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image2d_array_t"), ImgAddrSpc);
-  case BuiltinType::OCLImage3d:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.image3d_t"), ImgAddrSpc);
-  case BuiltinType::OCLSampler:
-    return llvm::IntegerType::get(Ctx, 32);
-  case BuiltinType::OCLEvent:
-    return llvm::PointerType::get(llvm::StructType::create(
-                           Ctx, "opencl.event_t"), 0);
+
+  if(!CGM.getCodeGenOpts().EmitAppleCLMetadata && !CGM.getLangOpts().Metal) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+      default:
+        llvm_unreachable("Unexpected opencl builtin type!");
+        return nullptr;
+      case BuiltinType::OCLImage1d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image1d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image1d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dBuffer:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image1d_buffer_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_array_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_msaa_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_array_msaa_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_msaa_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image2d_array_msaa_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCube:
+      case BuiltinType::OCLImageCubeArray:
+      case BuiltinType::OCLImageCubeDepth:
+      case BuiltinType::OCLImageCubeArrayDepth:
+        // NOTE: cube map types not handled/implemented yet
+        llvm_unreachable("Unsupported image type (cube maps are not supported by opencl)!");
+        return nullptr;
+      case BuiltinType::OCLImage3d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.image3d_t"), ImgAddrSpc);
+      case BuiltinType::OCLSampler:
+        return llvm::IntegerType::get(Ctx, 32);
+      case BuiltinType::OCLEvent:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "opencl.event_t"), 0);
+    }
+  }
+  else if(CGM.getCodeGenOpts().EmitAppleCLMetadata) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+      default:
+        llvm_unreachable("Unexpected opencl builtin type!");
+        return nullptr;
+      case BuiltinType::OCLImage1d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image1d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image1d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dBuffer:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image1d_buffer_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_array_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_msaa_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_array_msaa_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_msaa_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image2d_array_msaa_depth_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCube:
+      case BuiltinType::OCLImageCubeArray:
+      case BuiltinType::OCLImageCubeDepth:
+      case BuiltinType::OCLImageCubeArrayDepth:
+        // NOTE: cube map types not handled/implemented yet
+        llvm_unreachable("Unsupported image type (cube maps are not supported by opencl)!");
+        return nullptr;
+      case BuiltinType::OCLImage3d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._image3d_t"), ImgAddrSpc);
+      case BuiltinType::OCLSampler:
+        return llvm::IntegerType::get(Ctx, 32);
+      case BuiltinType::OCLEvent:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._event_t"), 0);
+    }
+  }
+  else if(CGM.getLangOpts().Metal) {
+    switch (cast<BuiltinType>(T)->getKind()) {
+      default:
+        llvm_unreachable("Unexpected metal builtin type!");
+        return nullptr;
+      case BuiltinType::OCLImage1d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_1d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage1dBuffer:
+        llvm_unreachable("Unsupported image type (1D-buffer is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dMSAA:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAA:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImage2dMSAADepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_2d_ms_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage2dArrayMSAADepth:
+        llvm_unreachable("Unsupported image type (2D-Array-MSAA-Depth is not supported by metal)!");
+        return nullptr;
+      case BuiltinType::OCLImageCube:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArray:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_t"), ImgAddrSpc);
+      case BuiltinType::OCLImageCubeArrayDepth:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._depth_cube_array_t"), ImgAddrSpc);
+      case BuiltinType::OCLImage3d:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._texture_3d_t"), ImgAddrSpc);
+      case BuiltinType::OCLSampler:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._sampler_t"),
+                                      CGM.getContext().getTargetAddressSpace(LangAS::opencl_constant));
+      case BuiltinType::OCLEvent:
+        return llvm::PointerType::get(llvm::StructType::create(Ctx, "struct._event_t"), 0);
+    }
   }
+  llvm_unreachable("Unexpected builtin type!");
+  return nullptr;
 }
diff --git a/tools/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp b/tools/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp
index a10d8e7..852a803 100644
--- a/tools/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp
+++ b/tools/clang/lib/CodeGen/CGRecordLayoutBuilder.cpp
@@ -765,6 +765,43 @@ CGRecordLayout *CodeGenTypes::ComputeRecordLayout(const RecordDecl *D,
   return RL;
 }
 
+
+void CodeGenTypes::create_flattened_cg_layout(const CXXRecordDecl* D, llvm::StructType* Ty,
+											  const std::vector<CodeGenTypes::aggregate_scalar_entry>& fields) {
+	bool zero_init = true;
+	for(const auto& field : fields) {
+		// vector types (or replaced vector types) are always zero initializable
+		if(field.type->isExtVectorType() ||
+		   field.type->isVectorType()) {
+			continue;
+		}
+		
+		// else: need to make some calls based on the field decl type
+		const Type *Type = field.field_decl->getType()->getBaseElementTypeUnsafe();
+		if (const MemberPointerType *MPT = Type->getAs<MemberPointerType>()) {
+			if(!TheCXXABI.isZeroInitializable(MPT)) {
+				zero_init = false;
+				break;
+			}
+		}
+		else if (const CXXRecordDecl* cxx_rdecl = Type->getAsCXXRecordDecl()) {
+			if(!isZeroInitializable(cxx_rdecl)) {
+				zero_init = false;
+				break;
+			}
+		}
+		// else: it is zero initializable
+	}
+	
+	CGRecordLayout *RL = new CGRecordLayout(Ty, Ty, zero_init, zero_init);
+	uint32_t field_idx = 0;
+	for(const auto& field : fields) {
+		RL->FieldInfo.insert({ field.field_decl, field_idx++ });
+	}
+	
+	FlattenedCGRecordLayouts.insert({ Ty, RL });
+}
+
 void CGRecordLayout::print(raw_ostream &OS) const {
   OS << "<CGRecordLayout\n";
   OS << "  LLVMType:" << *CompleteObjectType << "\n";
diff --git a/tools/clang/lib/CodeGen/CodeGenFunction.cpp b/tools/clang/lib/CodeGen/CodeGenFunction.cpp
index 5ca3a78..bb30aa2 100644
--- a/tools/clang/lib/CodeGen/CodeGenFunction.cpp
+++ b/tools/clang/lib/CodeGen/CodeGenFunction.cpp
@@ -30,6 +30,8 @@
 #include "llvm/IR/Intrinsics.h"
 #include "llvm/IR/MDBuilder.h"
 #include "llvm/IR/Operator.h"
+#include <sstream>
+#include <unordered_set>
 using namespace clang;
 using namespace CodeGen;
 
@@ -333,6 +335,112 @@ void CodeGenFunction::EmitMCountInstrumentation() {
   EmitNounwindRuntimeCall(MCountFn);
 }
 
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained fields
+static std::vector<RecordDecl::field_iterator> get_aggregate_fields(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	//
+	std::vector<RecordDecl::field_iterator> ret;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_fields(base.getType()->getAsCXXRecordDecl());
+		if(!base_ret.empty()) {
+			ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+		}
+	}
+	
+	// iterate over all fields/members
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		ret.push_back(iter);
+	}
+	
+	return ret;
+}
+
+// will recurse through the specified class/struct decl and its base classes,
+// returning a vector containing all iterators to all contained image types
+// NOTE: will return an empty vector if not a proper aggregate image
+static std::vector<RecordDecl::field_iterator> get_aggregate_image_fields(const CXXRecordDecl* decl) {
+	// extract all fields, then check if all are image types (if one isn't, fail)
+	const auto ret = get_aggregate_fields(decl);
+	for(const auto& iter : ret) {
+		if(!iter->getType()->isImageType()) {
+			return {};
+		}
+	}
+	return ret;
+}
+
+// will recurse through the specified class/struct decl and its base classes,
+// returning the first image access attribute that it encounters (or nullptr if none)
+static const ImageAccessAttr* get_aggregate_access_attr(const CXXRecordDecl* decl) {
+	if(decl == nullptr) return nullptr;
+	
+	// must have definition
+	if(!decl->hasDefinition()) return nullptr;
+	
+	// iterate over / recurse into all bases
+	for(const auto& base : decl->bases()) {
+		const auto base_ret = get_aggregate_access_attr(base.getTypeSourceInfo()->getType()->getAsCXXRecordDecl());
+		if(base_ret != nullptr) {
+			return base_ret;
+		}
+	}
+	
+	// iterate over all fields/members and return the first access attr
+	for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+		// try direct attr first
+		const ImageAccessAttr* access_attr = iter->getAttr<ImageAccessAttr>();
+		if(access_attr != nullptr) {
+			return access_attr;
+		}
+		
+		// then check if this is a c++ decl (struct/union/class) and check if it has the attr
+		const auto as_decl = iter->getType()->getAsCXXRecordDecl();
+		if(as_decl != nullptr) {
+			access_attr = as_decl->getAttr<ImageAccessAttr>();
+			if(access_attr != nullptr) {
+				return access_attr;
+			}
+		}
+	}
+	
+	return nullptr;
+}
+
+
+// Metadata values extractors.
+static std::string getScalarMetadataValue(const clang::Type *Ty) {
+	if (Ty->isHalfType()) return "half";
+	
+	if (!Ty->isUnsignedIntegerType()) {
+		return QualType(Ty, 0).getAsString();
+	}
+	
+	std::string TyName = QualType(Ty, 0).getAsString();
+	if (llvm::StringRef(TyName).startswith("unsigned")) {
+		// Replace unsigned <ty> with u<ty>
+		TyName.erase(1, 8);
+	}
+	
+	return TyName;
+}
+static std::string getVectorMetadataValue(const clang::ExtVectorType *Ty) {
+	const clang::VectorType *VTy = llvm::dyn_cast<clang::VectorType>(Ty);
+	assert(VTy && "Cast to vector failed");
+	
+	std::stringstream Ret;
+	Ret << getScalarMetadataValue(VTy->getElementType().getTypePtr());
+	Ret << VTy->getNumElements();
+	
+	return Ret.str();
+}
+
 // OpenCL v1.2 s5.6.4.6 allows the compiler to store kernel argument
 // information in the program executable. The argument information stored
 // includes the argument name, its type, the address and access qualifiers used.
@@ -340,127 +448,1180 @@ static void GenOpenCLArgMetadata(const FunctionDecl *FD, llvm::Function *Fn,
                                  CodeGenModule &CGM,llvm::LLVMContext &Context,
                                  SmallVector <llvm::Value*, 5> &kernelMDArgs,
                                  CGBuilderTy& Builder, ASTContext &ASTCtx) {
-  // Create MDNodes that represent the kernel arg metadata.
-  // Each MDNode is a list in the form of "key", N number of values which is
-  // the same number of values as their are kernel arguments.
-
-  const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
-
-  // MDNode for the kernel argument address space qualifiers.
-  SmallVector<llvm::Value*, 8> addressQuals;
-  addressQuals.push_back(llvm::MDString::get(Context, "kernel_arg_addr_space"));
-
-  // MDNode for the kernel argument access qualifiers (images only).
-  SmallVector<llvm::Value*, 8> accessQuals;
-  accessQuals.push_back(llvm::MDString::get(Context, "kernel_arg_access_qual"));
-
-  // MDNode for the kernel argument type names.
-  SmallVector<llvm::Value*, 8> argTypeNames;
-  argTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_type"));
-
-  // MDNode for the kernel argument type qualifiers.
-  SmallVector<llvm::Value*, 8> argTypeQuals;
-  argTypeQuals.push_back(llvm::MDString::get(Context, "kernel_arg_type_qual"));
-
-  // MDNode for the kernel argument names.
-  SmallVector<llvm::Value*, 8> argNames;
-  argNames.push_back(llvm::MDString::get(Context, "kernel_arg_name"));
-
-  for (unsigned i = 0, e = FD->getNumParams(); i != e; ++i) {
-    const ParmVarDecl *parm = FD->getParamDecl(i);
-    QualType ty = parm->getType();
-    std::string typeQuals;
-
-    if (ty->isPointerType()) {
-      QualType pointeeTy = ty->getPointeeType();
-
-      // Get address qualifier.
-      addressQuals.push_back(Builder.getInt32(ASTCtx.getTargetAddressSpace(
-        pointeeTy.getAddressSpace())));
-
-      // Get argument type name.
-      std::string typeName =
-          pointeeTy.getUnqualifiedType().getAsString(Policy) + "*";
-
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (pos != std::string::npos)
-        typeName.erase(pos+1, 8);
-
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
-
-      // Get argument type qualifiers:
-      if (ty.isRestrictQualified())
-        typeQuals = "restrict";
-      if (pointeeTy.isConstQualified() ||
-          (pointeeTy.getAddressSpace() == LangAS::opencl_constant))
-        typeQuals += typeQuals.empty() ? "const" : " const";
-      if (pointeeTy.isVolatileQualified())
-        typeQuals += typeQuals.empty() ? "volatile" : " volatile";
-    } else {
-      uint32_t AddrSpc = 0;
-      if (ty->isImageType())
-        AddrSpc =
-          CGM.getContext().getTargetAddressSpace(LangAS::opencl_global);
-
-      addressQuals.push_back(Builder.getInt32(AddrSpc));
-
-      // Get argument type name.
-      std::string typeName = ty.getUnqualifiedType().getAsString(Policy);
-
-      // Turn "unsigned type" to "utype"
-      std::string::size_type pos = typeName.find("unsigned");
-      if (pos != std::string::npos)
-        typeName.erase(pos+1, 8);
-
-      argTypeNames.push_back(llvm::MDString::get(Context, typeName));
-
-      // Get argument type qualifiers:
-      if (ty.isConstQualified())
-        typeQuals = "const";
-      if (ty.isVolatileQualified())
-        typeQuals += typeQuals.empty() ? "volatile" : " volatile";
-    }
-
-    argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+	// Create MDNodes that represent the kernel arg metadata.
+	// Each MDNode is a list in the form of "key", N number of values which is
+	// the same number of values as their are kernel arguments.
+	
+	// MDNode for the kernel argument address space qualifiers.
+	SmallVector<llvm::Value*, 8> addressQuals;
+	addressQuals.push_back(llvm::MDString::get(Context, "kernel_arg_addr_space"));
+	
+	// MDNode for the kernel argument access qualifiers (images only).
+	SmallVector<llvm::Value*, 8> accessQuals;
+	accessQuals.push_back(llvm::MDString::get(Context, "kernel_arg_access_qual"));
+	
+	// MDNode for the kernel argument type names.
+	SmallVector<llvm::Value*, 8> argTypeNames;
+	argTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_type"));
+	
+	// MDNode for the kernel argument base type names.
+	SmallVector<llvm::Value*, 8> argBaseTypeNames;
+	argBaseTypeNames.push_back(llvm::MDString::get(Context, "kernel_arg_base_type"));
+	
+	// MDNode for the kernel argument type qualifiers.
+	SmallVector<llvm::Value*, 8> argTypeQuals;
+	argTypeQuals.push_back(llvm::MDString::get(Context, "kernel_arg_type_qual"));
+	
+	// MDNode for the kernel argument names.
+	SmallVector<llvm::Value*, 8> argNames;
+	argNames.push_back(llvm::MDString::get(Context, "kernel_arg_name"));
+	
+	// Creates a canonical name for complex types. In case of anonymous types, the
+	// function appends the meta-type name as prefix: e.g., in case the type is
+	// defined as: typedef struct {...} S, the method returns struct S.
+	static const auto canonicalName = [](const std::string &TyName,
+										 const std::string &MetaTyName) {
+		if (StringRef(TyName).startswith(MetaTyName)) {
+			return TyName;
+		}
+		
+		return std::string(MetaTyName) + " __" + TyName;
+	};
+	
+	static const auto getComplexMetadataValue = [](const clang::Type *Ty) {
+		std::string TyName = QualType(Ty, 0).getCanonicalType().getAsString();
+		
+		if (Ty->isStructureOrClassType()) {
+			return canonicalName(TyName, "struct");
+		}
+		
+		if (Ty->isUnionType()) {
+			return canonicalName(TyName, "union");
+		}
+		
+		if (Ty->isEnumeralType()) {
+			return canonicalName(TyName, "enum");
+		}
+		
+		return getScalarMetadataValue(Ty);
+	};
+	
+	static const auto getPointerOrRefMetadataValue = [](const clang::Type *PTy, bool CanTy) {
+		std::string Ret;
+		
+		if (const ExtVectorType *VTy = llvm::dyn_cast<ExtVectorType>(PTy)) {
+			Ret = getVectorMetadataValue(VTy);
+		}
+		else {
+			Ret = CanTy ? getComplexMetadataValue(PTy) : getScalarMetadataValue(PTy);
+		}
+		
+		return Ret + "*";
+	};
+	
+	const auto add_image_arg = [&Builder, &Context, &CGM,
+								&addressQuals, &accessQuals, &argTypeNames, &argBaseTypeNames,
+								&argNames, &argTypeQuals](const clang::QualType& type,
+														  const ImageAccessAttr* access_attr,
+														  const std::string& name) {
+		// image is always in global address space
+		addressQuals.push_back(Builder.getInt32(CGM.getContext().getTargetAddressSpace(LangAS::opencl_global)));
+		
+		// set access qualifier
+		if (access_attr && access_attr->isWriteOnly()) {
+			accessQuals.push_back(llvm::MDString::get(Context, "write_only"));
+		}
+		else if (access_attr && access_attr->isReadWrite()) {
+			accessQuals.push_back(llvm::MDString::get(Context, "read_write"));
+		}
+		else {
+			accessQuals.push_back(llvm::MDString::get(Context, "read_only"));
+		}
+		
+		// image type / base type
+		// NOTE: always set base type, because types in image aggregates might be "weird", but should be considered normal
+		const QualType baseTy = type.isCanonical() ? type : type.getCanonicalType();
+		const auto type_name = getComplexMetadataValue(baseTy.getTypePtr());
+		argTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		argBaseTypeNames.push_back(llvm::MDString::get(Context, type_name));
+		
+		// set arg name
+		argNames.push_back(llvm::MDString::get(Context, name));
+		
+		// type quals is always empty for images
+		argTypeQuals.push_back(llvm::MDString::get(Context, ""));
+	};
+	
+	for(const auto& parm : FD->params()) {
+		const auto clang_type = parm->getType();
+		const bool IsCanonical = clang_type.isCanonical();
+		
+		// pointer / buffer
+		if (clang_type->isPointerType() || clang_type->isReferenceType()) {
+			// Get argument type name.
+			std::string tyName;
+			if (const PointerType *PTy = dyn_cast<PointerType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(PTy->getPointeeType().getTypePtr(), false);
+			}
+			else if (const ReferenceType *RTy = dyn_cast<ReferenceType>(clang_type.getTypePtr())) {
+				tyName = getPointerOrRefMetadataValue(RTy->getPointeeType().getTypePtr(), false);
+			}
+			else {
+				tyName = getScalarMetadataValue(clang_type.getTypePtr());
+			}
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			std::string baseTyName;
+			if (IsCanonical) baseTyName = tyName;
+			else {
+				baseTyName = getPointerOrRefMetadataValue(clang_type.getCanonicalType()->getAs<PointerType>()->getPointeeType().getTypePtr(), true);
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get address qualifier.
+			QualType pointeeTy = clang_type->getPointeeType();
+			addressQuals.push_back(Builder.getInt32(ASTCtx.getTargetAddressSpace(pointeeTy.getAddressSpace())));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isRestrictQualified()) {
+				typeQuals = "restrict";
+			}
+			if (pointeeTy.isConstQualified() ||
+				(pointeeTy.getAddressSpace() == LangAS::opencl_constant)) {
+				typeQuals += typeQuals.empty() ? "const" : " const";
+			}
+			if (pointeeTy.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			accessQuals.push_back(llvm::MDString::get(Context, "none"));
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+		// normal image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getName().str());
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto decl = clang_type->getAsCXXRecordDecl();
+			const auto agg_images = get_aggregate_image_fields(decl);
+			
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				const auto img_type = img->getType();
+				
+				add_image_arg(img_type, img->getAttr<ImageAccessAttr>(),
+							  base_name + std::to_string(img_idx));
+				++img_idx;
+			}
+		}
+		// kernel parameter
+		else {
+			addressQuals.push_back(Builder.getInt32(0 /* private address space*/));
+			
+			// Get argument type name.
+			std::string tyName = getScalarMetadataValue(clang_type.getTypePtr());
+			argTypeNames.push_back(llvm::MDString::get(Context, tyName));
+			
+			// Acquiring the base type of the parameter.
+			QualType baseTy = IsCanonical ? clang_type : clang_type.getCanonicalType();
+			std::string baseTyName;
+			if (clang_type->isVectorType()) {
+				baseTyName = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(baseTy.getTypePtr()));
+			}
+			else {
+				baseTyName = getComplexMetadataValue(baseTy.getTypePtr());
+			}
+			argBaseTypeNames.push_back(llvm::MDString::get(Context, baseTyName));
+			
+			// Get argument type qualifiers:
+			std::string typeQuals;
+			if (clang_type.isConstQualified()) {
+				typeQuals = "const";
+			}
+			if (clang_type.isVolatileQualified()) {
+				typeQuals += typeQuals.empty() ? "volatile" : " volatile";
+			}
+			argTypeQuals.push_back(llvm::MDString::get(Context, typeQuals));
+			
+			accessQuals.push_back(llvm::MDString::get(Context, "none"));
+			argNames.push_back(llvm::MDString::get(Context, parm->getName()));
+		}
+	}
+	
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, addressQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, accessQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argBaseTypeNames));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeQuals));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, argNames));
+}
 
-    // Get image access qualifier:
-    if (ty->isImageType()) {
-      const OpenCLImageAccessAttr *A = parm->getAttr<OpenCLImageAccessAttr>();
-      if (A && A->isWriteOnly())
-        accessQuals.push_back(llvm::MDString::get(Context, "write_only"));
-      else
-        accessQuals.push_back(llvm::MDString::get(Context, "read_only"));
-      // FIXME: what about read_write?
-    } else
-      accessQuals.push_back(llvm::MDString::get(Context, "none"));
+static void GenAIRMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+						   CodeGenModule &CGM,llvm::LLVMContext &Context,
+						   SmallVector <llvm::Value*, 5> &kernelMDArgs,
+						   CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	
+	//
+	SmallVector<llvm::Value*, 4> stage_infos;
+	SmallVector<llvm::Value*, 8> arg_infos;
+	
+	//
+	const PrintingPolicy &Policy = ASTCtx.getPrintingPolicy();
+	const auto make_type_name = [&Policy](const clang::QualType& type) {
+		// NOTE: air wants the type w/o qualifiers
+		const auto base_unq_type = type.getTypePtr()->getBaseElementTypeUnsafe();
+		const auto unqualified_type = base_unq_type->getCanonicalTypeInternal();
+		std::string type_name = "";
+		if(type->isVectorType()) {
+			type_name = getVectorMetadataValue(llvm::dyn_cast<clang::ExtVectorType>(unqualified_type.getTypePtr()));
+		}
+		else if(type->isHalfType()) type_name = "half";
+		else type_name = unqualified_type.getAsString(Policy);
+		// Turn "unsigned type" to "utype"
+		const auto pos = type_name.find("unsigned");
+		if(pos != std::string::npos) type_name.erase(pos + 1, 8);
+		return type_name;
+	};
+	
+	//
+	unsigned int arg_idx = 0, buffer_idx = 0, tex_idx = 0;
+	for(const auto& parm : FD->params()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+
+		const auto add_image_arg = [&Builder, &tex_idx, &arg_infos, &arg_idx,
+									&Context, &ASTCtx, &CGM](const clang::QualType& type,
+															 const ImageAccessAttr* access_attr,
+															 const FloorImageDataTypeAttr* data_type,
+															 const std::string& name) {
+			SmallVector<llvm::Value*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(Builder.getInt32(arg_idx));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.texture"));
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(Builder.getInt32(tex_idx));
+			++tex_idx;
+			// #4: unknown? always 1
+			arg_info.push_back(Builder.getInt32(1));
+			// #5: access type (sample = 0, read = 1 or write = 2)
+			// note that "read" is essentially a subset of "sample" -> use "sample" for r/o
+			if(access_attr && access_attr->isWriteOnly()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else if(access_attr && access_attr->isReadWrite()) {
+				// TODO: this isn't really supported
+				arg_info.push_back(llvm::MDString::get(Context, "air.write"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.sample"));
+			}
+			
+			// #6/#7: texture type
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// proper type is necessary for metal debugging purposes
+			std::string tex_type_name;
+			if(type->isImage1dT()) tex_type_name = "texture1d";
+			else if(type->isImage1dArrayT()) tex_type_name = "texture1d_array";
+			//else if(type->isImage1dBufferT()) tex_type_name = ""; // not supported
+			else if(type->isImage2dT()) tex_type_name = "texture2d";
+			else if(type->isImage2dArrayT()) tex_type_name = "texture2d_array";
+			else if(type->isImage2dDepthT()) tex_type_name = "depth2d";
+			else if(type->isImage2dArrayDepthT()) tex_type_name = "depth2d_array";
+			else if(type->isImage2dMSAAT()) tex_type_name = "texture2d_ms";
+			//else if(type->isImage2dArrayMSAAT()) tex_type_name = ""; // not supported
+			else if(type->isImage2dMSAADepthT()) tex_type_name = "depth2d_ms";
+			//else if(type->isImage2dArrayMSAADepthT()) tex_type_name = ""; // not supported
+			else if(type->isImage3dT()) tex_type_name = "texture3d";
+			else if(type->isImageCubeT()) tex_type_name = "texturecube";
+			else if(type->isImageCubeArrayT()) tex_type_name = "texturecube_array";
+			else if(type->isImageCubeDepthT()) tex_type_name = "depthcube";
+			else if(type->isImageCubeArrayDepthT()) tex_type_name = "depthcube_array";
+			else tex_type_name = "texture";
+			
+			tex_type_name += "<";
+			std::string sample_type_str = "float";
+			if(data_type) {
+				const auto canon_data_type = data_type->getImageDataType().getCanonicalType();
+				if(canon_data_type->isIntegerType()) sample_type_str = "int";
+				if(canon_data_type->isUnsignedIntegerType()) sample_type_str = "uint";
+				// else: just assume float
+			}
+			tex_type_name += sample_type_str;
+			tex_type_name += ", ";
+			if(access_attr && access_attr->isReadOnly()) {
+				tex_type_name += "sample";
+			}
+			else tex_type_name += "write";
+			tex_type_name += ">";
+			
+			arg_info.push_back(llvm::MDString::get(Context, tex_type_name));
+			
+			// #8/#9: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, StringRef(name)));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		};
+		
+		// pointer / buffer
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			SmallVector<llvm::Value*, 16> arg_info;
+			
+			// #0: param index
+			arg_info.push_back(Builder.getInt32(arg_idx));
+			// #1: storage type
+			arg_info.push_back(llvm::MDString::get(Context, "air.buffer"));
+			
+			// references / single-object parameters also store/require the buffer_size
+			if(clang_type->isReferenceType()) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.buffer_size"));
+				arg_info.push_back(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type)));
+			}
+			
+			// #2/#3: location_index (note: separate for buffers and textures)
+			arg_info.push_back(llvm::MDString::get(Context, "air.location_index"));
+			arg_info.push_back(Builder.getInt32(buffer_idx));
+			++buffer_idx;
+			// #4: unknown? always 1
+			arg_info.push_back(Builder.getInt32(1));
+			// #5: access (read/read_write, TODO: write?)
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			if(clang_pointee_type.isConstQualified() ||
+			   (clang_pointee_type.getAddressSpace() == LangAS::opencl_constant)) {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "air.read_write"));
+			}
+			
+			// #6/#7: struct info
+			if(const auto pointee_rdecl = clang_pointee_type->getAsCXXRecordDecl()) {
+				SmallVector<llvm::Value*, 16> struct_info;
+				// TODO: this is not ideal and doesn't handle properly handle unions
+				const auto fields = get_aggregate_fields(pointee_rdecl);
+				bool ignore = false;
+				for(const auto& field : fields) {
+					if(field->isAnonymousStructOrUnion() ||
+					   field->isBitField()) {
+						ignore = true;
+						break;
+					}
+				}
+				
+				// TODO/NOTE: ignore anonymous structs/unions and bitfields for now
+				if(!ignore) {
+					SmallVector<llvm::Value*, 16> struct_info;
+					arg_info.push_back(llvm::MDString::get(Context, "air.struct_type_info"));
+					
+					uint32_t offset = 0;
+					for(const auto& field : fields) {
+						// #0: offset
+						struct_info.push_back(Builder.getInt32(offset));
+						// #1: sizeof
+						const auto llvm_mem_type = CGM.getTypes().ConvertTypeForMem(field->getType()); // TODO: should use this _everywhere_ instead of llvm type tracking/matching!
+						const auto size = (uint32_t)CGM.getDataLayout().getTypeStoreSize(llvm_mem_type);
+						offset += size;
+						struct_info.push_back(Builder.getInt32(size));
+						// #2: TODO? array or padding maybe?
+						struct_info.push_back(Builder.getInt32(0));
+						// #3: type name
+						struct_info.push_back(llvm::MDString::get(Context, make_type_name(field->getType())));
+						// #4: name/identifier
+						struct_info.push_back(llvm::MDString::get(Context, field->getName()));
+					}
+					arg_info.push_back(llvm::MDNode::get(Context, struct_info));
+				}
+			}
+			
+			// #8/#9: type size
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_size"));
+			arg_info.push_back(Builder.getInt32(CGM.getDataLayout().getTypeStoreSize(pointee_type)));
+			// #10/#11: type alignment
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_align_size"));
+			// max out at 16, anything higher is unreasonable
+			// TODO: make sure this is POT
+			const auto align_size = std::min(CGM.getDataLayout().getTypeAllocSize(pointee_type), uint64_t(16));
+			arg_info.push_back(Builder.getInt32(align_size));
+			//getPrimitiveSizeInBits
+			// #12/#13: type name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			// NOTE: air wants the pointed-to/pointee type here
+			arg_info.push_back(llvm::MDString::get(Context, make_type_name(clang_type->getPointeeType())));
+			// #14/#15: arg name
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, parm->getName()));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		}
+		// image
+		else if(clang_type->isImageType()) {
+			add_image_arg(clang_type, parm->getAttr<ImageAccessAttr>(),
+						  parm->getAttr<FloorImageDataTypeAttr>(), parm->getName().str());
+		}
+		// aggregate image
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			const std::string base_name = parm->getName().str() + ".";
+			unsigned int img_idx = 0;
+			for(const auto& img : agg_images) {
+				const auto img_type = img->getType();
+				
+				add_image_arg(img_type, img->getAttr<ImageAccessAttr>(),
+							  img->getAttr<FloorImageDataTypeAttr>(), base_name + std::to_string(img_idx));
+				++img_idx;
+				
+				// next llvm arg
+				++arg_idx;
+			}
+			// fix up llvm arg count (will inc again after this)
+			--arg_idx;
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					SmallVector<llvm::Value*, 16> arg_info;
+					
+					// #0: param index
+					arg_info.push_back(Builder.getInt32(arg_idx));
+					
+					// #1: type
+					// TODO: handle perspective/center correctly
+					if(field.hasAttr<GraphicsVertexPositionAttr>()) {
+						arg_info.push_back(llvm::MDString::get(Context, "air.position"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.no_perspective"));
+					}
+					else {
+						arg_info.push_back(llvm::MDString::get(Context, "air.fragment_input"));
+						arg_info.push_back(llvm::MDString::get(Context, StringRef(field.mangled_name)));
+						arg_info.push_back(llvm::MDString::get(Context, "air.center"));
+						arg_info.push_back(llvm::MDString::get(Context, "air.perspective"));
+					}
+					
+					// type name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					arg_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// arg name
+					arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					arg_info.push_back(llvm::MDString::get(Context, field.name));
+					arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+					
+					// next
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// TODO: add as-is
+			}
+		}
+		// unsupported simple kernel parameter
+		else {
+			CGM.Error(parm->getSourceRange().getBegin(),
+					  StringRef("metal kernel parameter must be a pointer or an image type!"));
+			return;
+		}
+		
+		// next llvm arg
+		++arg_idx;
+	}
+	
+	if(is_kernel) {
+		// add id handling arg metadata
+		// NOTE: the actual args are later added by MetalFinal + the order in here must match the order in MetalFinal
+		const auto add_id_arg = [&arg_idx, &arg_infos, &Builder, &Context](const char* name, const char* air_name) {
+			SmallVector<llvm::Value*, 6> arg_info;
+			arg_info.push_back(Builder.getInt32(arg_idx));
+			arg_info.push_back(llvm::MDString::get(Context, air_name));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			arg_info.push_back(llvm::MDString::get(Context, "uint3"));
+			arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			arg_info.push_back(llvm::MDString::get(Context, name));
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+			
+			// next llvm arg
+			++arg_idx;
+		};
+		add_id_arg("__metal__global_id__", "air.thread_position_in_grid");
+		add_id_arg("__metal__global_size__", "air.threads_per_grid");
+		add_id_arg("__metal__local_id__", "air.thread_position_in_threadgroup");
+		add_id_arg("__metal__local_size__", "air.threads_per_threadgroup");
+		add_id_arg("__metal__group_id__", "air.threadgroup_position_in_grid");
+		add_id_arg("__metal__group_size__", "air.threadgroups_per_grid");
+	}
+	else if(is_vertex) {
+		// TODO: instance id
+		
+		SmallVector<llvm::Value*, 6> arg_info;
+		arg_info.push_back(Builder.getInt32(arg_idx));
+		arg_info.push_back(llvm::MDString::get(Context, "air.vertex_id"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "uint"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__vertex_id__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_vs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const bool force_position = false) {
+			SmallVector<llvm::Value*, 6> ret_info;
+			
+			if(entry.hasAttr<GraphicsVertexPositionAttr>() || force_position) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.position"));
+			}
+			else if(entry.hasAttr<GraphicsPointSizeAttr>()) {
+				ret_info.push_back(llvm::MDString::get(Context, "air.point_size"));
+			}
+			else {
+				ret_info.push_back(llvm::MDString::get(Context, "air.vertex_output"));
+				ret_info.push_back(llvm::MDString::get(Context, StringRef(entry.mangled_name)));
+			}
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			ret_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			ret_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			ret_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, ret_info));
+		};
+		
+		// vertex output
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			for(const auto& field : fields) {
+				add_vs_output(field);
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			// direct output: always vertex position, no mangled name
+			add_vs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>())
+			}, true);
+		}
+	}
+	else if(is_fragment) {
+		// TODO: other stuff
+		
+		SmallVector<llvm::Value*, 6> arg_info;
+		arg_info.push_back(Builder.getInt32(arg_idx));
+		arg_info.push_back(llvm::MDString::get(Context, "air.point_coord"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "float2"));
+		arg_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+		arg_info.push_back(llvm::MDString::get(Context, "__metal__point_coord__"));
+		arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		++arg_idx; // next llvm arg
+		
+		const auto add_fs_output = [&Context, &Builder, &ASTCtx, &CGM,
+									&stage_infos, &make_type_name](const CodeGenTypes::aggregate_scalar_entry& entry,
+																   const unsigned int& location) {
+			SmallVector<llvm::Value*, 6> rtt_info;
+			
+			// #0/1: render target location index
+			rtt_info.push_back(llvm::MDString::get(Context, "air.render_target"));
+			rtt_info.push_back(Builder.getInt32(location));
+			
+			// #2/3: type name
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, make_type_name(entry.type)));
+			
+			// #4/#5: name/identifier
+			rtt_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+			rtt_info.push_back(llvm::MDString::get(Context, entry.name));
+			
+			stage_infos.push_back(llvm::MDNode::get(Context, rtt_info));
+		};
+		
+		// render targets / return types
+		const auto ret_type = FD->getReturnType();
+		const auto cxx_rdecl = ret_type->getAsCXXRecordDecl();
+		if(cxx_rdecl && !cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+			const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+			
+			// fbo output location resolve/computation needs to happen in two passes:
+			// * gather all fixed/attr locations, make sure none conflict
+			// * used fixed locations + generate automatic location for non-fixed outputs
+			std::unordered_set<unsigned int> fbo_locations;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					const auto loc_attr = field.getAttr<GraphicsFBOColorLocationAttr>();
+					if(!fbo_locations.insert(loc_attr->getEvalLocation()).second) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(loc_attr->getLocation(), StringRef("location already in use"));
+						// TODO: add note of prev location?
+						return;
+					}
+				}
+			}
+			
+			unsigned int location = 0;
+			for(const auto& field : fields) {
+				if(field.hasAttr<GraphicsFBOColorLocationAttr>()) {
+					add_fs_output(field, field.getAttr<GraphicsFBOColorLocationAttr>()->getEvalLocation());
+				}
+				else if(field.hasAttr<GraphicsFBODepthTypeAttr>()) {
+					const auto depth_attr = field.getAttr<GraphicsFBODepthTypeAttr>();
+					if(!field.type->isFloatingType()) {
+						// TODO: should have been detected earlier ...
+						CGM.Error(depth_attr->getLocation(),
+								  StringRef("depth attribute can only be applied to floating point types"));
+						return;
+					}
+					
+					SmallVector<llvm::Value*, 7> depth_info;
+					
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth"));
+					
+					// #1/2: depth qualifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.depth_qualifier"));
+					std::string depth_qual = "air.";
+					switch(depth_attr->getDepthQualifier()) {
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeAny: depth_qual += "any"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeLess: depth_qual += "less"; break;
+						case clang::GraphicsFBODepthTypeAttr::FBODepthTypeGreater: depth_qual += "greater"; break;
+					}
+					depth_info.push_back(llvm::MDString::get(Context, depth_qual));
+					
+					// #3/4: type name
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_type_name"));
+					depth_info.push_back(llvm::MDString::get(Context, make_type_name(field.type)));
+					
+					// #5/#6: name/identifier
+					depth_info.push_back(llvm::MDString::get(Context, "air.arg_name"));
+					depth_info.push_back(llvm::MDString::get(Context, field.name));
+					
+					stage_infos.push_back(llvm::MDNode::get(Context, depth_info));
+				}
+				else {
+					for(;;) {
+						if(fbo_locations.count(location) > 0) {
+							++location;
+						}
+						else break;
+					}
+					add_fs_output(field, location);
+					++location;
+				}
+			}
+		}
+		else if(!ret_type->isVoidType()) {
+			add_fs_output(CodeGenTypes::aggregate_scalar_entry {
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>() ?
+				 CGM.getTypes().get_compat_vector_type(cxx_rdecl) : ret_type),
+				FD->getName().str(), // func name if direct
+				"",
+				nullptr,
+				nullptr,
+				{},
+				(cxx_rdecl && cxx_rdecl->hasAttr<VectorCompatAttr>())
+			}, 0);
+		}
+	}
+
+	// insert into kernel metadata
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, stage_infos));
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, arg_infos));
+}
 
-    // Get argument name.
-    argNames.push_back(llvm::MDString::get(Context, parm->getName()));
-  }
+static void GenAppleCLMetadata(const FunctionDecl *FD, llvm::Function *Fn,
+							   CodeGenModule &CGM,llvm::LLVMContext &Context,
+							   SmallVector <llvm::Value*, 5> &kernelMDArgs,
+							   CGBuilderTy& Builder, ASTContext &ASTCtx) {
+	//
+	SmallVector<llvm::Value*, 8> arg_infos;
+	
+	// always starts with apple.cl.arg_metadata
+	arg_infos.push_back(llvm::MDString::get(Context, "apple.cl.arg_metadata"));
+	
+	//
+	for(const auto& parm : FD->params()) {
+		const auto clang_type = parm->getType();
+		
+		const auto add_image_arg = [&arg_infos, &Context](const ImageAccessAttr* access_attr) {
+			SmallVector<llvm::Value*, 2> arg_info;
+			
+			arg_info.push_back(llvm::MDString::get(Context, "image"));
+			
+			// access qualifier
+			if(access_attr && access_attr->isWriteOnly()) {
+				arg_info.push_back(llvm::MDString::get(Context, "write"));
+			}
+			else if(access_attr && access_attr->isReadWrite()) {
+				arg_info.push_back(llvm::MDString::get(Context, "read/write"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "read"));
+			}
+			
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		};
+		
+		// #0: storage type (stream or image)
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			SmallVector<llvm::Value*, 3> arg_info;
+			arg_info.push_back(llvm::MDString::get(Context, "stream"));
+			
+			// #1: access qualifier
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			if(clang_pointee_type.isConstQualified() ||
+			   (clang_pointee_type.getAddressSpace() == LangAS::opencl_constant)) {
+				arg_info.push_back(llvm::MDString::get(Context, "read"));
+			}
+			else {
+				arg_info.push_back(llvm::MDString::get(Context, "write"));
+			}
+			
+			// #2: address space
+			switch(clang_pointee_type.getAddressSpace()) {
+				case LangAS::opencl_global:
+					arg_info.push_back(llvm::MDString::get(Context, "global"));
+					break;
+				case LangAS::opencl_local:
+					arg_info.push_back(llvm::MDString::get(Context, "local"));
+					break;
+				case LangAS::opencl_constant:
+					arg_info.push_back(llvm::MDString::get(Context, "constant"));
+					break;
+			}
+			
+			arg_infos.push_back(llvm::MDNode::get(Context, arg_info));
+		}
+		else if(clang_type->isImageType()) {
+			add_image_arg(parm->getAttr<ImageAccessAttr>());
+		}
+		else if(clang_type->isAggregateImageType()) {
+			const auto decl = clang_type->getAsCXXRecordDecl();
+			const auto agg_images = get_aggregate_image_fields(decl);
+			for(const auto& img : agg_images) {
+				add_image_arg(img->getAttr<ImageAccessAttr>());
+			}
+		}
+		else {
+			// simple kernel parameter (not a buffer) -> don't write anything
+			arg_infos.push_back(llvm::MDNode::get(Context, {}));
+		}
+	}
+	
+	// insert into kernel metadata
+	kernelMDArgs.push_back(llvm::MDNode::get(Context, arg_infos));
+}
 
-  kernelMDArgs.push_back(llvm::MDNode::get(Context, addressQuals));
-  kernelMDArgs.push_back(llvm::MDNode::get(Context, accessQuals));
-  kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeNames));
-  kernelMDArgs.push_back(llvm::MDNode::get(Context, argTypeQuals));
-  kernelMDArgs.push_back(llvm::MDNode::get(Context, argNames));
+void CodeGenFunction::EmitFloorKernelMetadata(const FunctionDecl *FD,
+											  llvm::Function *Fn,
+											  const FunctionArgList &Args,
+											  const CGFunctionInfo &FnInfo) {
+	const bool is_kernel = FD->hasAttr<ComputeKernelAttr>();
+	const bool is_vertex = FD->hasAttr<GraphicsVertexShaderAttr>();
+	const bool is_fragment = FD->hasAttr<GraphicsFragmentShaderAttr>();
+	if (!is_kernel && !is_vertex && !is_fragment) {
+		return;
+	}
+	
+	llvm::LLVMContext &Context = getLLVMContext();
+	
+	//
+	SmallVector<llvm::Value*, 16> arg_infos;
+	
+	// #0: info version
+	arg_infos.push_back(Builder.getInt32(2));
+	// #1: function name
+	arg_infos.push_back(llvm::MDString::get(Context, Fn->getName()));
+	// #2: function type
+	arg_infos.push_back(Builder.getInt32(is_kernel ? 1 : (is_vertex ? 2 : 3)));
+	
+	// iterate over clang function decl parameters
+	// NOTE: in case of struct expansion, this doesn't match the llvm parameters
+	// (which is why it iterates over the original clang list!)
+	unsigned int arg_idx = 0;
+	auto abi_arg_info_iter = FnInfo.arg_begin();
+	for(const auto& parm : FD->params()) {
+		const auto clang_type = parm->getType();
+		const auto llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+		const auto cxx_rdecl = clang_type->getAsCXXRecordDecl();
+		
+		enum class FLOOR_ARG_INFO : uint64_t {
+			// 0 == invalid!
+			NONE						= (0ull),
+			
+			// sets: -------- 000000-- -------- 00000xxx 00000000 00000000 00000000 00000000
+			__AS_SHIFT					= (32ull),
+			__AS_MASK					= (0x0000000700000000ull),
+			AS_NONE						= NONE,
+			AS_GLOBAL					= (1ull << __AS_SHIFT),
+			AS_LOCAL					= (2ull << __AS_SHIFT),
+			AS_CONSTANT					= (3ull << __AS_SHIFT),
+			AS_IMAGE					= (4ull << __AS_SHIFT),
+			
+			// sets: -------- 000000-- xxxxxxxx 00000--- 00000000 00000000 00000000 00000000
+			__IMG_TYPE_SHIFT			= (40ull),
+			__IMG_TYPE_MASK				= (0x0000FF0000000000ull),
+			IMG_1D						= (1ull << __IMG_TYPE_SHIFT),
+			IMG_1D_ARRAY				= (2ull << __IMG_TYPE_SHIFT),
+			IMG_1D_BUFFER				= (3ull << __IMG_TYPE_SHIFT),
+			IMG_2D						= (4ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY				= (5ull << __IMG_TYPE_SHIFT),
+			IMG_2D_DEPTH				= (6ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_DEPTH			= (7ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA					= (8ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA			= (9ull << __IMG_TYPE_SHIFT),
+			IMG_2D_MSAA_DEPTH			= (10ull << __IMG_TYPE_SHIFT),
+			IMG_2D_ARRAY_MSAA_DEPTH		= (11ull << __IMG_TYPE_SHIFT),
+			IMG_3D						= (12ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE					= (13ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY				= (14ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_DEPTH				= (15ull << __IMG_TYPE_SHIFT),
+			IMG_CUBE_ARRAY_DEPTH		= (16ull << __IMG_TYPE_SHIFT),
+			
+			// sets: -------- 000000xx -------- 00000--- 00000000 00000000 00000000 00000000
+			__IMG_ACCESS_SHIFT			= (48ull),
+			__IMG_ACCESS_MASK			= (0x0003000000000000ull),
+			IMG_ACCESS_READ				= (1ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_WRITE			= (2ull << __IMG_ACCESS_SHIFT),
+			IMG_ACCESS_READ_WRITE		= (IMG_ACCESS_READ | IMG_ACCESS_WRITE),
+			
+			// sets: xxxxxxxx 000000-- -------- 00000--- 00000000 00000000 00000000 00000000
+			__SPECIAL_TYPE_SHIFT		= (56ull),
+			__SPECIAL_TYPE_MASK			= (0xFF00000000000000ull),
+			STAGE_INPUT					= (1ull << __SPECIAL_TYPE_SHIFT),
+		};
+		static const auto to_fas = [](const unsigned& addr_space) {
+			if(addr_space == LangAS::opencl_global) {
+				return FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			else if(addr_space == LangAS::opencl_local) {
+				return FLOOR_ARG_INFO::AS_LOCAL;
+			}
+			else if(addr_space == LangAS::opencl_constant) {
+				return FLOOR_ARG_INFO::AS_CONSTANT;
+			}
+			return FLOOR_ARG_INFO::AS_NONE;
+		};
+		
+		const auto compute_type_size = [this, &parm, &Fn](llvm::Type* type) {
+			if(!type->isSized()) {
+				auto err_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Fatal, "%0");
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), err_diagID) << "parameter uses a type with an unknown size (NOTE: this can happen when internal vector type conversion/replacement has failed)";
+				
+				auto note_diagID = CGM.getDiags().getCustomDiagID(DiagnosticsEngine::Note, "LLVM function type: %0");
+				std::string fun_type = "";
+				llvm::raw_string_ostream fun_type_stream(fun_type);
+				Fn->getFunctionType()->print(fun_type_stream);
+				CGM.getDiags().Report(parm->getSourceRange().getBegin(), note_diagID) << fun_type_stream.str();
+				
+				return uint64_t(0);
+			}
+			return CGM.getDataLayout().getTypeStoreSize(type);
+		};
+		
+		static const auto get_image_access = [](const ImageAccessAttr* access_attr) {
+			if(access_attr != nullptr) {
+				if(access_attr->isWriteOnly()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_WRITE;
+				}
+				else if(access_attr->isReadWrite()) {
+					return FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE;
+				}
+			}
+			return FLOOR_ARG_INFO::IMG_ACCESS_READ;
+		};
+		static const auto img_type_to_floor_type = [](const clang::Type* type) {
+			if(type->isImage1dT()) return FLOOR_ARG_INFO::IMG_1D;
+			else if(type->isImage1dArrayT()) return FLOOR_ARG_INFO::IMG_1D_ARRAY;
+			else if(type->isImage1dBufferT()) return FLOOR_ARG_INFO::IMG_1D_BUFFER;
+			else if(type->isImage2dT()) return FLOOR_ARG_INFO::IMG_2D;
+			else if(type->isImage2dArrayT()) return FLOOR_ARG_INFO::IMG_2D_ARRAY;
+			else if(type->isImage2dDepthT()) return FLOOR_ARG_INFO::IMG_2D_DEPTH;
+			else if(type->isImage2dArrayDepthT()) return FLOOR_ARG_INFO::IMG_2D_ARRAY_DEPTH;
+			else if(type->isImage2dMSAAT()) return FLOOR_ARG_INFO::IMG_2D_MSAA;
+			else if(type->isImage2dArrayMSAAT()) return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA;
+			else if(type->isImage2dMSAADepthT()) return FLOOR_ARG_INFO::IMG_2D_MSAA_DEPTH;
+			else if(type->isImage2dArrayMSAADepthT()) return FLOOR_ARG_INFO::IMG_2D_ARRAY_MSAA_DEPTH;
+			else if(type->isImage3dT()) return FLOOR_ARG_INFO::IMG_3D;
+			else if(type->isImageCubeT()) return FLOOR_ARG_INFO::IMG_CUBE;
+			else if(type->isImageCubeArrayT()) return FLOOR_ARG_INFO::IMG_CUBE_ARRAY;
+			else if(type->isImageCubeDepthT()) return FLOOR_ARG_INFO::IMG_CUBE_DEPTH;
+			else if(type->isImageCubeArrayDepthT()) return FLOOR_ARG_INFO::IMG_CUBE_ARRAY_DEPTH;
+			return (FLOOR_ARG_INFO)~0ull;
+		};
+		const auto add_image_arg = [this, &arg_infos](const FLOOR_ARG_INFO& floor_img_type,
+													  const FLOOR_ARG_INFO& access) {
+			uint64_t arg_info = uint64_t(FLOOR_ARG_INFO::AS_IMAGE);
+			arg_info |= uint64_t(floor_img_type);
+			arg_info |= uint64_t(access);
+			arg_infos.push_back(Builder.getInt64(arg_info));
+		};
+		// anything that isn't a pointer or special type
+		const auto add_normal_arg = [this, &arg_infos,
+									 &compute_type_size](llvm::Type* llvm_type,
+														 const clang::QualType& clang_type,
+														 const FLOOR_ARG_INFO init_info = FLOOR_ARG_INFO::NONE) {
+			// for now: just use the direct type size + no address space
+			uint64_t arg_info = (uint64_t)init_info;
+			// handle some llvm weirdness? why can this be a pointer still?
+			if(llvm_type->isPointerTy()) {
+				arg_info |= compute_type_size(llvm_type->getPointerElementType());
+			}
+			else {
+				arg_info |= compute_type_size(llvm_type);
+			}
+			arg_info |= (uint64_t)to_fas(clang_type.getAddressSpace());
+			arg_infos.push_back(Builder.getInt64(arg_info));
+		};
+		
+		// #2+: argument sizes + types
+		if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+			const auto clang_pointee_type = clang_type->getPointeeType();
+			const auto pointee_type = llvm_type->getPointerElementType();
+			
+			uint64_t arg_info = compute_type_size(pointee_type);
+			if(getLangOpts().OpenCL) {
+				// else: should be an error
+				arg_info |= (uint64_t)to_fas(clang_pointee_type.getAddressSpace());
+			}
+			else if(getLangOpts().CUDA) {
+				// always pretend this is global
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_GLOBAL;
+			}
+			arg_infos.push_back(Builder.getInt64(arg_info));
+		}
+		// handle image types
+		else if(clang_type->isImageType()) {
+			add_image_arg(img_type_to_floor_type(clang_type.getTypePtr()),
+						  get_image_access(parm->getAttr<ImageAccessAttr>()));
+		}
+		// aggregate of image types (used with opencl and metal)
+		else if(clang_type->isAggregateImageType()) {
+			const auto agg_images = get_aggregate_image_fields(cxx_rdecl);
+			
+			// image count must either be 1 (for single read or write images) or 2 (one read, one write image)
+			const auto field_count = agg_images.size();
+			if(field_count == 0) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("no images in aggregate-image (min: 1)"));
+				return;
+			}
+			else if(field_count > 2) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("too many images in aggregate-image (max: 2)"));
+				return;
+			}
+			
+			// sanity check that all field types are actually images, have proper access attributes and image types match
+			// (should probably put this somewhere else, since it is sema-checking, but then I'd need to duplicate code)
+			FLOOR_ARG_INFO floor_img_type = FLOOR_ARG_INFO::NONE;
+			uint64_t floor_img_access = 0;
+			for(const auto& img : agg_images) {
+				const auto access_attr = img->getAttr<ImageAccessAttr>();
+				if(access_attr == nullptr) {
+					CGM.Error(img->getSourceRange().getBegin(),
+							  StringRef("image type in an aggregate-image must have an access qualifier"));
+					return;
+				}
+				if(access_attr->isReadWrite()) {
+					CGM.Error(img->getSourceRange().getBegin(),
+							  StringRef("read-write access qualifier not allowed for images inside an aggregate-image"));
+					return;
+				}
+				floor_img_access |= uint64_t(get_image_access(access_attr));
+				
+				// first field initializes this
+				const auto img_type = img->getType();
+				if(floor_img_type == FLOOR_ARG_INFO::NONE) {
+					floor_img_type = img_type_to_floor_type(img_type.getTypePtr());
+				}
+				else {
+					// second field must have the same type!
+					if(floor_img_type != img_type_to_floor_type(img_type.getTypePtr())) {
+						CGM.Error(img->getSourceRange().getBegin(),
+								  StringRef("second image in aggregate-image does not have the same type as the first"));
+						return;
+					}
+				}
+			}
+			
+			// if the aggregate has two image objects, one must be read, one must be write -> read/write
+			if(field_count == 2 && floor_img_access != uint64_t(FLOOR_ARG_INFO::IMG_ACCESS_READ_WRITE)) {
+				CGM.Error(cxx_rdecl->getSourceRange().getBegin(),
+						  StringRef("aggregate-image has 2 image fields, but joint access is not read-write"));
+				return;
+			}
+			
+			// everything works out, add this as a single kernel argument (floor backends will handle r/w images as necessary)
+			add_image_arg(floor_img_type, (FLOOR_ARG_INFO)floor_img_access);
+			
+			// 1 clang aggregate-image == 2 llvm image types -> inc index once more
+			if(field_count == 2) ++arg_idx;
+		}
+		// handle non-pointer parameters
+		else if(getLangOpts().CUDA) {
+			// is this an aggregate that is expanded into multiple llvm arguments?
+			if(cxx_rdecl &&
+			   abi_arg_info_iter->info.isDirect() &&
+			   TargetCodeGenInfo::isAggregateTypeForABI(abi_arg_info_iter->type)) {
+				// check if this is an aggregate image (must have image access qualifiers)
+				const ImageAccessAttr* access_attr = get_aggregate_access_attr(cxx_rdecl);
+				if(access_attr != nullptr) {
+					uint64_t arg_info = compute_type_size(llvm_type);
+					arg_info |= uint64_t(get_image_access(access_attr));
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_IMAGE;
+					arg_infos.push_back(Builder.getInt64(arg_info));
+				}
+				else {
+					// simple aggregate, all constant -> must handle each field individually
+					// note that we're only interested in the first expanded layer, not multiple expansion
+					// (i.e. fully scalarized), as this is identical to what cuda / nvptx / the abi do
+					uint64_t arg_info = 0; // sizes will be accumulated
+					const auto fields = get_aggregate_fields(cxx_rdecl);
+					for(size_t i = 0; i < fields.size(); ++i) {
+						const auto field_llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+						arg_info += compute_type_size(field_llvm_type);
+						++arg_idx;
+					}
+					arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+					arg_infos.push_back(Builder.getInt64(arg_info));
+					--arg_idx; // fixup, b/c of inc later
+				}
+			}
+			else {
+				// -> this is a simple constant (scalar or aggregate with scalar eval)
+				// store the parameter size
+				uint64_t arg_info = compute_type_size(llvm_type);
+				arg_info |= (uint64_t)FLOOR_ARG_INFO::AS_CONSTANT;
+				arg_infos.push_back(Builder.getInt64(arg_info));
+			}
+		}
+		// stage input
+		else if(parm->hasAttr<GraphicsStageInputAttr>()) {
+			if(!is_vertex && !is_fragment) {
+				// TODO: should check this in sema
+				// TODO: should also make sure that only 1 exists
+				CGM.Error(FD->getSourceRange().getBegin(), "[[stage_input]] only allowed on vertex and fragment functions");
+			}
+			
+			if(cxx_rdecl) {
+				// must handle each field individually
+				const auto fields = CGM.getTypes().get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+				for(const auto& field : fields) {
+					// TODO: check if field type is int or float!
+					const auto field_llvm_type = next(Fn->getArgumentList().begin(), arg_idx)->getType();
+					add_normal_arg(field_llvm_type, field.type, FLOOR_ARG_INFO::STAGE_INPUT);
+					++arg_idx;
+				}
+				--arg_idx; // fixup, b/c of inc later
+			}
+			else {
+				// add as-is
+				// TODO: check if type is int or float!
+				add_normal_arg(llvm_type, clang_type, FLOOR_ARG_INFO::STAGE_INPUT);
+			}
+		}
+		else {
+			add_normal_arg(llvm_type, clang_type);
+		}
+		
+		// next arg
+		++arg_idx;
+		++abi_arg_info_iter;
+	}
+	
+	// if this is wrong, the kernel will almost certainly not be usable
+	if(arg_idx != Fn->arg_size()) {
+		// signal that this is _very_ bad
+		const std::string err_str {
+			"kernel function parameter count mismatch: " +
+			std::to_string(arg_idx) + " (clang), " +
+			std::to_string(Fn->arg_size()) + " (llvm)"
+		};
+		CGM.Error(FD->getSourceRange().getBegin(), StringRef(err_str));
+		return;
+	}
+	
+	//
+	llvm::MDNode *argsMDNode = llvm::MDNode::get(Context, arg_infos);
+	llvm::NamedMDNode *FloorFunctionsMetadata = CGM.getModule().getOrInsertNamedMetadata("floor.functions");
+	FloorFunctionsMetadata->addOperand(argsMDNode);
 }
 
 void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
                                                llvm::Function *Fn)
 {
-  if (!FD->hasAttr<OpenCLKernelAttr>())
+  if (!FD->hasAttr<ComputeKernelAttr>() &&
+	  !FD->hasAttr<GraphicsVertexShaderAttr>() &&
+	  !FD->hasAttr<GraphicsFragmentShaderAttr>())
     return;
 
   llvm::LLVMContext &Context = getLLVMContext();
 
   SmallVector <llvm::Value*, 5> kernelMDArgs;
-  kernelMDArgs.push_back(Fn);
+  if (!CGM.getLangOpts().Metal) {
+    kernelMDArgs.push_back(Fn);
+  }
+  else { // -> need to id/size handling args to the kernel function type
+	  // add original arg types
+	  SmallVector<llvm::Type*, 16> arg_types;
+	  for(const auto& arg : Fn->args()) {
+		  arg_types.push_back(arg.getType());
+	  }
+	  
+	  if(FD->hasAttr<ComputeKernelAttr>()) {
+		  // add id types
+		  const auto id_vec_type = llvm::VectorType::get(llvm::Type::getInt32Ty(Context), 3);
+		  for(int i = 0; i < 6; ++i) arg_types.push_back(id_vec_type);
+	  }
+	  else if(FD->hasAttr<GraphicsVertexShaderAttr>()) {
+		  // only vertex id for now
+		  arg_types.push_back(llvm::Type::getInt32Ty(Context));
+	  }
+	  else if(FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+		  // only point coord for now
+		  const auto pc_vec_type = llvm::VectorType::get(llvm::Type::getFloatTy(Context), 2);
+		  arg_types.push_back(pc_vec_type);
+	  }
+	  
+	  // create + add new function type
+	  const auto func_type_with_ids = llvm::FunctionType::get(Fn->getReturnType(), arg_types, false);
+	  kernelMDArgs.push_back(llvm::Function::Create(func_type_with_ids, Fn->getLinkage(), Fn->getName()));
+  }
 
-  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata)
+  if (CGM.getCodeGenOpts().EmitOpenCLArgMetadata && !CGM.getCodeGenOpts().EmitAppleCLMetadata)
     GenOpenCLArgMetadata(FD, Fn, CGM, Context, kernelMDArgs,
                          Builder, getContext());
 
+  if (CGM.getLangOpts().Metal)
+    GenAIRMetadata(FD, Fn, CGM, Context, kernelMDArgs, Builder, getContext());
+
+  if (CGM.getCodeGenOpts().EmitAppleCLMetadata)
+    GenAppleCLMetadata(FD, Fn, CGM, Context, kernelMDArgs, Builder, getContext());
+
   if (const VecTypeHintAttr *A = FD->getAttr<VecTypeHintAttr>()) {
     QualType hintQTy = A->getTypeHint();
     const ExtVectorType *hintEltQTy = hintQTy->getAs<ExtVectorType>();
@@ -498,9 +1659,85 @@ void CodeGenFunction::EmitOpenCLKernelMetadata(const FunctionDecl *FD,
   }
 
   llvm::MDNode *kernelMDNode = llvm::MDNode::get(Context, kernelMDArgs);
-  llvm::NamedMDNode *OpenCLKernelMetadata =
-    CGM.getModule().getOrInsertNamedMetadata("opencl.kernels");
-  OpenCLKernelMetadata->addOperand(kernelMDNode);
+  llvm::NamedMDNode *MainMetadataNode;
+  if(!CGM.getLangOpts().Metal) {
+	  MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata("opencl.kernels");
+  }
+  else {
+    MainMetadataNode = CGM.getModule().getOrInsertNamedMetadata(
+      (FD->hasAttr<GraphicsVertexShaderAttr>() ? "air.vertex" :
+       (FD->hasAttr<GraphicsFragmentShaderAttr>() ? "air.fragment" : "air.kernel")));
+  }
+  MainMetadataNode->addOperand(kernelMDNode);
+
+  // additional air info
+  if(CGM.getLangOpts().Metal) {
+	  // only do this once
+	  llvm::NamedMDNode *AIRVersion = CGM.getModule().getOrInsertNamedMetadata("air.version");
+	  if(AIRVersion->getNumOperands() > 0) return;
+	  
+	  // NOTE: this is fixed for now as only compiling in metal1.1 mode is possible
+	  const uint32_t metal_version[] = { 1, 8, 0 };
+	  const uint32_t metal_language_version[] = { 1, 1, 0 };
+	  
+	  SmallVector <llvm::Value*, 3> air_version;
+	  air_version.push_back(Builder.getInt32(metal_version[0]));
+	  air_version.push_back(Builder.getInt32(metal_version[1]));
+	  air_version.push_back(Builder.getInt32(metal_version[2]));
+	  AIRVersion->addOperand(llvm::MDNode::get(Context, air_version));
+	  
+	  llvm::NamedMDNode *AIRLangVersion = CGM.getModule().getOrInsertNamedMetadata("air.language_version");
+	  SmallVector <llvm::Value*, 4> air_lang_version;
+	  air_lang_version.push_back(llvm::MDString::get(Context, "METAL"));
+	  air_lang_version.push_back(Builder.getInt32(metal_language_version[0]));
+	  air_lang_version.push_back(Builder.getInt32(metal_language_version[1]));
+	  air_lang_version.push_back(Builder.getInt32(metal_language_version[2]));
+	  AIRLangVersion->addOperand(llvm::MDNode::get(Context, air_lang_version));
+	  
+	  llvm::NamedMDNode *AIRCompOpts = CGM.getModule().getOrInsertNamedMetadata("air.compile_options");
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.denorms_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.fast_math_enable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.framebuffer_fetch_disable")));
+	  AIRCompOpts->addOperand(llvm::MDNode::get(Context,
+												llvm::MDString::get(Context, "air.compile.native_double_disable")));
+  }
+  // additional opencl info
+  else if(CGM.getCodeGenOpts().EmitOpenCLArgMetadata && !CGM.getCodeGenOpts().EmitAppleCLMetadata) {
+	  // only do this once
+	  llvm::NamedMDNode *CLVersion = CGM.getModule().getOrInsertNamedMetadata("opencl.ocl.version");
+	  if(CLVersion->getNumOperands() > 0) return;
+	  
+	  llvm::NamedMDNode *SPIRVersion = CGM.getModule().getOrInsertNamedMetadata("opencl.spir.version");
+	  SmallVector <llvm::Value*, 3> cl_spir_version; // set both to 1.2
+	  cl_spir_version.push_back(Builder.getInt32(1));
+	  cl_spir_version.push_back(Builder.getInt32(2));
+	  CLVersion->addOperand(llvm::MDNode::get(Context, cl_spir_version));
+	  SPIRVersion->addOperand(llvm::MDNode::get(Context, cl_spir_version));
+	  
+	  llvm::NamedMDNode *CLCompOpts = CGM.getModule().getOrInsertNamedMetadata("opencl.compiler.options");
+	  SmallVector <llvm::Value*, 4> cl_comp_options;
+	  cl_comp_options.push_back(llvm::MDString::get(Context, "-cl-kernel-arg-info"));
+	  cl_comp_options.push_back(llvm::MDString::get(Context, "-cl-mad-enable"));
+	  cl_comp_options.push_back(llvm::MDString::get(Context, "-cl-denorms-are-zero"));
+	  cl_comp_options.push_back(llvm::MDString::get(Context, "-cl-unsafe-math-optimizations"));
+	  CLCompOpts->addOperand(llvm::MDNode::get(Context, cl_comp_options));
+	  
+	  llvm::NamedMDNode *CLOptFeatures = CGM.getModule().getOrInsertNamedMetadata("opencl.used.optional.core.features");
+	  SmallVector <llvm::Value*, 2> cl_opt_features;
+	  cl_opt_features.push_back(llvm::MDString::get(Context, "cl_images")); // always use images
+	  //cl_opt_features.push_back(llvm::MDString::get(Context, "cl_doubles")); // TODO: flag for this?
+	  CLOptFeatures->addOperand(llvm::MDNode::get(Context, cl_opt_features));
+	  
+	  // TODO: proper command line option for this
+	  llvm::NamedMDNode *CLExts = CGM.getModule().getOrInsertNamedMetadata("opencl.used.extensions");
+	  SmallVector <llvm::Value*, 8> cl_exts;
+	  cl_exts.push_back(llvm::MDString::get(Context, "cl_khr_global_int32_base_atomics"));
+	  cl_exts.push_back(llvm::MDString::get(Context, "cl_khr_local_int32_base_atomics"));
+	  CLExts->addOperand(llvm::MDNode::get(Context, cl_exts));
+  }
 }
 
 /// Determine whether the function F ends with a return stmt.
@@ -527,6 +1764,7 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
                                     SourceLocation Loc,
                                     SourceLocation StartLoc) {
   const Decl *D = GD.getDecl();
+  const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D);
 
   DidCallStackSave = false;
   CurCodeDecl = D;
@@ -542,7 +1780,7 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
   // Pass inline keyword to optimizer if it appears explicitly on any
   // declaration. Also, in the case of -fno-inline attach NoInline
   // attribute to all function that are not marked AlwaysInline.
-  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D)) {
+  if (FD) {
     if (!CGM.getCodeGenOpts().NoInline) {
       for (auto RI : FD->redecls())
         if (RI->isInlineSpecified()) {
@@ -553,16 +1791,37 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
       Fn->addFnAttr(llvm::Attribute::NoInline);
   }
 
-  if (getLangOpts().OpenCL) {
-    // Add metadata for a kernel function.
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D))
+  // emit compute metadata
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
+    if(FD) {
+      // add floor specific metadata for kernel functions
+      EmitFloorKernelMetadata(FD, Fn, Args, FnInfo);
+
+      // add "compute_kernel" llvm function attribute if this is a kernel function
+      if (FD->hasAttr<ComputeKernelAttr>()) {
+        Fn->addFnAttr("compute_kernel");
+      }
+      // add "vertex_shader" llvm function attribute if this is a vertex shader
+      if (FD->hasAttr<GraphicsVertexShaderAttr>()) {
+        Fn->addFnAttr("vertex_shader");
+      }
+      // add "fragment_shader" llvm function attribute if this is a fragment shader
+      if (FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+        Fn->addFnAttr("fragment_shader");
+      }
+    }
+    
+    // opencl/spir and metal specific metadata
+    if (getLangOpts().OpenCL) {
+      // Add metadata for a kernel function.
       EmitOpenCLKernelMetadata(FD, Fn);
+    }
   }
 
   // If we are checking function types, emit a function type signature as
   // prefix data.
   if (getLangOpts().CPlusPlus && SanOpts->Function) {
-    if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(D)) {
+    if (FD) {
       if (llvm::Constant *PrefixSig =
               CGM.getTargetCodeGenInfo().getUBSanFunctionSignature(CGM)) {
         llvm::Constant *FTRTTIConst =
@@ -633,7 +1892,16 @@ void CodeGenFunction::StartFunction(GlobalDecl GD,
     llvm::Value *Addr = Builder.CreateStructGEP(EI, Idx);
     ReturnValue = Builder.CreateLoad(Addr, "agg.result");
   } else {
-    ReturnValue = CreateIRTemp(RetTy, "retval");
+    // fix retval allocation for vertex/fragment shader return values (use the computed coerce type)
+    if(FD &&
+       (FD->hasAttr<GraphicsVertexShaderAttr>() ||
+        FD->hasAttr<GraphicsFragmentShaderAttr>())) {
+      llvm::AllocaInst* RetAlloc = CreateTempAlloca(FnInfo.getReturnInfo().getCoerceToType(), "retval");
+      CharUnits Align = getContext().getTypeAlignInChars(RetTy);
+      RetAlloc->setAlignment(Align.getQuantity());
+      ReturnValue = RetAlloc;
+    }
+    else ReturnValue = CreateIRTemp(RetTy, "retval");
 
     // Tell the epilog emitter to autorelease the result.  We do this
     // now so that various specialized functions can suppress it
@@ -755,6 +2023,91 @@ static void EmitSizedDeallocationFunction(CodeGenFunction &CGF,
   CGF.Builder.CreateCall(Unsized, &*CGF.CurFn->arg_begin());
 }
 
+void CodeGenFunction::EmitAppleCLKernelAnnotation(GlobalDecl& GD, llvm::Function* Fn) {
+	if(!getLangOpts().OpenCL) return;
+	
+	if(const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(GD.getDecl())) {
+		// Add global applecl kernel annotations.
+		if(CGM.getCodeGenOpts().EmitAppleCLMetadata && FD->hasAttr<ComputeKernelAttr>()) {
+			// go through all local decls and find the local memory decls
+			std::vector<llvm::Constant*> lmem_refs;
+			for(const auto& I : LocalDeclMap) {
+				const Decl* local_decl = I.first;
+				llvm::Value *Addr = I.second;
+				if(dyn_cast<llvm::GlobalValue>(Addr)) {
+					const VarDecl* lmem_VD = cast<VarDecl>(local_decl);
+					if(lmem_VD->getStorageClass() == SC_OpenCLWorkGroupLocal) {
+						lmem_refs.push_back(CGM.getStaticLocalDeclAddress(lmem_VD));
+					}
+				}
+			}
+			
+			// go through kernel arguments and set info
+			// "global float* a, global const float* b, constant float* c, constant const float* d, local float* e,
+			//  float f, const float g, read_only image2d_t h, write_only image2d_t i, read_write image2d_t j"
+			// -> "218890056a"
+			// TODO: sampler is "4" (NOTE: all other "numbers/chars" are unused)
+			std::string arg_info = "";
+			for(const auto& parm : FD->params()) {
+				const auto clang_type = parm->getType();
+				
+				const auto add_image_arg = [&arg_info](const ImageAccessAttr* access_attr) {
+					// access qualifier
+					if(access_attr && access_attr->isWriteOnly()) {
+						arg_info += "6";
+					}
+					else if(access_attr && access_attr->isReadWrite()) {
+						arg_info += "a";
+					}
+					else {
+						arg_info += "5";
+					}
+				};
+				
+				// storage type (stream or image)
+				if(clang_type->isPointerType() || clang_type->isReferenceType()) {
+					// access qualifier
+					const auto clang_pointee_type = clang_type->getPointeeType();
+					bool read_only = false;
+					if(clang_pointee_type.isConstQualified() ||
+					   (clang_pointee_type.getAddressSpace() == LangAS::opencl_constant)) {
+						read_only = true;
+					}
+					
+					// address space
+					switch(clang_pointee_type.getAddressSpace()) {
+						case LangAS::opencl_global:
+							arg_info += (read_only ? "1" : "2");
+							break;
+						case LangAS::opencl_local:
+							arg_info += "9";
+							break;
+						case LangAS::opencl_constant:
+							arg_info += "8";
+							break;
+					}
+				}
+				else if(clang_type->isImageType()) {
+					add_image_arg(parm->getAttr<ImageAccessAttr>());
+				}
+				else if(clang_type->isAggregateImageType()) {
+					const auto decl = clang_type->getAsCXXRecordDecl();
+					const auto agg_images = get_aggregate_image_fields(decl);
+					for(const auto& img : agg_images) {
+						add_image_arg(img->getAttr<ImageAccessAttr>());
+					}
+				}
+				else {
+					// simple kernel parameter (not a buffer)
+					arg_info += "0";
+				}
+			}
+			
+			CGM.AddAppleCLKernelAnnotation(Fn, arg_info, lmem_refs);
+		}
+	}
+}
+
 void CodeGenFunction::GenerateCode(GlobalDecl GD, llvm::Function *Fn,
                                    const CGFunctionInfo &FnInfo) {
   const FunctionDecl *FD = cast<FunctionDecl>(GD.getDecl());
@@ -808,7 +2161,7 @@ void CodeGenFunction::GenerateCode(GlobalDecl GD, llvm::Function *Fn,
     EmitConstructorBody(Args);
   else if (getLangOpts().CUDA &&
            !CGM.getCodeGenOpts().CUDAIsDevice &&
-           FD->hasAttr<CUDAGlobalAttr>())
+           FD->hasAttr<ComputeKernelAttr>())
     CGM.getCUDARuntime().EmitDeviceStubBody(*this, Args);
   else if (isa<CXXConversionDecl>(FD) &&
            cast<CXXConversionDecl>(FD)->isLambdaToBlockPointerConversion()) {
@@ -858,6 +2211,10 @@ void CodeGenFunction::GenerateCode(GlobalDecl GD, llvm::Function *Fn,
   // Emit the standard function epilogue.
   FinishFunction(BodyRange.getEnd());
 
+  // emit applecl metadata and global annotations
+  // note that this must be done at the end, because we need access to local memory declarations
+  EmitAppleCLKernelAnnotation(GD, Fn);
+
   // If we haven't marked the function nothrow through other means, do
   // a quick pass now to see if we can.
   if (!CurFn->doesNotThrow())
diff --git a/tools/clang/lib/CodeGen/CodeGenFunction.h b/tools/clang/lib/CodeGen/CodeGenFunction.h
index 59cc30d..bc9e3e1 100644
--- a/tools/clang/lib/CodeGen/CodeGenFunction.h
+++ b/tools/clang/lib/CodeGen/CodeGenFunction.h
@@ -989,7 +989,14 @@ private:
   ///   "reqd_work_group_size", and three 32-bit integers X, Y and Z.
   void EmitOpenCLKernelMetadata(const FunctionDecl *FD, 
                                 llvm::Function *Fn);
-
+	
+  void EmitFloorKernelMetadata(const FunctionDecl *FD,
+                               llvm::Function *Fn,
+                               const FunctionArgList &Args,
+                               const CGFunctionInfo &FnInfo);
+
+  void EmitAppleCLKernelAnnotation(GlobalDecl& GD, llvm::Function* Fn);
+	
 public:
   CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);
   ~CodeGenFunction();
diff --git a/tools/clang/lib/CodeGen/CodeGenModule.cpp b/tools/clang/lib/CodeGen/CodeGenModule.cpp
index 48823be..894bf42 100644
--- a/tools/clang/lib/CodeGen/CodeGenModule.cpp
+++ b/tools/clang/lib/CodeGen/CodeGenModule.cpp
@@ -359,7 +359,10 @@ void CodeGenModule::Release() {
     // parser will drop debug info with a different version number
     // (and warn about it, too).
     getModule().addModuleFlag(llvm::Module::Warning, "Debug Info Version",
-                              llvm::DEBUG_METADATA_VERSION);
+                              Context.getTargetInfo().getTriple().getOS() != llvm::Triple::IOS ?
+                              llvm::DEBUG_METADATA_VERSION :
+                              // metal/ios uses/requires a very specific metadata version number
+                              llvm::IOS_METAL_DEBUG_METADATA_VERSION);
 
   // We need to record the widths of enums and wchar_t, so that we can generate
   // the correct build attributes in the ARM backend.
@@ -1147,6 +1150,39 @@ void CodeGenModule::AddGlobalAnnotations(const ValueDecl *D,
     Annotations.push_back(EmitAnnotateAttr(GV, I, D->getLocation()));
 }
 
+void CodeGenModule::AddAppleCLKernelAnnotation(llvm::Function* Fn, const std::string& sgv_str,
+											   std::vector<llvm::Constant*> lmem_refs) {
+	// sgv contains the argument type information
+	llvm::Constant* sgv_data = llvm::ConstantDataArray::getString(getLLVMContext(), sgv_str);
+	llvm::Constant* sgv = new llvm::GlobalVariable(getModule(), sgv_data->getType(), true,
+												   llvm::GlobalValue::InternalLinkage, sgv_data, "sgv");
+	
+	// fgv is always empty (would usually contain the file name)
+	llvm::Constant* fgv_data = llvm::ConstantDataArray::getString(getLLVMContext(), "", false);
+	llvm::Constant* fgv = new llvm::GlobalVariable(getModule(), fgv_data->getType(), true,
+												   llvm::GlobalValue::InternalLinkage, fgv_data, "fgv");
+	
+	// lvgv contains the pointers to local memory decls
+	std::vector<llvm::Constant*> lvgv_data;
+	for(const auto& lmem : lmem_refs) {
+		lvgv_data.push_back(llvm::ConstantExpr::getBitCast(lmem, Int8PtrTy));
+	}
+	llvm::Constant* lvgv_container = llvm::ConstantArray::get(llvm::ArrayType::get(Int8PtrTy, lmem_refs.size()), lvgv_data);
+	llvm::Constant* lvgv = new llvm::GlobalVariable(getModule(), lvgv_container->getType(), true,
+													llvm::GlobalValue::InternalLinkage, lvgv_container, "lvgv");
+	
+	// Create the ConstantStruct for the global annotation.
+	llvm::Constant *Fields[5] = {
+		llvm::ConstantExpr::getBitCast(Fn, Int8PtrTy),
+		llvm::ConstantExpr::getBitCast(sgv, Int8PtrTy),
+		llvm::ConstantExpr::getBitCast(fgv, Int8PtrTy),
+		llvm::ConstantExpr::getBitCast(lvgv, Int8PtrTy),
+		// always 0?
+		llvm::ConstantInt::get(Int32Ty, 0)
+	};
+	Annotations.push_back(llvm::ConstantStruct::getAnon(Fields));
+}
+
 bool CodeGenModule::MayDeferGeneration(const ValueDecl *Global) {
   // Never defer when EmitAllDecls is specified.
   if (LangOpts.EmitAllDecls)
@@ -1218,23 +1254,6 @@ void CodeGenModule::EmitGlobal(GlobalDecl GD) {
   if (Global->hasAttr<AliasAttr>())
     return EmitAliasDefinition(GD);
 
-  // If this is CUDA, be selective about which declarations we emit.
-  if (LangOpts.CUDA) {
-    if (CodeGenOpts.CUDAIsDevice) {
-      if (!Global->hasAttr<CUDADeviceAttr>() &&
-          !Global->hasAttr<CUDAGlobalAttr>() &&
-          !Global->hasAttr<CUDAConstantAttr>() &&
-          !Global->hasAttr<CUDASharedAttr>())
-        return;
-    } else {
-      if (!Global->hasAttr<CUDAHostAttr>() && (
-            Global->hasAttr<CUDADeviceAttr>() ||
-            Global->hasAttr<CUDAConstantAttr>() ||
-            Global->hasAttr<CUDASharedAttr>()))
-        return;
-    }
-  }
-
   // Ignore declarations, they will be emitted on their first use.
   if (const auto *FD = dyn_cast<FunctionDecl>(Global)) {
     // Forward declarations are emitted lazily on first use.
@@ -2241,12 +2260,49 @@ void CodeGenModule::HandleCXXStaticMemberVarInstantiation(VarDecl *VD) {
   EmitTopLevelDecl(VD);
 }
 
+static llvm::Type* MetalExpandReturnType(const CanQualType& type,
+										 llvm::Type* llvm_type,
+										 CodeGenTypes& CGT) {
+	const llvm::StructType* ST = dyn_cast<llvm::StructType>(llvm_type);
+	if(!ST) return llvm_type;
+	
+	const auto cxx_rdecl = type->getAsCXXRecordDecl();
+	
+	// if the top decl already is a compat vector, return it directly
+	if(cxx_rdecl->hasAttr<VectorCompatAttr>()) {
+		return CGT.ConvertType(CGT.get_compat_vector_type(cxx_rdecl));
+	}
+	
+	// else: extract all fields and create a flat llvm struct from them
+	const auto fields = CGT.get_aggregate_scalar_fields(cxx_rdecl, cxx_rdecl);
+	std::vector<llvm::Type*> llvm_fields;
+	for(const auto& field : fields) {
+		llvm_fields.push_back(CGT.ConvertType(field.type));
+	}
+	
+	// TODO: only create once?
+	const std::string name = "__floor.flat." + cxx_rdecl->getName().str();
+	auto ret = llvm::StructType::create(llvm_fields, name, true); // always make this packed
+	ret->setMetalReturnType(); // fix up alignment/sizes/offsets
+	CGT.create_flattened_cg_layout(cxx_rdecl, ret, fields); // create corresponding flattend CGRecordLayout
+	return ret;
+}
+
 void CodeGenModule::EmitGlobalFunctionDefinition(GlobalDecl GD,
                                                  llvm::GlobalValue *GV) {
   const auto *D = cast<FunctionDecl>(GD.getDecl());
 
   // Compute the function info and LLVM type.
   const CGFunctionInfo &FI = getTypes().arrangeGlobalDeclaration(GD);
+  if(getLangOpts().Metal && D &&
+     FI.getReturnType()->isStructureOrClassType() &&
+     (D->hasAttr<GraphicsVertexShaderAttr>() ||
+      D->hasAttr<GraphicsFragmentShaderAttr>())) {
+    // if this is a vertex/fragment shader function and the return type is a struct/aggregate,
+    // fully expand/flatten all types within (i.e. structs and arrays to scalars, keep existing scalars)
+    auto& retInfo = (ABIArgInfo&)FI.getReturnInfo();
+    retInfo.setCoerceToType(MetalExpandReturnType(FI.getReturnType(), retInfo.getCoerceToType(), getTypes()));
+  }
   llvm::FunctionType *Ty = getTypes().GetFunctionType(FI);
 
   // Get or create the prototype for the function.
diff --git a/tools/clang/lib/CodeGen/CodeGenModule.h b/tools/clang/lib/CodeGen/CodeGenModule.h
index 9533a8d..d53d4e3 100644
--- a/tools/clang/lib/CodeGen/CodeGenModule.h
+++ b/tools/clang/lib/CodeGen/CodeGenModule.h
@@ -1009,6 +1009,9 @@ public:
   /// annotations are emitted during finalization of the LLVM code.
   void AddGlobalAnnotations(const ValueDecl *D, llvm::GlobalValue *GV);
 
+  void AddAppleCLKernelAnnotation(llvm::Function* Fn, const std::string& arg_info,
+                                  std::vector<llvm::Constant*> lmem_refs);
+
   const SanitizerBlacklist &getSanitizerBlacklist() const {
     return SanitizerBL;
   }
diff --git a/tools/clang/lib/CodeGen/CodeGenTypes.cpp b/tools/clang/lib/CodeGen/CodeGenTypes.cpp
index d4e2262..47454ca 100644
--- a/tools/clang/lib/CodeGen/CodeGenTypes.cpp
+++ b/tools/clang/lib/CodeGen/CodeGenTypes.cpp
@@ -380,6 +380,16 @@ llvm::Type *CodeGenTypes::ConvertType(QualType T) {
     case BuiltinType::OCLImage1dBuffer:
     case BuiltinType::OCLImage2d:
     case BuiltinType::OCLImage2dArray:
+    case BuiltinType::OCLImage2dDepth:
+    case BuiltinType::OCLImage2dArrayDepth:
+    case BuiltinType::OCLImage2dMSAA:
+    case BuiltinType::OCLImage2dArrayMSAA:
+    case BuiltinType::OCLImage2dMSAADepth:
+    case BuiltinType::OCLImage2dArrayMSAADepth:
+    case BuiltinType::OCLImageCube:
+    case BuiltinType::OCLImageCubeArray:
+    case BuiltinType::OCLImageCubeDepth:
+    case BuiltinType::OCLImageCubeArrayDepth:
     case BuiltinType::OCLImage3d:
     case BuiltinType::OCLSampler:
     case BuiltinType::OCLEvent:
@@ -685,7 +695,14 @@ llvm::StructType *CodeGenTypes::ConvertRecordDeclType(const RecordDecl *RD) {
 
 /// getCGRecordLayout - Return record layout info for the given record decl.
 const CGRecordLayout &
-CodeGenTypes::getCGRecordLayout(const RecordDecl *RD) {
+CodeGenTypes::getCGRecordLayout(const RecordDecl *RD, llvm::Type* struct_type) {
+  // check if there is a flattened layout for this llvm struct type,
+  // return it if so, otherwise continue as usual
+  if (struct_type != nullptr) {
+    const auto flat_layout = FlattenedCGRecordLayouts.lookup(struct_type);
+    if(flat_layout) return *flat_layout;
+  }
+
   const Type *Key = Context.getTagDeclType(RD).getTypePtr();
 
   const CGRecordLayout *Layout = CGRecordLayouts.lookup(Key);
@@ -726,3 +743,200 @@ bool CodeGenTypes::isZeroInitializable(QualType T) {
 bool CodeGenTypes::isZeroInitializable(const CXXRecordDecl *RD) {
   return getCGRecordLayout(RD).isZeroInitializable();
 }
+
+//
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  RecordDecl::field_iterator field_iter) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalFieldName(*field_iter, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+static std::string aggregate_scalar_fields_mangle(const CXXRecordDecl* root_decl,
+												  MangleContext& MC,
+												  const std::string& name,
+												  const clang::QualType& type) {
+	std::string gen_type_name = "";
+	llvm::raw_string_ostream gen_type_name_stream(gen_type_name);
+	MC.mangleMetalGeneric(name, type, root_decl, gen_type_name_stream);
+	return "generated(" + gen_type_name_stream.str() + ")";
+}
+
+clang::QualType CodeGenTypes::get_compat_vector_type(const CXXRecordDecl* decl) {
+	const auto fields = get_aggregate_scalar_fields(decl, decl, true, false);
+	
+	const auto vec_size = fields.size();
+	if(vec_size < 1 || vec_size > 4) {
+		assert("invalid vector size (must be >= 1 && <= 4)");
+		return Context.VoidTy;
+	}
+	
+	const auto elem_type = fields[0].type.getUnqualifiedType();
+	for(size_t i = 1; i < vec_size; ++i) {
+		if(fields[i].type.getUnqualifiedType() != elem_type) {
+			assert("all vector-compat element types must be equal");
+			return Context.VoidTy;
+		}
+	}
+	
+	return Context.getExtVectorType(elem_type, vec_size);
+}
+
+void CodeGenTypes::aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+													 const CXXRecordDecl* parent_decl,
+													 const ConstantArrayType* CAT,
+													 const AttrVec* attrs,
+													 const std::string& name,
+													 std::vector<CodeGenTypes::aggregate_scalar_entry>& ret) {
+	const auto count = CAT->getSize().getZExtValue();
+	const auto ET = CAT->getElementType();
+	if(const auto arr_rdecl = ET->getAsCXXRecordDecl()) {
+		auto contained_ret = get_aggregate_scalar_fields(root_decl, arr_rdecl);
+		for(auto& entry : contained_ret) {
+			entry.parents.push_back(parent_decl);
+		}
+		for(uint64_t i = 0; i < count; ++i) {
+			ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+		}
+	}
+	else if(ET->isArrayType()) {
+		const auto aoa_decl = dyn_cast<ConstantArrayType>(ET->getAsArrayTypeUnsafe());
+		if(aoa_decl) {
+			for(uint64_t i = 0; i < count; ++i) {
+				const auto idx_str = "_" + std::to_string(i);
+				aggregate_scalar_fields_add_array(root_decl, parent_decl, aoa_decl, attrs, name + idx_str, ret);
+			}
+		}
+		else {
+			// TODO: error
+		}
+	}
+	else {
+		for(uint64_t i = 0; i < count; ++i) {
+			const auto idx_str = "_" + std::to_string(i);
+			ret.push_back(aggregate_scalar_entry {
+				ET,
+				name + idx_str,
+				aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), name + idx_str, ET),
+				attrs,
+				nullptr,
+				{ parent_decl },
+				false
+			});
+		}
+	}
+}
+
+std::vector<CodeGenTypes::aggregate_scalar_entry>
+CodeGenTypes::get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+										  const CXXRecordDecl* decl,
+										  const bool ignore_root_vec_compat,
+										  const bool ignore_bases) {
+	if(decl == nullptr) return {};
+	
+	// must have definition
+	if(!decl->hasDefinition()) return {};
+	
+	// if the root decl is a direct compat vector, return it directly
+	if(!ignore_root_vec_compat &&
+	   decl->hasAttr<VectorCompatAttr>()) {
+		return {
+			aggregate_scalar_entry {
+				get_compat_vector_type(decl),
+				"",
+				"",
+				&decl->getAttrs(),
+				nullptr,
+				{},
+				true
+			}
+		};
+	}
+	
+	//
+	std::vector<aggregate_scalar_entry> ret;
+	
+	// iterate over / recurse into all bases
+	if(!ignore_bases) {
+		for(const auto& base : decl->bases()) {
+			const auto base_ret = get_aggregate_scalar_fields(root_decl, base.getType()->getAsCXXRecordDecl());
+			if(!base_ret.empty()) {
+				ret.insert(ret.end(), base_ret.begin(), base_ret.end());
+			}
+		}
+	}
+	
+	// TODO/NOTE: make sure attrs are correctly forwarded/inherited/passed-through
+	const auto add_field = [this, &root_decl, &decl, &ret](RecordDecl::field_iterator field_iter) {
+		if(const auto rdecl = field_iter->getType()->getAsCXXRecordDecl()) {
+			if(rdecl->hasAttr<VectorCompatAttr>() ||
+			   field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+				const auto vec_type = get_compat_vector_type(rdecl);
+				
+				if(field_iter->hasAttr<GraphicsVertexPositionAttr>()) {
+					const auto as_vec_type = vec_type->getAs<ExtVectorType>();
+					if(as_vec_type->getNumElements() != 4 ||
+					   !as_vec_type->getElementType()->isFloatingType()) {
+						// TODO: error!
+					}
+				}
+				
+				ret.push_back(aggregate_scalar_entry {
+					vec_type,
+					field_iter->getName().str(),
+					aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(),
+												   field_iter->getName().str(), vec_type),
+					field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+					*field_iter,
+					{ decl },
+					true
+				});
+			}
+			else {
+				auto contained_ret = get_aggregate_scalar_fields(root_decl, rdecl);
+				for(auto& entry : contained_ret) {
+					entry.parents.push_back(decl);
+				}
+				if(!contained_ret.empty()) {
+					ret.insert(ret.end(), contained_ret.begin(), contained_ret.end());
+				}
+			}
+		}
+		else if(field_iter->getType()->isArrayType()) {
+			const auto arr_decl = dyn_cast<ConstantArrayType>(field_iter->getType()->getAsArrayTypeUnsafe());
+			if(arr_decl) {
+				aggregate_scalar_fields_add_array(root_decl, decl, arr_decl,
+												  field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+												  field_iter->getName().str(), ret);
+			}
+			else {
+				// TODO: error
+			}
+		}
+		else {
+			ret.push_back(aggregate_scalar_entry {
+				field_iter->getType(),
+				field_iter->getName().str(),
+				aggregate_scalar_fields_mangle(root_decl, TheCXXABI.getMangleContext(), field_iter),
+				field_iter->hasAttrs() ? &field_iter->getAttrs() : nullptr,
+				*field_iter,
+				{ decl },
+				false
+			});
+		}
+	};
+	
+	if(!decl->isUnion()) {
+		// iterate over all fields/members
+		for(auto iter = decl->field_begin(); iter != decl->field_end(); ++iter) {
+			add_field(iter);
+		}
+	}
+	else {
+		// for unions: only use the first field
+		add_field(decl->field_begin());
+	}
+	
+	return ret;
+}
diff --git a/tools/clang/lib/CodeGen/CodeGenTypes.h b/tools/clang/lib/CodeGen/CodeGenTypes.h
index fe155b5..16777d5 100644
--- a/tools/clang/lib/CodeGen/CodeGenTypes.h
+++ b/tools/clang/lib/CodeGen/CodeGenTypes.h
@@ -81,6 +81,10 @@ class CodeGenTypes {
   /// record layout info.
   llvm::DenseMap<const Type*, CGRecordLayout *> CGRecordLayouts;
 
+  /// FlattenedCGRecordLayouts - This maps special flattened llvm struct types
+  /// with the corresponding record layout info.
+  llvm::DenseMap<const llvm::Type*, CGRecordLayout *> FlattenedCGRecordLayouts;
+
   /// RecordDeclTypes - This contains the LLVM IR type for any converted
   /// RecordDecl.
   llvm::DenseMap<const Type*, llvm::StructType *> RecordDeclTypes;
@@ -143,7 +147,8 @@ public:
   /// and/or incomplete argument types, this will return the opaque type.
   llvm::Type *GetFunctionTypeForVTable(GlobalDecl GD);
 
-  const CGRecordLayout &getCGRecordLayout(const RecordDecl*);
+  const CGRecordLayout &getCGRecordLayout(const RecordDecl*,
+										  llvm::Type* struct_type = nullptr);
 
   /// UpdateCompletedType - When we find the full definition for a TagDecl,
   /// replace the 'opaque' type we previously made for it if applicable.
@@ -233,7 +238,56 @@ public:
   /// optional suffix and name the given LLVM type using it.
   void addRecordTypeName(const RecordDecl *RD, llvm::StructType *Ty,
                          StringRef suffix);
-  
+
+  //
+  struct aggregate_scalar_entry {
+	clang::QualType type;
+	std::string name;
+	std::string mangled_name;
+    const AttrVec* attrs;
+	// NOTE: this is nullptr for non-fields!
+    const FieldDecl* field_decl;
+    std::vector<const CXXRecordDecl*> parents;
+    bool compat_vector;
+	
+	template <typename SpecificAttr>
+	bool hasAttr() const {
+		if(attrs == nullptr) return false;
+		return hasSpecificAttr<SpecificAttr>(*attrs);
+	}
+	
+	template <typename SpecificAttr>
+	SpecificAttr* getAttr() const {
+		if(attrs == nullptr) return nullptr;
+		return getSpecificAttr<SpecificAttr>(*attrs);
+	}
+  };
+
+  // will recurse through the specified class/struct decl, its base classes,
+  // all its contained class/struct/union decls, all its contained arrays,
+  // returning a vector of all contained/scalarized fields + info
+  // NOTE: for unions, only the first field will be considered
+  // NOTE: this also transform/converts [[vector_compat]] types to clang vector types
+  std::vector<aggregate_scalar_entry> get_aggregate_scalar_fields(const CXXRecordDecl* root_decl,
+                                                                  const CXXRecordDecl* decl,
+																  const bool ignore_root_vec_compat = false,
+																  const bool ignore_bases = false);
+
+  // returns the corresponding clang vector type for a [[vector_compat]] aggregate
+  clang::QualType get_compat_vector_type(const CXXRecordDecl* decl);
+
+  //
+  void create_flattened_cg_layout(const CXXRecordDecl* decl, llvm::StructType* type,
+								  const std::vector<aggregate_scalar_entry>& fields);
+
+private:
+  // helper function for get_aggregate_scalar_fields
+  void aggregate_scalar_fields_add_array(const CXXRecordDecl* root_decl,
+										 const CXXRecordDecl* parent_decl,
+                                         const ConstantArrayType* CAT,
+                                         const AttrVec* attrs,
+                                         const std::string& name,
+                                         std::vector<CodeGenTypes::aggregate_scalar_entry>& ret);
 
 public:  // These are internal details of CGT that shouldn't be used externally.
   /// ConvertRecordDeclType - Lay out a tagged decl type like struct or union.
diff --git a/tools/clang/lib/CodeGen/ItaniumCXXABI.cpp b/tools/clang/lib/CodeGen/ItaniumCXXABI.cpp
index d7e61f0..03c08c2 100644
--- a/tools/clang/lib/CodeGen/ItaniumCXXABI.cpp
+++ b/tools/clang/lib/CodeGen/ItaniumCXXABI.cpp
@@ -2173,6 +2173,16 @@ static bool TypeInfoIsInStandardLibrary(const BuiltinType *Ty) {
     case BuiltinType::OCLImage1dBuffer:
     case BuiltinType::OCLImage2d:
     case BuiltinType::OCLImage2dArray:
+    case BuiltinType::OCLImage2dDepth:
+    case BuiltinType::OCLImage2dArrayDepth:
+    case BuiltinType::OCLImage2dMSAA:
+    case BuiltinType::OCLImage2dArrayMSAA:
+    case BuiltinType::OCLImage2dMSAADepth:
+    case BuiltinType::OCLImage2dArrayMSAADepth:
+    case BuiltinType::OCLImageCube:
+    case BuiltinType::OCLImageCubeArray:
+    case BuiltinType::OCLImageCubeDepth:
+    case BuiltinType::OCLImageCubeArrayDepth:
     case BuiltinType::OCLImage3d:
     case BuiltinType::OCLSampler:
     case BuiltinType::OCLEvent:
diff --git a/tools/clang/lib/CodeGen/TargetInfo.cpp b/tools/clang/lib/CodeGen/TargetInfo.cpp
index f75e59d..b702b94 100644
--- a/tools/clang/lib/CodeGen/TargetInfo.cpp
+++ b/tools/clang/lib/CodeGen/TargetInfo.cpp
@@ -41,11 +41,15 @@ static void AssignToArrayRange(CodeGen::CGBuilderTy &Builder,
   }
 }
 
-static bool isAggregateTypeForABI(QualType T) {
+bool TargetCodeGenInfo::isAggregateTypeForABI(QualType T) {
   return !CodeGenFunction::hasScalarEvaluationKind(T) ||
          T->isMemberFunctionPointerType();
 }
 
+static bool isAggregateImageType(QualType T) {
+  return CodeGenFunction::hasAggregateEvaluationKind(T) && T->isAggregateImageType();
+}
+
 ABIInfo::~ABIInfo() {}
 
 static CGCXXABI::RecordArgABI getRecordArgABI(const RecordType *RT,
@@ -264,7 +268,7 @@ static const Type *isSingleElementStruct(QualType T, ASTContext &Context) {
       FT = AT->getElementType();
     }
 
-    if (!isAggregateTypeForABI(FT)) {
+    if (!TargetCodeGenInfo::isAggregateTypeForABI(FT)) {
       Found = FT.getTypePtr();
     } else {
       Found = isSingleElementStruct(FT, Context);
@@ -376,7 +380,10 @@ llvm::Value *DefaultABIInfo::EmitVAArg(llvm::Value *VAListAddr, QualType Ty,
 }
 
 ABIArgInfo DefaultABIInfo::classifyArgumentType(QualType Ty) const {
-  if (isAggregateTypeForABI(Ty))
+  if (isAggregateImageType(Ty))
+    return ABIArgInfo::getExpand();
+
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return ABIArgInfo::getIndirect(0);
 
   // Treat an enum type as its underlying type.
@@ -391,7 +398,7 @@ ABIArgInfo DefaultABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVoidType())
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return ABIArgInfo::getIndirect(0);
 
   // Treat an enum type as its underlying type.
@@ -442,7 +449,7 @@ llvm::Value *PNaClABIInfo::EmitVAArg(llvm::Value *VAListAddr, QualType Ty,
 
 /// \brief Classify argument of given type \p Ty.
 ABIArgInfo PNaClABIInfo::classifyArgumentType(QualType Ty) const {
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return ABIArgInfo::getIndirect(0, RAA == CGCXXABI::RAA_DirectInMemory);
     return ABIArgInfo::getIndirect(0);
@@ -463,7 +470,7 @@ ABIArgInfo PNaClABIInfo::classifyReturnType(QualType RetTy) const {
     return ABIArgInfo::getIgnore();
 
   // In the PNaCl ABI we always return records/structures on the stack.
-  if (isAggregateTypeForABI(RetTy))
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy))
     return ABIArgInfo::getIndirect(0);
 
   // Treat an enum type as its underlying type.
@@ -695,7 +702,7 @@ ABIArgInfo X86_32ABIInfo::classifyReturnType(QualType RetTy, CCState &State) con
     return ABIArgInfo::getDirect();
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     if (const RecordType *RT = RetTy->getAs<RecordType>()) {
       // Structures with flexible arrays are always indirect.
       if (RT->getDecl()->hasFlexibleArrayMember())
@@ -867,7 +874,7 @@ bool X86_32ABIInfo::shouldUseInReg(QualType Ty, CCState &State,
 ABIArgInfo X86_32ABIInfo::classifyArgumentType(QualType Ty,
                                                CCState &State) const {
   // FIXME: Set alignment on indirect arguments.
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (const RecordType *RT = Ty->getAs<RecordType>()) {
       // Check with the C++ ABI first.
       CGCXXABI::RecordArgABI RAA = getRecordArgABI(RT, getCXXABI());
@@ -1831,7 +1838,7 @@ void X86_64ABIInfo::classify(QualType Ty, uint64_t OffsetBase,
 ABIArgInfo X86_64ABIInfo::getIndirectReturnResult(QualType Ty) const {
   // If this is a scalar LLVM value then assume LLVM will pass it in the right
   // place naturally.
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -1864,7 +1871,7 @@ ABIArgInfo X86_64ABIInfo::getIndirectResult(QualType Ty,
   // the argument in the free register. This does not seem to happen currently,
   // but this code would be much safer if we could mark the argument with
   // 'onstack'. See PR12193.
-  if (!isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !IsIllegalVectorType(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -3036,7 +3043,7 @@ PPC64_SVR4_ABIInfo::isAlignedParamType(QualType Ty) const {
   const Type *Base = nullptr;
   uint64_t Members = 0;
   if (!AlignAsType && Kind == ELFv2 &&
-      isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
+      TargetCodeGenInfo::isAggregateTypeForABI(Ty) && isHomogeneousAggregate(Ty, Base, Members))
     AlignAsType = Base;
 
   // With special case aggregates, only vector base types need alignment.
@@ -3045,7 +3052,7 @@ PPC64_SVR4_ABIInfo::isAlignedParamType(QualType Ty) const {
 
   // Otherwise, we only need alignment for any aggregate type that
   // has an alignment requirement of >= 16 bytes.
-  if (isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128)
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) && getContext().getTypeAlign(Ty) >= 128)
     return true;
 
   return false;
@@ -3161,7 +3168,7 @@ PPC64_SVR4_ABIInfo::classifyArgumentType(QualType Ty) const {
     }
   }
 
-  if (isAggregateTypeForABI(Ty)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     if (CGCXXABI::RecordArgABI RAA = getRecordArgABI(Ty, getCXXABI()))
       return ABIArgInfo::getIndirect(0, RAA == CGCXXABI::RAA_DirectInMemory);
 
@@ -3232,7 +3239,7 @@ PPC64_SVR4_ABIInfo::classifyReturnType(QualType RetTy) const {
     }
   }
 
-  if (isAggregateTypeForABI(RetTy)) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // ELFv2 homogeneous aggregates are returned as array types.
     const Type *Base = nullptr;
     uint64_t Members = 0;
@@ -3573,7 +3580,7 @@ ABIArgInfo AArch64ABIInfo::classifyArgumentType(QualType Ty,
       AllocatedVFP++;
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -3656,7 +3663,7 @@ ABIArgInfo AArch64ABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 128)
     return ABIArgInfo::getIndirect(0);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -3838,7 +3845,7 @@ static llvm::Value *EmitAArch64VAArg(llvm::Value *VAListAddr, QualType Ty,
     // Otherwise the object is contiguous in memory
     unsigned BeAlign = reg_top_index == 2 ? 16 : 8;
     if (CGF.CGM.getDataLayout().isBigEndian() &&
-        (IsHFA || !isAggregateTypeForABI(Ty)) &&
+        (IsHFA || !TargetCodeGenInfo::isAggregateTypeForABI(Ty)) &&
         Ctx.getTypeSize(Ty) < (BeAlign * 8)) {
       int Offset = BeAlign - Ctx.getTypeSize(Ty) / 8;
       BaseAddr = CGF.Builder.CreatePtrToInt(BaseAddr, CGF.Int64Ty);
@@ -3896,7 +3903,7 @@ static llvm::Value *EmitAArch64VAArg(llvm::Value *VAListAddr, QualType Ty,
   // Write the new value of __stack for the next call to va_arg
   CGF.Builder.CreateStore(NewStack, stack_p);
 
-  if (CGF.CGM.getDataLayout().isBigEndian() && !isAggregateTypeForABI(Ty) &&
+  if (CGF.CGM.getDataLayout().isBigEndian() && !TargetCodeGenInfo::isAggregateTypeForABI(Ty) &&
       Ctx.getTypeSize(Ty) < 64) {
     int Offset = 8 - Ctx.getTypeSize(Ty) / 8;
     OnStackAddr = CGF.Builder.CreatePtrToInt(OnStackAddr, CGF.Int64Ty);
@@ -3943,7 +3950,7 @@ llvm::Value *AArch64ABIInfo::EmitDarwinVAArg(llvm::Value *VAListAddr, QualType T
   // We do not support va_arg for aggregates or illegal vector types.
   // Lower VAArg here for these cases and use the LLVM va_arg instruction for
   // other cases.
-  if (!isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty) && !isIllegalVectorType(Ty))
     return nullptr;
 
   uint64_t Size = CGF.getContext().getTypeSize(Ty) / 8;
@@ -4442,7 +4449,7 @@ ABIArgInfo ARMABIInfo::classifyArgumentType(QualType Ty, bool isVariadic,
     }
   }
 
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>()) {
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -4624,7 +4631,7 @@ ABIArgInfo ARMABIInfo::classifyReturnType(QualType RetTy,
     return ABIArgInfo::getIndirect(0);
   }
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -4910,7 +4917,7 @@ SetTargetAttributes(const Decl *D, llvm::GlobalValue *GV,
   if (M.getLangOpts().OpenCL) {
     // Use OpenCL function attributes to check for kernel functions
     // By default, all functions are device functions
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL __kernel functions get kernel metadata
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
@@ -4924,7 +4931,7 @@ SetTargetAttributes(const Decl *D, llvm::GlobalValue *GV,
     // CUDA __global__ functions get a kernel metadata entry.  Since
     // __global__ functions cannot be called from the device, we do not
     // need to set the noinline attribute.
-    if (FD->hasAttr<CUDAGlobalAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // Create !{<func-ref>, metadata !"kernel", i32 1} node
       addNVVMMetadata(F, "kernel", 1);
     }
@@ -4962,6 +4969,101 @@ void NVPTXTargetCodeGenInfo::addNVVMMetadata(llvm::Function *F, StringRef Name,
 }
 
 //===----------------------------------------------------------------------===//
+// OpenCL/SPIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class SPIRABIInfo : public DefaultABIInfo {
+public:
+  SPIRABIInfo(CodeGenTypes &CGT) : DefaultABIInfo(CGT) {}
+};
+
+class SPIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  SPIRTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new SPIRABIInfo(CGT)) {}
+};
+	
+}
+
+//===----------------------------------------------------------------------===//
+// Metal/AIR ABI Implementation
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+class AIRABIInfo : public ABIInfo {
+public:
+  AIRABIInfo(CodeGenTypes &CGT) : ABIInfo(CGT) {}
+
+  ABIArgInfo classifyReturnType(QualType RetTy) const;
+  ABIArgInfo classifyArgumentType(QualType Ty) const;
+
+  void computeInfo(CGFunctionInfo &FI) const override;
+  llvm::Value *EmitVAArg(llvm::Value *VAListAddr, QualType Ty,
+                         CodeGenFunction &CFG) const override;
+};
+
+class AIRTargetCodeGenInfo : public TargetCodeGenInfo {
+public:
+  AIRTargetCodeGenInfo(CodeGenTypes &CGT)
+    : TargetCodeGenInfo(new AIRABIInfo(CGT)) {}
+};
+
+ABIArgInfo AIRABIInfo::classifyReturnType(QualType RetTy) const {
+  if (RetTy->isVoidType())
+    return ABIArgInfo::getIgnore();
+
+  // note: this is different from default ABI
+  if (!RetTy->isScalarType())
+    return ABIArgInfo::getDirect();
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
+    RetTy = EnumTy->getDecl()->getIntegerType();
+
+  return (RetTy->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+ABIArgInfo AIRABIInfo::classifyArgumentType(QualType Ty) const {
+  if (CodeGenFunction::hasAggregateEvaluationKind(Ty) &&
+      Ty->isStructureOrClassType()) {
+    return ABIArgInfo::getExpand();
+  }
+
+  // Treat an enum type as its underlying type.
+  if (const EnumType *EnumTy = Ty->getAs<EnumType>())
+    Ty = EnumTy->getDecl()->getIntegerType();
+
+  return (Ty->isPromotableIntegerType() ?
+          ABIArgInfo::getExtend() : ABIArgInfo::getDirect());
+}
+
+void AIRABIInfo::computeInfo(CGFunctionInfo &FI) const {
+  // return type should never be indirect
+  // TODO: ... if the function is a kernel/vs/fs
+  FI.getReturnInfo() = classifyReturnType(FI.getReturnType());
+
+  for (auto &I : FI.arguments())
+    I.info = classifyArgumentType(I.type);
+
+  // Always honor user-specified calling convention.
+  if (FI.getCallingConvention() != llvm::CallingConv::C)
+    return;
+
+  FI.setEffectiveCallingConvention(getRuntimeCC());
+}
+
+llvm::Value *AIRABIInfo::EmitVAArg(llvm::Value *VAListAddr, QualType Ty,
+                                   CodeGenFunction &CFG) const {
+  llvm_unreachable("AIR does not support varargs");
+}
+
+}
+
+//===----------------------------------------------------------------------===//
 // SystemZ ABI Implementation
 //===----------------------------------------------------------------------===//
 
@@ -5019,7 +5121,7 @@ bool SystemZABIInfo::isPromotableIntegerType(QualType Ty) const {
 }
 
 bool SystemZABIInfo::isCompoundType(QualType Ty) const {
-  return Ty->isAnyComplexType() || isAggregateTypeForABI(Ty);
+  return Ty->isAnyComplexType() || TargetCodeGenInfo::isAggregateTypeForABI(Ty);
 }
 
 bool SystemZABIInfo::isFPArgumentType(QualType Ty) const {
@@ -5433,7 +5535,7 @@ MipsABIInfo::classifyArgumentType(QualType Ty, uint64_t &Offset) const {
   unsigned CurrOffset = llvm::RoundUpToAlignment(Offset, Align);
   Offset = CurrOffset + llvm::RoundUpToAlignment(TySize, Align * 8) / 8;
 
-  if (isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(Ty) || Ty->isVectorType()) {
     // Ignore empty aggregates.
     if (TySize == 0)
       return ABIArgInfo::getIgnore();
@@ -5518,7 +5620,7 @@ ABIArgInfo MipsABIInfo::classifyReturnType(QualType RetTy) const {
   if (!IsO32 && Size == 0)
     return ABIArgInfo::getIgnore();
 
-  if (isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
+  if (TargetCodeGenInfo::isAggregateTypeForABI(RetTy) || RetTy->isVectorType()) {
     if (Size <= 128) {
       if (RetTy->isAnyComplexType())
         return ABIArgInfo::getDirect();
@@ -5657,7 +5759,7 @@ void TCETargetCodeGenInfo::SetTargetAttributes(const Decl *D,
   llvm::Function *F = cast<llvm::Function>(GV);
   
   if (M.getLangOpts().OpenCL) {
-    if (FD->hasAttr<OpenCLKernelAttr>()) {
+    if (FD->hasAttr<ComputeKernelAttr>()) {
       // OpenCL C Kernel functions are not subject to inlining
       F->addFnAttr(llvm::Attribute::NoInline);
       const ReqdWorkGroupSizeAttr *Attr = FD->getAttr<ReqdWorkGroupSizeAttr>();
@@ -5732,7 +5834,7 @@ void HexagonABIInfo::computeInfo(CGFunctionInfo &FI) const {
 }
 
 ABIArgInfo HexagonABIInfo::classifyArgumentType(QualType Ty) const {
-  if (!isAggregateTypeForABI(Ty)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = Ty->getAs<EnumType>())
       Ty = EnumTy->getDecl()->getIntegerType();
@@ -5770,7 +5872,7 @@ ABIArgInfo HexagonABIInfo::classifyReturnType(QualType RetTy) const {
   if (RetTy->isVectorType() && getContext().getTypeSize(RetTy) > 64)
     return ABIArgInfo::getIndirect(0);
 
-  if (!isAggregateTypeForABI(RetTy)) {
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(RetTy)) {
     // Treat an enum type as its underlying type.
     if (const EnumType *EnumTy = RetTy->getAs<EnumType>())
       RetTy = EnumTy->getDecl()->getIntegerType();
@@ -5994,7 +6096,7 @@ SparcV9ABIInfo::classifyType(QualType Ty, unsigned SizeLimit) const {
     return ABIArgInfo::getExtend();
 
   // Other non-aggregates go in registers.
-  if (!isAggregateTypeForABI(Ty))
+  if (!TargetCodeGenInfo::isAggregateTypeForABI(Ty))
     return ABIArgInfo::getDirect();
 
   // If a C++ object has either a non-trivial copy constructor or a non-trivial
@@ -6877,5 +6979,10 @@ const TargetCodeGenInfo &CodeGenModule::getTargetCodeGenInfo() {
     return *(TheTargetCodeGenInfo = new SparcV9TargetCodeGenInfo(Types));
   case llvm::Triple::xcore:
     return *(TheTargetCodeGenInfo = new XCoreTargetCodeGenInfo(Types));
+  case llvm::Triple::spir:
+  case llvm::Triple::spir64:
+    return *(TheTargetCodeGenInfo = new SPIRTargetCodeGenInfo(Types));
+  case llvm::Triple::air64:
+    return *(TheTargetCodeGenInfo = new AIRTargetCodeGenInfo(Types));
   }
 }
diff --git a/tools/clang/lib/CodeGen/TargetInfo.h b/tools/clang/lib/CodeGen/TargetInfo.h
index 2616820..6cac0cd 100644
--- a/tools/clang/lib/CodeGen/TargetInfo.h
+++ b/tools/clang/lib/CodeGen/TargetInfo.h
@@ -209,6 +209,9 @@ public:
   virtual void getDetectMismatchOption(llvm::StringRef Name,
                                        llvm::StringRef Value,
                                        llvm::SmallString<32> &Opt) const {}
+
+  static bool isAggregateTypeForABI(QualType T);
+
 };
 }
 
diff --git a/tools/clang/lib/Driver/Tools.cpp b/tools/clang/lib/Driver/Tools.cpp
index 198e82e..41a24da 100644
--- a/tools/clang/lib/Driver/Tools.cpp
+++ b/tools/clang/lib/Driver/Tools.cpp
@@ -5366,6 +5366,7 @@ llvm::Triple::ArchType darwin::getArchTypeForMachOArchName(StringRef Str) {
     .Case("nvptx64", llvm::Triple::nvptx64)
     .Case("amdil", llvm::Triple::amdil)
     .Case("spir", llvm::Triple::spir)
+    .Case("air64", llvm::Triple::air64)
     .Default(llvm::Triple::UnknownArch);
 }
 
diff --git a/tools/clang/lib/Frontend/CompilerInstance.cpp b/tools/clang/lib/Frontend/CompilerInstance.cpp
index 6af920d..a83d536 100644
--- a/tools/clang/lib/Frontend/CompilerInstance.cpp
+++ b/tools/clang/lib/Frontend/CompilerInstance.cpp
@@ -842,6 +842,8 @@ bool CompilerInstance::ExecuteAction(FrontendAction &Act) {
 /// \brief Determine the appropriate source input kind based on language
 /// options.
 static InputKind getSourceInputKindFromOptions(const LangOptions &LangOpts) {
+  if (LangOpts.Metal)
+    return IK_Metal;
   if (LangOpts.OpenCL)
     return IK_OpenCL;
   if (LangOpts.CUDA)
diff --git a/tools/clang/lib/Frontend/CompilerInvocation.cpp b/tools/clang/lib/Frontend/CompilerInvocation.cpp
index ce61a46..813b9c9 100644
--- a/tools/clang/lib/Frontend/CompilerInvocation.cpp
+++ b/tools/clang/lib/Frontend/CompilerInvocation.cpp
@@ -73,7 +73,7 @@ using namespace llvm::opt;
 static unsigned getOptimizationLevel(ArgList &Args, InputKind IK,
                                      DiagnosticsEngine &Diags) {
   unsigned DefaultOpt = 0;
-  if (IK == IK_OpenCL && !Args.hasArg(OPT_cl_opt_disable))
+  if ((IK == IK_OpenCL || IK == IK_Metal) && !Args.hasArg(OPT_cl_opt_disable))
     DefaultOpt = 2;
 
   if (Arg *A = Args.getLastArg(options::OPT_O_Group)) {
@@ -474,6 +474,12 @@ static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args, InputKind IK,
   Opts.InstrumentFunctions = Args.hasArg(OPT_finstrument_functions);
   Opts.InstrumentForProfiling = Args.hasArg(OPT_pg);
   Opts.EmitOpenCLArgMetadata = Args.hasArg(OPT_cl_kernel_arg_info);
+  if (IK == IK_Metal) {
+    // dwarf version must always be 2 for metal/air
+    Opts.DwarfVersion = 2;
+  }
+  Opts.EmitAppleCLMetadata = Args.hasArg(OPT_applecl_kernel_info);
+  Opts.MetalIntelWorkarounds = Args.hasArg(OPT_metal_intel_workarounds);
   Opts.CompressDebugSections = Args.hasArg(OPT_compress_debug_sections);
   Opts.DebugCompilationDir = Args.getLastArgValue(OPT_fdebug_compilation_dir);
   Opts.LinkBitcodeFile = Args.getLastArgValue(OPT_mlink_bitcode_file);
@@ -904,6 +910,7 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
     DashX = llvm::StringSwitch<InputKind>(A->getValue())
       .Case("c", IK_C)
       .Case("cl", IK_OpenCL)
+      .Case("metal", IK_Metal)
       .Case("cuda", IK_CUDA)
       .Case("c++", IK_CXX)
       .Case("objective-c", IK_ObjC)
@@ -917,6 +924,7 @@ static InputKind ParseFrontendArgs(FrontendOptions &Opts, ArgList &Args,
       .Case("objc++-cpp-output", IK_PreprocessedObjCXX)
       .Case("c-header", IK_C)
       .Case("cl-header", IK_OpenCL)
+      .Case("metal-header", IK_Metal)
       .Case("objective-c-header", IK_ObjC)
       .Case("c++-header", IK_CXX)
       .Case("objective-c++-header", IK_ObjCXX)
@@ -1110,6 +1118,9 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
     case IK_OpenCL:
       LangStd = LangStandard::lang_opencl;
       break;
+    case IK_Metal:
+      LangStd = LangStandard::lang_metal11;
+      break;
     case IK_CUDA:
       LangStd = LangStandard::lang_cuda;
       break;
@@ -1151,7 +1162,14 @@ void CompilerInvocation::setLangDefaults(LangOptions &Opts, InputKind IK,
       Opts.OpenCLVersion = 110;
   else if (LangStd == LangStandard::lang_opencl12)
     Opts.OpenCLVersion = 120;
-  
+
+  // as Metal is largely compiled as OpenCL, also enable + init opencl
+  if (LangStd == LangStandard::lang_metal11 || IK == IK_Metal) {
+    Opts.Metal = 1;
+    Opts.OpenCL = 1;
+    Opts.OpenCLVersion = 120;
+  }
+
   // OpenCL has some additional defaults.
   if (Opts.OpenCL) {
     Opts.AltiVec = 0;
@@ -1276,10 +1294,15 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
             << A->getAsString(Args) << "C++/ObjC++";
         break;
       case IK_OpenCL:
-        if (!Std.isC99())
+        if (!Std.isC99() && !Std.isCPlusPlus())
           Diags.Report(diag::err_drv_argument_not_allowed_with)
             << A->getAsString(Args) << "OpenCL";
         break;
+      case IK_Metal:
+        if (!Std.isCPlusPlus())
+          Diags.Report(diag::err_drv_argument_not_allowed_with)
+            << A->getAsString(Args) << "Metal";
+        break;
       case IK_CUDA:
         if (!Std.isCPlusPlus())
           Diags.Report(diag::err_drv_argument_not_allowed_with)
@@ -1311,6 +1334,12 @@ static void ParseLangArgs(LangOptions &Opts, ArgList &Args, InputKind IK,
   
   CompilerInvocation::setLangDefaults(Opts, IK, LangStd);
 
+  // extract libfloor image capabilities
+  if (const Arg *A = Args.getLastArg(OPT_floor_image_capabilities)) {
+    StringRef image_caps = A->getValue();
+    Opts.floor_image_capabilities = (unsigned int)std::stoul(image_caps);
+  }
+
   // We abuse '-f[no-]gnu-keywords' to force overriding all GNU-extension
   // keywords. This behavior is provided by GCC's poorly named '-fasm' flag,
   // while a subset (the non-C++ GNU keywords) is provided by GCC's
diff --git a/tools/clang/lib/Frontend/FrontendActions.cpp b/tools/clang/lib/Frontend/FrontendActions.cpp
index 6dcaf38..8f18343 100644
--- a/tools/clang/lib/Frontend/FrontendActions.cpp
+++ b/tools/clang/lib/Frontend/FrontendActions.cpp
@@ -661,6 +661,7 @@ void PrintPreambleAction::ExecuteAction() {
   case IK_ObjC:
   case IK_ObjCXX:
   case IK_OpenCL:
+  case IK_Metal:
   case IK_CUDA:
     break;
       
diff --git a/tools/clang/lib/Frontend/InitPreprocessor.cpp b/tools/clang/lib/Frontend/InitPreprocessor.cpp
index 7a9d09a..17c60f6 100644
--- a/tools/clang/lib/Frontend/InitPreprocessor.cpp
+++ b/tools/clang/lib/Frontend/InitPreprocessor.cpp
@@ -113,11 +113,14 @@ static void AddImplicitIncludePCH(MacroBuilder &Builder, Preprocessor &PP,
 /// PickFP - This is used to pick a value based on the FP semantics of the
 /// specified FP model.
 template <typename T>
-static T PickFP(const llvm::fltSemantics *Sem, T IEEESingleVal,
+static T PickFP(const llvm::fltSemantics *Sem,
+				T IEEEHalfVal, T IEEESingleVal,
                 T IEEEDoubleVal, T X87DoubleExtendedVal, T PPCDoubleDoubleVal,
                 T IEEEQuadVal) {
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEsingle)
     return IEEESingleVal;
+  if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEhalf)
+    return IEEEHalfVal;
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::IEEEdouble)
     return IEEEDoubleVal;
   if (Sem == (const llvm::fltSemantics*)&llvm::APFloat::x87DoubleExtended)
@@ -131,25 +134,25 @@ static T PickFP(const llvm::fltSemantics *Sem, T IEEESingleVal,
 static void DefineFloatMacros(MacroBuilder &Builder, StringRef Prefix,
                               const llvm::fltSemantics *Sem, StringRef Ext) {
   const char *DenormMin, *Epsilon, *Max, *Min;
-  DenormMin = PickFP(Sem, "1.40129846e-45", "4.9406564584124654e-324",
+  DenormMin = PickFP(Sem, "6.10352e-5", "1.40129846e-45", "4.9406564584124654e-324",
                      "3.64519953188247460253e-4951",
                      "4.94065645841246544176568792868221e-324",
                      "6.47517511943802511092443895822764655e-4966");
-  int Digits = PickFP(Sem, 6, 15, 18, 31, 33);
-  Epsilon = PickFP(Sem, "1.19209290e-7", "2.2204460492503131e-16",
+  int Digits = PickFP(Sem, 3, 6, 15, 18, 31, 33);
+  Epsilon = PickFP(Sem, "0x1.0p-10", "1.19209290e-7", "2.2204460492503131e-16",
                    "1.08420217248550443401e-19",
                    "4.94065645841246544176568792868221e-324",
                    "1.92592994438723585305597794258492732e-34");
-  int MantissaDigits = PickFP(Sem, 24, 53, 64, 106, 113);
-  int Min10Exp = PickFP(Sem, -37, -307, -4931, -291, -4931);
-  int Max10Exp = PickFP(Sem, 38, 308, 4932, 308, 4932);
-  int MinExp = PickFP(Sem, -125, -1021, -16381, -968, -16381);
-  int MaxExp = PickFP(Sem, 128, 1024, 16384, 1024, 16384);
-  Min = PickFP(Sem, "1.17549435e-38", "2.2250738585072014e-308",
+  int MantissaDigits = PickFP(Sem, 11, 24, 53, 64, 106, 113);
+  int Min10Exp = PickFP(Sem, -4, -37, -307, -4931, -291, -4931);
+  int Max10Exp = PickFP(Sem, 4, 38, 308, 4932, 308, 4932);
+  int MinExp = PickFP(Sem, -13, -125, -1021, -16381, -968, -16381);
+  int MaxExp = PickFP(Sem, 16, 128, 1024, 16384, 1024, 16384);
+  Min = PickFP(Sem, "0x1.0p-14", "1.17549435e-38", "2.2250738585072014e-308",
                "3.36210314311209350626e-4932",
                "2.00416836000897277799610805135016e-292",
                "3.36210314311209350626267781732175260e-4932");
-  Max = PickFP(Sem, "3.40282347e+38", "1.7976931348623157e+308",
+  Max = PickFP(Sem, "0x1.ffcp15", "3.40282347e+38", "1.7976931348623157e+308",
                "1.18973149535723176502e+4932",
                "1.79769313486231580793728971405301e+308",
                "1.18973149535723176508575932662800702e+4932");
@@ -685,7 +688,8 @@ static void InitializePredefinedMacros(const TargetInfo &TI,
     DefineFmt("__UINTPTR", TI.getUIntPtrType(), TI, Builder);
     DefineTypeWidth("__UINTPTR_WIDTH__", TI.getUIntPtrType(), TI, Builder);
   }
-
+	
+  DefineFloatMacros(Builder, "HALF", &TI.getHalfFormat(), "H");
   DefineFloatMacros(Builder, "FLT", &TI.getFloatFormat(), "F");
   DefineFloatMacros(Builder, "DBL", &TI.getDoubleFormat(), "");
   DefineFloatMacros(Builder, "LDBL", &TI.getLongDoubleFormat(), "L");
@@ -822,8 +826,7 @@ static void InitializePredefinedMacros(const TargetInfo &TI,
   // Macros to control C99 numerics and <float.h>
   Builder.defineMacro("__FLT_EVAL_METHOD__", Twine(TI.getFloatEvalMethod()));
   Builder.defineMacro("__FLT_RADIX__", "2");
-  int Dig = PickFP(&TI.getLongDoubleFormat(), -1/*FIXME*/, 17, 21, 33, 36);
-  Builder.defineMacro("__DECIMAL_DIG__", Twine(Dig));
+  Builder.defineMacro("__DECIMAL_DIG__", "__LDBL_DECIMAL_DIG__");
 
   if (LangOpts.getStackProtector() == LangOptions::SSPOn)
     Builder.defineMacro("__SSP__");
diff --git a/tools/clang/lib/Index/USRGeneration.cpp b/tools/clang/lib/Index/USRGeneration.cpp
index e08b85e..f64c535 100644
--- a/tools/clang/lib/Index/USRGeneration.cpp
+++ b/tools/clang/lib/Index/USRGeneration.cpp
@@ -592,6 +592,16 @@ void USRGenerator::VisitType(QualType T) {
         case BuiltinType::OCLImage1dBuffer:
         case BuiltinType::OCLImage2d:
         case BuiltinType::OCLImage2dArray:
+        case BuiltinType::OCLImage2dDepth:
+        case BuiltinType::OCLImage2dArrayDepth:
+        case BuiltinType::OCLImage2dMSAA:
+        case BuiltinType::OCLImage2dArrayMSAA:
+        case BuiltinType::OCLImage2dMSAADepth:
+        case BuiltinType::OCLImage2dArrayMSAADepth:
+        case BuiltinType::OCLImageCube:
+        case BuiltinType::OCLImageCubeArray:
+        case BuiltinType::OCLImageCubeDepth:
+        case BuiltinType::OCLImageCubeArrayDepth:
         case BuiltinType::OCLImage3d:
         case BuiltinType::OCLEvent:
         case BuiltinType::OCLSampler:
diff --git a/tools/clang/lib/Lex/LiteralSupport.cpp b/tools/clang/lib/Lex/LiteralSupport.cpp
index 6417d0f..a022b44 100644
--- a/tools/clang/lib/Lex/LiteralSupport.cpp
+++ b/tools/clang/lib/Lex/LiteralSupport.cpp
@@ -583,6 +583,12 @@ NumericLiteralParser::NumericLiteralParser(StringRef TokSpelling,
       if (isFloat || isLong) break; // FF, LF invalid.
       isFloat = true;
       continue;  // Success.
+    case 'h':      // FP Suffix for "float"
+    case 'H':
+      if (!isFPConstant) break;  // Error for integer constant.
+      if (isFloat || isLong) break; // FF, LF invalid.
+      isFloat = true;
+      continue;  // Success.
     case 'u':
     case 'U':
       if (isFPConstant) break;  // Error for floating constant.
diff --git a/tools/clang/lib/Lex/PPDirectives.cpp b/tools/clang/lib/Lex/PPDirectives.cpp
index 1741c30..2236e48 100644
--- a/tools/clang/lib/Lex/PPDirectives.cpp
+++ b/tools/clang/lib/Lex/PPDirectives.cpp
@@ -1807,7 +1807,7 @@ bool Preprocessor::ReadMacroDefinitionArgList(MacroInfo *MI, Token &Tok) {
              diag::ext_variadic_macro);
 
       // OpenCL v1.2 s6.9.e: variadic macros are not supported.
-      if (LangOpts.OpenCL) {
+      if (LangOpts.OpenCL && !LangOpts.CPlusPlus) {
         Diag(Tok, diag::err_pp_opencl_variadic_macros);
         return true;
       }
diff --git a/tools/clang/lib/Parse/ParseDecl.cpp b/tools/clang/lib/Parse/ParseDecl.cpp
index 62d4376..8aa86b0 100644
--- a/tools/clang/lib/Parse/ParseDecl.cpp
+++ b/tools/clang/lib/Parse/ParseDecl.cpp
@@ -610,23 +610,6 @@ void Parser::ParseBorlandTypeAttributes(ParsedAttributes &attrs) {
   }
 }
 
-void Parser::ParseOpenCLAttributes(ParsedAttributes &attrs) {
-  // Treat these like attributes
-  while (Tok.is(tok::kw___kernel)) {
-    IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-    SourceLocation AttrNameLoc = ConsumeToken();
-    attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-                 AttributeList::AS_Keyword);
-  }
-}
-
-void Parser::ParseOpenCLQualifiers(ParsedAttributes &Attrs) {
-  IdentifierInfo *AttrName = Tok.getIdentifierInfo();
-  SourceLocation AttrNameLoc = Tok.getLocation();
-  Attrs.addNew(AttrName, AttrNameLoc, nullptr, AttrNameLoc, nullptr, 0,
-               AttributeList::AS_Keyword);
-}
-
 /// \brief Parse a version number.
 ///
 /// version:
@@ -2438,7 +2421,6 @@ Parser::DiagnoseMissingSemiAfterTagDefinition(DeclSpec &DS, AccessSpecifier AS,
 /// [C99]   'inline'
 /// [C++]   'virtual'
 /// [C++]   'explicit'
-/// [OpenCL] '__kernel'
 ///       'friend': [C++ dcl.friend]
 ///       'constexpr': [C++0x dcl.constexpr]
 
@@ -2871,11 +2853,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
       ParseBorlandTypeAttributes(DS.getAttributes());
       continue;
 
-    // OpenCL single token adornments.
-    case tok::kw___kernel:
-      ParseOpenCLAttributes(DS.getAttributes());
-      continue;
-
     // storage-class-specifier
     case tok::kw_typedef:
       isInvalid = DS.SetStorageClassSpec(Actions, DeclSpec::SCS_typedef, Loc,
@@ -3168,17 +3145,6 @@ void Parser::ParseDeclarationSpecifiers(DeclSpec &DS,
                                  getLangOpts());
       break;
 
-    // OpenCL qualifiers:
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
     case tok::less:
       // GCC ObjC supports types like "<SomeProtocol>" as a synonym for
       // "id<SomeProtocol>".  This is hopelessly old fashioned and dangerous,
@@ -3917,13 +3883,6 @@ bool Parser::isTypeQualifier() const {
   case tok::kw_const:
   case tok::kw_volatile:
   case tok::kw_restrict:
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
     return true;
   }
 }
@@ -4065,14 +4024,6 @@ bool Parser::isTypeSpecifierQualifier() {
   case tok::kw___pascal:
   case tok::kw___unaligned:
 
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-
     return true;
 
   // C11 _Atomic
@@ -4236,14 +4187,6 @@ bool Parser::isDeclarationSpecifier(bool DisambiguatingWithExpression) {
   case tok::kw___pascal:
   case tok::kw___unaligned:
 
-  case tok::kw___private:
-  case tok::kw___local:
-  case tok::kw___global:
-  case tok::kw___constant:
-  case tok::kw___read_only:
-  case tok::kw___read_write:
-  case tok::kw___write_only:
-
     return true;
   }
 }
@@ -4425,17 +4368,6 @@ void Parser::ParseTypeQualifierListOpt(DeclSpec &DS,
                                  getLangOpts());
       break;
 
-    // OpenCL qualifiers:
-    case tok::kw___private:
-    case tok::kw___global:
-    case tok::kw___local:
-    case tok::kw___constant:
-    case tok::kw___read_only:
-    case tok::kw___write_only:
-    case tok::kw___read_write:
-      ParseOpenCLQualifiers(DS.getAttributes());
-      break;
-
     case tok::kw___uptr:
       // GNU libc headers in C mode use '__uptr' as an identifer which conflicts
       // with the MS modifier keyword.
diff --git a/tools/clang/lib/Sema/Sema.cpp b/tools/clang/lib/Sema/Sema.cpp
index 2c65332..303fc49 100644
--- a/tools/clang/lib/Sema/Sema.cpp
+++ b/tools/clang/lib/Sema/Sema.cpp
@@ -206,6 +206,16 @@ void Sema::Initialize() {
     addImplicitTypedef("image1d_buffer_t", Context.OCLImage1dBufferTy);
     addImplicitTypedef("image2d_t", Context.OCLImage2dTy);
     addImplicitTypedef("image2d_array_t", Context.OCLImage2dArrayTy);
+    addImplicitTypedef("image2d_depth_t", Context.OCLImage2dDepthTy);
+    addImplicitTypedef("image2d_array_depth_t", Context.OCLImage2dArrayDepthTy);
+    addImplicitTypedef("image2d_msaa_t", Context.OCLImage2dMSAATy);
+    addImplicitTypedef("image2d_array_msaa_t", Context.OCLImage2dArrayMSAATy);
+    addImplicitTypedef("image2d_msaa_depth_t", Context.OCLImage2dMSAADepthTy);
+    addImplicitTypedef("image2d_array_msaa_depth_t", Context.OCLImage2dArrayMSAADepthTy);
+    addImplicitTypedef("imagecube_t", Context.OCLImageCubeTy);
+    addImplicitTypedef("imagecube_array_t", Context.OCLImageCubeArrayTy);
+    addImplicitTypedef("imagecube_depth_t", Context.OCLImageCubeDepthTy);
+    addImplicitTypedef("imagecube_array_depth_t", Context.OCLImageCubeArrayDepthTy);
     addImplicitTypedef("image3d_t", Context.OCLImage3dTy);
     addImplicitTypedef("sampler_t", Context.OCLSamplerTy);
     addImplicitTypedef("event_t", Context.OCLEventTy);
diff --git a/tools/clang/lib/Sema/SemaDecl.cpp b/tools/clang/lib/Sema/SemaDecl.cpp
index 8716227..2de4683 100644
--- a/tools/clang/lib/Sema/SemaDecl.cpp
+++ b/tools/clang/lib/Sema/SemaDecl.cpp
@@ -5994,17 +5994,41 @@ void Sema::CheckVariableDeclarationType(VarDecl *NewVD) {
   if (getLangOpts().OpenCL && NewVD->isFileVarDecl()
       && T.getAddressSpace() != LangAS::opencl_constant
       && !T->isSamplerT()){
-    Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space);
-    NewVD->setInvalidDecl();
-    return;
+    // if the variable doesn't have an address space, but is a global static const variable,
+    // automatically add the constant address space
+    if (T.getAddressSpace() == 0 &&
+        (NewVD->isStaticDataMember() || NewVD->hasGlobalStorage()) &&
+        T.isConstQualified()) {
+      QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+      TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+      NewVD->setType(constant_Tinfo->getType());
+      NewVD->setTypeSourceInfo(constant_Tinfo);
+    }
+    else {
+      Diag(NewVD->getLocation(), diag::err_opencl_global_invalid_addr_space);
+      NewVD->setInvalidDecl();
+      return;
+    }
   }
   
-  // OpenCL v1.2 s6.8 -- The static qualifier is valid only in program
-  // scope.
-  if ((getLangOpts().OpenCLVersion >= 120)
-      && NewVD->isStaticLocal()) {
-    Diag(NewVD->getLocation(), diag::err_static_function_scope);
-    NewVD->setInvalidDecl();
+  // OpenCL v1.2 s6.8 -- The static qualifier is valid only in program scope.
+  // (same for Metal, enabled for CUDA as well for compatibility)
+  if (NewVD->isStaticLocal()) {
+    // however, if it is constexpr, this can be safely put into the constant address space
+    if (NewVD->isConstexpr()) {
+      // CUDA (backend) can handle this on its own
+      if (getLangOpts().OpenCL) {
+        QualType constant_T = Context.getAddrSpaceQualType(T, LangAS::opencl_constant);
+        TypeSourceInfo* constant_Tinfo = Context.getTrivialTypeSourceInfo(constant_T);
+        NewVD->setType(constant_Tinfo->getType());
+        NewVD->setTypeSourceInfo(constant_Tinfo);
+      }
+    }
+    // CUDA shared/local decls are allowed to be static, so ignore them
+    else if(!(getLangOpts().CUDA && NewVD->hasAttr<CUDASharedAttr>())) {
+      Diag(NewVD->getLocation(), diag::err_static_function_scope);
+      NewVD->setInvalidDecl();
+    }
     return;
   }
 
@@ -6621,7 +6645,7 @@ enum OpenCLParamType {
   RecordKernelParam
 };
 
-static OpenCLParamType getOpenCLKernelParameterType(QualType PT) {
+static OpenCLParamType getOpenCLKernelParameterType(QualType PT, const bool is_metal) {
   if (PT->isPointerType()) {
     QualType PointeeType = PT->getPointeeType();
     if (PointeeType->isPointerType())
@@ -6642,7 +6666,7 @@ static OpenCLParamType getOpenCLKernelParameterType(QualType PT) {
   if (PT->isEventT())
     return InvalidKernelParam;
 
-  if (PT->isHalfType())
+  if (PT->isHalfType() && !is_metal)
     return InvalidKernelParam;
 
   if (PT->isRecordType())
@@ -6655,7 +6679,8 @@ static void checkIsValidOpenCLKernelParameter(
   Sema &S,
   Declarator &D,
   ParmVarDecl *Param,
-  llvm::SmallPtrSet<const Type *, 16> &ValidTypes) {
+  llvm::SmallPtrSet<const Type *, 16> &ValidTypes,
+  const bool is_metal) {
   QualType PT = Param->getType();
 
   // Cache the valid types we encounter to avoid rechecking structs that are
@@ -6663,7 +6688,7 @@ static void checkIsValidOpenCLKernelParameter(
   if (ValidTypes.count(PT.getTypePtr()))
     return;
 
-  switch (getOpenCLKernelParameterType(PT)) {
+  switch (getOpenCLKernelParameterType(PT, is_metal)) {
   case PtrPtrKernelParam:
     // OpenCL v1.2 s6.9.a:
     // A kernel function argument cannot be declared as a
@@ -6727,6 +6752,8 @@ static void checkIsValidOpenCLKernelParameter(
       continue;
     }
 
+    // TODO: this should also check base classes
+
     // Adds everything except the original parameter declaration (which is not a
     // field itself) to the history stack.
     const RecordDecl *RD;
@@ -6740,13 +6767,17 @@ static void checkIsValidOpenCLKernelParameter(
     // Add a null marker so we know when we've gone back up a level
     VisitStack.push_back(nullptr);
 
+    // if this is an aggregate of images, all is well
+    if (RD->getTypeForDecl()->isAggregateImageType())
+      continue;
+
     for (const auto *FD : RD->fields()) {
       QualType QT = FD->getType();
 
       if (ValidTypes.count(QT.getTypePtr()))
         continue;
 
-      OpenCLParamType ParamType = getOpenCLKernelParameterType(QT);
+      OpenCLParamType ParamType = getOpenCLKernelParameterType(QT, is_metal);
       if (ParamType == ValidKernelParam)
         continue;
 
@@ -7578,15 +7609,8 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
     }
   }
 
-  if (NewFD->hasAttr<OpenCLKernelAttr>()) {
-    // OpenCL v1.2 s6.8 static is invalid for kernel functions.
-    if ((getLangOpts().OpenCLVersion >= 120)
-        && (SC == SC_Static)) {
-      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
-      D.setInvalidType();
-    }
-    
-    // OpenCL v1.2, s6.9 -- Kernels can only have return type void.
+  if (NewFD->hasAttr<ComputeKernelAttr>()) {
+    // Kernels can only have return type void.
     if (!NewFD->getReturnType()->isVoidType()) {
       SourceRange RTRange = NewFD->getReturnTypeSourceRange();
       Diag(D.getIdentifierLoc(), diag::err_expected_kernel_void_return_type)
@@ -7594,10 +7618,23 @@ Sema::ActOnFunctionDeclarator(Scope *S, Declarator &D, DeclContext *DC,
                                 : FixItHint());
       D.setInvalidType();
     }
+  }
+
+  if(NewFD->hasAttr<ComputeKernelAttr>() ||
+     NewFD->hasAttr<GraphicsVertexShaderAttr>() ||
+     NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    // static is invalid for kernel/vertex/fragment functions.
+    if (SC == SC_Static) {
+      Diag(D.getIdentifierLoc(), diag::err_static_kernel);
+      D.setInvalidType();
+    }
 
-    llvm::SmallPtrSet<const Type *, 16> ValidTypes;
-    for (auto Param : NewFD->params())
-      checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes);
+    // only check this for opencl/metal
+    if (getLangOpts().OpenCL) {
+      llvm::SmallPtrSet<const Type *, 16> ValidTypes;
+      for (auto Param : NewFD->params())
+        checkIsValidOpenCLKernelParameter(*this, D, Param, ValidTypes, getLangOpts().Metal);
+    }
   }
 
   MarkUnusedFileScopedDecl(NewFD);
@@ -7918,7 +7955,10 @@ bool Sema::CheckFunctionDeclaration(Scope *S, FunctionDecl *NewFD,
     // the function returns a UDT (class, struct, or union type) that is not C
     // compatible, and if it does, warn the user.
     // But, issue any diagnostic on the first declaration only.
-    if (NewFD->isExternC() && Previous.empty()) {
+    if (NewFD->isExternC() && Previous.empty() &&
+		// ignore this for vertex/fragment shaders
+		!NewFD->hasAttr<GraphicsVertexShaderAttr>() &&
+		!NewFD->hasAttr<GraphicsFragmentShaderAttr>()) {
       QualType R = NewFD->getReturnType();
       if (R->isIncompleteType() && !R->isVoidType())
         Diag(NewFD->getLocation(), diag::warn_return_value_udt_incomplete)
@@ -7959,9 +7999,10 @@ void Sema::CheckMain(FunctionDecl* FD, const DeclSpec& DS) {
     FD->setConstexpr(false);
   }
 
-  if (getLangOpts().OpenCL) {
+  // TODO: this doesn't seem necessary?
+  if (getLangOpts().OpenCL || getLangOpts().CUDA) {
     Diag(FD->getLocation(), diag::err_opencl_no_main)
-        << FD->hasAttr<OpenCLKernelAttr>();
+        << FD->hasAttr<ComputeKernelAttr>();
     FD->setInvalidDecl();
     return;
   }
@@ -9781,8 +9822,10 @@ static bool ShouldWarnAboutMissingPrototype(const FunctionDecl *FD,
   if (FD->isFunctionTemplateSpecialization())
     return false;
 
-  // Don't warn for OpenCL kernels.
-  if (FD->hasAttr<OpenCLKernelAttr>())
+  // Don't warn for compute kernels, or vertex/fragment shaders.
+  if (FD->hasAttr<ComputeKernelAttr>() ||
+      FD->hasAttr<GraphicsVertexShaderAttr>() ||
+      FD->hasAttr<GraphicsFragmentShaderAttr>())
     return false;
 
   bool MissingPrototype = true;
@@ -9870,6 +9913,28 @@ static void RebuildLambdaScopeInfo(CXXMethodDecl *CallOperator,
   }
 }
 
+static void AggregateTypeCompleter(Sema& S, const CXXRecordDecl* decl) {
+	if(decl == nullptr) return;
+	
+	// make sure decl is complete
+	S.RequireCompleteType(decl->getLocStart(), QualType(decl->getTypeForDecl(), 0),
+						  diag::err_typecheck_decl_incomplete_type);
+	
+	// must have definition
+	if(!decl->hasDefinition()) return;
+	
+	// iterate over / recurse into all bases, and complete all their fields
+	for(const auto& base : decl->bases()) {
+		AggregateTypeCompleter(S, base.getType()->getAsCXXRecordDecl());
+	}
+	
+	// iterate over and complete all fields
+	for(const auto& field : decl->fields()) {
+		S.RequireCompleteType(field->getLocStart(), field->getType(),
+							  diag::err_typecheck_decl_incomplete_type);
+	}
+}
+
 Decl *Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Decl *D) {
   // Clear the last template instantiation error context.
   LastTemplateInstantiationErrorContext = ActiveTemplateInstantiation();
@@ -9954,6 +10019,32 @@ Decl *Sema::ActOnStartOfFunctionDef(Scope *FnBodyScope, Decl *D) {
   CheckParmsForFunctionDef(FD->param_begin(), FD->param_end(),
                            /*CheckParameterNames=*/true);
 
+  // for kernel and shader functions: make sure that function parameter types are complete,
+  // including pointer/pointee types that must always be complete as well, since their sizes
+  // and (possibly) structure need to be known later on
+  if(FD->hasAttr<ComputeKernelAttr>() ||
+     FD->hasAttr<GraphicsVertexShaderAttr>() ||
+     FD->hasAttr<GraphicsFragmentShaderAttr>()) {
+    for (const auto& Param : FD->params()) {
+      const auto param_type = Param->getType();
+      const CXXRecordDecl* cxx_rdecl = nullptr;
+      if(param_type->isPointerType()) {
+        const auto pointee_type = param_type->getPointeeType();
+        RequireCompleteType(Param->getLocation(), pointee_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = pointee_type->getAsCXXRecordDecl();
+      }
+      else {
+        RequireCompleteType(Param->getLocation(), param_type,
+                            diag::err_typecheck_decl_incomplete_type);
+        cxx_rdecl = param_type->getAsCXXRecordDecl();
+	  }
+
+      // if this is an aggregate, ensure that all contained types are also complete
+      AggregateTypeCompleter(*this, cxx_rdecl);
+    }
+  }
+
   // Introduce our parameters into the function scope
   for (auto Param : FD->params()) {
     Param->setOwningFunction(FD);
@@ -11941,7 +12032,7 @@ FieldDecl *Sema::CheckFieldDecl(DeclarationName Name, QualType T,
   }
 
   // OpenCL v1.2 s6.9.c: bitfields are not supported.
-  if (BitWidth && getLangOpts().OpenCL) {
+  if (BitWidth && getLangOpts().OpenCL && !getLangOpts().CPlusPlus) {
     Diag(Loc, diag::err_opencl_bitfields);
     InvalidDecl = true;
   }
diff --git a/tools/clang/lib/Sema/SemaDeclAttr.cpp b/tools/clang/lib/Sema/SemaDeclAttr.cpp
index 61683cd..1268dbb 100644
--- a/tools/clang/lib/Sema/SemaDeclAttr.cpp
+++ b/tools/clang/lib/Sema/SemaDeclAttr.cpp
@@ -1956,6 +1956,94 @@ static void handleVisibilityAttr(Sema &S, Decl *D, const AttributeList &Attr,
     D->addAttr(newAttr);
 }
 
+static void handleFloorImageDataTypeAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!Attr.hasParsedType()) {
+    S.Diag(Attr.getLoc(), diag::err_attribute_wrong_number_arguments)
+      << Attr.getName() << 1;
+    return;
+  }
+
+  TypeSourceInfo *ParmTSI = nullptr;
+  S.GetTypeFromParser(Attr.getTypeArg(), &ParmTSI);
+  D->addAttr(::new (S.Context) FloorImageDataTypeAttr(Attr.getLoc(), S.Context, ParmTSI,
+                                                      Attr.getAttributeSpellingListIndex()));
+}
+
+static void handleGraphicsFBOColorLocationAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+  S.AddGraphicsFBOColorLocationAttr(Attr.getRange(), D, Attr.getArgAsExpr(0),
+                                    Attr.getAttributeSpellingListIndex());
+}
+
+void Sema::AddGraphicsFBOColorLocationAttr(SourceRange AttrRange, Decl *D, Expr *E, unsigned SpellingListIndex) {
+  GraphicsFBOColorLocationAttr TmpAttr(AttrRange, Context, E, SpellingListIndex);
+  SourceLocation AttrLoc = AttrRange.getBegin();
+
+  QualType T;
+  if (ValueDecl *VD = dyn_cast<ValueDecl>(D))
+    T = VD->getType();
+  else {
+    Diag(AttrLoc, diag::err_attribute_argument_type) <<
+      &TmpAttr << AANT_ArgumentIntegerConstant;
+    return;
+  }
+
+  // TODO: check usage
+
+  if (!E->isValueDependent()) {
+    // TODO: might want to use/check isPotentialConstantExprUnevaluated
+
+    llvm::APSInt ColorLoc(32);
+    ExprResult ICE
+      = VerifyIntegerConstantExpression(E, &ColorLoc,
+          diag::err_align_value_attribute_argument_not_int,
+            /*AllowFold*/ true);
+    if (ICE.isInvalid())
+      return;
+
+    // check for < 0 location
+    if (ColorLoc.isNegative()) {
+      unsigned diagID = Diags.getCustomDiagID(DiagnosticsEngine::Error, "%0");
+      Diags.Report(AttrRange.getBegin(), diagID) << "location must not be negative!";
+      return;
+    }
+
+    auto loc_attr = ::new (Context) GraphicsFBOColorLocationAttr(AttrRange, Context, ICE.get(), SpellingListIndex);
+    loc_attr->setEvalLocation((unsigned int)ColorLoc.getZExtValue());
+    D->addAttr(loc_attr);
+    return;
+  }
+
+  // Save dependent expressions in the AST to be instantiated.
+  D->addAttr(::new (Context) GraphicsFBOColorLocationAttr(TmpAttr));
+  return;
+}
+
+static void handleGraphicsFBODepthTypeAttr(Sema &S, Decl *D, const AttributeList &Attr) {
+  if (!checkAttributeNumArgs(S, Attr, 1)) return;
+
+  GraphicsFBODepthTypeAttr::DepthQualifierType type;
+  if (Attr.isArgIdent(0)) {
+    IdentifierLoc *Ident = Attr.getArgAsIdent(0);
+    StringRef TypeString = Ident->Ident->getName();
+
+    if (!GraphicsFBODepthTypeAttr::ConvertStrToDepthQualifierType(TypeString, type)) {
+      S.Diag(Ident->Loc, diag::warn_attribute_type_not_supported)
+        << Attr.getName() << TypeString;
+      return;
+    }
+  }
+  else {
+    S.Diag(Attr.getLoc(), diag::err_attribute_argument_type) <<
+      Attr.getName() << AANT_ArgumentIdentifier;
+    return;
+  }
+
+  D->addAttr(::new (S.Context)
+             GraphicsFBODepthTypeAttr(Attr.getRange(), S.Context, type,
+                                      Attr.getAttributeSpellingListIndex()));
+}
+
 static void handleObjCMethodFamilyAttr(Sema &S, Decl *decl,
                                        const AttributeList &Attr) {
   ObjCMethodDecl *method = cast<ObjCMethodDecl>(decl);
@@ -2679,6 +2767,58 @@ static void handleAnnotateAttr(Sema &S, Decl *D, const AttributeList &Attr) {
                           Attr.getAttributeSpellingListIndex()));
 }
 
+static void handleAlignValueAttr(Sema &S, Decl *D,
+                                 const AttributeList &Attr) {
+  S.AddAlignValueAttr(Attr.getRange(), D, Attr.getArgAsExpr(0),
+                      Attr.getAttributeSpellingListIndex());
+}
+
+void Sema::AddAlignValueAttr(SourceRange AttrRange, Decl *D, Expr *E,
+                             unsigned SpellingListIndex) {
+  AlignValueAttr TmpAttr(AttrRange, Context, E, SpellingListIndex);
+  SourceLocation AttrLoc = AttrRange.getBegin();
+
+  QualType T;
+  if (TypedefNameDecl *TD = dyn_cast<TypedefNameDecl>(D))
+    T = TD->getUnderlyingType();
+  else if (ValueDecl *VD = dyn_cast<ValueDecl>(D))
+    T = VD->getType();
+  else
+    llvm_unreachable("Unknown decl type for align_value");
+
+  if (!T->isDependentType() && !T->isAnyPointerType() &&
+      !T->isReferenceType() && !T->isMemberPointerType()) {
+    Diag(AttrLoc, diag::warn_attribute_pointer_or_reference_only)
+      << &TmpAttr /*TmpAttr.getName()*/ << T << D->getSourceRange();
+    return;
+  }
+
+  if (!E->isValueDependent()) {
+    llvm::APSInt Alignment(32);
+    ExprResult ICE
+      = VerifyIntegerConstantExpression(E, &Alignment,
+          diag::err_align_value_attribute_argument_not_int,
+            /*AllowFold*/ false);
+    if (ICE.isInvalid())
+      return;
+
+    if (!Alignment.isPowerOf2()) {
+      Diag(AttrLoc, diag::err_alignment_not_power_of_two)
+        << E->getSourceRange();
+      return;
+    }
+
+    D->addAttr(::new (Context)
+               AlignValueAttr(AttrRange, Context, ICE.get(),
+               SpellingListIndex));
+    return;
+  }
+
+  // Save dependent expressions in the AST to be instantiated.
+  D->addAttr(::new (Context) AlignValueAttr(TmpAttr));
+  return;
+}
+
 static void handleAlignedAttr(Sema &S, Decl *D, const AttributeList &Attr) {
   // check the attribute arguments.
   if (Attr.getNumArgs() > 1) {
@@ -3026,22 +3166,6 @@ static void handleOptimizeNoneAttr(Sema &S, Decl *D,
                               Attr.getAttributeSpellingListIndex()));
 }
 
-static void handleGlobalAttr(Sema &S, Decl *D, const AttributeList &Attr) {
-  FunctionDecl *FD = cast<FunctionDecl>(D);
-  if (!FD->getReturnType()->isVoidType()) {
-    SourceRange RTRange = FD->getReturnTypeSourceRange();
-    S.Diag(FD->getTypeSpecStartLoc(), diag::err_kern_type_not_void_return)
-        << FD->getType()
-        << (RTRange.isValid() ? FixItHint::CreateReplacement(RTRange, "void")
-                              : FixItHint());
-    return;
-  }
-
-  D->addAttr(::new (S.Context)
-              CUDAGlobalAttr(Attr.getRange(), S.Context,
-                            Attr.getAttributeSpellingListIndex()));
-}
-
 static void handleGNUInlineAttr(Sema &S, Decl *D, const AttributeList &Attr) {
   FunctionDecl *Fn = cast<FunctionDecl>(D);
   if (!Fn->isInlineSpecified()) {
@@ -4102,6 +4226,9 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case AttributeList::AT_Aligned:
     handleAlignedAttr(S, D, Attr);
     break;
+  case AttributeList::AT_AlignValue:
+    handleAlignValueAttr(S, D, Attr);
+    break;
   case AttributeList::AT_AlwaysInline:
     handleAlwaysInlineAttr(S, D, Attr);
     break;
@@ -4159,9 +4286,6 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case AttributeList::AT_FormatArg:
     handleFormatArgAttr(S, D, Attr);
     break;
-  case AttributeList::AT_CUDAGlobal:
-    handleGlobalAttr(S, D, Attr);
-    break;
   case AttributeList::AT_CUDADevice:
     handleSimpleAttribute<CUDADeviceAttr>(S, D, Attr);
     break;
@@ -4399,11 +4523,38 @@ static void ProcessDeclAttribute(Sema &S, Scope *scope, Decl *D,
   case AttributeList::AT_IntelOclBicc:
     handleCallConvAttr(S, D, Attr);
     break;
-  case AttributeList::AT_OpenCLKernel:
-    handleSimpleAttribute<OpenCLKernelAttr>(S, D, Attr);
+  case AttributeList::AT_ComputeKernel:
+    handleSimpleAttribute<ComputeKernelAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsVertexShader:
+    handleSimpleAttribute<GraphicsVertexShaderAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFragmentShader:
+    handleSimpleAttribute<GraphicsFragmentShaderAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_ImageAccess:
+    handleSimpleAttribute<ImageAccessAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_FloorImageDataType:
+    handleFloorImageDataTypeAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_VectorCompat:
+    handleSimpleAttribute<VectorCompatAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFBOColorLocation:
+    handleGraphicsFBOColorLocationAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsFBODepthType:
+    handleGraphicsFBODepthTypeAttr(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsVertexPosition:
+    handleSimpleAttribute<GraphicsVertexPositionAttr>(S, D, Attr);
+    break;
+  case AttributeList::AT_GraphicsPointSize:
+    handleSimpleAttribute<GraphicsPointSizeAttr>(S, D, Attr);
     break;
-  case AttributeList::AT_OpenCLImageAccess:
-    handleSimpleAttribute<OpenCLImageAccessAttr>(S, D, Attr);
+  case AttributeList::AT_GraphicsStageInput:
+    handleSimpleAttribute<GraphicsStageInputAttr>(S, D, Attr);
     break;
 
   // Microsoft attributes:
@@ -4553,7 +4704,7 @@ void Sema::ProcessDeclAttributeList(Scope *S, Decl *D,
     return;
   }
 
-  if (!D->hasAttr<OpenCLKernelAttr>()) {
+  if (!D->hasAttr<ComputeKernelAttr>()) {
     // These attributes cannot be applied to a non-kernel function.
     if (Attr *A = D->getAttr<ReqdWorkGroupSizeAttr>()) {
       Diag(D->getLocation(), diag::err_opencl_kernel_attr) << A;
diff --git a/tools/clang/lib/Sema/SemaDeclCXX.cpp b/tools/clang/lib/Sema/SemaDeclCXX.cpp
index c5cd83d..71aeb7e 100644
--- a/tools/clang/lib/Sema/SemaDeclCXX.cpp
+++ b/tools/clang/lib/Sema/SemaDeclCXX.cpp
@@ -13026,21 +13026,13 @@ Sema::checkExceptionSpecification(ExceptionSpecificationType EST,
 
 /// IdentifyCUDATarget - Determine the CUDA compilation target for this function
 Sema::CUDAFunctionTarget Sema::IdentifyCUDATarget(const FunctionDecl *D) {
-  // Implicitly declared functions (e.g. copy constructors) are
-  // __host__ __device__
-  if (D->isImplicit())
-    return CFT_HostDevice;
-
-  if (D->hasAttr<CUDAGlobalAttr>())
+  if (D->hasAttr<ComputeKernelAttr>())
     return CFT_Global;
 
-  if (D->hasAttr<CUDADeviceAttr>()) {
-    if (D->hasAttr<CUDAHostAttr>())
-      return CFT_HostDevice;
-    return CFT_Device;
-  }
-
-  return CFT_Host;
+  // if not a kernel, always default to device
+  // this is IMO a much saner approach and doesn't require to add the __device__
+  // attribute to _all_ functions
+  return CFT_Device;
 }
 
 bool Sema::CheckCUDATarget(CUDAFunctionTarget CallerTarget,
diff --git a/tools/clang/lib/Sema/SemaExpr.cpp b/tools/clang/lib/Sema/SemaExpr.cpp
index 35dad82..7eb8f69 100644
--- a/tools/clang/lib/Sema/SemaExpr.cpp
+++ b/tools/clang/lib/Sema/SemaExpr.cpp
@@ -444,7 +444,7 @@ ExprResult Sema::DefaultFunctionArrayConversion(Expr *E) {
   if (Ty->isFunctionType()) {
     // If we are here, we are not calling a function but taking
     // its address (which is not allowed in OpenCL v1.0 s6.8.a.3).
-    if (getLangOpts().OpenCL) {
+    if (getLangOpts().OpenCL && !LangOpts.CPlusPlus) {
       Diag(E->getExprLoc(), diag::err_opencl_taking_function_address);
       return ExprError();
     }
@@ -4712,7 +4712,7 @@ Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
   if (getLangOpts().CUDA) {
     if (Config) {
       // CUDA: Kernel calls must be to global functions
-      if (FDecl && !FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && !FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc,diag::err_kern_call_not_global_function)
             << FDecl->getName() << Fn->getSourceRange());
 
@@ -4722,7 +4722,7 @@ Sema::BuildResolvedCallExpr(Expr *Fn, NamedDecl *NDecl,
             << Fn->getType() << Fn->getSourceRange());
     } else {
       // CUDA: Calls to global functions must be configured
-      if (FDecl && FDecl->hasAttr<CUDAGlobalAttr>())
+      if (FDecl && FDecl->hasAttr<ComputeKernelAttr>())
         return ExprError(Diag(LParenLoc, diag::err_global_call_not_config)
             << FDecl->getName() << Fn->getSourceRange());
     }
@@ -8953,7 +8953,7 @@ QualType Sema::CheckAddressOfOperand(ExprResult &OrigOp, SourceLocation OpLoc) {
   Expr *op = OrigOp.get()->IgnoreParens();
 
   // OpenCL v1.0 s6.8.a.3: Pointers to functions are not allowed.
-  if (LangOpts.OpenCL && op->getType()->isFunctionType()) {
+  if (LangOpts.OpenCL && !LangOpts.CPlusPlus && op->getType()->isFunctionType()) {
     Diag(op->getExprLoc(), diag::err_opencl_taking_function_address);
     return QualType();
   }
diff --git a/tools/clang/lib/Sema/SemaInit.cpp b/tools/clang/lib/Sema/SemaInit.cpp
index 06ca9ae..a517db4 100644
--- a/tools/clang/lib/Sema/SemaInit.cpp
+++ b/tools/clang/lib/Sema/SemaInit.cpp
@@ -3970,6 +3970,7 @@ static void TryReferenceInitializationCore(Sema &S,
   //         where "cv1 T1" is reference-compatible with "cv3 T3",
   //
   // DR1287 removes the "implicitly" here.
+  bool isOpenCLASRef = false;
   if (T2->isRecordType()) {
     if (RefRelationship == Sema::Ref_Incompatible) {
       ConvOvlResult = TryRefInitWithConversionFunction(
@@ -3990,8 +3991,15 @@ static void TryReferenceInitializationCore(Sema &S,
       return;
     }
 
-    Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
-    return;
+    if(S.getLangOpts().OpenCL &&
+       ((cv1T1.getAddressSpace() == 0 && cv2T2.getAddressSpace() != 0) ||
+        (cv1T1.getAddressSpace() != 0 && cv2T2.getAddressSpace() == 0))) {
+      isOpenCLASRef = true;
+    }
+    if(!isOpenCLASRef) {
+      Sequence.SetFailed(InitializationSequence::FK_ReferenceInitDropsQualifiers);
+      return;
+    }
   }
 
   //      - Otherwise, a temporary of type "cv1 T1" is created and initialized
@@ -4721,13 +4729,18 @@ void InitializationSequence::InitializeFrom(Sema &S,
         tryObjCWritebackConversion(S, *this, Entity, Initializer)) {
       return;
     }
+  }
 
+  // need to try these two when using C++ with OpenCL
+  if (!S.getLangOpts().CPlusPlus || S.getLangOpts().OpenCL) {
     if (TryOCLSamplerInitialization(S, *this, DestType, Initializer))
       return;
 
     if (TryOCLZeroEventInitialization(S, *this, DestType, Initializer))
       return;
+  }
 
+  if (!S.getLangOpts().CPlusPlus) {
     // Handle initialization in C
     AddCAssignmentStep(DestType);
     MaybeProduceObjCObject(S, *this, Entity);
@@ -5926,7 +5939,10 @@ InitializationSequence::Perform(Sema &S,
 
     case SK_BindReferenceToTemporary: {
       // Make sure the "temporary" is actually an rvalue.
-      assert(CurInit.get()->isRValue() && "not a temporary");
+      // TODO: fix this!
+      //if(CurInit.get()->getType()) {
+      //assert(CurInit.get()->isRValue() && "not a temporary");
+      //}
 
       // Check exception specifications
       if (S.CheckExceptionSpecCompatibility(CurInit.get(), DestType))
diff --git a/tools/clang/lib/Sema/SemaOverload.cpp b/tools/clang/lib/Sema/SemaOverload.cpp
index 03001d8..2c4bc8c 100644
--- a/tools/clang/lib/Sema/SemaOverload.cpp
+++ b/tools/clang/lib/Sema/SemaOverload.cpp
@@ -1451,6 +1451,7 @@ static bool IsStandardConversion(Sema &S, Expr* From, QualType ToType,
       // We were able to resolve the address of the overloaded function,
       // so we can convert to the type of that function.
       FromType = Fn->getType();
+      SCS.setFromType(FromType);
 
       // we can sometimes resolve &foo<int> regardless of ToType, so check
       // if the type matches (identity) or we are converting to bool
@@ -4048,7 +4049,7 @@ Sema::CompareReferenceRelationship(SourceLocation Loc,
     
   if (T1Quals == T2Quals)
     return Ref_Compatible;
-  else if (T1Quals.compatiblyIncludes(T2Quals))
+  else if (T1Quals.compatiblyIncludes(T2Quals, !getASTContext().getLangOpts().OpenCL))
     return Ref_Compatible_With_Added_Qualification;
   else
     return Ref_Related;
@@ -4387,7 +4388,7 @@ TryReferenceInit(Sema &S, Expr *Init, QualType DeclType,
     T1Quals.removeObjCLifetime();
     T2Quals.removeObjCGCAttr();
     T2Quals.removeObjCLifetime();
-    if (!T1Quals.compatiblyIncludes(T2Quals))
+    if (!T1Quals.compatiblyIncludes(T2Quals, !S.getLangOpts().OpenCL))
       return ICS;
   }
 
diff --git a/tools/clang/lib/Sema/SemaStmtAttr.cpp b/tools/clang/lib/Sema/SemaStmtAttr.cpp
index a32e0fb..9876c05 100644
--- a/tools/clang/lib/Sema/SemaStmtAttr.cpp
+++ b/tools/clang/lib/Sema/SemaStmtAttr.cpp
@@ -95,7 +95,7 @@ static Attr *handleLoopHintAttr(Sema &S, Stmt *St, const AttributeList &A,
     }
     if (ValueInfo->isStr("disable"))
       ValueInt = 0;
-    else if (ValueInfo->isStr("enable"))
+    else if (ValueInfo->isStr("enable") || ValueInfo->isStr("full"))
       ValueInt = 1;
     else {
       S.Diag(ValueLoc->Loc, diag::err_pragma_loop_invalid_keyword);
diff --git a/tools/clang/lib/Sema/SemaTemplateDeduction.cpp b/tools/clang/lib/Sema/SemaTemplateDeduction.cpp
index 53a75d2..1e31cb8 100644
--- a/tools/clang/lib/Sema/SemaTemplateDeduction.cpp
+++ b/tools/clang/lib/Sema/SemaTemplateDeduction.cpp
@@ -2715,7 +2715,7 @@ CheckOriginalCallArgDeduction(Sema &S, Sema::OriginalCallArg OriginalArg,
 
     if (AQuals == DeducedAQuals) {
       // Qualifiers match; there's nothing to do.
-    } else if (!DeducedAQuals.compatiblyIncludes(AQuals)) {
+    } else if (!DeducedAQuals.compatiblyIncludes(AQuals, !S.getLangOpts().OpenCL)) {
       return true;
     } else {        
       // Qualifiers are compatible, so have the argument type adopt the
diff --git a/tools/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp b/tools/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp
index accec95..333f28b 100644
--- a/tools/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp
+++ b/tools/clang/lib/Sema/SemaTemplateInstantiateDecl.cpp
@@ -129,6 +129,17 @@ static void instantiateDependentAlignedAttr(
   }
 }
 
+static void instantiateDependentAlignValueAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const AlignValueAttr *Aligned, Decl *New) {
+  // The alignment expression is a constant expression.
+  EnterExpressionEvaluationContext Unevaluated(S, Sema::ConstantEvaluated);
+  ExprResult Result = S.SubstExpr(Aligned->getAlignment(), TemplateArgs);
+  if (!Result.isInvalid())
+    S.AddAlignValueAttr(Aligned->getLocation(), New, Result.getAs<Expr>(),
+                        Aligned->getSpellingListIndex());
+}
+
 static void instantiateDependentEnableIfAttr(
     Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
     const EnableIfAttr *A, const Decl *Tmpl, Decl *New) {
@@ -164,6 +175,30 @@ static void instantiateDependentEnableIfAttr(
   New->addAttr(EIA);
 }
 
+static void instantiateDependentFloorImageDataTypeAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const FloorImageDataTypeAttr *A, const Decl *Tmpl, Decl *New) {
+  TypeSourceInfo *Result = S.SubstType(A->getImageDataTypeLoc(), TemplateArgs,
+                                       A->getLocation(), DeclarationName());
+  if (Result) {
+    FloorImageDataTypeAttr *new_attr = new (S.getASTContext())
+        FloorImageDataTypeAttr(A->getLocation(), S.getASTContext(), Result,
+                               A->getSpellingListIndex());
+    New->addAttr(new_attr);
+  }
+}
+
+static void instantiateDependentGraphicsFBOColorLocationAttr(
+    Sema &S, const MultiLevelTemplateArgumentList &TemplateArgs,
+    const GraphicsFBOColorLocationAttr *A, const Decl *Tmpl, Decl *New) {
+  // TODO: check Tmpl with isPotentialConstantExprUnevaluated?
+  EnterExpressionEvaluationContext Unevaluated(S, Sema::ConstantEvaluated);
+  ExprResult Result = S.SubstExpr(A->getColorLocation(), TemplateArgs);
+  if (!Result.isInvalid())
+    S.AddGraphicsFBOColorLocationAttr(A->getLocation(), New, Result.getAs<Expr>(),
+                                      A->getSpellingListIndex());
+}
+
 void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
                             const Decl *Tmpl, Decl *New,
                             LateInstantiatedAttrVec *LateAttrs,
@@ -176,6 +211,12 @@ void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
       continue;
     }
 
+    const AlignValueAttr *AlignValue = dyn_cast<AlignValueAttr>(TmplAttr);
+    if (AlignValue) {
+      instantiateDependentAlignValueAttr(*this, TemplateArgs, AlignValue, New);
+      continue;
+    }
+
     const EnableIfAttr *EnableIf = dyn_cast<EnableIfAttr>(TmplAttr);
     if (EnableIf && EnableIf->getCond()->isValueDependent()) {
       instantiateDependentEnableIfAttr(*this, TemplateArgs, EnableIf, Tmpl,
@@ -183,6 +224,18 @@ void Sema::InstantiateAttrs(const MultiLevelTemplateArgumentList &TemplateArgs,
       continue;
     }
 
+    const FloorImageDataTypeAttr *ImgType = dyn_cast<FloorImageDataTypeAttr>(TmplAttr);
+    if (ImgType && ImgType->getImageDataType()->isDependentType()) {
+      instantiateDependentFloorImageDataTypeAttr(*this, TemplateArgs, ImgType, Tmpl, New);
+      continue;
+    }
+
+    const GraphicsFBOColorLocationAttr *ColorLoc = dyn_cast<GraphicsFBOColorLocationAttr>(TmplAttr);
+    if (ColorLoc) {
+      instantiateDependentGraphicsFBOColorLocationAttr(*this, TemplateArgs, ColorLoc, Tmpl, New);
+      continue;
+    }
+
     assert(!TmplAttr->isPackExpansion());
     if (TmplAttr->isLateParsed() && LateAttrs) {
       // Late parsed attributes must be instantiated and attached after the
diff --git a/tools/clang/lib/Sema/SemaType.cpp b/tools/clang/lib/Sema/SemaType.cpp
index be1191c..dd9edad 100644
--- a/tools/clang/lib/Sema/SemaType.cpp
+++ b/tools/clang/lib/Sema/SemaType.cpp
@@ -1746,7 +1746,7 @@ bool Sema::CheckFunctionReturnType(QualType T, SourceLocation Loc) {
   }
 
   // Functions cannot return half FP.
-  if (T->isHalfType()) {
+  if (T->isHalfType() && !LangOpts.OpenCL && !LangOpts.CUDA) {
     Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 1 <<
       FixItHint::CreateInsertion(Loc, "*");
     return true;
@@ -1776,7 +1776,7 @@ QualType Sema::BuildFunctionType(QualType T,
     if (ParamType->isVoidType()) {
       Diag(Loc, diag::err_param_with_void_type);
       Invalid = true;
-    } else if (ParamType->isHalfType()) {
+    } else if (ParamType->isHalfType() && !LangOpts.OpenCL && !LangOpts.CUDA) {
       // Disallow half FP arguments.
       Diag(Loc, diag::err_parameters_retval_cannot_have_fp16_type) << 0 <<
         FixItHint::CreateInsertion(Loc, "*");
@@ -2474,8 +2474,24 @@ getCCForDeclaratorChunk(Sema &S, Declarator &D,
     }
   }
 
-  return S.Context.getDefaultCallingConvention(FTI.isVariadic,
-                                               IsCXXInstanceMethod);
+  CallingConv CC = S.Context.getDefaultCallingConvention(FTI.isVariadic,
+                                                         IsCXXInstanceMethod);
+
+  // Attribute AT_ComputeKernel affects the calling convention only on
+  // the SPIR target, hence it cannot be treated as a calling
+  // convention attribute. This is the simplest place to infer
+  // "spir_kernel" for OpenCL kernels on SPIR.
+  if (CC == CC_SpirFunction) {
+    for (const AttributeList *Attr = D.getDeclSpec().getAttributes().getList();
+         Attr; Attr = Attr->getNext()) {
+      if (Attr->getKind() == AttributeList::AT_ComputeKernel) {
+        CC = CC_SpirKernel;
+        break;
+      }
+    }
+  }
+
+  return CC;
 }
 
 static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
@@ -2751,7 +2767,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
             S.Diag(D.getIdentifierLoc(), diag::err_opencl_half_return) << T;
             D.setInvalidType(true);
           } 
-        } else {
+        } else if (!S.getLangOpts().CUDA) {
           S.Diag(D.getIdentifierLoc(),
             diag::err_parameters_retval_cannot_have_fp16_type) << 1;
           D.setInvalidType(true);
@@ -2941,7 +2957,7 @@ static TypeSourceInfo *GetFullTypeForDeclarator(TypeProcessingState &state,
                 D.setInvalidType();
                 Param->setInvalidDecl();
               }
-            } else {
+            } else if (S.getLangOpts().CUDA) {
               S.Diag(Param->getLocation(),
                 diag::err_parameters_retval_cannot_have_fp16_type) << 0;
               D.setInvalidType();
@@ -3969,14 +3985,14 @@ static void HandleAddressSpaceTypeAttribute(QualType &Type,
   } else {
     // The keyword-based type attributes imply which address space to use.
     switch (Attr.getKind()) {
-    case AttributeList::AT_OpenCLGlobalAddressSpace:
+    case AttributeList::AT_GlobalAddressSpace:
       ASIdx = LangAS::opencl_global; break;
-    case AttributeList::AT_OpenCLLocalAddressSpace:
+    case AttributeList::AT_LocalAddressSpace:
       ASIdx = LangAS::opencl_local; break;
-    case AttributeList::AT_OpenCLConstantAddressSpace:
+    case AttributeList::AT_ConstantAddressSpace:
       ASIdx = LangAS::opencl_constant; break;
     default:
-      assert(Attr.getKind() == AttributeList::AT_OpenCLPrivateAddressSpace);
+      assert(Attr.getKind() == AttributeList::AT_PrivateAddressSpace);
       ASIdx = 0; break;
     }
   }
@@ -4895,10 +4911,10 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
       // it it breaks large amounts of Linux software.
       attr.setUsedAsTypeAttr();
       break;
-    case AttributeList::AT_OpenCLPrivateAddressSpace:
-    case AttributeList::AT_OpenCLGlobalAddressSpace:
-    case AttributeList::AT_OpenCLLocalAddressSpace:
-    case AttributeList::AT_OpenCLConstantAddressSpace:
+    case AttributeList::AT_PrivateAddressSpace:
+    case AttributeList::AT_GlobalAddressSpace:
+    case AttributeList::AT_LocalAddressSpace:
+    case AttributeList::AT_ConstantAddressSpace:
     case AttributeList::AT_AddressSpace:
       HandleAddressSpaceTypeAttribute(type, attr, state.getSema());
       attr.setUsedAsTypeAttr();
@@ -4926,11 +4942,32 @@ static void processTypeAttrs(TypeProcessingState &state, QualType &type,
                                VectorType::NeonPolyVector);
       attr.setUsedAsTypeAttr();
       break;
-    case AttributeList::AT_OpenCLImageAccess:
+    case AttributeList::AT_ImageAccess:
       // FIXME: there should be some type checking happening here, I would
       // imagine, but the original handler's checking was entirely superfluous.
       attr.setUsedAsTypeAttr();
       break;
+    case AttributeList::AT_FloorImageDataType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_VectorCompat:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsFBOColorLocation:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsFBODepthType:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsVertexPosition:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsPointSize:
+      attr.setUsedAsTypeAttr();
+      break;
+    case AttributeList::AT_GraphicsStageInput:
+      attr.setUsedAsTypeAttr();
+      break;
 
     MS_TYPE_ATTRS_CASELIST:
       if (!handleMSPointerTypeQualifierAttr(state, attr, type))
diff --git a/tools/clang/lib/Serialization/ASTCommon.cpp b/tools/clang/lib/Serialization/ASTCommon.cpp
index ad046ff..be31b68 100644
--- a/tools/clang/lib/Serialization/ASTCommon.cpp
+++ b/tools/clang/lib/Serialization/ASTCommon.cpp
@@ -66,6 +66,16 @@ serialization::TypeIdxFromBuiltin(const BuiltinType *BT) {
   case BuiltinType::OCLImage1dBuffer: ID = PREDEF_TYPE_IMAGE1D_BUFF_ID; break;
   case BuiltinType::OCLImage2d:       ID = PREDEF_TYPE_IMAGE2D_ID;      break;
   case BuiltinType::OCLImage2dArray:  ID = PREDEF_TYPE_IMAGE2D_ARR_ID;  break;
+  case BuiltinType::OCLImage2dDepth:  ID = PREDEF_TYPE_IMAGE2D_DEPTH_ID;  break;
+  case BuiltinType::OCLImage2dArrayDepth:  ID = PREDEF_TYPE_IMAGE2D_ARR_DEPTH_ID;  break;
+  case BuiltinType::OCLImage2dMSAA:  ID = PREDEF_TYPE_IMAGE2D_MSAA_ID;  break;
+  case BuiltinType::OCLImage2dArrayMSAA:  ID = PREDEF_TYPE_IMAGE2D_ARR_MSAA_ID;  break;
+  case BuiltinType::OCLImage2dMSAADepth:  ID = PREDEF_TYPE_IMAGE2D_MSAA_DEPTH_ID;  break;
+  case BuiltinType::OCLImage2dArrayMSAADepth:  ID = PREDEF_TYPE_IMAGE2D_ARR_MSAA_DEPTH_ID;  break;
+  case BuiltinType::OCLImageCube: ID = PREDEF_TYPE_IMAGECUBE_ID; break;
+  case BuiltinType::OCLImageCubeArray: ID = PREDEF_TYPE_IMAGECUBE_ARR_ID; break;
+  case BuiltinType::OCLImageCubeDepth: ID = PREDEF_TYPE_IMAGECUBE_DEPTH_ID; break;
+  case BuiltinType::OCLImageCubeArrayDepth: ID = PREDEF_TYPE_IMAGECUBE_ARR_DEPTH_ID; break;
   case BuiltinType::OCLImage3d:       ID = PREDEF_TYPE_IMAGE3D_ID;      break;
   case BuiltinType::OCLSampler:       ID = PREDEF_TYPE_SAMPLER_ID;      break;
   case BuiltinType::OCLEvent:         ID = PREDEF_TYPE_EVENT_ID;        break;
diff --git a/tools/clang/lib/Serialization/ASTReader.cpp b/tools/clang/lib/Serialization/ASTReader.cpp
index ae41654..098f631 100644
--- a/tools/clang/lib/Serialization/ASTReader.cpp
+++ b/tools/clang/lib/Serialization/ASTReader.cpp
@@ -5836,6 +5836,16 @@ QualType ASTReader::GetType(TypeID ID) {
     case PREDEF_TYPE_IMAGE1D_BUFF_ID: T = Context.OCLImage1dBufferTy; break;
     case PREDEF_TYPE_IMAGE2D_ID:    T = Context.OCLImage2dTy;       break;
     case PREDEF_TYPE_IMAGE2D_ARR_ID: T = Context.OCLImage2dArrayTy; break;
+    case PREDEF_TYPE_IMAGE2D_DEPTH_ID:    T = Context.OCLImage2dDepthTy; break;
+    case PREDEF_TYPE_IMAGE2D_ARR_DEPTH_ID: T = Context.OCLImage2dArrayDepthTy; break;
+    case PREDEF_TYPE_IMAGE2D_MSAA_ID:    T = Context.OCLImage2dMSAATy; break;
+    case PREDEF_TYPE_IMAGE2D_ARR_MSAA_ID: T = Context.OCLImage2dArrayMSAATy; break;
+    case PREDEF_TYPE_IMAGE2D_MSAA_DEPTH_ID:    T = Context.OCLImage2dMSAADepthTy; break;
+    case PREDEF_TYPE_IMAGE2D_ARR_MSAA_DEPTH_ID: T = Context.OCLImage2dArrayMSAADepthTy; break;
+    case PREDEF_TYPE_IMAGECUBE_ID:  T = Context.OCLImageCubeTy;      break;
+    case PREDEF_TYPE_IMAGECUBE_ARR_ID:  T = Context.OCLImageCubeArrayTy; break;
+    case PREDEF_TYPE_IMAGECUBE_DEPTH_ID:  T = Context.OCLImageCubeDepthTy; break;
+    case PREDEF_TYPE_IMAGECUBE_ARR_DEPTH_ID:  T = Context.OCLImageCubeArrayDepthTy; break;
     case PREDEF_TYPE_IMAGE3D_ID:    T = Context.OCLImage3dTy;       break;
     case PREDEF_TYPE_SAMPLER_ID:    T = Context.OCLSamplerTy;       break;
     case PREDEF_TYPE_EVENT_ID:      T = Context.OCLEventTy;         break;
diff --git a/tools/clang/tools/libclang/CIndex.cpp b/tools/clang/tools/libclang/CIndex.cpp
index fc8703a..adc680b 100644
--- a/tools/clang/tools/libclang/CIndex.cpp
+++ b/tools/clang/tools/libclang/CIndex.cpp
@@ -1418,6 +1418,16 @@ bool CursorVisitor::VisitBuiltinTypeLoc(BuiltinTypeLoc TL) {
   case BuiltinType::OCLImage1dBuffer:
   case BuiltinType::OCLImage2d:
   case BuiltinType::OCLImage2dArray:
+  case BuiltinType::OCLImage2dDepth:
+  case BuiltinType::OCLImage2dArrayDepth:
+  case BuiltinType::OCLImage2dMSAA:
+  case BuiltinType::OCLImage2dArrayMSAA:
+  case BuiltinType::OCLImage2dMSAADepth:
+  case BuiltinType::OCLImage2dArrayMSAADepth:
+  case BuiltinType::OCLImageCube:
+  case BuiltinType::OCLImageCubeArray:
+  case BuiltinType::OCLImageCubeDepth:
+  case BuiltinType::OCLImageCubeArrayDepth:
   case BuiltinType::OCLImage3d:
   case BuiltinType::OCLSampler:
   case BuiltinType::OCLEvent:
@@ -3990,11 +4000,11 @@ CXString clang_getCursorKindSpelling(enum CXCursorKind Kind) {
   case CXCursor_NoDuplicateAttr:
     return cxstring::createRef("attribute(noduplicate)");
   case CXCursor_CUDAConstantAttr:
-    return cxstring::createRef("attribute(constant)");
+    return cxstring::createRef("attribute(constant_cuda)");
   case CXCursor_CUDADeviceAttr:
     return cxstring::createRef("attribute(device)");
-  case CXCursor_CUDAGlobalAttr:
-    return cxstring::createRef("attribute(global)");
+  case CXCursor_ComputeKernelAttr:
+    return cxstring::createRef("attribute(compute_kernel)");
   case CXCursor_CUDAHostAttr:
     return cxstring::createRef("attribute(host)");
   case CXCursor_PreprocessingDirective:
diff --git a/tools/clang/tools/libclang/CXCursor.cpp b/tools/clang/tools/libclang/CXCursor.cpp
index 4321903..08f0179 100644
--- a/tools/clang/tools/libclang/CXCursor.cpp
+++ b/tools/clang/tools/libclang/CXCursor.cpp
@@ -55,7 +55,7 @@ static CXCursorKind GetCursorKind(const Attr *A) {
     case attr::NoDuplicate: return CXCursor_NoDuplicateAttr;
     case attr::CUDAConstant: return CXCursor_CUDAConstantAttr;
     case attr::CUDADevice: return CXCursor_CUDADeviceAttr;
-    case attr::CUDAGlobal: return CXCursor_CUDAGlobalAttr;
+    case attr::ComputeKernel: return CXCursor_ComputeKernelAttr;
     case attr::CUDAHost: return CXCursor_CUDAHostAttr;
   }
 
diff --git a/tools/clang/tools/libclang/CXType.cpp b/tools/clang/tools/libclang/CXType.cpp
index fe45899..0f97dc0 100644
--- a/tools/clang/tools/libclang/CXType.cpp
+++ b/tools/clang/tools/libclang/CXType.cpp
@@ -526,6 +526,8 @@ CXCallingConv clang_getFunctionTypeCallingConv(CXType X) {
       TCALLINGCONV(AAPCS_VFP);
       TCALLINGCONV(PnaclCall);
       TCALLINGCONV(IntelOclBicc);
+      TCALLINGCONV(SpirFunction);
+      TCALLINGCONV(SpirKernel);
     }
 #undef TCALLINGCONV
   }
